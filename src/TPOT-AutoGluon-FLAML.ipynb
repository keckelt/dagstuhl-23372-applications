{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55541fc6-cd46-46b2-b6a5-f89bdb44899a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install tpot autogluon flaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3789628-8882-402b-8a60-f9271bb6b8de",
   "metadata": {},
   "source": [
    "Random State for reproduceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c395ba-a71a-4bcf-8069-fc305f169202",
   "metadata": {},
   "outputs": [],
   "source": [
    "dagstuhl_seed=23372"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1303b68e-b938-41a9-b5e5-97dc019b210f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb22754-a6e5-46b9-b3fc-739b2af1f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884ebf47-3b49-4ec4-8b4a-23959f8325ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label    0    1    2    3    4    5    6    7    8  ...  1014  1015  \\\n",
       "4306      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4307      0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4308      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4309      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4310      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "      1016  1017  1018  1019  1020  1021  1022  1023  \n",
       "4306   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "4307   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4308   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "4309   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4310   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/preprocessed.csv')\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df = df.replace(['inactive', 'active'], [0,1]) # swap -1 (inactive) and 0 (unknown)\n",
    "\n",
    "df_train = pd.read_csv('../data/preprocessed-train.csv')\n",
    "df_train = df_train.loc[:, ~df_train.columns.str.contains('^Unnamed')]\n",
    "df_train = df_train.replace(['inactive', 'active'], [0,1]) # swap -1 (inactive) and 0 (unknown)\n",
    "\n",
    "df_test = pd.read_csv('../data/preprocessed-test.csv')\n",
    "df_test = df_test.loc[:, ~df_test.columns.str.contains('^Unnamed')]\n",
    "df_test = df_test.replace(['inactive', 'active'], [0,1]) # swap -1 (inactive) and 0 (unknown)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a58bed2-9e3a-4962-8e78-ccc5f81c7d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3592, 1024)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_train['label']\n",
    "X_train = df_train.loc[:, df_train.columns != \"label\"]\n",
    "\n",
    "y_test = df_train['label']\n",
    "X_test = df_train.loc[:, df_train.columns != \"label\"]\n",
    "\n",
    "X_train.to_numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d40d74c-0227-460e-b1cd-24cac3726434",
   "metadata": {},
   "source": [
    "# AutoML Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165047b1-0dfc-4af9-9e03-dfcbaf08760f",
   "metadata": {},
   "source": [
    "### Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b4e45e-fc54-4069-a0b2-a153954f4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60c125-1e0a-45af-8867-bddba8b62fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tpot\n",
    "tpot.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411d5837-f2d4-4996-a5e6-27012a509d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon import tabular\n",
    "tabular.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b5431-4b4d-4dc9-921d-4fc0cb1461fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flaml\n",
    "flaml.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a07c7f-b6a5-452c-9631-0eb1e734d3cf",
   "metadata": {},
   "source": [
    "### Time Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79ae1dff-2785-43a9-a751-8f378fabe79f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_min = 30\n",
    "time_sec = time_min * 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d049b93e-4618-4b57-8592-d7380aaef4cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f313239-e3be-4ad0-a540-65f6b1a9277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5f32e29-d868-405c-81c1-2906c6e95386",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7087872f6cd3415faec75e8221274051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped pipeline #33 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #50 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #58 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #94 due to time out. Continuing to the next pipeline.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "Skipped pipeline #137 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "33.85 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "CPU times: user 2min 46s, sys: 1min 3s, total: 3min 50s\n",
      "Wall time: 35min 2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(max_time_mins=30, n_jobs=-1, verbosity=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TPOTClassifier</label><div class=\"sk-toggleable__content\"><pre>TPOTClassifier(max_time_mins=30, n_jobs=-1, verbosity=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TPOTClassifier(max_time_mins=30, n_jobs=-1, verbosity=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline_optimizer = TPOTClassifier(verbosity=3, max_time_mins=time_min, n_jobs=-1)\n",
    "pipeline_optimizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36478590-b837-41d7-b80b-f7891f38f8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but BernoulliNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but BernoulliNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9387527839643652\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_optimizer.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "865bb1a3-cf12-47d2-b3c8-b5b544a32fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimizer.export('tpot_exported_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546170fd-da52-4552-b1dc-1e3d7c056245",
   "metadata": {},
   "source": [
    "## AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccbff795-2c98-4d67-97c0-b7dc2e32389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7704b97-ef64-4330-a55e-3270f217f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(df_train)\n",
    "test_data = TabularDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eed093c-2780-46f6-b3a5-766f532476d9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230922_090845/\"\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'auto_stack': True, 'verbosity': 4}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': True,\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 4}\n",
      "========================================\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20\n",
      "Saving AutogluonModels/ag-20230922_090845/learner.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/predictor.pkl\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230922_090845/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Jan 27 02:56:13 UTC 2023\n",
      "Disk Space Avail:   925.02 GB / 1081.10 GB (85.6%)\n",
      "Train Data Rows:    3592\n",
      "Train Data Columns: 1024\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13924.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 29.43 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 951 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\t2.0s = Fit runtime\n",
      "\t\t\t951 features in original data used to generate 951 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t951 features in original data used to generate 951 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t951 features in original data used to generate 951 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t951 features in original data used to generate 951 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\t65 duplicate columns removed: ['291', '553', '765', '773', '933', '986', '993', '514', '48', '76', '86', '103', '146', '163', '170', '174', '182', '195', '223', '234', '254', '262', '267', '298', '303', '330', '334', '336', '368', '375', '400', '439', '466', '488', '509', '515', '532', '536', '566', '581', '596', '613', '625', '630', '631', '645', '647', '660', '685', '712', '719', '746', '777', '818', '843', '876', '901', '907', '919', '963', '966', '988', '1006', '1012', '1018']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\t5.3s = Fit runtime\n",
      "\t\t\t886 features in original data used to generate 886 features in processed data.\n",
      "\tUseless Original Features (Count: 73): ['2', '16', '20', '21', '68', '78', '82', '93', '100', '109', '127', '153', '161', '168', '173', '185', '187', '201', '203', '205', '217', '230', '243', '311', '331', '340', '354', '365', '377', '388', '390', '405', '410', '411', '415', '436', '437', '443', '450', '454', '459', '465', '475', '477', '513', '522', '529', '530', '572', '595', '618', '638', '648', '651', '671', '689', '717', '768', '774', '776', '780', '793', '797', '817', '858', '866', '870', '903', '906', '912', '930', '1008', '1023']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 65): ['48', '76', '86', '103', '146', '163', '170', '174', '182', '195', '223', '234', '254', '262', '267', '291', '298', '303', '330', '334', '336', '368', '375', '400', '439', '466', '488', '509', '514', '515', '532', '536', '553', '566', '581', '596', '613', '625', '630', '631', '645', '647', '660', '685', '712', '719', '746', '765', '773', '777', '818', '843', '876', '901', '907', '919', '933', '963', '966', '986', '988', '993', '1006', '1012', '1018']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 65 | ['48', '76', '86', '103', '146', ...]\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('int8', 'int') : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', ['bool']) : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\t8.5s = Fit runtime\n",
      "\t886 features in original data used to generate 886 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.18 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 8.83s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving AutogluonModels/ag-20230922_090845/learner.pkl\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Saving AutogluonModels/ag-20230922_090845/utils/data/X.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/utils/data/y.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1791.17s of the 1791.14s of remaining time.\n",
      "\tDropped 886 of 886 features.\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1791.11s of the 1791.09s of remaining time.\n",
      "\tDropped 886 of 886 features.\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1791.06s of the 1791.04s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9357\t = Validation score   (accuracy)\n",
      "\t5.32s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1777.59s of the 1777.57s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9357\t = Validation score   (accuracy)\n",
      "\t6.03s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1766.52s of the 1766.49s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting RandomForestGini_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230922_090845/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 886 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving AutogluonModels/ag-20230922_090845/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/RandomForestGini_BAG_L1/model.pkl\n",
      "\t0.9329\t = Validation score   (accuracy)\n",
      "\t2.33s\t = Training   runtime\n",
      "\t0.95s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1762.83s of the 1762.81s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting RandomForestEntr_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230922_090845/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 886 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving AutogluonModels/ag-20230922_090845/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "\t0.9335\t = Validation score   (accuracy)\n",
      "\t2.01s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1759.6s of the 1759.57s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9357\t = Validation score   (accuracy)\n",
      "\t16.81s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1738.03s of the 1738.0s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting ExtraTreesGini_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230922_090845/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 886 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving AutogluonModels/ag-20230922_090845/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "\t0.9323\t = Validation score   (accuracy)\n",
      "\t2.31s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1734.33s of the 1734.3s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting ExtraTreesEntr_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230922_090845/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 886 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving AutogluonModels/ag-20230922_090845/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "\t0.9323\t = Validation score   (accuracy)\n",
      "\t1.98s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1731.13s of the 1731.1s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9207\t = Validation score   (accuracy)\n",
      "\t30.5s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1695.85s of the 1695.82s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9354\t = Validation score   (accuracy)\n",
      "\t12.87s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1677.3s of the 1677.26s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t29.14s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1643.28s of the 1643.25s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9368\t = Validation score   (accuracy)\n",
      "\t10.45s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Repeating k-fold bagging: 2/20\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1627.22s of the 1627.18s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9326\t = Validation score   (accuracy)\n",
      "\t10.55s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1617.29s of the 1617.26s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9326\t = Validation score   (accuracy)\n",
      "\t10.86s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1607.25s of the 1607.23s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9332\t = Validation score   (accuracy)\n",
      "\t34.02s\t = Training   runtime\n",
      "\t1.82s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1584.99s of the 1584.96s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9207\t = Validation score   (accuracy)\n",
      "\t59.9s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1550.9s of the 1550.86s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9323\t = Validation score   (accuracy)\n",
      "\t28.72s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1529.56s of the 1529.53s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9329\t = Validation score   (accuracy)\n",
      "\t63.34s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1489.28s of the 1489.25s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9343\t = Validation score   (accuracy)\n",
      "\t23.16s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Repeating k-fold bagging: 3/20\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1471.32s of the 1471.29s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9332\t = Validation score   (accuracy)\n",
      "\t15.6s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1461.55s of the 1461.53s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9332\t = Validation score   (accuracy)\n",
      "\t16.61s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1450.67s of the 1450.63s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t49.09s\t = Training   runtime\n",
      "\t2.82s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1430.51s of the 1430.48s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9273\t = Validation score   (accuracy)\n",
      "\t91.24s\t = Training   runtime\n",
      "\t1.35s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1393.9s of the 1393.87s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9318\t = Validation score   (accuracy)\n",
      "\t47.06s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1369.17s of the 1369.14s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9354\t = Validation score   (accuracy)\n",
      "\t96.59s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1330.82s of the 1330.8s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9346\t = Validation score   (accuracy)\n",
      "\t34.26s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Repeating k-fold bagging: 4/20\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1314.17s of the 1314.13s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9337\t = Validation score   (accuracy)\n",
      "\t22.6s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1302.37s of the 1302.34s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9337\t = Validation score   (accuracy)\n",
      "\t22.08s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1289.91s of the 1289.88s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t73.19s\t = Training   runtime\n",
      "\t4.84s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1259.59s of the 1259.54s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9304\t = Validation score   (accuracy)\n",
      "\t123.41s\t = Training   runtime\n",
      "\t1.83s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1220.59s of the 1220.55s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9329\t = Validation score   (accuracy)\n",
      "\t61.79s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1200.24s of the 1200.21s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9329\t = Validation score   (accuracy)\n",
      "\t131.69s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1159.68s of the 1159.65s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t45.54s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Repeating k-fold bagging: 5/20\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1143.17s of the 1143.14s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9337\t = Validation score   (accuracy)\n",
      "\t29.52s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1129.64s of the 1129.61s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9337\t = Validation score   (accuracy)\n",
      "\t28.56s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1117.75s of the 1117.72s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9335\t = Validation score   (accuracy)\n",
      "\t90.19s\t = Training   runtime\n",
      "\t5.72s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1095.55s of the 1095.51s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9273\t = Validation score   (accuracy)\n",
      "\t150.41s\t = Training   runtime\n",
      "\t2.3s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1063.14s of the 1063.11s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9343\t = Validation score   (accuracy)\n",
      "\t83.44s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1034.64s of the 1034.61s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9346\t = Validation score   (accuracy)\n",
      "\t160.79s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1000.54s of the 1000.51s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9349\t = Validation score   (accuracy)\n",
      "\t59.14s\t = Training   runtime\n",
      "\t1.11s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Repeating k-fold bagging: 6/20\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 981.11s of the 981.07s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9351\t = Validation score   (accuracy)\n",
      "\t34.71s\t = Training   runtime\n",
      "\t1.3s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 970.39s of the 970.35s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9351\t = Validation score   (accuracy)\n",
      "\t33.95s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 959.48s of the 959.44s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9332\t = Validation score   (accuracy)\n",
      "\t109.96s\t = Training   runtime\n",
      "\t6.6s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 934.34s of the 934.31s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.929\t = Validation score   (accuracy)\n",
      "\t177.1s\t = Training   runtime\n",
      "\t2.71s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 902.7s of the 902.66s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t98.26s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 881.77s of the 881.74s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9335\t = Validation score   (accuracy)\n",
      "\t189.44s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 847.88s of the 847.86s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9346\t = Validation score   (accuracy)\n",
      "\t70.54s\t = Training   runtime\n",
      "\t1.3s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Repeating k-fold bagging: 7/20\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 831.5s of the 831.47s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9354\t = Validation score   (accuracy)\n",
      "\t42.14s\t = Training   runtime\n",
      "\t1.74s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 818.25s of the 818.17s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9354\t = Validation score   (accuracy)\n",
      "\t41.4s\t = Training   runtime\n",
      "\t1.67s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 804.08s of the 804.04s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9326\t = Validation score   (accuracy)\n",
      "\t130.62s\t = Training   runtime\n",
      "\t7.6s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 777.65s of the 777.62s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9301\t = Validation score   (accuracy)\n",
      "\t203.93s\t = Training   runtime\n",
      "\t3.12s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 745.99s of the 745.96s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9332\t = Validation score   (accuracy)\n",
      "\t112.89s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 724.82s of the 724.79s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9346\t = Validation score   (accuracy)\n",
      "\t225.44s\t = Training   runtime\n",
      "\t1.35s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 683.62s of the 683.59s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9343\t = Validation score   (accuracy)\n",
      "\t84.67s\t = Training   runtime\n",
      "\t1.6s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Repeating k-fold bagging: 8/20\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 663.23s of the 663.2s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.936\t = Validation score   (accuracy)\n",
      "\t50.26s\t = Training   runtime\n",
      "\t2.13s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 648.47s of the 648.42s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.936\t = Validation score   (accuracy)\n",
      "\t50.51s\t = Training   runtime\n",
      "\t1.9s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 631.13s of the 631.1s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9329\t = Validation score   (accuracy)\n",
      "\t154.19s\t = Training   runtime\n",
      "\t9.09s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 600.63s of the 600.6s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9296\t = Validation score   (accuracy)\n",
      "\t245.56s\t = Training   runtime\n",
      "\t3.86s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 552.33s of the 552.29s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9346\t = Validation score   (accuracy)\n",
      "\t137.87s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 519.17s of the 519.14s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9337\t = Validation score   (accuracy)\n",
      "\t273.69s\t = Training   runtime\n",
      "\t1.58s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 462.31s of the 462.27s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9351\t = Validation score   (accuracy)\n",
      "\t107.08s\t = Training   runtime\n",
      "\t2.04s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Repeating k-fold bagging: 9/20\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 431.14s of the 431.11s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9357\t = Validation score   (accuracy)\n",
      "\t58.16s\t = Training   runtime\n",
      "\t2.38s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 415.2s of the 415.16s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9357\t = Validation score   (accuracy)\n",
      "\t58.39s\t = Training   runtime\n",
      "\t2.23s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 399.25s of the 399.2s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9329\t = Validation score   (accuracy)\n",
      "\t180.22s\t = Training   runtime\n",
      "\t10.74s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 365.5s of the 365.47s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9312\t = Validation score   (accuracy)\n",
      "\t299.93s\t = Training   runtime\n",
      "\t4.7s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 301.13s of the 301.1s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t155.79s\t = Training   runtime\n",
      "\t1.33s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 274.0s of the 273.97s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9337\t = Validation score   (accuracy)\n",
      "\t305.57s\t = Training   runtime\n",
      "\t1.72s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 236.44s of the 236.41s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 761371cddc5fb5575f6db659b352cfb026bdc29c6926ad52cebfa059\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9349\t = Validation score   (accuracy)\n",
      "\t117.43s\t = Training   runtime\n",
      "\t2.2s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Not enough time left to finish repeated k-fold bagging, stopping early ...\n",
      "Completed 9/20 k-fold bagging repeats ...\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 221.08s of remaining time.\n",
      "\tDropped 0 of 11 features.\n",
      "\tDropped 0 of 11 features.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230922_090845/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 11 features.\n",
      "Ensemble size: 1\n",
      "Ensemble indices: [0]\n",
      "Ensemble weights: \n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Saving AutogluonModels/ag-20230922_090845/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/WeightedEnsemble_L2/model.pkl\n",
      "\t0.9357\t = Validation score   (accuracy)\n",
      "\t1.86s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 1580.85s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/learner.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/predictor.pkl\n",
      "Saving AutogluonModels/ag-20230922_090845/__version__ with contents \"0.8.2\"\n",
      "Saving AutogluonModels/ag-20230922_090845/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230922_090845/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 11s, sys: 1min 39s, total: 4min 51s\n",
      "Wall time: 26min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = TabularPredictor(label='label').fit(train_data=train_data, verbosity=4, time_limit=time_sec, presets='best_quality')\n",
    "# model will decide how many cores to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea649d73-ee6c-4c7c-863f-83d85810f865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/WeightedEnsemble_L2/model.pkl\n",
      "Evaluation: accuracy on test data: 0.9401947148817803\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.9401947148817803,\n",
      "    \"balanced_accuracy\": 0.5731151883196589,\n",
      "    \"mcc\": 0.29154867707650123,\n",
      "    \"roc_auc\": 0.8268622004005427,\n",
      "    \"f1\": 0.2456140350877193,\n",
      "    \"precision\": 0.6363636363636364,\n",
      "    \"recall\": 0.15217391304347827\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9401947148817803,\n",
       " 'balanced_accuracy': 0.5731151883196589,\n",
       " 'mcc': 0.29154867707650123,\n",
       " 'roc_auc': 0.8268622004005427,\n",
       " 'f1': 0.2456140350877193,\n",
       " 'precision': 0.6363636363636364,\n",
       " 'recall': 0.15217391304347827}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6df09c9-9e76-48bc-afd4-f98fef699669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230922_090845/models/WeightedEnsemble_L2/model.pkl\n",
      "Model scores:\n",
      "{'LightGBMXT_BAG_L1': 0.9401947148817803, 'LightGBM_BAG_L1': 0.9401947148817803, 'RandomForestGini_BAG_L1': 0.9415855354659249, 'RandomForestEntr_BAG_L1': 0.9415855354659249, 'CatBoost_BAG_L1': 0.9415855354659249, 'ExtraTreesGini_BAG_L1': 0.9429763560500696, 'ExtraTreesEntr_BAG_L1': 0.9429763560500696, 'NeuralNetFastAI_BAG_L1': 0.9374130737134909, 'XGBoost_BAG_L1': 0.9443671766342142, 'NeuralNetTorch_BAG_L1': 0.933240611961057, 'LightGBMLarge_BAG_L1': 0.9388038942976356, 'WeightedEnsemble_L2': 0.9401947148817803}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.944367</td>\n",
       "      <td>0.934020</td>\n",
       "      <td>1.554220</td>\n",
       "      <td>1.328699</td>\n",
       "      <td>155.791217</td>\n",
       "      <td>1.554220</td>\n",
       "      <td>1.328699</td>\n",
       "      <td>155.791217</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.942976</td>\n",
       "      <td>0.932350</td>\n",
       "      <td>0.336041</td>\n",
       "      <td>1.054570</td>\n",
       "      <td>2.312812</td>\n",
       "      <td>0.336041</td>\n",
       "      <td>1.054570</td>\n",
       "      <td>2.312812</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.942976</td>\n",
       "      <td>0.932350</td>\n",
       "      <td>0.360988</td>\n",
       "      <td>0.942730</td>\n",
       "      <td>1.975779</td>\n",
       "      <td>0.360988</td>\n",
       "      <td>0.942730</td>\n",
       "      <td>1.975779</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.941586</td>\n",
       "      <td>0.933463</td>\n",
       "      <td>0.307003</td>\n",
       "      <td>0.980565</td>\n",
       "      <td>2.007208</td>\n",
       "      <td>0.307003</td>\n",
       "      <td>0.980565</td>\n",
       "      <td>2.007208</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.941586</td>\n",
       "      <td>0.932906</td>\n",
       "      <td>0.309322</td>\n",
       "      <td>0.952581</td>\n",
       "      <td>2.328351</td>\n",
       "      <td>0.309322</td>\n",
       "      <td>0.952581</td>\n",
       "      <td>2.328351</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.941586</td>\n",
       "      <td>0.932906</td>\n",
       "      <td>4.400525</td>\n",
       "      <td>10.742911</td>\n",
       "      <td>180.217100</td>\n",
       "      <td>4.400525</td>\n",
       "      <td>10.742911</td>\n",
       "      <td>180.217100</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.940195</td>\n",
       "      <td>0.935690</td>\n",
       "      <td>1.017484</td>\n",
       "      <td>2.226668</td>\n",
       "      <td>58.388364</td>\n",
       "      <td>1.017484</td>\n",
       "      <td>2.226668</td>\n",
       "      <td>58.388364</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.940195</td>\n",
       "      <td>0.935690</td>\n",
       "      <td>1.075064</td>\n",
       "      <td>2.383983</td>\n",
       "      <td>58.157029</td>\n",
       "      <td>1.075064</td>\n",
       "      <td>2.383983</td>\n",
       "      <td>58.157029</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.940195</td>\n",
       "      <td>0.935690</td>\n",
       "      <td>1.080796</td>\n",
       "      <td>2.392670</td>\n",
       "      <td>60.012530</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>1.855501</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.938804</td>\n",
       "      <td>0.934855</td>\n",
       "      <td>1.433577</td>\n",
       "      <td>2.203835</td>\n",
       "      <td>117.427994</td>\n",
       "      <td>1.433577</td>\n",
       "      <td>2.203835</td>\n",
       "      <td>117.427994</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.937413</td>\n",
       "      <td>0.931236</td>\n",
       "      <td>3.986149</td>\n",
       "      <td>4.695556</td>\n",
       "      <td>299.926735</td>\n",
       "      <td>3.986149</td>\n",
       "      <td>4.695556</td>\n",
       "      <td>299.926735</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.933241</td>\n",
       "      <td>0.933742</td>\n",
       "      <td>1.225143</td>\n",
       "      <td>1.723919</td>\n",
       "      <td>305.568346</td>\n",
       "      <td>1.225143</td>\n",
       "      <td>1.723919</td>\n",
       "      <td>305.568346</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_test  score_val  pred_time_test  \\\n",
       "0            XGBoost_BAG_L1    0.944367   0.934020        1.554220   \n",
       "1     ExtraTreesGini_BAG_L1    0.942976   0.932350        0.336041   \n",
       "2     ExtraTreesEntr_BAG_L1    0.942976   0.932350        0.360988   \n",
       "3   RandomForestEntr_BAG_L1    0.941586   0.933463        0.307003   \n",
       "4   RandomForestGini_BAG_L1    0.941586   0.932906        0.309322   \n",
       "5           CatBoost_BAG_L1    0.941586   0.932906        4.400525   \n",
       "6           LightGBM_BAG_L1    0.940195   0.935690        1.017484   \n",
       "7         LightGBMXT_BAG_L1    0.940195   0.935690        1.075064   \n",
       "8       WeightedEnsemble_L2    0.940195   0.935690        1.080796   \n",
       "9      LightGBMLarge_BAG_L1    0.938804   0.934855        1.433577   \n",
       "10   NeuralNetFastAI_BAG_L1    0.937413   0.931236        3.986149   \n",
       "11    NeuralNetTorch_BAG_L1    0.933241   0.933742        1.225143   \n",
       "\n",
       "    pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0        1.328699  155.791217                 1.554220   \n",
       "1        1.054570    2.312812                 0.336041   \n",
       "2        0.942730    1.975779                 0.360988   \n",
       "3        0.980565    2.007208                 0.307003   \n",
       "4        0.952581    2.328351                 0.309322   \n",
       "5       10.742911  180.217100                 4.400525   \n",
       "6        2.226668   58.388364                 1.017484   \n",
       "7        2.383983   58.157029                 1.075064   \n",
       "8        2.392670   60.012530                 0.005731   \n",
       "9        2.203835  117.427994                 1.433577   \n",
       "10       4.695556  299.926735                 3.986149   \n",
       "11       1.723919  305.568346                 1.225143   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 1.328699         155.791217            1       True   \n",
       "1                 1.054570           2.312812            1       True   \n",
       "2                 0.942730           1.975779            1       True   \n",
       "3                 0.980565           2.007208            1       True   \n",
       "4                 0.952581           2.328351            1       True   \n",
       "5                10.742911         180.217100            1       True   \n",
       "6                 2.226668          58.388364            1       True   \n",
       "7                 2.383983          58.157029            1       True   \n",
       "8                 0.008687           1.855501            2       True   \n",
       "9                 2.203835         117.427994            1       True   \n",
       "10                4.695556         299.926735            1       True   \n",
       "11                1.723919         305.568346            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           9  \n",
       "1           6  \n",
       "2           7  \n",
       "3           4  \n",
       "4           3  \n",
       "5           5  \n",
       "6           2  \n",
       "7           1  \n",
       "8          12  \n",
       "9          11  \n",
       "10          8  \n",
       "11         10  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d889a-2da6-459e-b7f5-3d95cf2e4e16",
   "metadata": {},
   "source": [
    "# FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d18a7cb6-e526-4afb-8fec-0b35dc45fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b1cf3-1d3f-4995-9671-075b4c59bc79",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 09-22 09:35:31] {1679} INFO - task = classification\n",
      "[flaml.automl.logger: 09-22 09:35:31] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 09-22 09:35:31] {1788} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl.logger: 09-22 09:35:31] {1900} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl.logger: 09-22 09:35:31] {2218} INFO - iteration 0, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:31] {805} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}\n",
      "[flaml.tune.tune: 09-22 09:35:32] {197} INFO - result: {'pred_time': 1.3683875203841545e-05, 'wall_clock_time': 5.874639987945557, 'metric_for_logging': {'pred_time': 1.3683875203841545e-05}, 'val_loss': 0.3371834396384621, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613474dc0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 20, 'config/learning_rate': 0.09999999999999995, 'config/log_max_bin': 8, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.0, 'experiment_tag': 'exp', 'time_total_s': 0.4802892208099365}\n",
      "[flaml.tune.tune: 09-22 09:35:32] {197} INFO - result: {'pred_time': 1.3683875203841545e-05, 'wall_clock_time': 5.874639987945557, 'metric_for_logging': {'pred_time': 1.3683875203841545e-05}, 'val_loss': 0.3371834396384621, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613474dc0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 20, 'config/learning_rate': 0.09999999999999995, 'config/log_max_bin': 8, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.0, 'experiment_tag': 'exp', 'time_total_s': 0.4818413257598877}\n",
      "[flaml.automl.logger: 09-22 09:35:32] {2344} INFO - Estimated sufficient time budget=4948s. Estimated necessary time budget=121s.\n",
      "[flaml.automl.logger: 09-22 09:35:32] {2391} INFO -  at 5.9s,\testimator lgbm's best error=0.3372,\tbest estimator lgbm's best error=0.3372\n",
      "[flaml.automl.logger: 09-22 09:35:32] {2218} INFO - iteration 1, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:32] {805} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 33, 'learning_rate': 0.03735454900037746, 'log_max_bin': 9, 'colsample_bytree': 0.8085131463835397, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.692397057684401}\n",
      "[flaml.tune.tune: 09-22 09:35:32] {197} INFO - result: {'pred_time': 1.1358498454596871e-05, 'wall_clock_time': 6.410869121551514, 'metric_for_logging': {'pred_time': 1.1358498454596871e-05}, 'val_loss': 0.36526976030349345, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613483b50>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 33, 'learning_rate': 0.03735454900037746, 'log_max_bin': 9, 'colsample_bytree': 0.8085131463835397, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.692397057684401}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 33, 'config/learning_rate': 0.03735454900037746, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8085131463835397, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.692397057684401, 'experiment_tag': 'exp', 'time_total_s': 0.5253286361694336}\n",
      "[flaml.tune.tune: 09-22 09:35:32] {197} INFO - result: {'pred_time': 1.1358498454596871e-05, 'wall_clock_time': 6.410869121551514, 'metric_for_logging': {'pred_time': 1.1358498454596871e-05}, 'val_loss': 0.36526976030349345, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613483b50>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 33, 'learning_rate': 0.03735454900037746, 'log_max_bin': 9, 'colsample_bytree': 0.8085131463835397, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.692397057684401}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 33, 'config/learning_rate': 0.03735454900037746, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8085131463835397, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.692397057684401, 'experiment_tag': 'exp', 'time_total_s': 0.526667594909668}\n",
      "[flaml.automl.logger: 09-22 09:35:32] {2391} INFO -  at 6.4s,\testimator lgbm's best error=0.3372,\tbest estimator lgbm's best error=0.3372\n",
      "[flaml.automl.logger: 09-22 09:35:32] {2218} INFO - iteration 2, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:32] {805} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.26770501231052046, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.4442580148221913}\n",
      "[flaml.tune.tune: 09-22 09:35:33] {197} INFO - result: {'pred_time': 1.2008951641365053e-05, 'wall_clock_time': 6.867974519729614, 'metric_for_logging': {'pred_time': 1.2008951641365053e-05}, 'val_loss': 0.32027092396282797, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613387b20>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.26770501231052046, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.4442580148221913}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 12, 'config/learning_rate': 0.26770501231052046, 'config/log_max_bin': 7, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.001348364934537134, 'config/reg_lambda': 1.4442580148221913, 'experiment_tag': 'exp', 'time_total_s': 0.45081233978271484}\n",
      "[flaml.tune.tune: 09-22 09:35:33] {197} INFO - result: {'pred_time': 1.2008951641365053e-05, 'wall_clock_time': 6.867974519729614, 'metric_for_logging': {'pred_time': 1.2008951641365053e-05}, 'val_loss': 0.32027092396282797, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613387b20>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.26770501231052046, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.4442580148221913}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 12, 'config/learning_rate': 0.26770501231052046, 'config/log_max_bin': 7, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.001348364934537134, 'config/reg_lambda': 1.4442580148221913, 'experiment_tag': 'exp', 'time_total_s': 0.45300865173339844}\n",
      "[flaml.automl.logger: 09-22 09:35:33] {2391} INFO -  at 6.9s,\testimator lgbm's best error=0.3203,\tbest estimator lgbm's best error=0.3203\n",
      "[flaml.automl.logger: 09-22 09:35:33] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:35:33] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:35:34] {197} INFO - result: {'pred_time': 4.591096324610966e-05, 'wall_clock_time': 8.379932880401611, 'metric_for_logging': {'pred_time': 4.591096324610966e-05}, 'val_loss': 0.41041591556958873, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613387640>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 0.9999999999999993, 'config/learning_rate': 0.09999999999999995, 'config/subsample': 1.0, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.0, 'experiment_tag': 'exp', 'time_total_s': 1.501417636871338}\n",
      "[flaml.tune.tune: 09-22 09:35:34] {197} INFO - result: {'pred_time': 4.591096324610966e-05, 'wall_clock_time': 8.379932880401611, 'metric_for_logging': {'pred_time': 4.591096324610966e-05}, 'val_loss': 0.41041591556958873, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613387640>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 0.9999999999999993, 'config/learning_rate': 0.09999999999999995, 'config/subsample': 1.0, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.0, 'experiment_tag': 'exp', 'time_total_s': 1.5027422904968262}\n",
      "[flaml.automl.logger: 09-22 09:35:34] {2391} INFO -  at 8.4s,\testimator xgboost's best error=0.4104,\tbest estimator lgbm's best error=0.3203\n",
      "[flaml.automl.logger: 09-22 09:35:34] {2218} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:35:34] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 4, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:35:35] {197} INFO - result: {'pred_time': 3.140129387353523e-05, 'wall_clock_time': 8.828848123550415, 'metric_for_logging': {'pred_time': 3.140129387353523e-05}, 'val_loss': 0.3686062460800092, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387fd0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.42823147773742676}\n",
      "[flaml.tune.tune: 09-22 09:35:35] {197} INFO - result: {'pred_time': 3.140129387353523e-05, 'wall_clock_time': 8.828848123550415, 'metric_for_logging': {'pred_time': 3.140129387353523e-05}, 'val_loss': 0.3686062460800092, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387fd0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.42951083183288574}\n",
      "[flaml.automl.logger: 09-22 09:35:35] {2391} INFO -  at 8.8s,\testimator extra_tree's best error=0.3686,\tbest estimator lgbm's best error=0.3203\n",
      "[flaml.automl.logger: 09-22 09:35:35] {2218} INFO - iteration 5, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:35] {805} INFO - trial 1 config: {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 9, 'learning_rate': 0.7260594590615893, 'log_max_bin': 9, 'colsample_bytree': 0.9285002286474459, 'reg_alpha': 0.0036840681931986645, 'reg_lambda': 0.7532480505730402}\n",
      "[flaml.tune.tune: 09-22 09:35:35] {197} INFO - result: {'pred_time': 1.1678610734339079e-05, 'wall_clock_time': 9.328991889953613, 'metric_for_logging': {'pred_time': 1.1678610734339079e-05}, 'val_loss': 0.29574750912831876, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613387190>, 'training_iteration': 0, 'config': {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 9, 'learning_rate': 0.7260594590615893, 'log_max_bin': 9, 'colsample_bytree': 0.9285002286474459, 'reg_alpha': 0.0036840681931986645, 'reg_lambda': 0.7532480505730402}, 'config/n_estimators': 9, 'config/num_leaves': 4, 'config/min_child_samples': 9, 'config/learning_rate': 0.7260594590615893, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.9285002286474459, 'config/reg_alpha': 0.0036840681931986645, 'config/reg_lambda': 0.7532480505730402, 'experiment_tag': 'exp', 'time_total_s': 0.49027323722839355}\n",
      "[flaml.tune.tune: 09-22 09:35:35] {197} INFO - result: {'pred_time': 1.1678610734339079e-05, 'wall_clock_time': 9.328991889953613, 'metric_for_logging': {'pred_time': 1.1678610734339079e-05}, 'val_loss': 0.29574750912831876, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613387190>, 'training_iteration': 1, 'config': {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 9, 'learning_rate': 0.7260594590615893, 'log_max_bin': 9, 'colsample_bytree': 0.9285002286474459, 'reg_alpha': 0.0036840681931986645, 'reg_lambda': 0.7532480505730402}, 'config/n_estimators': 9, 'config/num_leaves': 4, 'config/min_child_samples': 9, 'config/learning_rate': 0.7260594590615893, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.9285002286474459, 'config/reg_alpha': 0.0036840681931986645, 'config/reg_lambda': 0.7532480505730402, 'experiment_tag': 'exp', 'time_total_s': 0.49167370796203613}\n",
      "[flaml.automl.logger: 09-22 09:35:35] {2391} INFO -  at 9.3s,\testimator lgbm's best error=0.2957,\tbest estimator lgbm's best error=0.2957\n",
      "[flaml.automl.logger: 09-22 09:35:35] {2218} INFO - iteration 6, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:35] {805} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.2677050123105203, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.444258014822189}\n",
      "[flaml.tune.tune: 09-22 09:35:36] {197} INFO - result: {'pred_time': 1.173734597489095e-05, 'wall_clock_time': 9.809715747833252, 'metric_for_logging': {'pred_time': 1.173734597489095e-05}, 'val_loss': 0.32027092396282797, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613387940>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.2677050123105203, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.444258014822189}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 12, 'config/learning_rate': 0.2677050123105203, 'config/log_max_bin': 7, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.001348364934537134, 'config/reg_lambda': 1.444258014822189, 'experiment_tag': 'exp', 'time_total_s': 0.47278928756713867}\n",
      "[flaml.tune.tune: 09-22 09:35:36] {197} INFO - result: {'pred_time': 1.173734597489095e-05, 'wall_clock_time': 9.809715747833252, 'metric_for_logging': {'pred_time': 1.173734597489095e-05}, 'val_loss': 0.32027092396282797, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613387940>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.2677050123105203, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.444258014822189}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 12, 'config/learning_rate': 0.2677050123105203, 'config/log_max_bin': 7, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.001348364934537134, 'config/reg_lambda': 1.444258014822189, 'experiment_tag': 'exp', 'time_total_s': 0.47477245330810547}\n",
      "[flaml.automl.logger: 09-22 09:35:36] {2391} INFO -  at 9.8s,\testimator lgbm's best error=0.2957,\tbest estimator lgbm's best error=0.2957\n",
      "[flaml.automl.logger: 09-22 09:35:36] {2218} INFO - iteration 7, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:36] {805} INFO - trial 1 config: {'n_estimators': 10, 'num_leaves': 5, 'min_child_samples': 5, 'learning_rate': 0.7590459488450945, 'log_max_bin': 8, 'colsample_bytree': 0.8304072431299575, 'reg_alpha': 0.001951378031519758, 'reg_lambda': 0.04792552866398477}\n",
      "[flaml.tune.tune: 09-22 09:35:36] {197} INFO - result: {'pred_time': 1.2809055504132424e-05, 'wall_clock_time': 10.3977792263031, 'metric_for_logging': {'pred_time': 1.2809055504132424e-05}, 'val_loss': 0.3122745799657344, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613387d60>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'num_leaves': 5, 'min_child_samples': 5, 'learning_rate': 0.7590459488450945, 'log_max_bin': 8, 'colsample_bytree': 0.8304072431299575, 'reg_alpha': 0.001951378031519758, 'reg_lambda': 0.04792552866398477}, 'config/n_estimators': 10, 'config/num_leaves': 5, 'config/min_child_samples': 5, 'config/learning_rate': 0.7590459488450945, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8304072431299575, 'config/reg_alpha': 0.001951378031519758, 'config/reg_lambda': 0.04792552866398477, 'experiment_tag': 'exp', 'time_total_s': 0.5780730247497559}\n",
      "[flaml.tune.tune: 09-22 09:35:36] {197} INFO - result: {'pred_time': 1.2809055504132424e-05, 'wall_clock_time': 10.3977792263031, 'metric_for_logging': {'pred_time': 1.2809055504132424e-05}, 'val_loss': 0.3122745799657344, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613387d60>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'num_leaves': 5, 'min_child_samples': 5, 'learning_rate': 0.7590459488450945, 'log_max_bin': 8, 'colsample_bytree': 0.8304072431299575, 'reg_alpha': 0.001951378031519758, 'reg_lambda': 0.04792552866398477}, 'config/n_estimators': 10, 'config/num_leaves': 5, 'config/min_child_samples': 5, 'config/learning_rate': 0.7590459488450945, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8304072431299575, 'config/reg_alpha': 0.001951378031519758, 'config/reg_lambda': 0.04792552866398477, 'experiment_tag': 'exp', 'time_total_s': 0.5799963474273682}\n",
      "[flaml.automl.logger: 09-22 09:35:36] {2391} INFO -  at 10.4s,\testimator lgbm's best error=0.2957,\tbest estimator lgbm's best error=0.2957\n",
      "[flaml.automl.logger: 09-22 09:35:36] {2218} INFO - iteration 8, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:36] {805} INFO - trial 1 config: {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 15, 'learning_rate': 0.6945064905423671, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.006955268652669901, 'reg_lambda': 11.838839163780849}\n",
      "[flaml.tune.tune: 09-22 09:35:37] {197} INFO - result: {'pred_time': 1.1918274605099764e-05, 'wall_clock_time': 10.888847827911377, 'metric_for_logging': {'pred_time': 1.1918274605099764e-05}, 'val_loss': 0.2807560703362802, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613387100>, 'training_iteration': 0, 'config': {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 15, 'learning_rate': 0.6945064905423671, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.006955268652669901, 'reg_lambda': 11.838839163780849}, 'config/n_estimators': 8, 'config/num_leaves': 4, 'config/min_child_samples': 15, 'config/learning_rate': 0.6945064905423671, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.006955268652669901, 'config/reg_lambda': 11.838839163780849, 'experiment_tag': 'exp', 'time_total_s': 0.48218727111816406}\n",
      "[flaml.tune.tune: 09-22 09:35:37] {197} INFO - result: {'pred_time': 1.1918274605099764e-05, 'wall_clock_time': 10.888847827911377, 'metric_for_logging': {'pred_time': 1.1918274605099764e-05}, 'val_loss': 0.2807560703362802, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613387100>, 'training_iteration': 1, 'config': {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 15, 'learning_rate': 0.6945064905423671, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.006955268652669901, 'reg_lambda': 11.838839163780849}, 'config/n_estimators': 8, 'config/num_leaves': 4, 'config/min_child_samples': 15, 'config/learning_rate': 0.6945064905423671, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.006955268652669901, 'config/reg_lambda': 11.838839163780849, 'experiment_tag': 'exp', 'time_total_s': 0.48421406745910645}\n",
      "[flaml.automl.logger: 09-22 09:35:37] {2391} INFO -  at 10.9s,\testimator lgbm's best error=0.2808,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-22 09:35:37] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:35:37] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:35:38] {197} INFO - result: {'pred_time': 4.6257594086550165e-05, 'wall_clock_time': 12.554547548294067, 'metric_for_logging': {'pred_time': 4.6257594086550165e-05}, 'val_loss': 0.4495247741687022, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613387dc0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 3.815612027960909, 'config/learning_rate': 0.03859136192132085, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8148474110627004, 'config/colsample_bytree': 0.9777234800442423, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.525802807180917, 'experiment_tag': 'exp', 'time_total_s': 1.6571133136749268}\n",
      "[flaml.tune.tune: 09-22 09:35:38] {197} INFO - result: {'pred_time': 4.6257594086550165e-05, 'wall_clock_time': 12.554547548294067, 'metric_for_logging': {'pred_time': 4.6257594086550165e-05}, 'val_loss': 0.4495247741687022, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613387dc0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 3.815612027960909, 'config/learning_rate': 0.03859136192132085, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8148474110627004, 'config/colsample_bytree': 0.9777234800442423, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.525802807180917, 'experiment_tag': 'exp', 'time_total_s': 1.6584899425506592}\n",
      "[flaml.automl.logger: 09-22 09:35:38] {2391} INFO -  at 12.6s,\testimator xgboost's best error=0.4104,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-22 09:35:38] {2218} INFO - iteration 10, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:35:38] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:35:40] {197} INFO - result: {'pred_time': 4.52448682650437e-05, 'wall_clock_time': 14.102272033691406, 'metric_for_logging': {'pred_time': 4.52448682650437e-05}, 'val_loss': 0.3691610146070416, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613403c40>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25912534572860507, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292954, 'experiment_tag': 'exp', 'time_total_s': 1.539215326309204}\n",
      "[flaml.tune.tune: 09-22 09:35:40] {197} INFO - result: {'pred_time': 4.52448682650437e-05, 'wall_clock_time': 14.102272033691406, 'metric_for_logging': {'pred_time': 4.52448682650437e-05}, 'val_loss': 0.3691610146070416, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613403c40>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25912534572860507, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292954, 'experiment_tag': 'exp', 'time_total_s': 1.5406804084777832}\n",
      "[flaml.automl.logger: 09-22 09:35:40] {2391} INFO -  at 14.1s,\testimator xgboost's best error=0.3692,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-22 09:35:40] {2218} INFO - iteration 11, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:35:40] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 9, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:35:40] {197} INFO - result: {'pred_time': 2.6565163350956077e-05, 'wall_clock_time': 14.499845027923584, 'metric_for_logging': {'pred_time': 2.6565163350956077e-05}, 'val_loss': 0.33992101315939405, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387af0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3896145820617676}\n",
      "[flaml.tune.tune: 09-22 09:35:40] {197} INFO - result: {'pred_time': 2.6565163350956077e-05, 'wall_clock_time': 14.499845027923584, 'metric_for_logging': {'pred_time': 2.6565163350956077e-05}, 'val_loss': 0.33992101315939405, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387af0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.39127564430236816}\n",
      "[flaml.automl.logger: 09-22 09:35:40] {2391} INFO -  at 14.5s,\testimator extra_tree's best error=0.3399,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-22 09:35:40] {2218} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:35:40] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.03397343291117424, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:35:41] {197} INFO - result: {'pred_time': 2.7253746551802506e-05, 'wall_clock_time': 14.877893924713135, 'metric_for_logging': {'pred_time': 2.7253746551802506e-05}, 'val_loss': 0.39872796190262455, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133874f0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.03397343291117424, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.03397343291117424, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3678882122039795}\n",
      "[flaml.tune.tune: 09-22 09:35:41] {197} INFO - result: {'pred_time': 2.7253746551802506e-05, 'wall_clock_time': 14.877893924713135, 'metric_for_logging': {'pred_time': 2.7253746551802506e-05}, 'val_loss': 0.39872796190262455, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133874f0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.03397343291117424, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.03397343291117424, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.36890149116516113}\n",
      "[flaml.automl.logger: 09-22 09:35:41] {2391} INFO -  at 14.9s,\testimator extra_tree's best error=0.3399,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-22 09:35:41] {2218} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:35:41] {805} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:35:41] {197} INFO - result: {'pred_time': 3.145965936905583e-05, 'wall_clock_time': 15.339144706726074, 'metric_for_logging': {'pred_time': 3.145965936905583e-05}, 'val_loss': 0.31615117597126596, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133871c0>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 8, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.45506978034973145}\n",
      "[flaml.tune.tune: 09-22 09:35:41] {197} INFO - result: {'pred_time': 3.145965936905583e-05, 'wall_clock_time': 15.339144706726074, 'metric_for_logging': {'pred_time': 3.145965936905583e-05}, 'val_loss': 0.31615117597126596, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133871c0>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 8, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.45635175704956055}\n",
      "[flaml.automl.logger: 09-22 09:35:41] {2391} INFO -  at 15.3s,\testimator extra_tree's best error=0.3162,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-22 09:35:41] {2218} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:35:41] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:35:42] {197} INFO - result: {'pred_time': 3.1600171994734565e-05, 'wall_clock_time': 15.783915281295776, 'metric_for_logging': {'pred_time': 3.1600171994734565e-05}, 'val_loss': 0.28286896053012994, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387fd0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.06028451938646044, 'config/max_leaves': 9, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.4375021457672119}\n",
      "[flaml.tune.tune: 09-22 09:35:42] {197} INFO - result: {'pred_time': 3.1600171994734565e-05, 'wall_clock_time': 15.783915281295776, 'metric_for_logging': {'pred_time': 3.1600171994734565e-05}, 'val_loss': 0.28286896053012994, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387fd0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.06028451938646044, 'config/max_leaves': 9, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.4390537738800049}\n",
      "[flaml.automl.logger: 09-22 09:35:42] {2391} INFO -  at 15.8s,\testimator extra_tree's best error=0.2829,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-22 09:35:42] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:35:42] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:35:43] {197} INFO - result: {'pred_time': 4.458590013561953e-05, 'wall_clock_time': 17.36984920501709, 'metric_for_logging': {'pred_time': 4.458590013561953e-05}, 'val_loss': 0.33463751059328267, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613387cd0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 1.8630223791106992, 'config/learning_rate': 1.0, 'config/subsample': 0.8513627344387318, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.946138073111236, 'config/reg_alpha': 0.0018311776973217071, 'config/reg_lambda': 0.27901659190538414, 'experiment_tag': 'exp', 'time_total_s': 1.5781643390655518}\n",
      "[flaml.tune.tune: 09-22 09:35:43] {197} INFO - result: {'pred_time': 4.458590013561953e-05, 'wall_clock_time': 17.36984920501709, 'metric_for_logging': {'pred_time': 4.458590013561953e-05}, 'val_loss': 0.33463751059328267, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613387cd0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 1.8630223791106992, 'config/learning_rate': 1.0, 'config/subsample': 0.8513627344387318, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.946138073111236, 'config/reg_alpha': 0.0018311776973217071, 'config/reg_lambda': 0.27901659190538414, 'experiment_tag': 'exp', 'time_total_s': 1.5799312591552734}\n",
      "[flaml.automl.logger: 09-22 09:35:43] {2391} INFO -  at 17.4s,\testimator xgboost's best error=0.3346,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-22 09:35:43] {2218} INFO - iteration 16, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:35:43] {805} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.0600075785575137, 'max_leaves': 6, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:35:44] {197} INFO - result: {'pred_time': 3.308675142853989e-05, 'wall_clock_time': 17.89724826812744, 'metric_for_logging': {'pred_time': 3.308675142853989e-05}, 'val_loss': 0.2817902162917155, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613403310>, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_features': 0.0600075785575137, 'max_leaves': 6, 'criterion': 'entropy'}, 'config/n_estimators': 8, 'config/max_features': 0.0600075785575137, 'config/max_leaves': 6, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.5185604095458984}\n",
      "[flaml.tune.tune: 09-22 09:35:44] {197} INFO - result: {'pred_time': 3.308675142853989e-05, 'wall_clock_time': 17.89724826812744, 'metric_for_logging': {'pred_time': 3.308675142853989e-05}, 'val_loss': 0.2817902162917155, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613403310>, 'training_iteration': 1, 'config': {'n_estimators': 8, 'max_features': 0.0600075785575137, 'max_leaves': 6, 'criterion': 'entropy'}, 'config/n_estimators': 8, 'config/max_features': 0.0600075785575137, 'config/max_leaves': 6, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.5203230381011963}\n",
      "[flaml.automl.logger: 09-22 09:35:44] {2391} INFO -  at 17.9s,\testimator extra_tree's best error=0.2818,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-22 09:35:44] {2218} INFO - iteration 17, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:44] {805} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 5, 'min_child_samples': 20, 'learning_rate': 1.0, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0617777062707411, 'reg_lambda': 61.136054010477544}\n",
      "[flaml.tune.tune: 09-22 09:35:44] {197} INFO - result: {'pred_time': 1.2150926251644036e-05, 'wall_clock_time': 18.340656042099, 'metric_for_logging': {'pred_time': 1.2150926251644036e-05}, 'val_loss': 0.288079396718827, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6133876a0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'num_leaves': 5, 'min_child_samples': 20, 'learning_rate': 1.0, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0617777062707411, 'reg_lambda': 61.136054010477544}, 'config/n_estimators': 4, 'config/num_leaves': 5, 'config/min_child_samples': 20, 'config/learning_rate': 1.0, 'config/log_max_bin': 9, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0617777062707411, 'config/reg_lambda': 61.136054010477544, 'experiment_tag': 'exp', 'time_total_s': 0.4348316192626953}\n",
      "[flaml.tune.tune: 09-22 09:35:44] {197} INFO - result: {'pred_time': 1.2150926251644036e-05, 'wall_clock_time': 18.340656042099, 'metric_for_logging': {'pred_time': 1.2150926251644036e-05}, 'val_loss': 0.288079396718827, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6133876a0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'num_leaves': 5, 'min_child_samples': 20, 'learning_rate': 1.0, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0617777062707411, 'reg_lambda': 61.136054010477544}, 'config/n_estimators': 4, 'config/num_leaves': 5, 'config/min_child_samples': 20, 'config/learning_rate': 1.0, 'config/log_max_bin': 9, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0617777062707411, 'config/reg_lambda': 61.136054010477544, 'experiment_tag': 'exp', 'time_total_s': 0.43696165084838867}\n",
      "[flaml.automl.logger: 09-22 09:35:44] {2391} INFO -  at 18.3s,\testimator lgbm's best error=0.2808,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-22 09:35:44] {2218} INFO - iteration 18, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:35:44] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:35:45] {197} INFO - result: {'pred_time': 2.740116748884225e-05, 'wall_clock_time': 18.726935625076294, 'metric_for_logging': {'pred_time': 2.740116748884225e-05}, 'val_loss': 0.3273635618088392, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387940>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.06028451938646044, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.37734174728393555}\n",
      "[flaml.tune.tune: 09-22 09:35:45] {197} INFO - result: {'pred_time': 2.740116748884225e-05, 'wall_clock_time': 18.726935625076294, 'metric_for_logging': {'pred_time': 2.740116748884225e-05}, 'val_loss': 0.3273635618088392, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387940>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.06028451938646044, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.37874293327331543}\n",
      "[flaml.automl.logger: 09-22 09:35:45] {2391} INFO -  at 18.7s,\testimator extra_tree's best error=0.2818,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-22 09:35:45] {2218} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:35:45] {805} INFO - trial 1 config: {'n_estimators': 23, 'max_features': 0.04701175335151481, 'max_leaves': 9, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:35:45] {197} INFO - result: {'pred_time': 5.017384413880416e-05, 'wall_clock_time': 19.516929864883423, 'metric_for_logging': {'pred_time': 5.017384413880416e-05}, 'val_loss': 0.2733014296732438, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387490>, 'training_iteration': 0, 'config': {'n_estimators': 23, 'max_features': 0.04701175335151481, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 23, 'config/max_features': 0.04701175335151481, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.7813177108764648}\n",
      "[flaml.tune.tune: 09-22 09:35:45] {197} INFO - result: {'pred_time': 5.017384413880416e-05, 'wall_clock_time': 19.516929864883423, 'metric_for_logging': {'pred_time': 5.017384413880416e-05}, 'val_loss': 0.2733014296732438, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387490>, 'training_iteration': 1, 'config': {'n_estimators': 23, 'max_features': 0.04701175335151481, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 23, 'config/max_features': 0.04701175335151481, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.7830038070678711}\n",
      "[flaml.automl.logger: 09-22 09:35:45] {2391} INFO -  at 19.5s,\testimator extra_tree's best error=0.2733,\tbest estimator extra_tree's best error=0.2733\n",
      "[flaml.automl.logger: 09-22 09:35:45] {2218} INFO - iteration 20, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:35:45] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 4, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:35:46] {197} INFO - result: {'pred_time': 2.5636927548120837e-05, 'wall_clock_time': 19.915878772735596, 'metric_for_logging': {'pred_time': 2.5636927548120837e-05}, 'val_loss': 0.37391776218612804, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613387dc0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.3888998031616211}\n",
      "[flaml.tune.tune: 09-22 09:35:46] {197} INFO - result: {'pred_time': 2.5636927548120837e-05, 'wall_clock_time': 19.915878772735596, 'metric_for_logging': {'pred_time': 2.5636927548120837e-05}, 'val_loss': 0.37391776218612804, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613387dc0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.39009857177734375}\n",
      "[flaml.automl.logger: 09-22 09:35:46] {2391} INFO -  at 19.9s,\testimator rf's best error=0.3739,\tbest estimator extra_tree's best error=0.2733\n",
      "[flaml.automl.logger: 09-22 09:35:46] {2218} INFO - iteration 21, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:35:46] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 9, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:35:46] {197} INFO - result: {'pred_time': 2.918162337702516e-05, 'wall_clock_time': 20.347288370132446, 'metric_for_logging': {'pred_time': 2.918162337702516e-05}, 'val_loss': 0.37032468259979506, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6133f9fa0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.4242665767669678}\n",
      "[flaml.tune.tune: 09-22 09:35:46] {197} INFO - result: {'pred_time': 2.918162337702516e-05, 'wall_clock_time': 20.347288370132446, 'metric_for_logging': {'pred_time': 2.918162337702516e-05}, 'val_loss': 0.37032468259979506, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6133f9fa0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.4265754222869873}\n",
      "[flaml.automl.logger: 09-22 09:35:46] {2391} INFO -  at 20.3s,\testimator rf's best error=0.3703,\tbest estimator extra_tree's best error=0.2733\n",
      "[flaml.automl.logger: 09-22 09:35:46] {2218} INFO - iteration 22, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:46] {805} INFO - trial 1 config: {'n_estimators': 22, 'num_leaves': 4, 'min_child_samples': 11, 'learning_rate': 0.38363923015550033, 'log_max_bin': 10, 'colsample_bytree': 0.930646190497405, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.292560666768758}\n",
      "[flaml.tune.tune: 09-22 09:35:47] {197} INFO - result: {'pred_time': 1.3095579916164683e-05, 'wall_clock_time': 20.902639389038086, 'metric_for_logging': {'pred_time': 1.3095579916164683e-05}, 'val_loss': 0.25440871040571195, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397130>, 'training_iteration': 0, 'config': {'n_estimators': 22, 'num_leaves': 4, 'min_child_samples': 11, 'learning_rate': 0.38363923015550033, 'log_max_bin': 10, 'colsample_bytree': 0.930646190497405, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.292560666768758}, 'config/n_estimators': 22, 'config/num_leaves': 4, 'config/min_child_samples': 11, 'config/learning_rate': 0.38363923015550033, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.930646190497405, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.292560666768758, 'experiment_tag': 'exp', 'time_total_s': 0.5452160835266113}\n",
      "[flaml.tune.tune: 09-22 09:35:47] {197} INFO - result: {'pred_time': 1.3095579916164683e-05, 'wall_clock_time': 20.902639389038086, 'metric_for_logging': {'pred_time': 1.3095579916164683e-05}, 'val_loss': 0.25440871040571195, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397130>, 'training_iteration': 1, 'config': {'n_estimators': 22, 'num_leaves': 4, 'min_child_samples': 11, 'learning_rate': 0.38363923015550033, 'log_max_bin': 10, 'colsample_bytree': 0.930646190497405, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.292560666768758}, 'config/n_estimators': 22, 'config/num_leaves': 4, 'config/min_child_samples': 11, 'config/learning_rate': 0.38363923015550033, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.930646190497405, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.292560666768758, 'experiment_tag': 'exp', 'time_total_s': 0.5477662086486816}\n",
      "[flaml.automl.logger: 09-22 09:35:47] {2391} INFO -  at 20.9s,\testimator lgbm's best error=0.2544,\tbest estimator lgbm's best error=0.2544\n",
      "[flaml.automl.logger: 09-22 09:35:47] {2218} INFO - iteration 23, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:47] {805} INFO - trial 1 config: {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 13, 'learning_rate': 0.9243511266864246, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013805492389047578, 'reg_lambda': 3.1467717908237858}\n",
      "[flaml.tune.tune: 09-22 09:35:47] {197} INFO - result: {'pred_time': 1.1140411603333516e-05, 'wall_clock_time': 21.361987829208374, 'metric_for_logging': {'pred_time': 1.1140411603333516e-05}, 'val_loss': 0.26647333817498736, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397760>, 'training_iteration': 0, 'config': {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 13, 'learning_rate': 0.9243511266864246, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013805492389047578, 'reg_lambda': 3.1467717908237858}, 'config/n_estimators': 8, 'config/num_leaves': 4, 'config/min_child_samples': 13, 'config/learning_rate': 0.9243511266864246, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013805492389047578, 'config/reg_lambda': 3.1467717908237858, 'experiment_tag': 'exp', 'time_total_s': 0.45117712020874023}\n",
      "[flaml.tune.tune: 09-22 09:35:47] {197} INFO - result: {'pred_time': 1.1140411603333516e-05, 'wall_clock_time': 21.361987829208374, 'metric_for_logging': {'pred_time': 1.1140411603333516e-05}, 'val_loss': 0.26647333817498736, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397760>, 'training_iteration': 1, 'config': {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 13, 'learning_rate': 0.9243511266864246, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013805492389047578, 'reg_lambda': 3.1467717908237858}, 'config/n_estimators': 8, 'config/num_leaves': 4, 'config/min_child_samples': 13, 'config/learning_rate': 0.9243511266864246, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013805492389047578, 'config/reg_lambda': 3.1467717908237858, 'experiment_tag': 'exp', 'time_total_s': 0.45253634452819824}\n",
      "[flaml.automl.logger: 09-22 09:35:47] {2391} INFO -  at 21.4s,\testimator lgbm's best error=0.2544,\tbest estimator lgbm's best error=0.2544\n",
      "[flaml.automl.logger: 09-22 09:35:47] {2218} INFO - iteration 24, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:35:47] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:35:49] {197} INFO - result: {'pred_time': 4.725467515801541e-05, 'wall_clock_time': 22.92135715484619, 'metric_for_logging': {'pred_time': 4.725467515801541e-05}, 'val_loss': 0.3318375635467089, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6133976d0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}, 'config/n_estimators': 4, 'config/max_leaves': 7, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292968, 'experiment_tag': 'exp', 'time_total_s': 1.5523600578308105}\n",
      "[flaml.tune.tune: 09-22 09:35:49] {197} INFO - result: {'pred_time': 4.725467515801541e-05, 'wall_clock_time': 22.92135715484619, 'metric_for_logging': {'pred_time': 4.725467515801541e-05}, 'val_loss': 0.3318375635467089, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6133976d0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}, 'config/n_estimators': 4, 'config/max_leaves': 7, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292968, 'experiment_tag': 'exp', 'time_total_s': 1.5544373989105225}\n",
      "[flaml.automl.logger: 09-22 09:35:49] {2391} INFO -  at 22.9s,\testimator xgboost's best error=0.3318,\tbest estimator lgbm's best error=0.2544\n",
      "[flaml.automl.logger: 09-22 09:35:49] {2218} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:35:49] {805} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.0600075785575137, 'max_leaves': 6, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:35:49] {197} INFO - result: {'pred_time': 3.443999607488266e-05, 'wall_clock_time': 23.469868898391724, 'metric_for_logging': {'pred_time': 3.443999607488266e-05}, 'val_loss': 0.3163425044234639, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133977f0>, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_features': 0.0600075785575137, 'max_leaves': 6, 'criterion': 'gini'}, 'config/n_estimators': 8, 'config/max_features': 0.0600075785575137, 'config/max_leaves': 6, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.5402143001556396}\n",
      "[flaml.tune.tune: 09-22 09:35:49] {197} INFO - result: {'pred_time': 3.443999607488266e-05, 'wall_clock_time': 23.469868898391724, 'metric_for_logging': {'pred_time': 3.443999607488266e-05}, 'val_loss': 0.3163425044234639, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133977f0>, 'training_iteration': 1, 'config': {'n_estimators': 8, 'max_features': 0.0600075785575137, 'max_leaves': 6, 'criterion': 'gini'}, 'config/n_estimators': 8, 'config/max_features': 0.0600075785575137, 'config/max_leaves': 6, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.5414824485778809}\n",
      "[flaml.automl.logger: 09-22 09:35:49] {2391} INFO -  at 23.5s,\testimator extra_tree's best error=0.2733,\tbest estimator lgbm's best error=0.2544\n",
      "[flaml.automl.logger: 09-22 09:35:49] {2218} INFO - iteration 26, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:35:49] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.03397343291117424, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:35:50] {197} INFO - result: {'pred_time': 2.6903861437831796e-05, 'wall_clock_time': 23.868311643600464, 'metric_for_logging': {'pred_time': 2.6903861437831796e-05}, 'val_loss': 0.3861720214044052, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397160>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.03397343291117424, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.03397343291117424, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3905360698699951}\n",
      "[flaml.tune.tune: 09-22 09:35:50] {197} INFO - result: {'pred_time': 2.6903861437831796e-05, 'wall_clock_time': 23.868311643600464, 'metric_for_logging': {'pred_time': 2.6903861437831796e-05}, 'val_loss': 0.3861720214044052, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397160>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.03397343291117424, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.03397343291117424, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3918609619140625}\n",
      "[flaml.automl.logger: 09-22 09:35:50] {2391} INFO -  at 23.9s,\testimator rf's best error=0.3703,\tbest estimator lgbm's best error=0.2544\n",
      "[flaml.automl.logger: 09-22 09:35:50] {2218} INFO - iteration 27, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:35:50] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.08262716617929555, 'learning_rate': 0.13674064538052125, 'subsample': 0.8885937069868678, 'colsample_bylevel': 0.735249880070874, 'colsample_bytree': 0.8648827061331837, 'reg_alpha': 0.0018753066867999496, 'reg_lambda': 0.4131495174987749}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:35:51] {197} INFO - result: {'pred_time': 4.7124081822595796e-05, 'wall_clock_time': 25.465985536575317, 'metric_for_logging': {'pred_time': 4.7124081822595796e-05}, 'val_loss': 0.329268343998479, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6133fbc70>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.08262716617929555, 'learning_rate': 0.13674064538052125, 'subsample': 0.8885937069868678, 'colsample_bylevel': 0.735249880070874, 'colsample_bytree': 0.8648827061331837, 'reg_alpha': 0.0018753066867999496, 'reg_lambda': 0.4131495174987749}, 'config/n_estimators': 4, 'config/max_leaves': 7, 'config/min_child_weight': 0.08262716617929555, 'config/learning_rate': 0.13674064538052125, 'config/subsample': 0.8885937069868678, 'config/colsample_bylevel': 0.735249880070874, 'config/colsample_bytree': 0.8648827061331837, 'config/reg_alpha': 0.0018753066867999496, 'config/reg_lambda': 0.4131495174987749, 'experiment_tag': 'exp', 'time_total_s': 1.5900673866271973}\n",
      "[flaml.tune.tune: 09-22 09:35:51] {197} INFO - result: {'pred_time': 4.7124081822595796e-05, 'wall_clock_time': 25.465985536575317, 'metric_for_logging': {'pred_time': 4.7124081822595796e-05}, 'val_loss': 0.329268343998479, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6133fbc70>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.08262716617929555, 'learning_rate': 0.13674064538052125, 'subsample': 0.8885937069868678, 'colsample_bylevel': 0.735249880070874, 'colsample_bytree': 0.8648827061331837, 'reg_alpha': 0.0018753066867999496, 'reg_lambda': 0.4131495174987749}, 'config/n_estimators': 4, 'config/max_leaves': 7, 'config/min_child_weight': 0.08262716617929555, 'config/learning_rate': 0.13674064538052125, 'config/subsample': 0.8885937069868678, 'config/colsample_bylevel': 0.735249880070874, 'config/colsample_bytree': 0.8648827061331837, 'config/reg_alpha': 0.0018753066867999496, 'config/reg_lambda': 0.4131495174987749, 'experiment_tag': 'exp', 'time_total_s': 1.5914819240570068}\n",
      "[flaml.automl.logger: 09-22 09:35:51] {2391} INFO -  at 25.5s,\testimator xgboost's best error=0.3293,\tbest estimator lgbm's best error=0.2544\n",
      "[flaml.automl.logger: 09-22 09:35:51] {2218} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:35:51] {805} INFO - trial 1 config: {'n_estimators': 27, 'max_features': 0.0537726392498419, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:35:52] {197} INFO - result: {'pred_time': 5.561877200161426e-05, 'wall_clock_time': 26.353577852249146, 'metric_for_logging': {'pred_time': 5.561877200161426e-05}, 'val_loss': 0.30058924539809095, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133fb8b0>, 'training_iteration': 0, 'config': {'n_estimators': 27, 'max_features': 0.0537726392498419, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 27, 'config/max_features': 0.0537726392498419, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.8782041072845459}\n",
      "[flaml.tune.tune: 09-22 09:35:52] {197} INFO - result: {'pred_time': 5.561877200161426e-05, 'wall_clock_time': 26.353577852249146, 'metric_for_logging': {'pred_time': 5.561877200161426e-05}, 'val_loss': 0.30058924539809095, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133fb8b0>, 'training_iteration': 1, 'config': {'n_estimators': 27, 'max_features': 0.0537726392498419, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 27, 'config/max_features': 0.0537726392498419, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.8799374103546143}\n",
      "[flaml.automl.logger: 09-22 09:35:52] {2391} INFO -  at 26.4s,\testimator extra_tree's best error=0.2733,\tbest estimator lgbm's best error=0.2544\n",
      "[flaml.automl.logger: 09-22 09:35:52] {2218} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:35:52] {805} INFO - trial 1 config: {'n_estimators': 20, 'max_features': 0.04110092017084993, 'max_leaves': 29, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:35:53] {197} INFO - result: {'pred_time': 4.643287447577431e-05, 'wall_clock_time': 27.13520836830139, 'metric_for_logging': {'pred_time': 4.643287447577431e-05}, 'val_loss': 0.24782855020861022, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133fb250>, 'training_iteration': 0, 'config': {'n_estimators': 20, 'max_features': 0.04110092017084993, 'max_leaves': 29, 'criterion': 'entropy'}, 'config/n_estimators': 20, 'config/max_features': 0.04110092017084993, 'config/max_leaves': 29, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7728502750396729}\n",
      "[flaml.tune.tune: 09-22 09:35:53] {197} INFO - result: {'pred_time': 4.643287447577431e-05, 'wall_clock_time': 27.13520836830139, 'metric_for_logging': {'pred_time': 4.643287447577431e-05}, 'val_loss': 0.24782855020861022, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133fb250>, 'training_iteration': 1, 'config': {'n_estimators': 20, 'max_features': 0.04110092017084993, 'max_leaves': 29, 'criterion': 'entropy'}, 'config/n_estimators': 20, 'config/max_features': 0.04110092017084993, 'config/max_leaves': 29, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7743592262268066}\n",
      "[flaml.automl.logger: 09-22 09:35:53] {2391} INFO -  at 27.1s,\testimator extra_tree's best error=0.2478,\tbest estimator extra_tree's best error=0.2478\n",
      "[flaml.automl.logger: 09-22 09:35:53] {2218} INFO - iteration 30, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:53] {805} INFO - trial 1 config: {'n_estimators': 57, 'num_leaves': 13, 'min_child_samples': 9, 'learning_rate': 0.15922418945050276, 'log_max_bin': 10, 'colsample_bytree': 0.8345075630938922, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.6702305601383631}\n",
      "[flaml.tune.tune: 09-22 09:35:54] {197} INFO - result: {'pred_time': 1.3294942779288596e-05, 'wall_clock_time': 27.94189143180847, 'metric_for_logging': {'pred_time': 1.3294942779288596e-05}, 'val_loss': 0.21320537323161015, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6134030a0>, 'training_iteration': 0, 'config': {'n_estimators': 57, 'num_leaves': 13, 'min_child_samples': 9, 'learning_rate': 0.15922418945050276, 'log_max_bin': 10, 'colsample_bytree': 0.8345075630938922, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.6702305601383631}, 'config/n_estimators': 57, 'config/num_leaves': 13, 'config/min_child_samples': 9, 'config/learning_rate': 0.15922418945050276, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8345075630938922, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.6702305601383631, 'experiment_tag': 'exp', 'time_total_s': 0.7995970249176025}\n",
      "[flaml.tune.tune: 09-22 09:35:54] {197} INFO - result: {'pred_time': 1.3294942779288596e-05, 'wall_clock_time': 27.94189143180847, 'metric_for_logging': {'pred_time': 1.3294942779288596e-05}, 'val_loss': 0.21320537323161015, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6134030a0>, 'training_iteration': 1, 'config': {'n_estimators': 57, 'num_leaves': 13, 'min_child_samples': 9, 'learning_rate': 0.15922418945050276, 'log_max_bin': 10, 'colsample_bytree': 0.8345075630938922, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.6702305601383631}, 'config/n_estimators': 57, 'config/num_leaves': 13, 'config/min_child_samples': 9, 'config/learning_rate': 0.15922418945050276, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8345075630938922, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.6702305601383631, 'experiment_tag': 'exp', 'time_total_s': 0.8008840084075928}\n",
      "[flaml.automl.logger: 09-22 09:35:54] {2391} INFO -  at 27.9s,\testimator lgbm's best error=0.2132,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:35:54] {2218} INFO - iteration 31, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:54] {805} INFO - trial 1 config: {'n_estimators': 72, 'num_leaves': 15, 'min_child_samples': 7, 'learning_rate': 0.6936087284316672, 'log_max_bin': 10, 'colsample_bytree': 0.7709706901317468, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.3174169729642264}\n",
      "[flaml.tune.tune: 09-22 09:35:55] {197} INFO - result: {'pred_time': 1.3618539880549526e-05, 'wall_clock_time': 28.81966495513916, 'metric_for_logging': {'pred_time': 1.3618539880549526e-05}, 'val_loss': 0.23905812166681736, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613403850>, 'training_iteration': 0, 'config': {'n_estimators': 72, 'num_leaves': 15, 'min_child_samples': 7, 'learning_rate': 0.6936087284316672, 'log_max_bin': 10, 'colsample_bytree': 0.7709706901317468, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.3174169729642264}, 'config/n_estimators': 72, 'config/num_leaves': 15, 'config/min_child_samples': 7, 'config/learning_rate': 0.6936087284316672, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7709706901317468, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.3174169729642264, 'experiment_tag': 'exp', 'time_total_s': 0.8704619407653809}\n",
      "[flaml.tune.tune: 09-22 09:35:55] {197} INFO - result: {'pred_time': 1.3618539880549526e-05, 'wall_clock_time': 28.81966495513916, 'metric_for_logging': {'pred_time': 1.3618539880549526e-05}, 'val_loss': 0.23905812166681736, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613403850>, 'training_iteration': 1, 'config': {'n_estimators': 72, 'num_leaves': 15, 'min_child_samples': 7, 'learning_rate': 0.6936087284316672, 'log_max_bin': 10, 'colsample_bytree': 0.7709706901317468, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.3174169729642264}, 'config/n_estimators': 72, 'config/num_leaves': 15, 'config/min_child_samples': 7, 'config/learning_rate': 0.6936087284316672, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7709706901317468, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.3174169729642264, 'experiment_tag': 'exp', 'time_total_s': 0.8719267845153809}\n",
      "[flaml.automl.logger: 09-22 09:35:55] {2391} INFO -  at 28.8s,\testimator lgbm's best error=0.2132,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:35:55] {2218} INFO - iteration 32, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:55] {805} INFO - trial 1 config: {'n_estimators': 45, 'num_leaves': 11, 'min_child_samples': 11, 'learning_rate': 0.03655136025103705, 'log_max_bin': 9, 'colsample_bytree': 0.8980444360560376, 'reg_alpha': 0.001538995396757784, 'reg_lambda': 8.788660851902563}\n",
      "[flaml.tune.tune: 09-22 09:35:55] {197} INFO - result: {'pred_time': 1.2454888164482386e-05, 'wall_clock_time': 29.49547505378723, 'metric_for_logging': {'pred_time': 1.2454888164482386e-05}, 'val_loss': 0.2755431362627764, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613403e20>, 'training_iteration': 0, 'config': {'n_estimators': 45, 'num_leaves': 11, 'min_child_samples': 11, 'learning_rate': 0.03655136025103705, 'log_max_bin': 9, 'colsample_bytree': 0.8980444360560376, 'reg_alpha': 0.001538995396757784, 'reg_lambda': 8.788660851902563}, 'config/n_estimators': 45, 'config/num_leaves': 11, 'config/min_child_samples': 11, 'config/learning_rate': 0.03655136025103705, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8980444360560376, 'config/reg_alpha': 0.001538995396757784, 'config/reg_lambda': 8.788660851902563, 'experiment_tag': 'exp', 'time_total_s': 0.6661794185638428}\n",
      "[flaml.tune.tune: 09-22 09:35:55] {197} INFO - result: {'pred_time': 1.2454888164482386e-05, 'wall_clock_time': 29.49547505378723, 'metric_for_logging': {'pred_time': 1.2454888164482386e-05}, 'val_loss': 0.2755431362627764, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613403e20>, 'training_iteration': 1, 'config': {'n_estimators': 45, 'num_leaves': 11, 'min_child_samples': 11, 'learning_rate': 0.03655136025103705, 'log_max_bin': 9, 'colsample_bytree': 0.8980444360560376, 'reg_alpha': 0.001538995396757784, 'reg_lambda': 8.788660851902563}, 'config/n_estimators': 45, 'config/num_leaves': 11, 'config/min_child_samples': 11, 'config/learning_rate': 0.03655136025103705, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8980444360560376, 'config/reg_alpha': 0.001538995396757784, 'config/reg_lambda': 8.788660851902563, 'experiment_tag': 'exp', 'time_total_s': 0.6684510707855225}\n",
      "[flaml.automl.logger: 09-22 09:35:55] {2391} INFO -  at 29.5s,\testimator lgbm's best error=0.2132,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:35:55] {2218} INFO - iteration 33, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:35:55] {805} INFO - trial 1 config: {'n_estimators': 9, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292982}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:35:57] {197} INFO - result: {'pred_time': 5.2405090342671926e-05, 'wall_clock_time': 31.51482653617859, 'metric_for_logging': {'pred_time': 5.2405090342671926e-05}, 'val_loss': 0.2767818750015152, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6133975b0>, 'training_iteration': 0, 'config': {'n_estimators': 9, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292982}, 'config/n_estimators': 9, 'config/max_leaves': 7, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292982, 'experiment_tag': 'exp', 'time_total_s': 2.010716199874878}\n",
      "[flaml.tune.tune: 09-22 09:35:57] {197} INFO - result: {'pred_time': 5.2405090342671926e-05, 'wall_clock_time': 31.51482653617859, 'metric_for_logging': {'pred_time': 5.2405090342671926e-05}, 'val_loss': 0.2767818750015152, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6133975b0>, 'training_iteration': 1, 'config': {'n_estimators': 9, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292982}, 'config/n_estimators': 9, 'config/max_leaves': 7, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292982, 'experiment_tag': 'exp', 'time_total_s': 2.0131657123565674}\n",
      "[flaml.automl.logger: 09-22 09:35:57] {2391} INFO -  at 31.5s,\testimator xgboost's best error=0.2768,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:35:57] {2218} INFO - iteration 34, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:35:57] {805} INFO - trial 1 config: {'n_estimators': 84, 'num_leaves': 4, 'min_child_samples': 8, 'learning_rate': 0.2963869736609299, 'log_max_bin': 10, 'colsample_bytree': 0.9026377604690098, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.956628470408563}\n",
      "[flaml.tune.tune: 09-22 09:35:58] {197} INFO - result: {'pred_time': 1.5326092264355856e-05, 'wall_clock_time': 32.6183876991272, 'metric_for_logging': {'pred_time': 1.5326092264355856e-05}, 'val_loss': 0.23552549349026108, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397ca0>, 'training_iteration': 0, 'config': {'n_estimators': 84, 'num_leaves': 4, 'min_child_samples': 8, 'learning_rate': 0.2963869736609299, 'log_max_bin': 10, 'colsample_bytree': 0.9026377604690098, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.956628470408563}, 'config/n_estimators': 84, 'config/num_leaves': 4, 'config/min_child_samples': 8, 'config/learning_rate': 0.2963869736609299, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.9026377604690098, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.956628470408563, 'experiment_tag': 'exp', 'time_total_s': 1.0942902565002441}\n",
      "[flaml.tune.tune: 09-22 09:35:58] {197} INFO - result: {'pred_time': 1.5326092264355856e-05, 'wall_clock_time': 32.6183876991272, 'metric_for_logging': {'pred_time': 1.5326092264355856e-05}, 'val_loss': 0.23552549349026108, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397ca0>, 'training_iteration': 1, 'config': {'n_estimators': 84, 'num_leaves': 4, 'min_child_samples': 8, 'learning_rate': 0.2963869736609299, 'log_max_bin': 10, 'colsample_bytree': 0.9026377604690098, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.956628470408563}, 'config/n_estimators': 84, 'config/num_leaves': 4, 'config/min_child_samples': 8, 'config/learning_rate': 0.2963869736609299, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.9026377604690098, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.956628470408563, 'experiment_tag': 'exp', 'time_total_s': 1.0974910259246826}\n",
      "[flaml.automl.logger: 09-22 09:35:58] {2391} INFO -  at 32.6s,\testimator lgbm's best error=0.2132,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:35:58] {2218} INFO - iteration 35, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:35:58] {805} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:35:59] {197} INFO - result: {'pred_time': 5.5623603718472945e-05, 'wall_clock_time': 33.471492528915405, 'metric_for_logging': {'pred_time': 5.5623603718472945e-05}, 'val_loss': 0.2907738178727684, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397610>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 8, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.8382885456085205}\n",
      "[flaml.tune.tune: 09-22 09:35:59] {197} INFO - result: {'pred_time': 5.5623603718472945e-05, 'wall_clock_time': 33.471492528915405, 'metric_for_logging': {'pred_time': 5.5623603718472945e-05}, 'val_loss': 0.2907738178727684, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397610>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 8, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.8399078845977783}\n",
      "[flaml.automl.logger: 09-22 09:35:59] {2391} INFO -  at 33.5s,\testimator rf's best error=0.2908,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:35:59] {2218} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:35:59] {805} INFO - trial 1 config: {'n_estimators': 12, 'max_features': 0.032427221756276076, 'max_leaves': 23, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:36:00] {197} INFO - result: {'pred_time': 5.0621578769971357e-05, 'wall_clock_time': 34.33425426483154, 'metric_for_logging': {'pred_time': 5.0621578769971357e-05}, 'val_loss': 0.2717199655542984, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133fb3a0>, 'training_iteration': 0, 'config': {'n_estimators': 12, 'max_features': 0.032427221756276076, 'max_leaves': 23, 'criterion': 'gini'}, 'config/n_estimators': 12, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 23, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.8524305820465088}\n",
      "[flaml.tune.tune: 09-22 09:36:00] {197} INFO - result: {'pred_time': 5.0621578769971357e-05, 'wall_clock_time': 34.33425426483154, 'metric_for_logging': {'pred_time': 5.0621578769971357e-05}, 'val_loss': 0.2717199655542984, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133fb3a0>, 'training_iteration': 1, 'config': {'n_estimators': 12, 'max_features': 0.032427221756276076, 'max_leaves': 23, 'criterion': 'gini'}, 'config/n_estimators': 12, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 23, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.8538477420806885}\n",
      "[flaml.automl.logger: 09-22 09:36:00] {2391} INFO -  at 34.3s,\testimator extra_tree's best error=0.2478,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:36:00] {2218} INFO - iteration 37, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:36:00] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:36:01] {197} INFO - result: {'pred_time': 2.8360535398421628e-05, 'wall_clock_time': 34.762377977371216, 'metric_for_logging': {'pred_time': 2.8360535398421628e-05}, 'val_loss': 0.34709469156620576, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613045100>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.06028451938646044, 'config/max_leaves': 9, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.42063474655151367}\n",
      "[flaml.tune.tune: 09-22 09:36:01] {197} INFO - result: {'pred_time': 2.8360535398421628e-05, 'wall_clock_time': 34.762377977371216, 'metric_for_logging': {'pred_time': 2.8360535398421628e-05}, 'val_loss': 0.34709469156620576, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613045100>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.06028451938646044, 'config/max_leaves': 9, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.4222145080566406}\n",
      "[flaml.automl.logger: 09-22 09:36:01] {2391} INFO -  at 34.8s,\testimator rf's best error=0.2908,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:36:01] {2218} INFO - iteration 38, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:36:01] {805} INFO - trial 1 config: {'n_estimators': 15, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 1.0, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796909}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:36:03] {197} INFO - result: {'pred_time': 4.4970174770342e-05, 'wall_clock_time': 36.71973514556885, 'metric_for_logging': {'pred_time': 4.4970174770342e-05}, 'val_loss': 0.2535289787538663, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb61304eee0>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 1.0, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796909}, 'config/n_estimators': 15, 'config/max_leaves': 5, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.6618201818236865, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.7979503033535307, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644693, 'config/reg_lambda': 0.8085739292796909, 'experiment_tag': 'exp', 'time_total_s': 1.9510066509246826}\n",
      "[flaml.tune.tune: 09-22 09:36:03] {197} INFO - result: {'pred_time': 4.4970174770342e-05, 'wall_clock_time': 36.71973514556885, 'metric_for_logging': {'pred_time': 4.4970174770342e-05}, 'val_loss': 0.2535289787538663, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb61304eee0>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 1.0, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796909}, 'config/n_estimators': 15, 'config/max_leaves': 5, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.6618201818236865, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.7979503033535307, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644693, 'config/reg_lambda': 0.8085739292796909, 'experiment_tag': 'exp', 'time_total_s': 1.952530860900879}\n",
      "[flaml.automl.logger: 09-22 09:36:03] {2391} INFO -  at 36.7s,\testimator xgboost's best error=0.2535,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:36:03] {2218} INFO - iteration 39, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:36:03] {805} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.032427221756276076, 'max_leaves': 5, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:36:03] {197} INFO - result: {'pred_time': 4.348087586783559e-05, 'wall_clock_time': 37.48954367637634, 'metric_for_logging': {'pred_time': 4.348087586783559e-05}, 'val_loss': 0.2875579448667905, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613387fd0>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.032427221756276076, 'max_leaves': 5, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 5, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7627763748168945}\n",
      "[flaml.tune.tune: 09-22 09:36:03] {197} INFO - result: {'pred_time': 4.348087586783559e-05, 'wall_clock_time': 37.48954367637634, 'metric_for_logging': {'pred_time': 4.348087586783559e-05}, 'val_loss': 0.2875579448667905, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613387fd0>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.032427221756276076, 'max_leaves': 5, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 5, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7642014026641846}\n",
      "[flaml.automl.logger: 09-22 09:36:03] {2391} INFO -  at 37.5s,\testimator rf's best error=0.2876,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:36:03] {2218} INFO - iteration 40, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:36:03] {805} INFO - trial 1 config: {'n_estimators': 9, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9079647052885418, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292995}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:36:05] {197} INFO - result: {'pred_time': 4.284138202355036e-05, 'wall_clock_time': 39.210254430770874, 'metric_for_logging': {'pred_time': 4.284138202355036e-05}, 'val_loss': 0.2861053058017076, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613403ac0>, 'training_iteration': 0, 'config': {'n_estimators': 9, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9079647052885418, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292995}, 'config/n_estimators': 9, 'config/max_leaves': 7, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9079647052885418, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292995, 'experiment_tag': 'exp', 'time_total_s': 1.7133893966674805}\n",
      "[flaml.tune.tune: 09-22 09:36:05] {197} INFO - result: {'pred_time': 4.284138202355036e-05, 'wall_clock_time': 39.210254430770874, 'metric_for_logging': {'pred_time': 4.284138202355036e-05}, 'val_loss': 0.2861053058017076, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613403ac0>, 'training_iteration': 1, 'config': {'n_estimators': 9, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9079647052885418, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292995}, 'config/n_estimators': 9, 'config/max_leaves': 7, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9079647052885418, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292995, 'experiment_tag': 'exp', 'time_total_s': 1.7148182392120361}\n",
      "[flaml.automl.logger: 09-22 09:36:05] {2391} INFO -  at 39.2s,\testimator xgboost's best error=0.2535,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:36:05] {2218} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:36:05] {805} INFO - trial 1 config: {'n_estimators': 34, 'max_features': 0.05391196221275601, 'max_leaves': 36, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:36:06] {197} INFO - result: {'pred_time': 6.673237879897046e-05, 'wall_clock_time': 40.3862943649292, 'metric_for_logging': {'pred_time': 6.673237879897046e-05}, 'val_loss': 0.23562796737459407, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6134033a0>, 'training_iteration': 0, 'config': {'n_estimators': 34, 'max_features': 0.05391196221275601, 'max_leaves': 36, 'criterion': 'entropy'}, 'config/n_estimators': 34, 'config/max_features': 0.05391196221275601, 'config/max_leaves': 36, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.1663479804992676}\n",
      "[flaml.tune.tune: 09-22 09:36:06] {197} INFO - result: {'pred_time': 6.673237879897046e-05, 'wall_clock_time': 40.3862943649292, 'metric_for_logging': {'pred_time': 6.673237879897046e-05}, 'val_loss': 0.23562796737459407, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6134033a0>, 'training_iteration': 1, 'config': {'n_estimators': 34, 'max_features': 0.05391196221275601, 'max_leaves': 36, 'criterion': 'entropy'}, 'config/n_estimators': 34, 'config/max_features': 0.05391196221275601, 'config/max_leaves': 36, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.1678509712219238}\n",
      "[flaml.automl.logger: 09-22 09:36:06] {2391} INFO -  at 40.4s,\testimator extra_tree's best error=0.2356,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:36:06] {2218} INFO - iteration 42, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:36:06] {805} INFO - trial 1 config: {'n_estimators': 39, 'num_leaves': 42, 'min_child_samples': 11, 'learning_rate': 0.085537978248575, 'log_max_bin': 9, 'colsample_bytree': 0.7663773657187746, 'reg_alpha': 0.006958608037974516, 'reg_lambda': 0.4683303882185497}\n",
      "[flaml.tune.tune: 09-22 09:36:07] {197} INFO - result: {'pred_time': 1.3817053059800695e-05, 'wall_clock_time': 41.37371230125427, 'metric_for_logging': {'pred_time': 1.3817053059800695e-05}, 'val_loss': 0.21463536682802054, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397040>, 'training_iteration': 0, 'config': {'n_estimators': 39, 'num_leaves': 42, 'min_child_samples': 11, 'learning_rate': 0.085537978248575, 'log_max_bin': 9, 'colsample_bytree': 0.7663773657187746, 'reg_alpha': 0.006958608037974516, 'reg_lambda': 0.4683303882185497}, 'config/n_estimators': 39, 'config/num_leaves': 42, 'config/min_child_samples': 11, 'config/learning_rate': 0.085537978248575, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7663773657187746, 'config/reg_alpha': 0.006958608037974516, 'config/reg_lambda': 0.4683303882185497, 'experiment_tag': 'exp', 'time_total_s': 0.9799718856811523}\n",
      "[flaml.tune.tune: 09-22 09:36:07] {197} INFO - result: {'pred_time': 1.3817053059800695e-05, 'wall_clock_time': 41.37371230125427, 'metric_for_logging': {'pred_time': 1.3817053059800695e-05}, 'val_loss': 0.21463536682802054, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397040>, 'training_iteration': 1, 'config': {'n_estimators': 39, 'num_leaves': 42, 'min_child_samples': 11, 'learning_rate': 0.085537978248575, 'log_max_bin': 9, 'colsample_bytree': 0.7663773657187746, 'reg_alpha': 0.006958608037974516, 'reg_lambda': 0.4683303882185497}, 'config/n_estimators': 39, 'config/num_leaves': 42, 'config/min_child_samples': 11, 'config/learning_rate': 0.085537978248575, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7663773657187746, 'config/reg_alpha': 0.006958608037974516, 'config/reg_lambda': 0.4683303882185497, 'experiment_tag': 'exp', 'time_total_s': 0.98221755027771}\n",
      "[flaml.automl.logger: 09-22 09:36:07] {2391} INFO -  at 41.4s,\testimator lgbm's best error=0.2132,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:36:07] {2218} INFO - iteration 43, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:36:07] {805} INFO - trial 1 config: {'n_estimators': 15, 'max_leaves': 11, 'min_child_weight': 0.7694377042261122, 'learning_rate': 0.8060470431177518, 'subsample': 1.0, 'colsample_bylevel': 0.8256882078026019, 'colsample_bytree': 0.7967145599266738, 'reg_alpha': 0.058176484040363505, 'reg_lambda': 4.081433281365184}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:36:10] {197} INFO - result: {'pred_time': 4.746480357769282e-05, 'wall_clock_time': 43.7722065448761, 'metric_for_logging': {'pred_time': 4.746480357769282e-05}, 'val_loss': 0.24543571509463566, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613397640>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_leaves': 11, 'min_child_weight': 0.7694377042261122, 'learning_rate': 0.8060470431177518, 'subsample': 1.0, 'colsample_bylevel': 0.8256882078026019, 'colsample_bytree': 0.7967145599266738, 'reg_alpha': 0.058176484040363505, 'reg_lambda': 4.081433281365184}, 'config/n_estimators': 15, 'config/max_leaves': 11, 'config/min_child_weight': 0.7694377042261122, 'config/learning_rate': 0.8060470431177518, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8256882078026019, 'config/colsample_bytree': 0.7967145599266738, 'config/reg_alpha': 0.058176484040363505, 'config/reg_lambda': 4.081433281365184, 'experiment_tag': 'exp', 'time_total_s': 2.3895294666290283}\n",
      "[flaml.tune.tune: 09-22 09:36:10] {197} INFO - result: {'pred_time': 4.746480357769282e-05, 'wall_clock_time': 43.7722065448761, 'metric_for_logging': {'pred_time': 4.746480357769282e-05}, 'val_loss': 0.24543571509463566, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613397640>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_leaves': 11, 'min_child_weight': 0.7694377042261122, 'learning_rate': 0.8060470431177518, 'subsample': 1.0, 'colsample_bylevel': 0.8256882078026019, 'colsample_bytree': 0.7967145599266738, 'reg_alpha': 0.058176484040363505, 'reg_lambda': 4.081433281365184}, 'config/n_estimators': 15, 'config/max_leaves': 11, 'config/min_child_weight': 0.7694377042261122, 'config/learning_rate': 0.8060470431177518, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8256882078026019, 'config/colsample_bytree': 0.7967145599266738, 'config/reg_alpha': 0.058176484040363505, 'config/reg_lambda': 4.081433281365184, 'experiment_tag': 'exp', 'time_total_s': 2.3913111686706543}\n",
      "[flaml.automl.logger: 09-22 09:36:10] {2391} INFO -  at 43.8s,\testimator xgboost's best error=0.2454,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:36:10] {2218} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:36:10] {805} INFO - trial 1 config: {'n_estimators': 12, 'max_features': 0.05878478553813811, 'max_leaves': 55, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:36:10] {197} INFO - result: {'pred_time': 4.477433746257613e-05, 'wall_clock_time': 44.6222779750824, 'metric_for_logging': {'pred_time': 4.477433746257613e-05}, 'val_loss': 0.2443264377859581, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613397700>, 'training_iteration': 0, 'config': {'n_estimators': 12, 'max_features': 0.05878478553813811, 'max_leaves': 55, 'criterion': 'entropy'}, 'config/n_estimators': 12, 'config/max_features': 0.05878478553813811, 'config/max_leaves': 55, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.8419396877288818}\n",
      "[flaml.tune.tune: 09-22 09:36:10] {197} INFO - result: {'pred_time': 4.477433746257613e-05, 'wall_clock_time': 44.6222779750824, 'metric_for_logging': {'pred_time': 4.477433746257613e-05}, 'val_loss': 0.2443264377859581, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613397700>, 'training_iteration': 1, 'config': {'n_estimators': 12, 'max_features': 0.05878478553813811, 'max_leaves': 55, 'criterion': 'entropy'}, 'config/n_estimators': 12, 'config/max_features': 0.05878478553813811, 'config/max_leaves': 55, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.8432736396789551}\n",
      "[flaml.automl.logger: 09-22 09:36:10] {2391} INFO -  at 44.6s,\testimator extra_tree's best error=0.2356,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:36:10] {2218} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:36:10] {805} INFO - trial 1 config: {'n_estimators': 93, 'max_features': 0.04944305984996691, 'max_leaves': 23, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:36:13] {197} INFO - result: {'pred_time': 0.0001463395507759415, 'wall_clock_time': 47.01758408546448, 'metric_for_logging': {'pred_time': 0.0001463395507759415}, 'val_loss': 0.25190466097512576, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613397790>, 'training_iteration': 0, 'config': {'n_estimators': 93, 'max_features': 0.04944305984996691, 'max_leaves': 23, 'criterion': 'gini'}, 'config/n_estimators': 93, 'config/max_features': 0.04944305984996691, 'config/max_leaves': 23, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.3872509002685547}\n",
      "[flaml.tune.tune: 09-22 09:36:13] {197} INFO - result: {'pred_time': 0.0001463395507759415, 'wall_clock_time': 47.01758408546448, 'metric_for_logging': {'pred_time': 0.0001463395507759415}, 'val_loss': 0.25190466097512576, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613397790>, 'training_iteration': 1, 'config': {'n_estimators': 93, 'max_features': 0.04944305984996691, 'max_leaves': 23, 'criterion': 'gini'}, 'config/n_estimators': 93, 'config/max_features': 0.04944305984996691, 'config/max_leaves': 23, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.3889410495758057}\n",
      "[flaml.automl.logger: 09-22 09:36:13] {2391} INFO -  at 47.0s,\testimator extra_tree's best error=0.2356,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:36:13] {2218} INFO - iteration 46, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:36:13] {805} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.032576876548045676, 'max_leaves': 7, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:36:13] {197} INFO - result: {'pred_time': 3.090881141108898e-05, 'wall_clock_time': 47.53696084022522, 'metric_for_logging': {'pred_time': 3.090881141108898e-05}, 'val_loss': 0.3355473077736946, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb61304e910>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.032576876548045676, 'max_leaves': 7, 'criterion': 'gini'}, 'config/n_estimators': 7, 'config/max_features': 0.032576876548045676, 'config/max_leaves': 7, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.5102427005767822}\n",
      "[flaml.tune.tune: 09-22 09:36:13] {197} INFO - result: {'pred_time': 3.090881141108898e-05, 'wall_clock_time': 47.53696084022522, 'metric_for_logging': {'pred_time': 3.090881141108898e-05}, 'val_loss': 0.3355473077736946, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb61304e910>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.032576876548045676, 'max_leaves': 7, 'criterion': 'gini'}, 'config/n_estimators': 7, 'config/max_features': 0.032576876548045676, 'config/max_leaves': 7, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.5125651359558105}\n",
      "[flaml.automl.logger: 09-22 09:36:13] {2391} INFO -  at 47.5s,\testimator rf's best error=0.2876,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:36:13] {2218} INFO - iteration 47, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:36:13] {805} INFO - trial 1 config: {'n_estimators': 15, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 0.9661106209889765, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644698, 'reg_lambda': 0.8085739292796903}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:36:15] {197} INFO - result: {'pred_time': 4.402210278853009e-05, 'wall_clock_time': 49.47356557846069, 'metric_for_logging': {'pred_time': 4.402210278853009e-05}, 'val_loss': 0.24515036747045746, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb61304e8b0>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 0.9661106209889765, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644698, 'reg_lambda': 0.8085739292796903}, 'config/n_estimators': 15, 'config/max_leaves': 5, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.6618201818236865, 'config/subsample': 0.9661106209889765, 'config/colsample_bylevel': 0.7979503033535307, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644698, 'config/reg_lambda': 0.8085739292796903, 'experiment_tag': 'exp', 'time_total_s': 1.929063081741333}\n",
      "[flaml.tune.tune: 09-22 09:36:15] {197} INFO - result: {'pred_time': 4.402210278853009e-05, 'wall_clock_time': 49.47356557846069, 'metric_for_logging': {'pred_time': 4.402210278853009e-05}, 'val_loss': 0.24515036747045746, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb61304e8b0>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 0.9661106209889765, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644698, 'reg_lambda': 0.8085739292796903}, 'config/n_estimators': 15, 'config/max_leaves': 5, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.6618201818236865, 'config/subsample': 0.9661106209889765, 'config/colsample_bylevel': 0.7979503033535307, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644698, 'config/reg_lambda': 0.8085739292796903, 'experiment_tag': 'exp', 'time_total_s': 1.9306566715240479}\n",
      "[flaml.automl.logger: 09-22 09:36:15] {2391} INFO -  at 49.5s,\testimator xgboost's best error=0.2452,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-22 09:36:15] {2218} INFO - iteration 48, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:36:15] {805} INFO - trial 1 config: {'n_estimators': 51, 'num_leaves': 38, 'min_child_samples': 8, 'learning_rate': 0.6308228540989652, 'log_max_bin': 10, 'colsample_bytree': 0.9220414673185544, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.8579939426349152}\n",
      "[flaml.tune.tune: 09-22 09:36:16] {197} INFO - result: {'pred_time': 1.4651970869604769e-05, 'wall_clock_time': 50.51926255226135, 'metric_for_logging': {'pred_time': 1.4651970869604769e-05}, 'val_loss': 0.20585452249620162, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb61304e3d0>, 'training_iteration': 0, 'config': {'n_estimators': 51, 'num_leaves': 38, 'min_child_samples': 8, 'learning_rate': 0.6308228540989652, 'log_max_bin': 10, 'colsample_bytree': 0.9220414673185544, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.8579939426349152}, 'config/n_estimators': 51, 'config/num_leaves': 38, 'config/min_child_samples': 8, 'config/learning_rate': 0.6308228540989652, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.9220414673185544, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.8579939426349152, 'experiment_tag': 'exp', 'time_total_s': 1.0384385585784912}\n",
      "[flaml.tune.tune: 09-22 09:36:16] {197} INFO - result: {'pred_time': 1.4651970869604769e-05, 'wall_clock_time': 50.51926255226135, 'metric_for_logging': {'pred_time': 1.4651970869604769e-05}, 'val_loss': 0.20585452249620162, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb61304e3d0>, 'training_iteration': 1, 'config': {'n_estimators': 51, 'num_leaves': 38, 'min_child_samples': 8, 'learning_rate': 0.6308228540989652, 'log_max_bin': 10, 'colsample_bytree': 0.9220414673185544, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.8579939426349152}, 'config/n_estimators': 51, 'config/num_leaves': 38, 'config/min_child_samples': 8, 'config/learning_rate': 0.6308228540989652, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.9220414673185544, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.8579939426349152, 'experiment_tag': 'exp', 'time_total_s': 1.040086269378662}\n",
      "[flaml.automl.logger: 09-22 09:36:16] {2391} INFO -  at 50.5s,\testimator lgbm's best error=0.2059,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:16] {2218} INFO - iteration 49, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:36:16] {805} INFO - trial 1 config: {'n_estimators': 42, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:36:18] {197} INFO - result: {'pred_time': 7.582359046913424e-05, 'wall_clock_time': 51.98447918891907, 'metric_for_logging': {'pred_time': 7.582359046913424e-05}, 'val_loss': 0.25813705673150955, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6133fbc40>, 'training_iteration': 0, 'config': {'n_estimators': 42, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'gini'}, 'config/n_estimators': 42, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 8, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.455707311630249}\n",
      "[flaml.tune.tune: 09-22 09:36:18] {197} INFO - result: {'pred_time': 7.582359046913424e-05, 'wall_clock_time': 51.98447918891907, 'metric_for_logging': {'pred_time': 7.582359046913424e-05}, 'val_loss': 0.25813705673150955, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6133fbc40>, 'training_iteration': 1, 'config': {'n_estimators': 42, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'gini'}, 'config/n_estimators': 42, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 8, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.4572505950927734}\n",
      "[flaml.automl.logger: 09-22 09:36:18] {2391} INFO -  at 52.0s,\testimator rf's best error=0.2581,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:18] {2218} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:36:18] {805} INFO - trial 1 config: {'n_estimators': 26, 'max_features': 0.06745889217551715, 'max_leaves': 88, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:36:19] {197} INFO - result: {'pred_time': 6.468171586516366e-05, 'wall_clock_time': 53.28132200241089, 'metric_for_logging': {'pred_time': 6.468171586516366e-05}, 'val_loss': 0.2178092563212503, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613397610>, 'training_iteration': 0, 'config': {'n_estimators': 26, 'max_features': 0.06745889217551715, 'max_leaves': 88, 'criterion': 'entropy'}, 'config/n_estimators': 26, 'config/max_features': 0.06745889217551715, 'config/max_leaves': 88, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2888216972351074}\n",
      "[flaml.tune.tune: 09-22 09:36:19] {197} INFO - result: {'pred_time': 6.468171586516366e-05, 'wall_clock_time': 53.28132200241089, 'metric_for_logging': {'pred_time': 6.468171586516366e-05}, 'val_loss': 0.2178092563212503, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613397610>, 'training_iteration': 1, 'config': {'n_estimators': 26, 'max_features': 0.06745889217551715, 'max_leaves': 88, 'criterion': 'entropy'}, 'config/n_estimators': 26, 'config/max_features': 0.06745889217551715, 'config/max_leaves': 88, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2906408309936523}\n",
      "[flaml.automl.logger: 09-22 09:36:19] {2391} INFO -  at 53.3s,\testimator extra_tree's best error=0.2178,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:19] {2218} INFO - iteration 51, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:36:19] {805} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.04139133127820161, 'max_leaves': 5, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:36:20] {197} INFO - result: {'pred_time': 4.1565447895056946e-05, 'wall_clock_time': 54.00164556503296, 'metric_for_logging': {'pred_time': 4.1565447895056946e-05}, 'val_loss': 0.3268777946439116, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397dc0>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.04139133127820161, 'max_leaves': 5, 'criterion': 'gini'}, 'config/n_estimators': 15, 'config/max_features': 0.04139133127820161, 'config/max_leaves': 5, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.7112839221954346}\n",
      "[flaml.tune.tune: 09-22 09:36:20] {197} INFO - result: {'pred_time': 4.1565447895056946e-05, 'wall_clock_time': 54.00164556503296, 'metric_for_logging': {'pred_time': 4.1565447895056946e-05}, 'val_loss': 0.3268777946439116, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397dc0>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.04139133127820161, 'max_leaves': 5, 'criterion': 'gini'}, 'config/n_estimators': 15, 'config/max_features': 0.04139133127820161, 'config/max_leaves': 5, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.7127895355224609}\n",
      "[flaml.automl.logger: 09-22 09:36:20] {2391} INFO -  at 54.0s,\testimator rf's best error=0.2581,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:20] {2218} INFO - iteration 52, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:36:20] {805} INFO - trial 1 config: {'n_estimators': 49, 'max_features': 0.037090667185649066, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:36:21] {197} INFO - result: {'pred_time': 8.497738834408754e-05, 'wall_clock_time': 55.59533166885376, 'metric_for_logging': {'pred_time': 8.497738834408754e-05}, 'val_loss': 0.2796997594411388, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397130>, 'training_iteration': 0, 'config': {'n_estimators': 49, 'max_features': 0.037090667185649066, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 49, 'config/max_features': 0.037090667185649066, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.5863037109375}\n",
      "[flaml.tune.tune: 09-22 09:36:21] {197} INFO - result: {'pred_time': 8.497738834408754e-05, 'wall_clock_time': 55.59533166885376, 'metric_for_logging': {'pred_time': 8.497738834408754e-05}, 'val_loss': 0.2796997594411388, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397130>, 'training_iteration': 1, 'config': {'n_estimators': 49, 'max_features': 0.037090667185649066, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 49, 'config/max_features': 0.037090667185649066, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.5879085063934326}\n",
      "[flaml.automl.logger: 09-22 09:36:21] {2391} INFO -  at 55.6s,\testimator rf's best error=0.2581,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:21] {2218} INFO - iteration 53, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:36:21] {805} INFO - trial 1 config: {'n_estimators': 57, 'num_leaves': 13, 'min_child_samples': 9, 'learning_rate': 0.15922418945050276, 'log_max_bin': 9, 'colsample_bytree': 0.8345075630938922, 'reg_alpha': 0.001858538296879656, 'reg_lambda': 1.6702305601383631}\n",
      "[flaml.tune.tune: 09-22 09:36:22] {197} INFO - result: {'pred_time': 1.4165837159339076e-05, 'wall_clock_time': 56.39489126205444, 'metric_for_logging': {'pred_time': 1.4165837159339076e-05}, 'val_loss': 0.21437559979538987, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6133f9c70>, 'training_iteration': 0, 'config': {'n_estimators': 57, 'num_leaves': 13, 'min_child_samples': 9, 'learning_rate': 0.15922418945050276, 'log_max_bin': 9, 'colsample_bytree': 0.8345075630938922, 'reg_alpha': 0.001858538296879656, 'reg_lambda': 1.6702305601383631}, 'config/n_estimators': 57, 'config/num_leaves': 13, 'config/min_child_samples': 9, 'config/learning_rate': 0.15922418945050276, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8345075630938922, 'config/reg_alpha': 0.001858538296879656, 'config/reg_lambda': 1.6702305601383631, 'experiment_tag': 'exp', 'time_total_s': 0.7914960384368896}\n",
      "[flaml.tune.tune: 09-22 09:36:22] {197} INFO - result: {'pred_time': 1.4165837159339076e-05, 'wall_clock_time': 56.39489126205444, 'metric_for_logging': {'pred_time': 1.4165837159339076e-05}, 'val_loss': 0.21437559979538987, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6133f9c70>, 'training_iteration': 1, 'config': {'n_estimators': 57, 'num_leaves': 13, 'min_child_samples': 9, 'learning_rate': 0.15922418945050276, 'log_max_bin': 9, 'colsample_bytree': 0.8345075630938922, 'reg_alpha': 0.001858538296879656, 'reg_lambda': 1.6702305601383631}, 'config/n_estimators': 57, 'config/num_leaves': 13, 'config/min_child_samples': 9, 'config/learning_rate': 0.15922418945050276, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8345075630938922, 'config/reg_alpha': 0.001858538296879656, 'config/reg_lambda': 1.6702305601383631, 'experiment_tag': 'exp', 'time_total_s': 0.7928895950317383}\n",
      "[flaml.automl.logger: 09-22 09:36:22] {2391} INFO -  at 56.4s,\testimator lgbm's best error=0.2059,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:22] {2218} INFO - iteration 54, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:36:22] {805} INFO - trial 1 config: {'n_estimators': 34, 'num_leaves': 113, 'min_child_samples': 6, 'learning_rate': 0.5548452475162691, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.6113984717644443}\n",
      "[flaml.tune.tune: 09-22 09:36:23] {197} INFO - result: {'pred_time': 1.4607852149844055e-05, 'wall_clock_time': 57.62995624542236, 'metric_for_logging': {'pred_time': 1.4607852149844055e-05}, 'val_loss': 0.21457818388103247, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397520>, 'training_iteration': 0, 'config': {'n_estimators': 34, 'num_leaves': 113, 'min_child_samples': 6, 'learning_rate': 0.5548452475162691, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.6113984717644443}, 'config/n_estimators': 34, 'config/num_leaves': 113, 'config/min_child_samples': 6, 'config/learning_rate': 0.5548452475162691, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.6113984717644443, 'experiment_tag': 'exp', 'time_total_s': 1.2268025875091553}\n",
      "[flaml.tune.tune: 09-22 09:36:23] {197} INFO - result: {'pred_time': 1.4607852149844055e-05, 'wall_clock_time': 57.62995624542236, 'metric_for_logging': {'pred_time': 1.4607852149844055e-05}, 'val_loss': 0.21457818388103247, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397520>, 'training_iteration': 1, 'config': {'n_estimators': 34, 'num_leaves': 113, 'min_child_samples': 6, 'learning_rate': 0.5548452475162691, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.6113984717644443}, 'config/n_estimators': 34, 'config/num_leaves': 113, 'config/min_child_samples': 6, 'config/learning_rate': 0.5548452475162691, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.6113984717644443, 'experiment_tag': 'exp', 'time_total_s': 1.2282955646514893}\n",
      "[flaml.automl.logger: 09-22 09:36:23] {2391} INFO -  at 57.6s,\testimator lgbm's best error=0.2059,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:23] {2218} INFO - iteration 55, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:36:23] {805} INFO - trial 1 config: {'n_estimators': 9, 'max_leaves': 4, 'min_child_weight': 0.10422622872469292, 'learning_rate': 1.0, 'subsample': 0.794741631646611, 'colsample_bylevel': 0.7539376453684443, 'colsample_bytree': 0.9485956837704628, 'reg_alpha': 0.0063736480220318815, 'reg_lambda': 2.33607966864803}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:36:25] {197} INFO - result: {'pred_time': 4.5522261923747125e-05, 'wall_clock_time': 59.399256467819214, 'metric_for_logging': {'pred_time': 4.5522261923747125e-05}, 'val_loss': 0.27641732667969554, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613397040>, 'training_iteration': 0, 'config': {'n_estimators': 9, 'max_leaves': 4, 'min_child_weight': 0.10422622872469292, 'learning_rate': 1.0, 'subsample': 0.794741631646611, 'colsample_bylevel': 0.7539376453684443, 'colsample_bytree': 0.9485956837704628, 'reg_alpha': 0.0063736480220318815, 'reg_lambda': 2.33607966864803}, 'config/n_estimators': 9, 'config/max_leaves': 4, 'config/min_child_weight': 0.10422622872469292, 'config/learning_rate': 1.0, 'config/subsample': 0.794741631646611, 'config/colsample_bylevel': 0.7539376453684443, 'config/colsample_bytree': 0.9485956837704628, 'config/reg_alpha': 0.0063736480220318815, 'config/reg_lambda': 2.33607966864803, 'experiment_tag': 'exp', 'time_total_s': 1.76088285446167}\n",
      "[flaml.tune.tune: 09-22 09:36:25] {197} INFO - result: {'pred_time': 4.5522261923747125e-05, 'wall_clock_time': 59.399256467819214, 'metric_for_logging': {'pred_time': 4.5522261923747125e-05}, 'val_loss': 0.27641732667969554, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613397040>, 'training_iteration': 1, 'config': {'n_estimators': 9, 'max_leaves': 4, 'min_child_weight': 0.10422622872469292, 'learning_rate': 1.0, 'subsample': 0.794741631646611, 'colsample_bylevel': 0.7539376453684443, 'colsample_bytree': 0.9485956837704628, 'reg_alpha': 0.0063736480220318815, 'reg_lambda': 2.33607966864803}, 'config/n_estimators': 9, 'config/max_leaves': 4, 'config/min_child_weight': 0.10422622872469292, 'config/learning_rate': 1.0, 'config/subsample': 0.794741631646611, 'config/colsample_bylevel': 0.7539376453684443, 'config/colsample_bytree': 0.9485956837704628, 'config/reg_alpha': 0.0063736480220318815, 'config/reg_lambda': 2.33607966864803, 'experiment_tag': 'exp', 'time_total_s': 1.7624506950378418}\n",
      "[flaml.automl.logger: 09-22 09:36:25] {2391} INFO -  at 59.4s,\testimator xgboost's best error=0.2452,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:25] {2218} INFO - iteration 56, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:36:25] {805} INFO - trial 1 config: {'n_estimators': 36, 'max_features': 0.032427221756276076, 'max_leaves': 26, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:36:27] {197} INFO - result: {'pred_time': 7.045749385417468e-05, 'wall_clock_time': 60.73020315170288, 'metric_for_logging': {'pred_time': 7.045749385417468e-05}, 'val_loss': 0.23128626694968527, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397dc0>, 'training_iteration': 0, 'config': {'n_estimators': 36, 'max_features': 0.032427221756276076, 'max_leaves': 26, 'criterion': 'entropy'}, 'config/n_estimators': 36, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 26, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.3234903812408447}\n",
      "[flaml.tune.tune: 09-22 09:36:27] {197} INFO - result: {'pred_time': 7.045749385417468e-05, 'wall_clock_time': 60.73020315170288, 'metric_for_logging': {'pred_time': 7.045749385417468e-05}, 'val_loss': 0.23128626694968527, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397dc0>, 'training_iteration': 1, 'config': {'n_estimators': 36, 'max_features': 0.032427221756276076, 'max_leaves': 26, 'criterion': 'entropy'}, 'config/n_estimators': 36, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 26, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.3249454498291016}\n",
      "[flaml.automl.logger: 09-22 09:36:27] {2391} INFO -  at 60.7s,\testimator rf's best error=0.2313,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:27] {2218} INFO - iteration 57, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:36:27] {805} INFO - trial 1 config: {'n_estimators': 21, 'max_features': 0.032427221756276076, 'max_leaves': 21, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:36:27] {197} INFO - result: {'pred_time': 5.106497326136114e-05, 'wall_clock_time': 61.6541953086853, 'metric_for_logging': {'pred_time': 5.106497326136114e-05}, 'val_loss': 0.24985933921466152, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397730>, 'training_iteration': 0, 'config': {'n_estimators': 21, 'max_features': 0.032427221756276076, 'max_leaves': 21, 'criterion': 'gini'}, 'config/n_estimators': 21, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 21, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.9170951843261719}\n",
      "[flaml.tune.tune: 09-22 09:36:27] {197} INFO - result: {'pred_time': 5.106497326136114e-05, 'wall_clock_time': 61.6541953086853, 'metric_for_logging': {'pred_time': 5.106497326136114e-05}, 'val_loss': 0.24985933921466152, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397730>, 'training_iteration': 1, 'config': {'n_estimators': 21, 'max_features': 0.032427221756276076, 'max_leaves': 21, 'criterion': 'gini'}, 'config/n_estimators': 21, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 21, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.9189205169677734}\n",
      "[flaml.automl.logger: 09-22 09:36:27] {2391} INFO -  at 61.7s,\testimator rf's best error=0.2313,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:27] {2218} INFO - iteration 58, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:36:27] {805} INFO - trial 1 config: {'n_estimators': 25, 'max_leaves': 6, 'min_child_weight': 2.73397433954217, 'learning_rate': 0.42446153566346606, 'subsample': 1.0, 'colsample_bylevel': 0.841962961338617, 'colsample_bytree': 0.7512098613287459, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.279867081540575}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:36:30] {197} INFO - result: {'pred_time': 4.4786656539409604e-05, 'wall_clock_time': 64.29716324806213, 'metric_for_logging': {'pred_time': 4.4786656539409604e-05}, 'val_loss': 0.2449094536238464, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613397be0>, 'training_iteration': 0, 'config': {'n_estimators': 25, 'max_leaves': 6, 'min_child_weight': 2.73397433954217, 'learning_rate': 0.42446153566346606, 'subsample': 1.0, 'colsample_bylevel': 0.841962961338617, 'colsample_bytree': 0.7512098613287459, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.279867081540575}, 'config/n_estimators': 25, 'config/max_leaves': 6, 'config/min_child_weight': 2.73397433954217, 'config/learning_rate': 0.42446153566346606, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.841962961338617, 'config/colsample_bytree': 0.7512098613287459, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.279867081540575, 'experiment_tag': 'exp', 'time_total_s': 2.6329197883605957}\n",
      "[flaml.tune.tune: 09-22 09:36:30] {197} INFO - result: {'pred_time': 4.4786656539409604e-05, 'wall_clock_time': 64.29716324806213, 'metric_for_logging': {'pred_time': 4.4786656539409604e-05}, 'val_loss': 0.2449094536238464, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613397be0>, 'training_iteration': 1, 'config': {'n_estimators': 25, 'max_leaves': 6, 'min_child_weight': 2.73397433954217, 'learning_rate': 0.42446153566346606, 'subsample': 1.0, 'colsample_bylevel': 0.841962961338617, 'colsample_bytree': 0.7512098613287459, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.279867081540575}, 'config/n_estimators': 25, 'config/max_leaves': 6, 'config/min_child_weight': 2.73397433954217, 'config/learning_rate': 0.42446153566346606, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.841962961338617, 'config/colsample_bytree': 0.7512098613287459, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.279867081540575, 'experiment_tag': 'exp', 'time_total_s': 2.6345319747924805}\n",
      "[flaml.automl.logger: 09-22 09:36:30] {2391} INFO -  at 64.3s,\testimator xgboost's best error=0.2449,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:30] {2218} INFO - iteration 59, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:36:30] {805} INFO - trial 1 config: {'n_estimators': 78, 'num_leaves': 13, 'min_child_samples': 11, 'learning_rate': 0.717204436795498, 'log_max_bin': 8, 'colsample_bytree': 0.8406254356509558, 'reg_alpha': 0.0017271108100233477, 'reg_lambda': 0.4568414445572454}\n",
      "[flaml.tune.tune: 09-22 09:36:31] {197} INFO - result: {'pred_time': 1.3059176702825742e-05, 'wall_clock_time': 65.10469365119934, 'metric_for_logging': {'pred_time': 1.3059176702825742e-05}, 'val_loss': 0.21961083301038326, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6133976a0>, 'training_iteration': 0, 'config': {'n_estimators': 78, 'num_leaves': 13, 'min_child_samples': 11, 'learning_rate': 0.717204436795498, 'log_max_bin': 8, 'colsample_bytree': 0.8406254356509558, 'reg_alpha': 0.0017271108100233477, 'reg_lambda': 0.4568414445572454}, 'config/n_estimators': 78, 'config/num_leaves': 13, 'config/min_child_samples': 11, 'config/learning_rate': 0.717204436795498, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8406254356509558, 'config/reg_alpha': 0.0017271108100233477, 'config/reg_lambda': 0.4568414445572454, 'experiment_tag': 'exp', 'time_total_s': 0.7997586727142334}\n",
      "[flaml.tune.tune: 09-22 09:36:31] {197} INFO - result: {'pred_time': 1.3059176702825742e-05, 'wall_clock_time': 65.10469365119934, 'metric_for_logging': {'pred_time': 1.3059176702825742e-05}, 'val_loss': 0.21961083301038326, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6133976a0>, 'training_iteration': 1, 'config': {'n_estimators': 78, 'num_leaves': 13, 'min_child_samples': 11, 'learning_rate': 0.717204436795498, 'log_max_bin': 8, 'colsample_bytree': 0.8406254356509558, 'reg_alpha': 0.0017271108100233477, 'reg_lambda': 0.4568414445572454}, 'config/n_estimators': 78, 'config/num_leaves': 13, 'config/min_child_samples': 11, 'config/learning_rate': 0.717204436795498, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8406254356509558, 'config/reg_alpha': 0.0017271108100233477, 'config/reg_lambda': 0.4568414445572454, 'experiment_tag': 'exp', 'time_total_s': 0.80126953125}\n",
      "[flaml.automl.logger: 09-22 09:36:31] {2391} INFO -  at 65.1s,\testimator lgbm's best error=0.2059,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:31] {2218} INFO - iteration 60, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:36:31] {805} INFO - trial 1 config: {'n_estimators': 10, 'max_leaves': 11, 'min_child_weight': 2.3002955481543466, 'learning_rate': 1.0, 'subsample': 0.9728097438800569, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.7961300914414072, 'reg_alpha': 0.0030316436446129334, 'reg_lambda': 0.1544062642046082}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:36:33] {197} INFO - result: {'pred_time': 4.4937996607520156e-05, 'wall_clock_time': 66.98360991477966, 'metric_for_logging': {'pred_time': 4.4937996607520156e-05}, 'val_loss': 0.26922212836755566, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6133fbe50>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_leaves': 11, 'min_child_weight': 2.3002955481543466, 'learning_rate': 1.0, 'subsample': 0.9728097438800569, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.7961300914414072, 'reg_alpha': 0.0030316436446129334, 'reg_lambda': 0.1544062642046082}, 'config/n_estimators': 10, 'config/max_leaves': 11, 'config/min_child_weight': 2.3002955481543466, 'config/learning_rate': 1.0, 'config/subsample': 0.9728097438800569, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.7961300914414072, 'config/reg_alpha': 0.0030316436446129334, 'config/reg_lambda': 0.1544062642046082, 'experiment_tag': 'exp', 'time_total_s': 1.8701026439666748}\n",
      "[flaml.tune.tune: 09-22 09:36:33] {197} INFO - result: {'pred_time': 4.4937996607520156e-05, 'wall_clock_time': 66.98360991477966, 'metric_for_logging': {'pred_time': 4.4937996607520156e-05}, 'val_loss': 0.26922212836755566, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6133fbe50>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_leaves': 11, 'min_child_weight': 2.3002955481543466, 'learning_rate': 1.0, 'subsample': 0.9728097438800569, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.7961300914414072, 'reg_alpha': 0.0030316436446129334, 'reg_lambda': 0.1544062642046082}, 'config/n_estimators': 10, 'config/max_leaves': 11, 'config/min_child_weight': 2.3002955481543466, 'config/learning_rate': 1.0, 'config/subsample': 0.9728097438800569, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.7961300914414072, 'config/reg_alpha': 0.0030316436446129334, 'config/reg_lambda': 0.1544062642046082, 'experiment_tag': 'exp', 'time_total_s': 1.871274709701538}\n",
      "[flaml.automl.logger: 09-22 09:36:33] {2391} INFO -  at 67.0s,\testimator xgboost's best error=0.2449,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:33] {2218} INFO - iteration 61, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:36:33] {805} INFO - trial 1 config: {'n_estimators': 29, 'num_leaves': 21, 'min_child_samples': 9, 'learning_rate': 1.0, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0015564673105246884, 'reg_lambda': 0.5579966124152358}\n",
      "[flaml.tune.tune: 09-22 09:36:33] {197} INFO - result: {'pred_time': 1.2586370901577256e-05, 'wall_clock_time': 67.65403127670288, 'metric_for_logging': {'pred_time': 1.2586370901577256e-05}, 'val_loss': 0.2301610715778632, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6133fb130>, 'training_iteration': 0, 'config': {'n_estimators': 29, 'num_leaves': 21, 'min_child_samples': 9, 'learning_rate': 1.0, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0015564673105246884, 'reg_lambda': 0.5579966124152358}, 'config/n_estimators': 29, 'config/num_leaves': 21, 'config/min_child_samples': 9, 'config/learning_rate': 1.0, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0015564673105246884, 'config/reg_lambda': 0.5579966124152358, 'experiment_tag': 'exp', 'time_total_s': 0.6621444225311279}\n",
      "[flaml.tune.tune: 09-22 09:36:33] {197} INFO - result: {'pred_time': 1.2586370901577256e-05, 'wall_clock_time': 67.65403127670288, 'metric_for_logging': {'pred_time': 1.2586370901577256e-05}, 'val_loss': 0.2301610715778632, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6133fb130>, 'training_iteration': 1, 'config': {'n_estimators': 29, 'num_leaves': 21, 'min_child_samples': 9, 'learning_rate': 1.0, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0015564673105246884, 'reg_lambda': 0.5579966124152358}, 'config/n_estimators': 29, 'config/num_leaves': 21, 'config/min_child_samples': 9, 'config/learning_rate': 1.0, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0015564673105246884, 'config/reg_lambda': 0.5579966124152358, 'experiment_tag': 'exp', 'time_total_s': 0.663776159286499}\n",
      "[flaml.automl.logger: 09-22 09:36:33] {2391} INFO -  at 67.7s,\testimator lgbm's best error=0.2059,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:33] {2218} INFO - iteration 62, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:36:33] {805} INFO - trial 1 config: {'n_estimators': 60, 'max_leaves': 4, 'min_child_weight': 3.2494153611140617, 'learning_rate': 0.15560707746676394, 'subsample': 1.0, 'colsample_bylevel': 0.6602366975169772, 'colsample_bytree': 0.7062896312160846, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5072694669061312}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:36:37] {197} INFO - result: {'pred_time': 4.7635732004165785e-05, 'wall_clock_time': 71.65887475013733, 'metric_for_logging': {'pred_time': 4.7635732004165785e-05}, 'val_loss': 0.2475491291083495, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb61304efa0>, 'training_iteration': 0, 'config': {'n_estimators': 60, 'max_leaves': 4, 'min_child_weight': 3.2494153611140617, 'learning_rate': 0.15560707746676394, 'subsample': 1.0, 'colsample_bylevel': 0.6602366975169772, 'colsample_bytree': 0.7062896312160846, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5072694669061312}, 'config/n_estimators': 60, 'config/max_leaves': 4, 'config/min_child_weight': 3.2494153611140617, 'config/learning_rate': 0.15560707746676394, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.6602366975169772, 'config/colsample_bytree': 0.7062896312160846, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5072694669061312, 'experiment_tag': 'exp', 'time_total_s': 3.9967520236968994}\n",
      "[flaml.tune.tune: 09-22 09:36:37] {197} INFO - result: {'pred_time': 4.7635732004165785e-05, 'wall_clock_time': 71.65887475013733, 'metric_for_logging': {'pred_time': 4.7635732004165785e-05}, 'val_loss': 0.2475491291083495, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb61304efa0>, 'training_iteration': 1, 'config': {'n_estimators': 60, 'max_leaves': 4, 'min_child_weight': 3.2494153611140617, 'learning_rate': 0.15560707746676394, 'subsample': 1.0, 'colsample_bylevel': 0.6602366975169772, 'colsample_bytree': 0.7062896312160846, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5072694669061312}, 'config/n_estimators': 60, 'config/max_leaves': 4, 'config/min_child_weight': 3.2494153611140617, 'config/learning_rate': 0.15560707746676394, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.6602366975169772, 'config/colsample_bytree': 0.7062896312160846, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5072694669061312, 'experiment_tag': 'exp', 'time_total_s': 3.9982893466949463}\n",
      "[flaml.automl.logger: 09-22 09:36:37] {2391} INFO -  at 71.7s,\testimator xgboost's best error=0.2449,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:37] {2218} INFO - iteration 63, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:36:37] {805} INFO - trial 1 config: {'n_estimators': 16, 'max_leaves': 4, 'min_child_weight': 19.042454227847614, 'learning_rate': 0.25445569037444943, 'subsample': 0.9827721799620315, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8353833330765148, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5369588335339861}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:36:40] {197} INFO - result: {'pred_time': 4.76591939566766e-05, 'wall_clock_time': 73.93634295463562, 'metric_for_logging': {'pred_time': 4.76591939566766e-05}, 'val_loss': 0.28414628444613454, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb61304e4c0>, 'training_iteration': 0, 'config': {'n_estimators': 16, 'max_leaves': 4, 'min_child_weight': 19.042454227847614, 'learning_rate': 0.25445569037444943, 'subsample': 0.9827721799620315, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8353833330765148, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5369588335339861}, 'config/n_estimators': 16, 'config/max_leaves': 4, 'config/min_child_weight': 19.042454227847614, 'config/learning_rate': 0.25445569037444943, 'config/subsample': 0.9827721799620315, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.8353833330765148, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5369588335339861, 'experiment_tag': 'exp', 'time_total_s': 2.268583059310913}\n",
      "[flaml.tune.tune: 09-22 09:36:40] {197} INFO - result: {'pred_time': 4.76591939566766e-05, 'wall_clock_time': 73.93634295463562, 'metric_for_logging': {'pred_time': 4.76591939566766e-05}, 'val_loss': 0.28414628444613454, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb61304e4c0>, 'training_iteration': 1, 'config': {'n_estimators': 16, 'max_leaves': 4, 'min_child_weight': 19.042454227847614, 'learning_rate': 0.25445569037444943, 'subsample': 0.9827721799620315, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8353833330765148, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5369588335339861}, 'config/n_estimators': 16, 'config/max_leaves': 4, 'config/min_child_weight': 19.042454227847614, 'config/learning_rate': 0.25445569037444943, 'config/subsample': 0.9827721799620315, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.8353833330765148, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5369588335339861, 'experiment_tag': 'exp', 'time_total_s': 2.2702534198760986}\n",
      "[flaml.automl.logger: 09-22 09:36:40] {2391} INFO -  at 73.9s,\testimator xgboost's best error=0.2449,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-22 09:36:40] {2218} INFO - iteration 64, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:36:40] {805} INFO - trial 1 config: {'n_estimators': 90, 'num_leaves': 70, 'min_child_samples': 7, 'learning_rate': 0.20466906793634726, 'log_max_bin': 9, 'colsample_bytree': 0.7749909456010404, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3192797038889443}\n",
      "[flaml.tune.tune: 09-22 09:36:42] {197} INFO - result: {'pred_time': 1.5465927193483407e-05, 'wall_clock_time': 75.81228518486023, 'metric_for_logging': {'pred_time': 1.5465927193483407e-05}, 'val_loss': 0.19715560618858974, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb61304ef70>, 'training_iteration': 0, 'config': {'n_estimators': 90, 'num_leaves': 70, 'min_child_samples': 7, 'learning_rate': 0.20466906793634726, 'log_max_bin': 9, 'colsample_bytree': 0.7749909456010404, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3192797038889443}, 'config/n_estimators': 90, 'config/num_leaves': 70, 'config/min_child_samples': 7, 'config/learning_rate': 0.20466906793634726, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7749909456010404, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.3192797038889443, 'experiment_tag': 'exp', 'time_total_s': 1.8670828342437744}\n",
      "[flaml.tune.tune: 09-22 09:36:42] {197} INFO - result: {'pred_time': 1.5465927193483407e-05, 'wall_clock_time': 75.81228518486023, 'metric_for_logging': {'pred_time': 1.5465927193483407e-05}, 'val_loss': 0.19715560618858974, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb61304ef70>, 'training_iteration': 1, 'config': {'n_estimators': 90, 'num_leaves': 70, 'min_child_samples': 7, 'learning_rate': 0.20466906793634726, 'log_max_bin': 9, 'colsample_bytree': 0.7749909456010404, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3192797038889443}, 'config/n_estimators': 90, 'config/num_leaves': 70, 'config/min_child_samples': 7, 'config/learning_rate': 0.20466906793634726, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7749909456010404, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.3192797038889443, 'experiment_tag': 'exp', 'time_total_s': 1.8683295249938965}\n",
      "[flaml.automl.logger: 09-22 09:36:42] {2391} INFO -  at 75.8s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:36:42] {2218} INFO - iteration 65, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:36:42] {805} INFO - trial 1 config: {'n_estimators': 61, 'max_features': 0.0425346962238793, 'max_leaves': 33, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:36:44] {197} INFO - result: {'pred_time': 0.00011103562396019193, 'wall_clock_time': 78.00628900527954, 'metric_for_logging': {'pred_time': 0.00011103562396019193}, 'val_loss': 0.21678672098462207, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6134037f0>, 'training_iteration': 0, 'config': {'n_estimators': 61, 'max_features': 0.0425346962238793, 'max_leaves': 33, 'criterion': 'entropy'}, 'config/n_estimators': 61, 'config/max_features': 0.0425346962238793, 'config/max_leaves': 33, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.185858964920044}\n",
      "[flaml.tune.tune: 09-22 09:36:44] {197} INFO - result: {'pred_time': 0.00011103562396019193, 'wall_clock_time': 78.00628900527954, 'metric_for_logging': {'pred_time': 0.00011103562396019193}, 'val_loss': 0.21678672098462207, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6134037f0>, 'training_iteration': 1, 'config': {'n_estimators': 61, 'max_features': 0.0425346962238793, 'max_leaves': 33, 'criterion': 'entropy'}, 'config/n_estimators': 61, 'config/max_features': 0.0425346962238793, 'config/max_leaves': 33, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.187613010406494}\n",
      "[flaml.automl.logger: 09-22 09:36:44] {2391} INFO -  at 78.0s,\testimator rf's best error=0.2168,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:36:44] {2218} INFO - iteration 66, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:36:44] {805} INFO - trial 1 config: {'n_estimators': 39, 'max_leaves': 9, 'min_child_weight': 0.3925237576963254, 'learning_rate': 0.7080509576840613, 'subsample': 1.0, 'colsample_bylevel': 0.6511224730099325, 'colsample_bytree': 0.667036389580977, 'reg_alpha': 0.0017607866203119683, 'reg_lambda': 0.14586887939721607}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:36:48] {197} INFO - result: {'pred_time': 5.2428013426206375e-05, 'wall_clock_time': 81.80884456634521, 'metric_for_logging': {'pred_time': 5.2428013426206375e-05}, 'val_loss': 0.23953685838993186, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6133fb460>, 'training_iteration': 0, 'config': {'n_estimators': 39, 'max_leaves': 9, 'min_child_weight': 0.3925237576963254, 'learning_rate': 0.7080509576840613, 'subsample': 1.0, 'colsample_bylevel': 0.6511224730099325, 'colsample_bytree': 0.667036389580977, 'reg_alpha': 0.0017607866203119683, 'reg_lambda': 0.14586887939721607}, 'config/n_estimators': 39, 'config/max_leaves': 9, 'config/min_child_weight': 0.3925237576963254, 'config/learning_rate': 0.7080509576840613, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.6511224730099325, 'config/colsample_bytree': 0.667036389580977, 'config/reg_alpha': 0.0017607866203119683, 'config/reg_lambda': 0.14586887939721607, 'experiment_tag': 'exp', 'time_total_s': 3.793870449066162}\n",
      "[flaml.tune.tune: 09-22 09:36:48] {197} INFO - result: {'pred_time': 5.2428013426206375e-05, 'wall_clock_time': 81.80884456634521, 'metric_for_logging': {'pred_time': 5.2428013426206375e-05}, 'val_loss': 0.23953685838993186, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6133fb460>, 'training_iteration': 1, 'config': {'n_estimators': 39, 'max_leaves': 9, 'min_child_weight': 0.3925237576963254, 'learning_rate': 0.7080509576840613, 'subsample': 1.0, 'colsample_bylevel': 0.6511224730099325, 'colsample_bytree': 0.667036389580977, 'reg_alpha': 0.0017607866203119683, 'reg_lambda': 0.14586887939721607}, 'config/n_estimators': 39, 'config/max_leaves': 9, 'config/min_child_weight': 0.3925237576963254, 'config/learning_rate': 0.7080509576840613, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.6511224730099325, 'config/colsample_bytree': 0.667036389580977, 'config/reg_alpha': 0.0017607866203119683, 'config/reg_lambda': 0.14586887939721607, 'experiment_tag': 'exp', 'time_total_s': 3.7953202724456787}\n",
      "[flaml.automl.logger: 09-22 09:36:48] {2391} INFO -  at 81.8s,\testimator xgboost's best error=0.2395,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:36:48] {2218} INFO - iteration 67, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:36:48] {805} INFO - trial 1 config: {'n_estimators': 22, 'max_features': 0.0463791873421922, 'max_leaves': 51, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:36:49] {197} INFO - result: {'pred_time': 5.2250836650462916e-05, 'wall_clock_time': 82.83742880821228, 'metric_for_logging': {'pred_time': 5.2250836650462916e-05}, 'val_loss': 0.23814156244815915, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397be0>, 'training_iteration': 0, 'config': {'n_estimators': 22, 'max_features': 0.0463791873421922, 'max_leaves': 51, 'criterion': 'entropy'}, 'config/n_estimators': 22, 'config/max_features': 0.0463791873421922, 'config/max_leaves': 51, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.0206506252288818}\n",
      "[flaml.tune.tune: 09-22 09:36:49] {197} INFO - result: {'pred_time': 5.2250836650462916e-05, 'wall_clock_time': 82.83742880821228, 'metric_for_logging': {'pred_time': 5.2250836650462916e-05}, 'val_loss': 0.23814156244815915, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb613397be0>, 'training_iteration': 1, 'config': {'n_estimators': 22, 'max_features': 0.0463791873421922, 'max_leaves': 51, 'criterion': 'entropy'}, 'config/n_estimators': 22, 'config/max_features': 0.0463791873421922, 'config/max_leaves': 51, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.022125005722046}\n",
      "[flaml.automl.logger: 09-22 09:36:49] {2391} INFO -  at 82.8s,\testimator rf's best error=0.2168,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:36:49] {2218} INFO - iteration 68, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:36:49] {805} INFO - trial 1 config: {'n_estimators': 152, 'num_leaves': 39, 'min_child_samples': 3, 'learning_rate': 0.2528431582281467, 'log_max_bin': 10, 'colsample_bytree': 0.8251789580300279, 'reg_alpha': 0.004577823970660193, 'reg_lambda': 2.8288672134668276}\n",
      "[flaml.tune.tune: 09-22 09:36:51] {197} INFO - result: {'pred_time': 1.8080855682614354e-05, 'wall_clock_time': 84.98080158233643, 'metric_for_logging': {'pred_time': 1.8080855682614354e-05}, 'val_loss': 0.21041223151418054, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6133fb400>, 'training_iteration': 0, 'config': {'n_estimators': 152, 'num_leaves': 39, 'min_child_samples': 3, 'learning_rate': 0.2528431582281467, 'log_max_bin': 10, 'colsample_bytree': 0.8251789580300279, 'reg_alpha': 0.004577823970660193, 'reg_lambda': 2.8288672134668276}, 'config/n_estimators': 152, 'config/num_leaves': 39, 'config/min_child_samples': 3, 'config/learning_rate': 0.2528431582281467, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8251789580300279, 'config/reg_alpha': 0.004577823970660193, 'config/reg_lambda': 2.8288672134668276, 'experiment_tag': 'exp', 'time_total_s': 2.135347843170166}\n",
      "[flaml.tune.tune: 09-22 09:36:51] {197} INFO - result: {'pred_time': 1.8080855682614354e-05, 'wall_clock_time': 84.98080158233643, 'metric_for_logging': {'pred_time': 1.8080855682614354e-05}, 'val_loss': 0.21041223151418054, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6133fb400>, 'training_iteration': 1, 'config': {'n_estimators': 152, 'num_leaves': 39, 'min_child_samples': 3, 'learning_rate': 0.2528431582281467, 'log_max_bin': 10, 'colsample_bytree': 0.8251789580300279, 'reg_alpha': 0.004577823970660193, 'reg_lambda': 2.8288672134668276}, 'config/n_estimators': 152, 'config/num_leaves': 39, 'config/min_child_samples': 3, 'config/learning_rate': 0.2528431582281467, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8251789580300279, 'config/reg_alpha': 0.004577823970660193, 'config/reg_lambda': 2.8288672134668276, 'experiment_tag': 'exp', 'time_total_s': 2.1367340087890625}\n",
      "[flaml.automl.logger: 09-22 09:36:51] {2391} INFO -  at 85.0s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:36:51] {2218} INFO - iteration 69, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:36:51] {805} INFO - trial 1 config: {'n_estimators': 166, 'max_features': 0.039008884944644585, 'max_leaves': 22, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:36:56] {197} INFO - result: {'pred_time': 0.00027105321733449306, 'wall_clock_time': 90.2917411327362, 'metric_for_logging': {'pred_time': 0.00027105321733449306}, 'val_loss': 0.22886635337909703, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6133fb910>, 'training_iteration': 0, 'config': {'n_estimators': 166, 'max_features': 0.039008884944644585, 'max_leaves': 22, 'criterion': 'gini'}, 'config/n_estimators': 166, 'config/max_features': 0.039008884944644585, 'config/max_leaves': 22, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 5.30186915397644}\n",
      "[flaml.tune.tune: 09-22 09:36:56] {197} INFO - result: {'pred_time': 0.00027105321733449306, 'wall_clock_time': 90.2917411327362, 'metric_for_logging': {'pred_time': 0.00027105321733449306}, 'val_loss': 0.22886635337909703, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6133fb910>, 'training_iteration': 1, 'config': {'n_estimators': 166, 'max_features': 0.039008884944644585, 'max_leaves': 22, 'criterion': 'gini'}, 'config/n_estimators': 166, 'config/max_features': 0.039008884944644585, 'config/max_leaves': 22, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 5.303113698959351}\n",
      "[flaml.automl.logger: 09-22 09:36:56] {2391} INFO -  at 90.3s,\testimator rf's best error=0.2168,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:36:56] {2218} INFO - iteration 70, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:36:56] {805} INFO - trial 1 config: {'n_estimators': 34, 'max_features': 0.05391196221275601, 'max_leaves': 36, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:36:57] {197} INFO - result: {'pred_time': 6.625347335929343e-05, 'wall_clock_time': 91.49884843826294, 'metric_for_logging': {'pred_time': 6.625347335929343e-05}, 'val_loss': 0.2589976191737811, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb61304e2b0>, 'training_iteration': 0, 'config': {'n_estimators': 34, 'max_features': 0.05391196221275601, 'max_leaves': 36, 'criterion': 'gini'}, 'config/n_estimators': 34, 'config/max_features': 0.05391196221275601, 'config/max_leaves': 36, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.1991372108459473}\n",
      "[flaml.tune.tune: 09-22 09:36:57] {197} INFO - result: {'pred_time': 6.625347335929343e-05, 'wall_clock_time': 91.49884843826294, 'metric_for_logging': {'pred_time': 6.625347335929343e-05}, 'val_loss': 0.2589976191737811, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb61304e2b0>, 'training_iteration': 1, 'config': {'n_estimators': 34, 'max_features': 0.05391196221275601, 'max_leaves': 36, 'criterion': 'gini'}, 'config/n_estimators': 34, 'config/max_features': 0.05391196221275601, 'config/max_leaves': 36, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.2011432647705078}\n",
      "[flaml.automl.logger: 09-22 09:36:57] {2391} INFO -  at 91.5s,\testimator extra_tree's best error=0.2178,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:36:57] {2218} INFO - iteration 71, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:36:57] {805} INFO - trial 1 config: {'n_estimators': 46, 'max_features': 0.05322276111861016, 'max_leaves': 81, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:36:59] {197} INFO - result: {'pred_time': 8.247468564642256e-05, 'wall_clock_time': 93.22225522994995, 'metric_for_logging': {'pred_time': 8.247468564642256e-05}, 'val_loss': 0.20544409448082607, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb61304ec40>, 'training_iteration': 0, 'config': {'n_estimators': 46, 'max_features': 0.05322276111861016, 'max_leaves': 81, 'criterion': 'entropy'}, 'config/n_estimators': 46, 'config/max_features': 0.05322276111861016, 'config/max_leaves': 81, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.715392827987671}\n",
      "[flaml.tune.tune: 09-22 09:36:59] {197} INFO - result: {'pred_time': 8.247468564642256e-05, 'wall_clock_time': 93.22225522994995, 'metric_for_logging': {'pred_time': 8.247468564642256e-05}, 'val_loss': 0.20544409448082607, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb61304ec40>, 'training_iteration': 1, 'config': {'n_estimators': 46, 'max_features': 0.05322276111861016, 'max_leaves': 81, 'criterion': 'entropy'}, 'config/n_estimators': 46, 'config/max_features': 0.05322276111861016, 'config/max_leaves': 81, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.7171986103057861}\n",
      "[flaml.automl.logger: 09-22 09:36:59] {2391} INFO -  at 93.2s,\testimator rf's best error=0.2054,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:36:59] {2218} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:36:59] {805} INFO - trial 1 config: {'n_estimators': 13, 'max_features': 0.042431336962006815, 'max_leaves': 106, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:37:00] {197} INFO - result: {'pred_time': 4.1785471681944975e-05, 'wall_clock_time': 93.99772787094116, 'metric_for_logging': {'pred_time': 4.1785471681944975e-05}, 'val_loss': 0.24954604298682265, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613045af0>, 'training_iteration': 0, 'config': {'n_estimators': 13, 'max_features': 0.042431336962006815, 'max_leaves': 106, 'criterion': 'entropy'}, 'config/n_estimators': 13, 'config/max_features': 0.042431336962006815, 'config/max_leaves': 106, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7671983242034912}\n",
      "[flaml.tune.tune: 09-22 09:37:00] {197} INFO - result: {'pred_time': 4.1785471681944975e-05, 'wall_clock_time': 93.99772787094116, 'metric_for_logging': {'pred_time': 4.1785471681944975e-05}, 'val_loss': 0.24954604298682265, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613045af0>, 'training_iteration': 1, 'config': {'n_estimators': 13, 'max_features': 0.042431336962006815, 'max_leaves': 106, 'criterion': 'entropy'}, 'config/n_estimators': 13, 'config/max_features': 0.042431336962006815, 'config/max_leaves': 106, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7686960697174072}\n",
      "[flaml.automl.logger: 09-22 09:37:00] {2391} INFO -  at 94.0s,\testimator extra_tree's best error=0.2178,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:00] {2218} INFO - iteration 73, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:37:00] {805} INFO - trial 1 config: {'n_estimators': 22, 'max_leaves': 5, 'min_child_weight': 0.536080133994739, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.8033661308483006, 'colsample_bytree': 0.7015002807960694, 'reg_alpha': 0.0011278602966694493, 'reg_lambda': 0.3601200978211006}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:37:04] {197} INFO - result: {'pred_time': 6.14958704742931e-05, 'wall_clock_time': 97.99764728546143, 'metric_for_logging': {'pred_time': 6.14958704742931e-05}, 'val_loss': 0.2556985713657378, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613397a00>, 'training_iteration': 0, 'config': {'n_estimators': 22, 'max_leaves': 5, 'min_child_weight': 0.536080133994739, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.8033661308483006, 'colsample_bytree': 0.7015002807960694, 'reg_alpha': 0.0011278602966694493, 'reg_lambda': 0.3601200978211006}, 'config/n_estimators': 22, 'config/max_leaves': 5, 'config/min_child_weight': 0.536080133994739, 'config/learning_rate': 1.0, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8033661308483006, 'config/colsample_bytree': 0.7015002807960694, 'config/reg_alpha': 0.0011278602966694493, 'config/reg_lambda': 0.3601200978211006, 'experiment_tag': 'exp', 'time_total_s': 3.9932055473327637}\n",
      "[flaml.tune.tune: 09-22 09:37:04] {197} INFO - result: {'pred_time': 6.14958704742931e-05, 'wall_clock_time': 97.99764728546143, 'metric_for_logging': {'pred_time': 6.14958704742931e-05}, 'val_loss': 0.2556985713657378, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613397a00>, 'training_iteration': 1, 'config': {'n_estimators': 22, 'max_leaves': 5, 'min_child_weight': 0.536080133994739, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.8033661308483006, 'colsample_bytree': 0.7015002807960694, 'reg_alpha': 0.0011278602966694493, 'reg_lambda': 0.3601200978211006}, 'config/n_estimators': 22, 'config/max_leaves': 5, 'config/min_child_weight': 0.536080133994739, 'config/learning_rate': 1.0, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8033661308483006, 'config/colsample_bytree': 0.7015002807960694, 'config/reg_alpha': 0.0011278602966694493, 'config/reg_lambda': 0.3601200978211006, 'experiment_tag': 'exp', 'time_total_s': 3.994906187057495}\n",
      "[flaml.automl.logger: 09-22 09:37:04] {2391} INFO -  at 98.0s,\testimator xgboost's best error=0.2395,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:04] {2218} INFO - iteration 74, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:37:04] {805} INFO - trial 1 config: {'n_estimators': 51, 'max_features': 0.10724861527749564, 'max_leaves': 73, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:37:06] {197} INFO - result: {'pred_time': 9.010016612678577e-05, 'wall_clock_time': 100.29753041267395, 'metric_for_logging': {'pred_time': 9.010016612678577e-05}, 'val_loss': 0.23896158296458153, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133976a0>, 'training_iteration': 0, 'config': {'n_estimators': 51, 'max_features': 0.10724861527749564, 'max_leaves': 73, 'criterion': 'gini'}, 'config/n_estimators': 51, 'config/max_features': 0.10724861527749564, 'config/max_leaves': 73, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.292464017868042}\n",
      "[flaml.tune.tune: 09-22 09:37:06] {197} INFO - result: {'pred_time': 9.010016612678577e-05, 'wall_clock_time': 100.29753041267395, 'metric_for_logging': {'pred_time': 9.010016612678577e-05}, 'val_loss': 0.23896158296458153, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133976a0>, 'training_iteration': 1, 'config': {'n_estimators': 51, 'max_features': 0.10724861527749564, 'max_leaves': 73, 'criterion': 'gini'}, 'config/n_estimators': 51, 'config/max_features': 0.10724861527749564, 'config/max_leaves': 73, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.2940685749053955}\n",
      "[flaml.automl.logger: 09-22 09:37:06] {2391} INFO -  at 100.3s,\testimator extra_tree's best error=0.2178,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:06] {2218} INFO - iteration 75, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:37:06] {805} INFO - trial 1 config: {'n_estimators': 53, 'num_leaves': 126, 'min_child_samples': 16, 'learning_rate': 0.16567356484344836, 'log_max_bin': 8, 'colsample_bytree': 0.724802933172053, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.615263568684897}\n",
      "[flaml.tune.tune: 09-22 09:37:07] {197} INFO - result: {'pred_time': 1.4991011268517917e-05, 'wall_clock_time': 101.47584366798401, 'metric_for_logging': {'pred_time': 1.4991011268517917e-05}, 'val_loss': 0.2129624723327872, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397730>, 'training_iteration': 0, 'config': {'n_estimators': 53, 'num_leaves': 126, 'min_child_samples': 16, 'learning_rate': 0.16567356484344836, 'log_max_bin': 8, 'colsample_bytree': 0.724802933172053, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.615263568684897}, 'config/n_estimators': 53, 'config/num_leaves': 126, 'config/min_child_samples': 16, 'config/learning_rate': 0.16567356484344836, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.724802933172053, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.615263568684897, 'experiment_tag': 'exp', 'time_total_s': 1.17014479637146}\n",
      "[flaml.tune.tune: 09-22 09:37:07] {197} INFO - result: {'pred_time': 1.4991011268517917e-05, 'wall_clock_time': 101.47584366798401, 'metric_for_logging': {'pred_time': 1.4991011268517917e-05}, 'val_loss': 0.2129624723327872, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397730>, 'training_iteration': 1, 'config': {'n_estimators': 53, 'num_leaves': 126, 'min_child_samples': 16, 'learning_rate': 0.16567356484344836, 'log_max_bin': 8, 'colsample_bytree': 0.724802933172053, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.615263568684897}, 'config/n_estimators': 53, 'config/num_leaves': 126, 'config/min_child_samples': 16, 'config/learning_rate': 0.16567356484344836, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.724802933172053, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.615263568684897, 'experiment_tag': 'exp', 'time_total_s': 1.172114610671997}\n",
      "[flaml.automl.logger: 09-22 09:37:07] {2391} INFO -  at 101.5s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:07] {2218} INFO - iteration 76, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:37:07] {805} INFO - trial 1 config: {'n_estimators': 117, 'num_leaves': 32, 'min_child_samples': 7, 'learning_rate': 0.08299817666065698, 'log_max_bin': 9, 'colsample_bytree': 0.9826080761242381, 'reg_alpha': 0.001346442339014509, 'reg_lambda': 2.345883690252503}\n",
      "[flaml.tune.tune: 09-22 09:37:09] {197} INFO - result: {'pred_time': 1.8404290033251978e-05, 'wall_clock_time': 103.33973741531372, 'metric_for_logging': {'pred_time': 1.8404290033251978e-05}, 'val_loss': 0.20109939399669535, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397040>, 'training_iteration': 0, 'config': {'n_estimators': 117, 'num_leaves': 32, 'min_child_samples': 7, 'learning_rate': 0.08299817666065698, 'log_max_bin': 9, 'colsample_bytree': 0.9826080761242381, 'reg_alpha': 0.001346442339014509, 'reg_lambda': 2.345883690252503}, 'config/n_estimators': 117, 'config/num_leaves': 32, 'config/min_child_samples': 7, 'config/learning_rate': 0.08299817666065698, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.9826080761242381, 'config/reg_alpha': 0.001346442339014509, 'config/reg_lambda': 2.345883690252503, 'experiment_tag': 'exp', 'time_total_s': 1.8547868728637695}\n",
      "[flaml.tune.tune: 09-22 09:37:09] {197} INFO - result: {'pred_time': 1.8404290033251978e-05, 'wall_clock_time': 103.33973741531372, 'metric_for_logging': {'pred_time': 1.8404290033251978e-05}, 'val_loss': 0.20109939399669535, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb613397040>, 'training_iteration': 1, 'config': {'n_estimators': 117, 'num_leaves': 32, 'min_child_samples': 7, 'learning_rate': 0.08299817666065698, 'log_max_bin': 9, 'colsample_bytree': 0.9826080761242381, 'reg_alpha': 0.001346442339014509, 'reg_lambda': 2.345883690252503}, 'config/n_estimators': 117, 'config/num_leaves': 32, 'config/min_child_samples': 7, 'config/learning_rate': 0.08299817666065698, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.9826080761242381, 'config/reg_alpha': 0.001346442339014509, 'config/reg_lambda': 2.345883690252503, 'experiment_tag': 'exp', 'time_total_s': 1.8562545776367188}\n",
      "[flaml.automl.logger: 09-22 09:37:09] {2391} INFO -  at 103.3s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:09] {2218} INFO - iteration 77, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:37:09] {805} INFO - trial 1 config: {'n_estimators': 25, 'max_features': 0.12888040862416833, 'max_leaves': 118, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:37:11] {197} INFO - result: {'pred_time': 5.520592881338214e-05, 'wall_clock_time': 104.94784426689148, 'metric_for_logging': {'pred_time': 5.520592881338214e-05}, 'val_loss': 0.2118189735693484, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613397d30>, 'training_iteration': 0, 'config': {'n_estimators': 25, 'max_features': 0.12888040862416833, 'max_leaves': 118, 'criterion': 'entropy'}, 'config/n_estimators': 25, 'config/max_features': 0.12888040862416833, 'config/max_leaves': 118, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.5990498065948486}\n",
      "[flaml.tune.tune: 09-22 09:37:11] {197} INFO - result: {'pred_time': 5.520592881338214e-05, 'wall_clock_time': 104.94784426689148, 'metric_for_logging': {'pred_time': 5.520592881338214e-05}, 'val_loss': 0.2118189735693484, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613397d30>, 'training_iteration': 1, 'config': {'n_estimators': 25, 'max_features': 0.12888040862416833, 'max_leaves': 118, 'criterion': 'entropy'}, 'config/n_estimators': 25, 'config/max_features': 0.12888040862416833, 'config/max_leaves': 118, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.6007485389709473}\n",
      "[flaml.automl.logger: 09-22 09:37:11] {2391} INFO -  at 104.9s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:11] {2218} INFO - iteration 78, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:37:11] {805} INFO - trial 1 config: {'n_estimators': 60, 'max_features': 0.0425346962238793, 'max_leaves': 33, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:37:14] {197} INFO - result: {'pred_time': 0.00015044343262269702, 'wall_clock_time': 108.16802382469177, 'metric_for_logging': {'pred_time': 0.00015044343262269702}, 'val_loss': 0.2205911250888762, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6133fb520>, 'training_iteration': 0, 'config': {'n_estimators': 60, 'max_features': 0.0425346962238793, 'max_leaves': 33, 'criterion': 'gini'}, 'config/n_estimators': 60, 'config/max_features': 0.0425346962238793, 'config/max_leaves': 33, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.211693048477173}\n",
      "[flaml.tune.tune: 09-22 09:37:14] {197} INFO - result: {'pred_time': 0.00015044343262269702, 'wall_clock_time': 108.16802382469177, 'metric_for_logging': {'pred_time': 0.00015044343262269702}, 'val_loss': 0.2205911250888762, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6133fb520>, 'training_iteration': 1, 'config': {'n_estimators': 60, 'max_features': 0.0425346962238793, 'max_leaves': 33, 'criterion': 'gini'}, 'config/n_estimators': 60, 'config/max_features': 0.0425346962238793, 'config/max_leaves': 33, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.213367462158203}\n",
      "[flaml.automl.logger: 09-22 09:37:14] {2391} INFO -  at 108.2s,\testimator rf's best error=0.2054,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:14] {2218} INFO - iteration 79, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:37:14] {805} INFO - trial 1 config: {'n_estimators': 69, 'num_leaves': 154, 'min_child_samples': 7, 'learning_rate': 0.5047029833101101, 'log_max_bin': 9, 'colsample_bytree': 0.5673738150778428, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.7419374388957709}\n",
      "[flaml.tune.tune: 09-22 09:37:17] {197} INFO - result: {'pred_time': 1.8088234603751604e-05, 'wall_clock_time': 110.79062843322754, 'metric_for_logging': {'pred_time': 1.8088234603751604e-05}, 'val_loss': 0.21094595633576146, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6133f93d0>, 'training_iteration': 0, 'config': {'n_estimators': 69, 'num_leaves': 154, 'min_child_samples': 7, 'learning_rate': 0.5047029833101101, 'log_max_bin': 9, 'colsample_bytree': 0.5673738150778428, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.7419374388957709}, 'config/n_estimators': 69, 'config/num_leaves': 154, 'config/min_child_samples': 7, 'config/learning_rate': 0.5047029833101101, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.5673738150778428, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.7419374388957709, 'experiment_tag': 'exp', 'time_total_s': 2.61350679397583}\n",
      "[flaml.tune.tune: 09-22 09:37:17] {197} INFO - result: {'pred_time': 1.8088234603751604e-05, 'wall_clock_time': 110.79062843322754, 'metric_for_logging': {'pred_time': 1.8088234603751604e-05}, 'val_loss': 0.21094595633576146, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6133f93d0>, 'training_iteration': 1, 'config': {'n_estimators': 69, 'num_leaves': 154, 'min_child_samples': 7, 'learning_rate': 0.5047029833101101, 'log_max_bin': 9, 'colsample_bytree': 0.5673738150778428, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.7419374388957709}, 'config/n_estimators': 69, 'config/num_leaves': 154, 'config/min_child_samples': 7, 'config/learning_rate': 0.5047029833101101, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.5673738150778428, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.7419374388957709, 'experiment_tag': 'exp', 'time_total_s': 2.615828514099121}\n",
      "[flaml.automl.logger: 09-22 09:37:17] {2391} INFO -  at 110.8s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:17] {2218} INFO - iteration 80, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:37:17] {805} INFO - trial 1 config: {'n_estimators': 26, 'max_features': 0.06745889217551715, 'max_leaves': 88, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:37:18] {197} INFO - result: {'pred_time': 5.814809883543865e-05, 'wall_clock_time': 112.07669806480408, 'metric_for_logging': {'pred_time': 5.814809883543865e-05}, 'val_loss': 0.2289348828704151, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133f9df0>, 'training_iteration': 0, 'config': {'n_estimators': 26, 'max_features': 0.06745889217551715, 'max_leaves': 88, 'criterion': 'gini'}, 'config/n_estimators': 26, 'config/max_features': 0.06745889217551715, 'config/max_leaves': 88, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.2771248817443848}\n",
      "[flaml.tune.tune: 09-22 09:37:18] {197} INFO - result: {'pred_time': 5.814809883543865e-05, 'wall_clock_time': 112.07669806480408, 'metric_for_logging': {'pred_time': 5.814809883543865e-05}, 'val_loss': 0.2289348828704151, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133f9df0>, 'training_iteration': 1, 'config': {'n_estimators': 26, 'max_features': 0.06745889217551715, 'max_leaves': 88, 'criterion': 'gini'}, 'config/n_estimators': 26, 'config/max_features': 0.06745889217551715, 'config/max_leaves': 88, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.2782840728759766}\n",
      "[flaml.automl.logger: 09-22 09:37:18] {2391} INFO -  at 112.1s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:18] {2218} INFO - iteration 81, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:37:18] {805} INFO - trial 1 config: {'n_estimators': 24, 'max_features': 0.033476875149333556, 'max_leaves': 98, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:37:19] {197} INFO - result: {'pred_time': 6.470709988221494e-05, 'wall_clock_time': 113.34542107582092, 'metric_for_logging': {'pred_time': 6.470709988221494e-05}, 'val_loss': 0.21591690294838725, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6133fbd90>, 'training_iteration': 0, 'config': {'n_estimators': 24, 'max_features': 0.033476875149333556, 'max_leaves': 98, 'criterion': 'entropy'}, 'config/n_estimators': 24, 'config/max_features': 0.033476875149333556, 'config/max_leaves': 98, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2621443271636963}\n",
      "[flaml.tune.tune: 09-22 09:37:19] {197} INFO - result: {'pred_time': 6.470709988221494e-05, 'wall_clock_time': 113.34542107582092, 'metric_for_logging': {'pred_time': 6.470709988221494e-05}, 'val_loss': 0.21591690294838725, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6133fbd90>, 'training_iteration': 1, 'config': {'n_estimators': 24, 'max_features': 0.033476875149333556, 'max_leaves': 98, 'criterion': 'entropy'}, 'config/n_estimators': 24, 'config/max_features': 0.033476875149333556, 'config/max_leaves': 98, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2636144161224365}\n",
      "[flaml.automl.logger: 09-22 09:37:19] {2391} INFO -  at 113.3s,\testimator rf's best error=0.2054,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:19] {2218} INFO - iteration 82, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:37:19] {805} INFO - trial 1 config: {'n_estimators': 30, 'max_features': 0.13940024717324384, 'max_leaves': 90, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:37:21] {197} INFO - result: {'pred_time': 7.48076038160418e-05, 'wall_clock_time': 115.32698607444763, 'metric_for_logging': {'pred_time': 7.48076038160418e-05}, 'val_loss': 0.22645596813512858, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133fbdf0>, 'training_iteration': 0, 'config': {'n_estimators': 30, 'max_features': 0.13940024717324384, 'max_leaves': 90, 'criterion': 'entropy'}, 'config/n_estimators': 30, 'config/max_features': 0.13940024717324384, 'config/max_leaves': 90, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.9709737300872803}\n",
      "[flaml.tune.tune: 09-22 09:37:21] {197} INFO - result: {'pred_time': 7.48076038160418e-05, 'wall_clock_time': 115.32698607444763, 'metric_for_logging': {'pred_time': 7.48076038160418e-05}, 'val_loss': 0.22645596813512858, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133fbdf0>, 'training_iteration': 1, 'config': {'n_estimators': 30, 'max_features': 0.13940024717324384, 'max_leaves': 90, 'criterion': 'entropy'}, 'config/n_estimators': 30, 'config/max_features': 0.13940024717324384, 'config/max_leaves': 90, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.9724788665771484}\n",
      "[flaml.automl.logger: 09-22 09:37:21] {2391} INFO -  at 115.3s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:21] {2218} INFO - iteration 83, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:37:21] {805} INFO - trial 1 config: {'n_estimators': 21, 'max_features': 0.11915444960789649, 'max_leaves': 154, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:37:23] {197} INFO - result: {'pred_time': 5.212736388573028e-05, 'wall_clock_time': 117.08869981765747, 'metric_for_logging': {'pred_time': 5.212736388573028e-05}, 'val_loss': 0.22791214406656685, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133fb400>, 'training_iteration': 0, 'config': {'n_estimators': 21, 'max_features': 0.11915444960789649, 'max_leaves': 154, 'criterion': 'gini'}, 'config/n_estimators': 21, 'config/max_features': 0.11915444960789649, 'config/max_leaves': 154, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.753288745880127}\n",
      "[flaml.tune.tune: 09-22 09:37:23] {197} INFO - result: {'pred_time': 5.212736388573028e-05, 'wall_clock_time': 117.08869981765747, 'metric_for_logging': {'pred_time': 5.212736388573028e-05}, 'val_loss': 0.22791214406656685, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6133fb400>, 'training_iteration': 1, 'config': {'n_estimators': 21, 'max_features': 0.11915444960789649, 'max_leaves': 154, 'criterion': 'gini'}, 'config/n_estimators': 21, 'config/max_features': 0.11915444960789649, 'config/max_leaves': 154, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.7548484802246094}\n",
      "[flaml.automl.logger: 09-22 09:37:23] {2391} INFO -  at 117.1s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:23] {2218} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:37:23] {805} INFO - trial 1 config: {'n_estimators': 53, 'max_features': 0.10027222567993475, 'max_leaves': 94, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:37:25] {197} INFO - result: {'pred_time': 9.160061917374139e-05, 'wall_clock_time': 119.41000652313232, 'metric_for_logging': {'pred_time': 9.160061917374139e-05}, 'val_loss': 0.2292641750850147, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387dc0>, 'training_iteration': 0, 'config': {'n_estimators': 53, 'max_features': 0.10027222567993475, 'max_leaves': 94, 'criterion': 'gini'}, 'config/n_estimators': 53, 'config/max_features': 0.10027222567993475, 'config/max_leaves': 94, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.312920570373535}\n",
      "[flaml.tune.tune: 09-22 09:37:25] {197} INFO - result: {'pred_time': 9.160061917374139e-05, 'wall_clock_time': 119.41000652313232, 'metric_for_logging': {'pred_time': 9.160061917374139e-05}, 'val_loss': 0.2292641750850147, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387dc0>, 'training_iteration': 1, 'config': {'n_estimators': 53, 'max_features': 0.10027222567993475, 'max_leaves': 94, 'criterion': 'gini'}, 'config/n_estimators': 53, 'config/max_features': 0.10027222567993475, 'config/max_leaves': 94, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.314270257949829}\n",
      "[flaml.automl.logger: 09-22 09:37:25] {2391} INFO -  at 119.4s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:25] {2218} INFO - iteration 85, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:37:25] {805} INFO - trial 1 config: {'n_estimators': 70, 'max_leaves': 17, 'min_child_weight': 0.2874102034110366, 'learning_rate': 0.2207726291366051, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.4988788151715646, 'colsample_bytree': 0.6325724983658846, 'reg_alpha': 0.0027488949929569983, 'reg_lambda': 0.0590850944041725}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:37:30] {197} INFO - result: {'pred_time': 4.3675808902842025e-05, 'wall_clock_time': 124.2603087425232, 'metric_for_logging': {'pred_time': 4.3675808902842025e-05}, 'val_loss': 0.2092249007166548, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613045e20>, 'training_iteration': 0, 'config': {'n_estimators': 70, 'max_leaves': 17, 'min_child_weight': 0.2874102034110366, 'learning_rate': 0.2207726291366051, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.4988788151715646, 'colsample_bytree': 0.6325724983658846, 'reg_alpha': 0.0027488949929569983, 'reg_lambda': 0.0590850944041725}, 'config/n_estimators': 70, 'config/max_leaves': 17, 'config/min_child_weight': 0.2874102034110366, 'config/learning_rate': 0.2207726291366051, 'config/subsample': 0.8895588746662894, 'config/colsample_bylevel': 0.4988788151715646, 'config/colsample_bytree': 0.6325724983658846, 'config/reg_alpha': 0.0027488949929569983, 'config/reg_lambda': 0.0590850944041725, 'experiment_tag': 'exp', 'time_total_s': 4.843149900436401}\n",
      "[flaml.tune.tune: 09-22 09:37:30] {197} INFO - result: {'pred_time': 4.3675808902842025e-05, 'wall_clock_time': 124.2603087425232, 'metric_for_logging': {'pred_time': 4.3675808902842025e-05}, 'val_loss': 0.2092249007166548, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb613045e20>, 'training_iteration': 1, 'config': {'n_estimators': 70, 'max_leaves': 17, 'min_child_weight': 0.2874102034110366, 'learning_rate': 0.2207726291366051, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.4988788151715646, 'colsample_bytree': 0.6325724983658846, 'reg_alpha': 0.0027488949929569983, 'reg_lambda': 0.0590850944041725}, 'config/n_estimators': 70, 'config/max_leaves': 17, 'config/min_child_weight': 0.2874102034110366, 'config/learning_rate': 0.2207726291366051, 'config/subsample': 0.8895588746662894, 'config/colsample_bylevel': 0.4988788151715646, 'config/colsample_bytree': 0.6325724983658846, 'config/reg_alpha': 0.0027488949929569983, 'config/reg_lambda': 0.0590850944041725, 'experiment_tag': 'exp', 'time_total_s': 4.844625234603882}\n",
      "[flaml.automl.logger: 09-22 09:37:30] {2391} INFO -  at 124.3s,\testimator xgboost's best error=0.2092,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:30] {2218} INFO - iteration 86, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:37:30] {805} INFO - trial 1 config: {'n_estimators': 12, 'max_features': 0.16565065365310247, 'max_leaves': 148, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:37:31] {197} INFO - result: {'pred_time': 3.660298252442298e-05, 'wall_clock_time': 125.40794348716736, 'metric_for_logging': {'pred_time': 3.660298252442298e-05}, 'val_loss': 0.23475650428424047, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387d30>, 'training_iteration': 0, 'config': {'n_estimators': 12, 'max_features': 0.16565065365310247, 'max_leaves': 148, 'criterion': 'entropy'}, 'config/n_estimators': 12, 'config/max_features': 0.16565065365310247, 'config/max_leaves': 148, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.1400885581970215}\n",
      "[flaml.tune.tune: 09-22 09:37:31] {197} INFO - result: {'pred_time': 3.660298252442298e-05, 'wall_clock_time': 125.40794348716736, 'metric_for_logging': {'pred_time': 3.660298252442298e-05}, 'val_loss': 0.23475650428424047, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb613387d30>, 'training_iteration': 1, 'config': {'n_estimators': 12, 'max_features': 0.16565065365310247, 'max_leaves': 148, 'criterion': 'entropy'}, 'config/n_estimators': 12, 'config/max_features': 0.16565065365310247, 'config/max_leaves': 148, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.1416926383972168}\n",
      "[flaml.automl.logger: 09-22 09:37:31] {2391} INFO -  at 125.4s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:31] {2218} INFO - iteration 87, current learner catboost\n",
      "[flaml.tune.tune: 09-22 09:37:31] {805} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.09999999999999996, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-22 09:37:34] {197} INFO - result: {'pred_time': 0.00010518688713898176, 'wall_clock_time': 128.3975865840912, 'metric_for_logging': {'pred_time': 0.00010518688713898176}, 'val_loss': 0.2506400083049259, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb6134033a0>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.09999999999999996, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.09999999999999996, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 2.981276512145996}\n",
      "[flaml.tune.tune: 09-22 09:37:34] {197} INFO - result: {'pred_time': 0.00010518688713898176, 'wall_clock_time': 128.3975865840912, 'metric_for_logging': {'pred_time': 0.00010518688713898176}, 'val_loss': 0.2506400083049259, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb6134033a0>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.09999999999999996, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.09999999999999996, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 2.982739210128784}\n",
      "[flaml.automl.logger: 09-22 09:37:34] {2391} INFO -  at 128.4s,\testimator catboost's best error=0.2506,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:34] {2218} INFO - iteration 88, current learner catboost\n",
      "[flaml.tune.tune: 09-22 09:37:34] {805} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.06233639237958607, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-22 09:37:39] {197} INFO - result: {'pred_time': 0.00011577318237866987, 'wall_clock_time': 132.87621665000916, 'metric_for_logging': {'pred_time': 0.00011577318237866987}, 'val_loss': 0.24165679634195375, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb612728a00>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.06233639237958607, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.06233639237958607, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.4694530963897705}\n",
      "[flaml.tune.tune: 09-22 09:37:39] {197} INFO - result: {'pred_time': 0.00011577318237866987, 'wall_clock_time': 132.87621665000916, 'metric_for_logging': {'pred_time': 0.00011577318237866987}, 'val_loss': 0.24165679634195375, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb612728a00>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.06233639237958607, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.06233639237958607, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.471099853515625}\n",
      "[flaml.automl.logger: 09-22 09:37:39] {2391} INFO -  at 132.9s,\testimator catboost's best error=0.2417,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:39] {2218} INFO - iteration 89, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:37:39] {805} INFO - trial 1 config: {'n_estimators': 90, 'max_features': 0.08461549318604882, 'max_leaves': 67, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:37:42] {197} INFO - result: {'pred_time': 0.00014372157149774296, 'wall_clock_time': 136.2275116443634, 'metric_for_logging': {'pred_time': 0.00014372157149774296}, 'val_loss': 0.21088511963699372, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb61271e610>, 'training_iteration': 0, 'config': {'n_estimators': 90, 'max_features': 0.08461549318604882, 'max_leaves': 67, 'criterion': 'gini'}, 'config/n_estimators': 90, 'config/max_features': 0.08461549318604882, 'config/max_leaves': 67, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.3433923721313477}\n",
      "[flaml.tune.tune: 09-22 09:37:42] {197} INFO - result: {'pred_time': 0.00014372157149774296, 'wall_clock_time': 136.2275116443634, 'metric_for_logging': {'pred_time': 0.00014372157149774296}, 'val_loss': 0.21088511963699372, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb61271e610>, 'training_iteration': 1, 'config': {'n_estimators': 90, 'max_features': 0.08461549318604882, 'max_leaves': 67, 'criterion': 'gini'}, 'config/n_estimators': 90, 'config/max_features': 0.08461549318604882, 'config/max_leaves': 67, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.3447794914245605}\n",
      "[flaml.automl.logger: 09-22 09:37:42] {2391} INFO -  at 136.2s,\testimator rf's best error=0.2054,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:42] {2218} INFO - iteration 90, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:37:42] {805} INFO - trial 1 config: {'n_estimators': 35, 'max_features': 0.0728059923666486, 'max_leaves': 93, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:37:43] {197} INFO - result: {'pred_time': 6.620860766774461e-05, 'wall_clock_time': 137.65209531784058, 'metric_for_logging': {'pred_time': 6.620860766774461e-05}, 'val_loss': 0.21948236727097292, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb61271e040>, 'training_iteration': 0, 'config': {'n_estimators': 35, 'max_features': 0.0728059923666486, 'max_leaves': 93, 'criterion': 'entropy'}, 'config/n_estimators': 35, 'config/max_features': 0.0728059923666486, 'config/max_leaves': 93, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.4168627262115479}\n",
      "[flaml.tune.tune: 09-22 09:37:43] {197} INFO - result: {'pred_time': 6.620860766774461e-05, 'wall_clock_time': 137.65209531784058, 'metric_for_logging': {'pred_time': 6.620860766774461e-05}, 'val_loss': 0.21948236727097292, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb61271e040>, 'training_iteration': 1, 'config': {'n_estimators': 35, 'max_features': 0.0728059923666486, 'max_leaves': 93, 'criterion': 'entropy'}, 'config/n_estimators': 35, 'config/max_features': 0.0728059923666486, 'config/max_leaves': 93, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.4180428981781006}\n",
      "[flaml.automl.logger: 09-22 09:37:43] {2391} INFO -  at 137.7s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:43] {2218} INFO - iteration 91, current learner catboost\n",
      "[flaml.tune.tune: 09-22 09:37:43] {805} INFO - trial 1 config: {'early_stopping_rounds': 12, 'learning_rate': 0.10000000000000002, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-22 09:37:47] {197} INFO - result: {'pred_time': 0.0001035810361602794, 'wall_clock_time': 140.7009584903717, 'metric_for_logging': {'pred_time': 0.0001035810361602794}, 'val_loss': 0.2506400083049259, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb612746310>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.10000000000000002, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.10000000000000002, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 3.042539358139038}\n",
      "[flaml.tune.tune: 09-22 09:37:47] {197} INFO - result: {'pred_time': 0.0001035810361602794, 'wall_clock_time': 140.7009584903717, 'metric_for_logging': {'pred_time': 0.0001035810361602794}, 'val_loss': 0.2506400083049259, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb612746310>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.10000000000000002, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.10000000000000002, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 3.044070243835449}\n",
      "[flaml.automl.logger: 09-22 09:37:47] {2391} INFO -  at 140.7s,\testimator catboost's best error=0.2417,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:47] {2218} INFO - iteration 92, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:37:47] {805} INFO - trial 1 config: {'n_estimators': 18, 'max_features': 0.22814275566061065, 'max_leaves': 150, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:37:49] {197} INFO - result: {'pred_time': 5.1347006605966474e-05, 'wall_clock_time': 142.94590759277344, 'metric_for_logging': {'pred_time': 5.1347006605966474e-05}, 'val_loss': 0.2614755901674942, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6127e5b50>, 'training_iteration': 0, 'config': {'n_estimators': 18, 'max_features': 0.22814275566061065, 'max_leaves': 150, 'criterion': 'gini'}, 'config/n_estimators': 18, 'config/max_features': 0.22814275566061065, 'config/max_leaves': 150, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.236462354660034}\n",
      "[flaml.tune.tune: 09-22 09:37:49] {197} INFO - result: {'pred_time': 5.1347006605966474e-05, 'wall_clock_time': 142.94590759277344, 'metric_for_logging': {'pred_time': 5.1347006605966474e-05}, 'val_loss': 0.2614755901674942, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6127e5b50>, 'training_iteration': 1, 'config': {'n_estimators': 18, 'max_features': 0.22814275566061065, 'max_leaves': 150, 'criterion': 'gini'}, 'config/n_estimators': 18, 'config/max_features': 0.22814275566061065, 'config/max_leaves': 150, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.2378392219543457}\n",
      "[flaml.automl.logger: 09-22 09:37:49] {2391} INFO -  at 142.9s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:49] {2218} INFO - iteration 93, current learner catboost\n",
      "[flaml.tune.tune: 09-22 09:37:49] {805} INFO - trial 1 config: {'early_stopping_rounds': 13, 'learning_rate': 0.04171721859304757, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-22 09:37:56] {197} INFO - result: {'pred_time': 0.00014444660889850272, 'wall_clock_time': 149.94685649871826, 'metric_for_logging': {'pred_time': 0.00014444660889850272}, 'val_loss': 0.2335158867205344, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb612754670>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 13, 'learning_rate': 0.04171721859304757, 'n_estimators': 8192}, 'config/early_stopping_rounds': 13, 'config/learning_rate': 0.04171721859304757, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.99369478225708}\n",
      "[flaml.tune.tune: 09-22 09:37:56] {197} INFO - result: {'pred_time': 0.00014444660889850272, 'wall_clock_time': 149.94685649871826, 'metric_for_logging': {'pred_time': 0.00014444660889850272}, 'val_loss': 0.2335158867205344, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb612754670>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 13, 'learning_rate': 0.04171721859304757, 'n_estimators': 8192}, 'config/early_stopping_rounds': 13, 'config/learning_rate': 0.04171721859304757, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.995042562484741}\n",
      "[flaml.automl.logger: 09-22 09:37:56] {2391} INFO -  at 149.9s,\testimator catboost's best error=0.2335,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:37:56] {2218} INFO - iteration 94, current learner catboost\n",
      "[flaml.tune.tune: 09-22 09:37:56] {805} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.062336392379586096, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-22 09:38:00] {197} INFO - result: {'pred_time': 7.499948384517305e-05, 'wall_clock_time': 154.12749409675598, 'metric_for_logging': {'pred_time': 7.499948384517305e-05}, 'val_loss': 0.24165679634195375, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb6127c4730>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.062336392379586096, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.062336392379586096, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.1727612018585205}\n",
      "[flaml.tune.tune: 09-22 09:38:00] {197} INFO - result: {'pred_time': 7.499948384517305e-05, 'wall_clock_time': 154.12749409675598, 'metric_for_logging': {'pred_time': 7.499948384517305e-05}, 'val_loss': 0.24165679634195375, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb6127c4730>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.062336392379586096, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.062336392379586096, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.1744139194488525}\n",
      "[flaml.automl.logger: 09-22 09:38:00] {2391} INFO -  at 154.1s,\testimator catboost's best error=0.2335,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:38:00] {2218} INFO - iteration 95, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:38:00] {805} INFO - trial 1 config: {'n_estimators': 63, 'num_leaves': 262, 'min_child_samples': 4, 'learning_rate': 0.1267824704459056, 'log_max_bin': 10, 'colsample_bytree': 0.7195975890246057, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.231060318119947}\n",
      "[flaml.tune.tune: 09-22 09:38:02] {197} INFO - result: {'pred_time': 1.3512980306583253e-05, 'wall_clock_time': 155.7116847038269, 'metric_for_logging': {'pred_time': 1.3512980306583253e-05}, 'val_loss': 0.2024917894483112, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6127dee20>, 'training_iteration': 0, 'config': {'n_estimators': 63, 'num_leaves': 262, 'min_child_samples': 4, 'learning_rate': 0.1267824704459056, 'log_max_bin': 10, 'colsample_bytree': 0.7195975890246057, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.231060318119947}, 'config/n_estimators': 63, 'config/num_leaves': 262, 'config/min_child_samples': 4, 'config/learning_rate': 0.1267824704459056, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7195975890246057, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.231060318119947, 'experiment_tag': 'exp', 'time_total_s': 1.5765681266784668}\n",
      "[flaml.tune.tune: 09-22 09:38:02] {197} INFO - result: {'pred_time': 1.3512980306583253e-05, 'wall_clock_time': 155.7116847038269, 'metric_for_logging': {'pred_time': 1.3512980306583253e-05}, 'val_loss': 0.2024917894483112, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6127dee20>, 'training_iteration': 1, 'config': {'n_estimators': 63, 'num_leaves': 262, 'min_child_samples': 4, 'learning_rate': 0.1267824704459056, 'log_max_bin': 10, 'colsample_bytree': 0.7195975890246057, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.231060318119947}, 'config/n_estimators': 63, 'config/num_leaves': 262, 'config/min_child_samples': 4, 'config/learning_rate': 0.1267824704459056, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7195975890246057, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.231060318119947, 'experiment_tag': 'exp', 'time_total_s': 1.577772617340088}\n",
      "[flaml.automl.logger: 09-22 09:38:02] {2391} INFO -  at 155.7s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:38:02] {2218} INFO - iteration 96, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:38:02] {805} INFO - trial 1 config: {'n_estimators': 38, 'max_features': 0.16432417704068714, 'max_leaves': 48, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:38:04] {197} INFO - result: {'pred_time': 9.088920590291197e-05, 'wall_clock_time': 158.138427734375, 'metric_for_logging': {'pred_time': 9.088920590291197e-05}, 'val_loss': 0.2375450917992147, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb612713640>, 'training_iteration': 0, 'config': {'n_estimators': 38, 'max_features': 0.16432417704068714, 'max_leaves': 48, 'criterion': 'entropy'}, 'config/n_estimators': 38, 'config/max_features': 0.16432417704068714, 'config/max_leaves': 48, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.4201862812042236}\n",
      "[flaml.tune.tune: 09-22 09:38:04] {197} INFO - result: {'pred_time': 9.088920590291197e-05, 'wall_clock_time': 158.138427734375, 'metric_for_logging': {'pred_time': 9.088920590291197e-05}, 'val_loss': 0.2375450917992147, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb612713640>, 'training_iteration': 1, 'config': {'n_estimators': 38, 'max_features': 0.16432417704068714, 'max_leaves': 48, 'criterion': 'entropy'}, 'config/n_estimators': 38, 'config/max_features': 0.16432417704068714, 'config/max_leaves': 48, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.4233756065368652}\n",
      "[flaml.automl.logger: 09-22 09:38:04] {2391} INFO -  at 158.1s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:38:04] {2218} INFO - iteration 97, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:38:04] {805} INFO - trial 1 config: {'n_estimators': 45, 'max_features': 0.10168223906236107, 'max_leaves': 109, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:38:07] {197} INFO - result: {'pred_time': 0.00011057309804990253, 'wall_clock_time': 161.06370568275452, 'metric_for_logging': {'pred_time': 0.00011057309804990253}, 'val_loss': 0.20117203612331047, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6127e5a60>, 'training_iteration': 0, 'config': {'n_estimators': 45, 'max_features': 0.10168223906236107, 'max_leaves': 109, 'criterion': 'entropy'}, 'config/n_estimators': 45, 'config/max_features': 0.10168223906236107, 'config/max_leaves': 109, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.9123661518096924}\n",
      "[flaml.tune.tune: 09-22 09:38:07] {197} INFO - result: {'pred_time': 0.00011057309804990253, 'wall_clock_time': 161.06370568275452, 'metric_for_logging': {'pred_time': 0.00011057309804990253}, 'val_loss': 0.20117203612331047, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6127e5a60>, 'training_iteration': 1, 'config': {'n_estimators': 45, 'max_features': 0.10168223906236107, 'max_leaves': 109, 'criterion': 'entropy'}, 'config/n_estimators': 45, 'config/max_features': 0.10168223906236107, 'config/max_leaves': 109, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.918522357940674}\n",
      "[flaml.automl.logger: 09-22 09:38:07] {2391} INFO -  at 161.1s,\testimator rf's best error=0.2012,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:38:07] {2218} INFO - iteration 98, current learner catboost\n",
      "[flaml.tune.tune: 09-22 09:38:07] {805} INFO - trial 1 config: {'early_stopping_rounds': 15, 'learning_rate': 0.025858503359419964, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-22 09:38:24] {197} INFO - result: {'pred_time': 0.00015647543015569212, 'wall_clock_time': 178.30654907226562, 'metric_for_logging': {'pred_time': 0.00015647543015569212}, 'val_loss': 0.24776746242263484, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb6127e5e50>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 15, 'learning_rate': 0.025858503359419964, 'n_estimators': 8192}, 'config/early_stopping_rounds': 15, 'config/learning_rate': 0.025858503359419964, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 17.227579832077026}\n",
      "[flaml.tune.tune: 09-22 09:38:24] {197} INFO - result: {'pred_time': 0.00015647543015569212, 'wall_clock_time': 178.30654907226562, 'metric_for_logging': {'pred_time': 0.00015647543015569212}, 'val_loss': 0.24776746242263484, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb6127e5e50>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 15, 'learning_rate': 0.025858503359419964, 'n_estimators': 8192}, 'config/early_stopping_rounds': 15, 'config/learning_rate': 0.025858503359419964, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 17.229517221450806}\n",
      "[flaml.automl.logger: 09-22 09:38:24] {2391} INFO -  at 178.3s,\testimator catboost's best error=0.2335,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:38:24] {2218} INFO - iteration 99, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:38:24] {805} INFO - trial 1 config: {'n_estimators': 46, 'max_features': 0.05322276111861015, 'max_leaves': 81, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:38:27] {197} INFO - result: {'pred_time': 0.0001122551664755824, 'wall_clock_time': 180.72480726242065, 'metric_for_logging': {'pred_time': 0.0001122551664755824}, 'val_loss': 0.21397405940134578, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6126f3be0>, 'training_iteration': 0, 'config': {'n_estimators': 46, 'max_features': 0.05322276111861015, 'max_leaves': 81, 'criterion': 'gini'}, 'config/n_estimators': 46, 'config/max_features': 0.05322276111861015, 'config/max_leaves': 81, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.406999111175537}\n",
      "[flaml.tune.tune: 09-22 09:38:27] {197} INFO - result: {'pred_time': 0.0001122551664755824, 'wall_clock_time': 180.72480726242065, 'metric_for_logging': {'pred_time': 0.0001122551664755824}, 'val_loss': 0.21397405940134578, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6126f3be0>, 'training_iteration': 1, 'config': {'n_estimators': 46, 'max_features': 0.05322276111861015, 'max_leaves': 81, 'criterion': 'gini'}, 'config/n_estimators': 46, 'config/max_features': 0.05322276111861015, 'config/max_leaves': 81, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.409562349319458}\n",
      "[flaml.automl.logger: 09-22 09:38:27] {2391} INFO -  at 180.7s,\testimator rf's best error=0.2012,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:38:27] {2218} INFO - iteration 100, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:38:27] {805} INFO - trial 1 config: {'n_estimators': 128, 'num_leaves': 19, 'min_child_samples': 13, 'learning_rate': 0.3304039369370558, 'log_max_bin': 8, 'colsample_bytree': 0.8303843021774752, 'reg_alpha': 0.0022190759769264894, 'reg_lambda': 0.7801218653559179}\n",
      "[flaml.tune.tune: 09-22 09:38:28] {197} INFO - result: {'pred_time': 1.8155684114907865e-05, 'wall_clock_time': 182.32797408103943, 'metric_for_logging': {'pred_time': 1.8155684114907865e-05}, 'val_loss': 0.21766874705405445, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6127689a0>, 'training_iteration': 0, 'config': {'n_estimators': 128, 'num_leaves': 19, 'min_child_samples': 13, 'learning_rate': 0.3304039369370558, 'log_max_bin': 8, 'colsample_bytree': 0.8303843021774752, 'reg_alpha': 0.0022190759769264894, 'reg_lambda': 0.7801218653559179}, 'config/n_estimators': 128, 'config/num_leaves': 19, 'config/min_child_samples': 13, 'config/learning_rate': 0.3304039369370558, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8303843021774752, 'config/reg_alpha': 0.0022190759769264894, 'config/reg_lambda': 0.7801218653559179, 'experiment_tag': 'exp', 'time_total_s': 1.5908434391021729}\n",
      "[flaml.tune.tune: 09-22 09:38:28] {197} INFO - result: {'pred_time': 1.8155684114907865e-05, 'wall_clock_time': 182.32797408103943, 'metric_for_logging': {'pred_time': 1.8155684114907865e-05}, 'val_loss': 0.21766874705405445, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6127689a0>, 'training_iteration': 1, 'config': {'n_estimators': 128, 'num_leaves': 19, 'min_child_samples': 13, 'learning_rate': 0.3304039369370558, 'log_max_bin': 8, 'colsample_bytree': 0.8303843021774752, 'reg_alpha': 0.0022190759769264894, 'reg_lambda': 0.7801218653559179}, 'config/n_estimators': 128, 'config/num_leaves': 19, 'config/min_child_samples': 13, 'config/learning_rate': 0.3304039369370558, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8303843021774752, 'config/reg_alpha': 0.0022190759769264894, 'config/reg_lambda': 0.7801218653559179, 'experiment_tag': 'exp', 'time_total_s': 1.5926225185394287}\n",
      "[flaml.automl.logger: 09-22 09:38:28] {2391} INFO -  at 182.3s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:38:28] {2218} INFO - iteration 101, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:38:28] {805} INFO - trial 1 config: {'n_estimators': 16, 'max_features': 0.10108165472826239, 'max_leaves': 288, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:38:30] {197} INFO - result: {'pred_time': 5.154524406977464e-05, 'wall_clock_time': 183.9156310558319, 'metric_for_logging': {'pred_time': 5.154524406977464e-05}, 'val_loss': 0.23374097341488648, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb61274dfa0>, 'training_iteration': 0, 'config': {'n_estimators': 16, 'max_features': 0.10108165472826239, 'max_leaves': 288, 'criterion': 'gini'}, 'config/n_estimators': 16, 'config/max_features': 0.10108165472826239, 'config/max_leaves': 288, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.5786595344543457}\n",
      "[flaml.tune.tune: 09-22 09:38:30] {197} INFO - result: {'pred_time': 5.154524406977464e-05, 'wall_clock_time': 183.9156310558319, 'metric_for_logging': {'pred_time': 5.154524406977464e-05}, 'val_loss': 0.23374097341488648, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb61274dfa0>, 'training_iteration': 1, 'config': {'n_estimators': 16, 'max_features': 0.10108165472826239, 'max_leaves': 288, 'criterion': 'gini'}, 'config/n_estimators': 16, 'config/max_features': 0.10108165472826239, 'config/max_leaves': 288, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.5801775455474854}\n",
      "[flaml.automl.logger: 09-22 09:38:30] {2391} INFO -  at 183.9s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:38:30] {2218} INFO - iteration 102, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:38:30] {805} INFO - trial 1 config: {'n_estimators': 38, 'max_leaves': 4, 'min_child_weight': 0.41997083011127556, 'learning_rate': 0.38063336262834907, 'subsample': 0.937812919568431, 'colsample_bylevel': 0.6155645729889492, 'colsample_bytree': 0.69018429172989, 'reg_alpha': 0.003959831078561366, 'reg_lambda': 0.019458360917398984}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:38:33] {197} INFO - result: {'pred_time': 4.999101284112121e-05, 'wall_clock_time': 187.045902967453, 'metric_for_logging': {'pred_time': 4.999101284112121e-05}, 'val_loss': 0.24032682203596747, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6127704f0>, 'training_iteration': 0, 'config': {'n_estimators': 38, 'max_leaves': 4, 'min_child_weight': 0.41997083011127556, 'learning_rate': 0.38063336262834907, 'subsample': 0.937812919568431, 'colsample_bylevel': 0.6155645729889492, 'colsample_bytree': 0.69018429172989, 'reg_alpha': 0.003959831078561366, 'reg_lambda': 0.019458360917398984}, 'config/n_estimators': 38, 'config/max_leaves': 4, 'config/min_child_weight': 0.41997083011127556, 'config/learning_rate': 0.38063336262834907, 'config/subsample': 0.937812919568431, 'config/colsample_bylevel': 0.6155645729889492, 'config/colsample_bytree': 0.69018429172989, 'config/reg_alpha': 0.003959831078561366, 'config/reg_lambda': 0.019458360917398984, 'experiment_tag': 'exp', 'time_total_s': 3.122847080230713}\n",
      "[flaml.tune.tune: 09-22 09:38:33] {197} INFO - result: {'pred_time': 4.999101284112121e-05, 'wall_clock_time': 187.045902967453, 'metric_for_logging': {'pred_time': 4.999101284112121e-05}, 'val_loss': 0.24032682203596747, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6127704f0>, 'training_iteration': 1, 'config': {'n_estimators': 38, 'max_leaves': 4, 'min_child_weight': 0.41997083011127556, 'learning_rate': 0.38063336262834907, 'subsample': 0.937812919568431, 'colsample_bylevel': 0.6155645729889492, 'colsample_bytree': 0.69018429172989, 'reg_alpha': 0.003959831078561366, 'reg_lambda': 0.019458360917398984}, 'config/n_estimators': 38, 'config/max_leaves': 4, 'config/min_child_weight': 0.41997083011127556, 'config/learning_rate': 0.38063336262834907, 'config/subsample': 0.937812919568431, 'config/colsample_bylevel': 0.6155645729889492, 'config/colsample_bytree': 0.69018429172989, 'config/reg_alpha': 0.003959831078561366, 'config/reg_lambda': 0.019458360917398984, 'experiment_tag': 'exp', 'time_total_s': 3.12427020072937}\n",
      "[flaml.automl.logger: 09-22 09:38:33] {2391} INFO -  at 187.0s,\testimator xgboost's best error=0.2092,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:38:33] {2218} INFO - iteration 103, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:38:33] {805} INFO - trial 1 config: {'n_estimators': 164, 'num_leaves': 121, 'min_child_samples': 5, 'learning_rate': 0.37924384644057557, 'log_max_bin': 8, 'colsample_bytree': 0.6676885310413292, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.2562927610768564}\n",
      "[flaml.tune.tune: 09-22 09:38:36] {197} INFO - result: {'pred_time': 1.8583730816105425e-05, 'wall_clock_time': 189.8585991859436, 'metric_for_logging': {'pred_time': 1.8583730816105425e-05}, 'val_loss': 0.20341136604255045, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb612770df0>, 'training_iteration': 0, 'config': {'n_estimators': 164, 'num_leaves': 121, 'min_child_samples': 5, 'learning_rate': 0.37924384644057557, 'log_max_bin': 8, 'colsample_bytree': 0.6676885310413292, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.2562927610768564}, 'config/n_estimators': 164, 'config/num_leaves': 121, 'config/min_child_samples': 5, 'config/learning_rate': 0.37924384644057557, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.6676885310413292, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.2562927610768564, 'experiment_tag': 'exp', 'time_total_s': 2.805675983428955}\n",
      "[flaml.tune.tune: 09-22 09:38:36] {197} INFO - result: {'pred_time': 1.8583730816105425e-05, 'wall_clock_time': 189.8585991859436, 'metric_for_logging': {'pred_time': 1.8583730816105425e-05}, 'val_loss': 0.20341136604255045, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb612770df0>, 'training_iteration': 1, 'config': {'n_estimators': 164, 'num_leaves': 121, 'min_child_samples': 5, 'learning_rate': 0.37924384644057557, 'log_max_bin': 8, 'colsample_bytree': 0.6676885310413292, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.2562927610768564}, 'config/n_estimators': 164, 'config/num_leaves': 121, 'config/min_child_samples': 5, 'config/learning_rate': 0.37924384644057557, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.6676885310413292, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.2562927610768564, 'experiment_tag': 'exp', 'time_total_s': 2.807257652282715}\n",
      "[flaml.automl.logger: 09-22 09:38:36] {2391} INFO -  at 189.9s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:38:36] {2218} INFO - iteration 104, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:38:36] {805} INFO - trial 1 config: {'n_estimators': 130, 'max_leaves': 75, 'min_child_weight': 0.1966913392601255, 'learning_rate': 0.12805118668349444, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.38219305735418013, 'colsample_bytree': 0.574960705001879, 'reg_alpha': 0.001908269199465285, 'reg_lambda': 0.17941122562016018}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:38:51] {197} INFO - result: {'pred_time': 5.2056028310882966e-05, 'wall_clock_time': 205.5528209209442, 'metric_for_logging': {'pred_time': 5.2056028310882966e-05}, 'val_loss': 0.19876160325935438, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6126f3220>, 'training_iteration': 0, 'config': {'n_estimators': 130, 'max_leaves': 75, 'min_child_weight': 0.1966913392601255, 'learning_rate': 0.12805118668349444, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.38219305735418013, 'colsample_bytree': 0.574960705001879, 'reg_alpha': 0.001908269199465285, 'reg_lambda': 0.17941122562016018}, 'config/n_estimators': 130, 'config/max_leaves': 75, 'config/min_child_weight': 0.1966913392601255, 'config/learning_rate': 0.12805118668349444, 'config/subsample': 0.8413048297641477, 'config/colsample_bylevel': 0.38219305735418013, 'config/colsample_bytree': 0.574960705001879, 'config/reg_alpha': 0.001908269199465285, 'config/reg_lambda': 0.17941122562016018, 'experiment_tag': 'exp', 'time_total_s': 15.686847448348999}\n",
      "[flaml.tune.tune: 09-22 09:38:51] {197} INFO - result: {'pred_time': 5.2056028310882966e-05, 'wall_clock_time': 205.5528209209442, 'metric_for_logging': {'pred_time': 5.2056028310882966e-05}, 'val_loss': 0.19876160325935438, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6126f3220>, 'training_iteration': 1, 'config': {'n_estimators': 130, 'max_leaves': 75, 'min_child_weight': 0.1966913392601255, 'learning_rate': 0.12805118668349444, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.38219305735418013, 'colsample_bytree': 0.574960705001879, 'reg_alpha': 0.001908269199465285, 'reg_lambda': 0.17941122562016018}, 'config/n_estimators': 130, 'config/max_leaves': 75, 'config/min_child_weight': 0.1966913392601255, 'config/learning_rate': 0.12805118668349444, 'config/subsample': 0.8413048297641477, 'config/colsample_bylevel': 0.38219305735418013, 'config/colsample_bytree': 0.574960705001879, 'config/reg_alpha': 0.001908269199465285, 'config/reg_lambda': 0.17941122562016018, 'experiment_tag': 'exp', 'time_total_s': 15.688355684280396}\n",
      "[flaml.automl.logger: 09-22 09:38:51] {2391} INFO -  at 205.6s,\testimator xgboost's best error=0.1988,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:38:51] {2218} INFO - iteration 105, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:38:51] {805} INFO - trial 1 config: {'n_estimators': 55, 'max_features': 0.10998203225562961, 'max_leaves': 83, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:38:54] {197} INFO - result: {'pred_time': 9.427536960097424e-05, 'wall_clock_time': 207.882257938385, 'metric_for_logging': {'pred_time': 9.427536960097424e-05}, 'val_loss': 0.20936369566429539, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6126f3070>, 'training_iteration': 0, 'config': {'n_estimators': 55, 'max_features': 0.10998203225562961, 'max_leaves': 83, 'criterion': 'entropy'}, 'config/n_estimators': 55, 'config/max_features': 0.10998203225562961, 'config/max_leaves': 83, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.3222951889038086}\n",
      "[flaml.tune.tune: 09-22 09:38:54] {197} INFO - result: {'pred_time': 9.427536960097424e-05, 'wall_clock_time': 207.882257938385, 'metric_for_logging': {'pred_time': 9.427536960097424e-05}, 'val_loss': 0.20936369566429539, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6126f3070>, 'training_iteration': 1, 'config': {'n_estimators': 55, 'max_features': 0.10998203225562961, 'max_leaves': 83, 'criterion': 'entropy'}, 'config/n_estimators': 55, 'config/max_features': 0.10998203225562961, 'config/max_leaves': 83, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.3236565589904785}\n",
      "[flaml.automl.logger: 09-22 09:38:54] {2391} INFO -  at 207.9s,\testimator rf's best error=0.2012,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:38:54] {2218} INFO - iteration 106, current learner catboost\n",
      "[flaml.tune.tune: 09-22 09:38:54] {805} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.0673018969021706, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-22 09:38:58] {197} INFO - result: {'pred_time': 7.495293208672423e-05, 'wall_clock_time': 212.4029746055603, 'metric_for_logging': {'pred_time': 7.495293208672423e-05}, 'val_loss': 0.2414051679981215, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb6126f3f70>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 11, 'learning_rate': 0.0673018969021706, 'n_estimators': 8192}, 'config/early_stopping_rounds': 11, 'config/learning_rate': 0.0673018969021706, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.512804985046387}\n",
      "[flaml.tune.tune: 09-22 09:38:58] {197} INFO - result: {'pred_time': 7.495293208672423e-05, 'wall_clock_time': 212.4029746055603, 'metric_for_logging': {'pred_time': 7.495293208672423e-05}, 'val_loss': 0.2414051679981215, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb6126f3f70>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 11, 'learning_rate': 0.0673018969021706, 'n_estimators': 8192}, 'config/early_stopping_rounds': 11, 'config/learning_rate': 0.0673018969021706, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.514068603515625}\n",
      "[flaml.automl.logger: 09-22 09:38:58] {2391} INFO -  at 212.4s,\testimator catboost's best error=0.2335,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:38:58] {2218} INFO - iteration 107, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:38:58] {805} INFO - trial 1 config: {'n_estimators': 23, 'max_features': 0.19621836558561395, 'max_leaves': 101, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:39:00] {197} INFO - result: {'pred_time': 5.718653998103251e-05, 'wall_clock_time': 214.36510729789734, 'metric_for_logging': {'pred_time': 5.718653998103251e-05}, 'val_loss': 0.22422391108672962, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6127c4e20>, 'training_iteration': 0, 'config': {'n_estimators': 23, 'max_features': 0.19621836558561395, 'max_leaves': 101, 'criterion': 'entropy'}, 'config/n_estimators': 23, 'config/max_features': 0.19621836558561395, 'config/max_leaves': 101, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.954540491104126}\n",
      "[flaml.tune.tune: 09-22 09:39:00] {197} INFO - result: {'pred_time': 5.718653998103251e-05, 'wall_clock_time': 214.36510729789734, 'metric_for_logging': {'pred_time': 5.718653998103251e-05}, 'val_loss': 0.22422391108672962, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6127c4e20>, 'training_iteration': 1, 'config': {'n_estimators': 23, 'max_features': 0.19621836558561395, 'max_leaves': 101, 'criterion': 'entropy'}, 'config/n_estimators': 23, 'config/max_features': 0.19621836558561395, 'config/max_leaves': 101, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.9560577869415283}\n",
      "[flaml.automl.logger: 09-22 09:39:00] {2391} INFO -  at 214.4s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:39:00] {2218} INFO - iteration 108, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:39:00] {805} INFO - trial 1 config: {'n_estimators': 37, 'max_features': 0.09400878969669989, 'max_leaves': 142, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:39:02] {197} INFO - result: {'pred_time': 7.275229445354336e-05, 'wall_clock_time': 216.19823622703552, 'metric_for_logging': {'pred_time': 7.275229445354336e-05}, 'val_loss': 0.21710812559763087, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb61278ec70>, 'training_iteration': 0, 'config': {'n_estimators': 37, 'max_features': 0.09400878969669989, 'max_leaves': 142, 'criterion': 'gini'}, 'config/n_estimators': 37, 'config/max_features': 0.09400878969669989, 'config/max_leaves': 142, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.8260166645050049}\n",
      "[flaml.tune.tune: 09-22 09:39:02] {197} INFO - result: {'pred_time': 7.275229445354336e-05, 'wall_clock_time': 216.19823622703552, 'metric_for_logging': {'pred_time': 7.275229445354336e-05}, 'val_loss': 0.21710812559763087, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb61278ec70>, 'training_iteration': 1, 'config': {'n_estimators': 37, 'max_features': 0.09400878969669989, 'max_leaves': 142, 'criterion': 'gini'}, 'config/n_estimators': 37, 'config/max_features': 0.09400878969669989, 'config/max_leaves': 142, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.8276007175445557}\n",
      "[flaml.automl.logger: 09-22 09:39:02] {2391} INFO -  at 216.2s,\testimator rf's best error=0.2012,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:39:02] {2218} INFO - iteration 109, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:39:02] {805} INFO - trial 1 config: {'n_estimators': 27, 'max_features': 0.0846514019090902, 'max_leaves': 138, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:39:03] {197} INFO - result: {'pred_time': 5.984003944421654e-05, 'wall_clock_time': 217.65366411209106, 'metric_for_logging': {'pred_time': 5.984003944421654e-05}, 'val_loss': 0.2285483600888399, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6127ceac0>, 'training_iteration': 0, 'config': {'n_estimators': 27, 'max_features': 0.0846514019090902, 'max_leaves': 138, 'criterion': 'gini'}, 'config/n_estimators': 27, 'config/max_features': 0.0846514019090902, 'config/max_leaves': 138, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.447998285293579}\n",
      "[flaml.tune.tune: 09-22 09:39:03] {197} INFO - result: {'pred_time': 5.984003944421654e-05, 'wall_clock_time': 217.65366411209106, 'metric_for_logging': {'pred_time': 5.984003944421654e-05}, 'val_loss': 0.2285483600888399, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6127ceac0>, 'training_iteration': 1, 'config': {'n_estimators': 27, 'max_features': 0.0846514019090902, 'max_leaves': 138, 'criterion': 'gini'}, 'config/n_estimators': 27, 'config/max_features': 0.0846514019090902, 'config/max_leaves': 138, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.4499690532684326}\n",
      "[flaml.automl.logger: 09-22 09:39:03] {2391} INFO -  at 217.7s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:39:03] {2218} INFO - iteration 110, current learner catboost\n",
      "[flaml.tune.tune: 09-22 09:39:03] {805} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.028185691492478487, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-22 09:39:10] {197} INFO - result: {'pred_time': 0.00011179746729433466, 'wall_clock_time': 223.90384340286255, 'metric_for_logging': {'pred_time': 0.00011179746729433466}, 'val_loss': 0.24546017445192855, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb6127c4250>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.028185691492478487, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.028185691492478487, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.241799831390381}\n",
      "[flaml.tune.tune: 09-22 09:39:10] {197} INFO - result: {'pred_time': 0.00011179746729433466, 'wall_clock_time': 223.90384340286255, 'metric_for_logging': {'pred_time': 0.00011179746729433466}, 'val_loss': 0.24546017445192855, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb6127c4250>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.028185691492478487, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.028185691492478487, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.243720531463623}\n",
      "[flaml.automl.logger: 09-22 09:39:10] {2391} INFO -  at 223.9s,\testimator catboost's best error=0.2335,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:39:10] {2218} INFO - iteration 111, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:39:10] {805} INFO - trial 1 config: {'n_estimators': 49, 'num_leaves': 40, 'min_child_samples': 11, 'learning_rate': 0.1104551273885913, 'log_max_bin': 10, 'colsample_bytree': 0.8822933601607518, 'reg_alpha': 0.004996244283600559, 'reg_lambda': 0.7713976515452791}\n",
      "[flaml.tune.tune: 09-22 09:39:11] {197} INFO - result: {'pred_time': 1.2331641698857062e-05, 'wall_clock_time': 224.82950901985168, 'metric_for_logging': {'pred_time': 1.2331641698857062e-05}, 'val_loss': 0.21008136351089873, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6127ce310>, 'training_iteration': 0, 'config': {'n_estimators': 49, 'num_leaves': 40, 'min_child_samples': 11, 'learning_rate': 0.1104551273885913, 'log_max_bin': 10, 'colsample_bytree': 0.8822933601607518, 'reg_alpha': 0.004996244283600559, 'reg_lambda': 0.7713976515452791}, 'config/n_estimators': 49, 'config/num_leaves': 40, 'config/min_child_samples': 11, 'config/learning_rate': 0.1104551273885913, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8822933601607518, 'config/reg_alpha': 0.004996244283600559, 'config/reg_lambda': 0.7713976515452791, 'experiment_tag': 'exp', 'time_total_s': 0.9163055419921875}\n",
      "[flaml.tune.tune: 09-22 09:39:11] {197} INFO - result: {'pred_time': 1.2331641698857062e-05, 'wall_clock_time': 224.82950901985168, 'metric_for_logging': {'pred_time': 1.2331641698857062e-05}, 'val_loss': 0.21008136351089873, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6127ce310>, 'training_iteration': 1, 'config': {'n_estimators': 49, 'num_leaves': 40, 'min_child_samples': 11, 'learning_rate': 0.1104551273885913, 'log_max_bin': 10, 'colsample_bytree': 0.8822933601607518, 'reg_alpha': 0.004996244283600559, 'reg_lambda': 0.7713976515452791}, 'config/n_estimators': 49, 'config/num_leaves': 40, 'config/min_child_samples': 11, 'config/learning_rate': 0.1104551273885913, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8822933601607518, 'config/reg_alpha': 0.004996244283600559, 'config/reg_lambda': 0.7713976515452791, 'experiment_tag': 'exp', 'time_total_s': 0.9178686141967773}\n",
      "[flaml.automl.logger: 09-22 09:39:11] {2391} INFO -  at 224.8s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:39:11] {2218} INFO - iteration 112, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:39:11] {805} INFO - trial 1 config: {'n_estimators': 41, 'max_features': 0.21253721092088082, 'max_leaves': 74, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:39:14] {197} INFO - result: {'pred_time': 8.115530079618644e-05, 'wall_clock_time': 227.99731755256653, 'metric_for_logging': {'pred_time': 8.115530079618644e-05}, 'val_loss': 0.24538305171738456, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb61268c8e0>, 'training_iteration': 0, 'config': {'n_estimators': 41, 'max_features': 0.21253721092088082, 'max_leaves': 74, 'criterion': 'gini'}, 'config/n_estimators': 41, 'config/max_features': 0.21253721092088082, 'config/max_leaves': 74, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.158876657485962}\n",
      "[flaml.tune.tune: 09-22 09:39:14] {197} INFO - result: {'pred_time': 8.115530079618644e-05, 'wall_clock_time': 227.99731755256653, 'metric_for_logging': {'pred_time': 8.115530079618644e-05}, 'val_loss': 0.24538305171738456, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb61268c8e0>, 'training_iteration': 1, 'config': {'n_estimators': 41, 'max_features': 0.21253721092088082, 'max_leaves': 74, 'criterion': 'gini'}, 'config/n_estimators': 41, 'config/max_features': 0.21253721092088082, 'config/max_leaves': 74, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.16048002243042}\n",
      "[flaml.automl.logger: 09-22 09:39:14] {2391} INFO -  at 228.0s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:39:14] {2218} INFO - iteration 113, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:39:14] {805} INFO - trial 1 config: {'n_estimators': 122, 'max_leaves': 41, 'min_child_weight': 0.14284111713370123, 'learning_rate': 0.33871891376195123, 'subsample': 0.8552583010104474, 'colsample_bylevel': 0.40969897693864493, 'colsample_bytree': 0.5242912069083713, 'reg_alpha': 0.027316112801918414, 'reg_lambda': 0.023614300073837108}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:39:26] {197} INFO - result: {'pred_time': 5.131273799359492e-05, 'wall_clock_time': 240.15762162208557, 'metric_for_logging': {'pred_time': 5.131273799359492e-05}, 'val_loss': 0.19937655046350702, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb612686670>, 'training_iteration': 0, 'config': {'n_estimators': 122, 'max_leaves': 41, 'min_child_weight': 0.14284111713370123, 'learning_rate': 0.33871891376195123, 'subsample': 0.8552583010104474, 'colsample_bylevel': 0.40969897693864493, 'colsample_bytree': 0.5242912069083713, 'reg_alpha': 0.027316112801918414, 'reg_lambda': 0.023614300073837108}, 'config/n_estimators': 122, 'config/max_leaves': 41, 'config/min_child_weight': 0.14284111713370123, 'config/learning_rate': 0.33871891376195123, 'config/subsample': 0.8552583010104474, 'config/colsample_bylevel': 0.40969897693864493, 'config/colsample_bytree': 0.5242912069083713, 'config/reg_alpha': 0.027316112801918414, 'config/reg_lambda': 0.023614300073837108, 'experiment_tag': 'exp', 'time_total_s': 12.152066469192505}\n",
      "[flaml.tune.tune: 09-22 09:39:26] {197} INFO - result: {'pred_time': 5.131273799359492e-05, 'wall_clock_time': 240.15762162208557, 'metric_for_logging': {'pred_time': 5.131273799359492e-05}, 'val_loss': 0.19937655046350702, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb612686670>, 'training_iteration': 1, 'config': {'n_estimators': 122, 'max_leaves': 41, 'min_child_weight': 0.14284111713370123, 'learning_rate': 0.33871891376195123, 'subsample': 0.8552583010104474, 'colsample_bylevel': 0.40969897693864493, 'colsample_bytree': 0.5242912069083713, 'reg_alpha': 0.027316112801918414, 'reg_lambda': 0.023614300073837108}, 'config/n_estimators': 122, 'config/max_leaves': 41, 'config/min_child_weight': 0.14284111713370123, 'config/learning_rate': 0.33871891376195123, 'config/subsample': 0.8552583010104474, 'config/colsample_bylevel': 0.40969897693864493, 'config/colsample_bytree': 0.5242912069083713, 'config/reg_alpha': 0.027316112801918414, 'config/reg_lambda': 0.023614300073837108, 'experiment_tag': 'exp', 'time_total_s': 12.154161930084229}\n",
      "[flaml.automl.logger: 09-22 09:39:26] {2391} INFO -  at 240.2s,\testimator xgboost's best error=0.1988,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:39:26] {2218} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:39:26] {805} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.07815177236571483, 'max_leaves': 188, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:39:27] {197} INFO - result: {'pred_time': 4.4124252635334466e-05, 'wall_clock_time': 241.29074335098267, 'metric_for_logging': {'pred_time': 4.4124252635334466e-05}, 'val_loss': 0.2299553315857664, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6126869d0>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.07815177236571483, 'max_leaves': 188, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.07815177236571483, 'config/max_leaves': 188, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.1187012195587158}\n",
      "[flaml.tune.tune: 09-22 09:39:27] {197} INFO - result: {'pred_time': 4.4124252635334466e-05, 'wall_clock_time': 241.29074335098267, 'metric_for_logging': {'pred_time': 4.4124252635334466e-05}, 'val_loss': 0.2299553315857664, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb6126869d0>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.07815177236571483, 'max_leaves': 188, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.07815177236571483, 'config/max_leaves': 188, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.1200673580169678}\n",
      "[flaml.automl.logger: 09-22 09:39:27] {2391} INFO -  at 241.3s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:39:27] {2218} INFO - iteration 115, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:39:27] {805} INFO - trial 1 config: {'n_estimators': 63, 'num_leaves': 27, 'min_child_samples': 7, 'learning_rate': 0.07277397200667446, 'log_max_bin': 8, 'colsample_bytree': 0.7299825924602295, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.1727447205932465}\n",
      "[flaml.tune.tune: 09-22 09:39:28] {197} INFO - result: {'pred_time': 1.3013550092074433e-05, 'wall_clock_time': 242.21630883216858, 'metric_for_logging': {'pred_time': 1.3013550092074433e-05}, 'val_loss': 0.2067156866819536, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb61276edc0>, 'training_iteration': 0, 'config': {'n_estimators': 63, 'num_leaves': 27, 'min_child_samples': 7, 'learning_rate': 0.07277397200667446, 'log_max_bin': 8, 'colsample_bytree': 0.7299825924602295, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.1727447205932465}, 'config/n_estimators': 63, 'config/num_leaves': 27, 'config/min_child_samples': 7, 'config/learning_rate': 0.07277397200667446, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7299825924602295, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.1727447205932465, 'experiment_tag': 'exp', 'time_total_s': 0.9184610843658447}\n",
      "[flaml.tune.tune: 09-22 09:39:28] {197} INFO - result: {'pred_time': 1.3013550092074433e-05, 'wall_clock_time': 242.21630883216858, 'metric_for_logging': {'pred_time': 1.3013550092074433e-05}, 'val_loss': 0.2067156866819536, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb61276edc0>, 'training_iteration': 1, 'config': {'n_estimators': 63, 'num_leaves': 27, 'min_child_samples': 7, 'learning_rate': 0.07277397200667446, 'log_max_bin': 8, 'colsample_bytree': 0.7299825924602295, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.1727447205932465}, 'config/n_estimators': 63, 'config/num_leaves': 27, 'config/min_child_samples': 7, 'config/learning_rate': 0.07277397200667446, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7299825924602295, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.1727447205932465, 'experiment_tag': 'exp', 'time_total_s': 0.9199471473693848}\n",
      "[flaml.automl.logger: 09-22 09:39:28] {2391} INFO -  at 242.2s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:39:28] {2218} INFO - iteration 116, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:39:28] {805} INFO - trial 1 config: {'n_estimators': 128, 'num_leaves': 180, 'min_child_samples': 7, 'learning_rate': 0.5756100184567533, 'log_max_bin': 10, 'colsample_bytree': 0.8199992987418515, 'reg_alpha': 0.0030765362612518886, 'reg_lambda': 10.075555021977012}\n",
      "[flaml.tune.tune: 09-22 09:39:30] {197} INFO - result: {'pred_time': 1.5580408494296945e-05, 'wall_clock_time': 244.05507707595825, 'metric_for_logging': {'pred_time': 1.5580408494296945e-05}, 'val_loss': 0.20251916661212016, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb61278d940>, 'training_iteration': 0, 'config': {'n_estimators': 128, 'num_leaves': 180, 'min_child_samples': 7, 'learning_rate': 0.5756100184567533, 'log_max_bin': 10, 'colsample_bytree': 0.8199992987418515, 'reg_alpha': 0.0030765362612518886, 'reg_lambda': 10.075555021977012}, 'config/n_estimators': 128, 'config/num_leaves': 180, 'config/min_child_samples': 7, 'config/learning_rate': 0.5756100184567533, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8199992987418515, 'config/reg_alpha': 0.0030765362612518886, 'config/reg_lambda': 10.075555021977012, 'experiment_tag': 'exp', 'time_total_s': 1.8305957317352295}\n",
      "[flaml.tune.tune: 09-22 09:39:30] {197} INFO - result: {'pred_time': 1.5580408494296945e-05, 'wall_clock_time': 244.05507707595825, 'metric_for_logging': {'pred_time': 1.5580408494296945e-05}, 'val_loss': 0.20251916661212016, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb61278d940>, 'training_iteration': 1, 'config': {'n_estimators': 128, 'num_leaves': 180, 'min_child_samples': 7, 'learning_rate': 0.5756100184567533, 'log_max_bin': 10, 'colsample_bytree': 0.8199992987418515, 'reg_alpha': 0.0030765362612518886, 'reg_lambda': 10.075555021977012}, 'config/n_estimators': 128, 'config/num_leaves': 180, 'config/min_child_samples': 7, 'config/learning_rate': 0.5756100184567533, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8199992987418515, 'config/reg_alpha': 0.0030765362612518886, 'config/reg_lambda': 10.075555021977012, 'experiment_tag': 'exp', 'time_total_s': 1.8319263458251953}\n",
      "[flaml.automl.logger: 09-22 09:39:30] {2391} INFO -  at 244.1s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:39:30] {2218} INFO - iteration 117, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:39:30] {805} INFO - trial 1 config: {'n_estimators': 17, 'max_features': 0.2319343679951419, 'max_leaves': 74, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:39:32] {197} INFO - result: {'pred_time': 4.8076673875067176e-05, 'wall_clock_time': 245.80329656600952, 'metric_for_logging': {'pred_time': 4.8076673875067176e-05}, 'val_loss': 0.2726623261480833, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb612793d90>, 'training_iteration': 0, 'config': {'n_estimators': 17, 'max_features': 0.2319343679951419, 'max_leaves': 74, 'criterion': 'gini'}, 'config/n_estimators': 17, 'config/max_features': 0.2319343679951419, 'config/max_leaves': 74, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.7393524646759033}\n",
      "[flaml.tune.tune: 09-22 09:39:32] {197} INFO - result: {'pred_time': 4.8076673875067176e-05, 'wall_clock_time': 245.80329656600952, 'metric_for_logging': {'pred_time': 4.8076673875067176e-05}, 'val_loss': 0.2726623261480833, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb612793d90>, 'training_iteration': 1, 'config': {'n_estimators': 17, 'max_features': 0.2319343679951419, 'max_leaves': 74, 'criterion': 'gini'}, 'config/n_estimators': 17, 'config/max_features': 0.2319343679951419, 'config/max_leaves': 74, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.7410807609558105}\n",
      "[flaml.automl.logger: 09-22 09:39:32] {2391} INFO -  at 245.8s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-22 09:39:32] {2218} INFO - iteration 118, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:39:32] {805} INFO - trial 1 config: {'n_estimators': 139, 'max_leaves': 136, 'min_child_weight': 0.27084276373818733, 'learning_rate': 0.0484091845623208, 'subsample': 0.827351358517848, 'colsample_bylevel': 0.35468713776971533, 'colsample_bytree': 0.6256302030953867, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3630887969527579}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:39:50] {197} INFO - result: {'pred_time': 6.09387277988305e-05, 'wall_clock_time': 264.0940535068512, 'metric_for_logging': {'pred_time': 6.09387277988305e-05}, 'val_loss': 0.18431557783131994, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb612793520>, 'training_iteration': 0, 'config': {'n_estimators': 139, 'max_leaves': 136, 'min_child_weight': 0.27084276373818733, 'learning_rate': 0.0484091845623208, 'subsample': 0.827351358517848, 'colsample_bylevel': 0.35468713776971533, 'colsample_bytree': 0.6256302030953867, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3630887969527579}, 'config/n_estimators': 139, 'config/max_leaves': 136, 'config/min_child_weight': 0.27084276373818733, 'config/learning_rate': 0.0484091845623208, 'config/subsample': 0.827351358517848, 'config/colsample_bylevel': 0.35468713776971533, 'config/colsample_bytree': 0.6256302030953867, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.3630887969527579, 'experiment_tag': 'exp', 'time_total_s': 18.281781435012817}\n",
      "[flaml.tune.tune: 09-22 09:39:50] {197} INFO - result: {'pred_time': 6.09387277988305e-05, 'wall_clock_time': 264.0940535068512, 'metric_for_logging': {'pred_time': 6.09387277988305e-05}, 'val_loss': 0.18431557783131994, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb612793520>, 'training_iteration': 1, 'config': {'n_estimators': 139, 'max_leaves': 136, 'min_child_weight': 0.27084276373818733, 'learning_rate': 0.0484091845623208, 'subsample': 0.827351358517848, 'colsample_bylevel': 0.35468713776971533, 'colsample_bytree': 0.6256302030953867, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3630887969527579}, 'config/n_estimators': 139, 'config/max_leaves': 136, 'config/min_child_weight': 0.27084276373818733, 'config/learning_rate': 0.0484091845623208, 'config/subsample': 0.827351358517848, 'config/colsample_bylevel': 0.35468713776971533, 'config/colsample_bytree': 0.6256302030953867, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.3630887969527579, 'experiment_tag': 'exp', 'time_total_s': 18.28455424308777}\n",
      "[flaml.automl.logger: 09-22 09:39:50] {2391} INFO -  at 264.1s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-22 09:39:50] {2218} INFO - iteration 119, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:39:50] {805} INFO - trial 1 config: {'n_estimators': 44, 'num_leaves': 131, 'min_child_samples': 3, 'learning_rate': 0.24321040089125873, 'log_max_bin': 8, 'colsample_bytree': 0.7164365225991386, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.2734086212284228}\n",
      "[flaml.tune.tune: 09-22 09:39:52] {197} INFO - result: {'pred_time': 1.7498192471700217e-05, 'wall_clock_time': 266.66943860054016, 'metric_for_logging': {'pred_time': 1.7498192471700217e-05}, 'val_loss': 0.20709711845394, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb612793ac0>, 'training_iteration': 0, 'config': {'n_estimators': 44, 'num_leaves': 131, 'min_child_samples': 3, 'learning_rate': 0.24321040089125873, 'log_max_bin': 8, 'colsample_bytree': 0.7164365225991386, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.2734086212284228}, 'config/n_estimators': 44, 'config/num_leaves': 131, 'config/min_child_samples': 3, 'config/learning_rate': 0.24321040089125873, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7164365225991386, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.2734086212284228, 'experiment_tag': 'exp', 'time_total_s': 2.5621490478515625}\n",
      "[flaml.tune.tune: 09-22 09:39:52] {197} INFO - result: {'pred_time': 1.7498192471700217e-05, 'wall_clock_time': 266.66943860054016, 'metric_for_logging': {'pred_time': 1.7498192471700217e-05}, 'val_loss': 0.20709711845394, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb612793ac0>, 'training_iteration': 1, 'config': {'n_estimators': 44, 'num_leaves': 131, 'min_child_samples': 3, 'learning_rate': 0.24321040089125873, 'log_max_bin': 8, 'colsample_bytree': 0.7164365225991386, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.2734086212284228}, 'config/n_estimators': 44, 'config/num_leaves': 131, 'config/min_child_samples': 3, 'config/learning_rate': 0.24321040089125873, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7164365225991386, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.2734086212284228, 'experiment_tag': 'exp', 'time_total_s': 2.5637760162353516}\n",
      "[flaml.automl.logger: 09-22 09:39:52] {2391} INFO -  at 266.7s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-22 09:39:52] {2218} INFO - iteration 120, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:39:52] {805} INFO - trial 1 config: {'n_estimators': 62, 'max_leaves': 309, 'min_child_weight': 0.08786481946462457, 'learning_rate': 0.02398777014900063, 'subsample': 0.8857073593591062, 'colsample_bylevel': 0.4491830868977382, 'colsample_bytree': 0.7118212477763237, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.163353258094623}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:40:00] {197} INFO - result: {'pred_time': 5.547810983379073e-05, 'wall_clock_time': 274.3884439468384, 'metric_for_logging': {'pred_time': 5.547810983379073e-05}, 'val_loss': 0.2386212818746552, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb612685ee0>, 'training_iteration': 0, 'config': {'n_estimators': 62, 'max_leaves': 309, 'min_child_weight': 0.08786481946462457, 'learning_rate': 0.02398777014900063, 'subsample': 0.8857073593591062, 'colsample_bylevel': 0.4491830868977382, 'colsample_bytree': 0.7118212477763237, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.163353258094623}, 'config/n_estimators': 62, 'config/max_leaves': 309, 'config/min_child_weight': 0.08786481946462457, 'config/learning_rate': 0.02398777014900063, 'config/subsample': 0.8857073593591062, 'config/colsample_bylevel': 0.4491830868977382, 'config/colsample_bytree': 0.7118212477763237, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.163353258094623, 'experiment_tag': 'exp', 'time_total_s': 7.709319591522217}\n",
      "[flaml.tune.tune: 09-22 09:40:00] {197} INFO - result: {'pred_time': 5.547810983379073e-05, 'wall_clock_time': 274.3884439468384, 'metric_for_logging': {'pred_time': 5.547810983379073e-05}, 'val_loss': 0.2386212818746552, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb612685ee0>, 'training_iteration': 1, 'config': {'n_estimators': 62, 'max_leaves': 309, 'min_child_weight': 0.08786481946462457, 'learning_rate': 0.02398777014900063, 'subsample': 0.8857073593591062, 'colsample_bylevel': 0.4491830868977382, 'colsample_bytree': 0.7118212477763237, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.163353258094623}, 'config/n_estimators': 62, 'config/max_leaves': 309, 'config/min_child_weight': 0.08786481946462457, 'config/learning_rate': 0.02398777014900063, 'config/subsample': 0.8857073593591062, 'config/colsample_bylevel': 0.4491830868977382, 'config/colsample_bytree': 0.7118212477763237, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.163353258094623, 'experiment_tag': 'exp', 'time_total_s': 7.710632085800171}\n",
      "[flaml.automl.logger: 09-22 09:40:00] {2391} INFO -  at 274.4s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-22 09:40:00] {2218} INFO - iteration 121, current learner xgboost\n",
      "[flaml.tune.tune: 09-22 09:40:00] {805} INFO - trial 1 config: {'n_estimators': 311, 'max_leaves': 60, 'min_child_weight': 0.8348711477051795, 'learning_rate': 0.09769349695417481, 'subsample': 0.7689953576765899, 'colsample_bylevel': 0.26019118864169244, 'colsample_bytree': 0.5394391584144498, 'reg_alpha': 0.0044372497585360125, 'reg_lambda': 0.35984581637239343}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-22 09:40:56] {197} INFO - result: {'pred_time': 7.468240037115658e-05, 'wall_clock_time': 330.3612959384918, 'metric_for_logging': {'pred_time': 7.468240037115658e-05}, 'val_loss': 0.2060513662087875, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6126851c0>, 'training_iteration': 0, 'config': {'n_estimators': 311, 'max_leaves': 60, 'min_child_weight': 0.8348711477051795, 'learning_rate': 0.09769349695417481, 'subsample': 0.7689953576765899, 'colsample_bylevel': 0.26019118864169244, 'colsample_bytree': 0.5394391584144498, 'reg_alpha': 0.0044372497585360125, 'reg_lambda': 0.35984581637239343}, 'config/n_estimators': 311, 'config/max_leaves': 60, 'config/min_child_weight': 0.8348711477051795, 'config/learning_rate': 0.09769349695417481, 'config/subsample': 0.7689953576765899, 'config/colsample_bylevel': 0.26019118864169244, 'config/colsample_bytree': 0.5394391584144498, 'config/reg_alpha': 0.0044372497585360125, 'config/reg_lambda': 0.35984581637239343, 'experiment_tag': 'exp', 'time_total_s': 55.96419286727905}\n",
      "[flaml.tune.tune: 09-22 09:40:56] {197} INFO - result: {'pred_time': 7.468240037115658e-05, 'wall_clock_time': 330.3612959384918, 'metric_for_logging': {'pred_time': 7.468240037115658e-05}, 'val_loss': 0.2060513662087875, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fb6126851c0>, 'training_iteration': 1, 'config': {'n_estimators': 311, 'max_leaves': 60, 'min_child_weight': 0.8348711477051795, 'learning_rate': 0.09769349695417481, 'subsample': 0.7689953576765899, 'colsample_bylevel': 0.26019118864169244, 'colsample_bytree': 0.5394391584144498, 'reg_alpha': 0.0044372497585360125, 'reg_lambda': 0.35984581637239343}, 'config/n_estimators': 311, 'config/max_leaves': 60, 'config/min_child_weight': 0.8348711477051795, 'config/learning_rate': 0.09769349695417481, 'config/subsample': 0.7689953576765899, 'config/colsample_bylevel': 0.26019118864169244, 'config/colsample_bytree': 0.5394391584144498, 'config/reg_alpha': 0.0044372497585360125, 'config/reg_lambda': 0.35984581637239343, 'experiment_tag': 'exp', 'time_total_s': 55.96576166152954}\n",
      "[flaml.automl.logger: 09-22 09:40:56] {2391} INFO -  at 330.4s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-22 09:40:56] {2218} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:40:56] {805} INFO - trial 1 config: {'n_estimators': 38, 'max_features': 0.07161577592278397, 'max_leaves': 188, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-22 09:40:58] {197} INFO - result: {'pred_time': 7.194808912728156e-05, 'wall_clock_time': 332.1506929397583, 'metric_for_logging': {'pred_time': 7.194808912728156e-05}, 'val_loss': 0.20063667490579035, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb612685ee0>, 'training_iteration': 0, 'config': {'n_estimators': 38, 'max_features': 0.07161577592278397, 'max_leaves': 188, 'criterion': 'entropy'}, 'config/n_estimators': 38, 'config/max_features': 0.07161577592278397, 'config/max_leaves': 188, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.7808098793029785}\n",
      "[flaml.tune.tune: 09-22 09:40:58] {197} INFO - result: {'pred_time': 7.194808912728156e-05, 'wall_clock_time': 332.1506929397583, 'metric_for_logging': {'pred_time': 7.194808912728156e-05}, 'val_loss': 0.20063667490579035, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fb612685ee0>, 'training_iteration': 1, 'config': {'n_estimators': 38, 'max_features': 0.07161577592278397, 'max_leaves': 188, 'criterion': 'entropy'}, 'config/n_estimators': 38, 'config/max_features': 0.07161577592278397, 'config/max_leaves': 188, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.7823255062103271}\n",
      "[flaml.automl.logger: 09-22 09:40:58] {2391} INFO -  at 332.2s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-22 09:40:58] {2218} INFO - iteration 123, current learner catboost\n",
      "[flaml.tune.tune: 09-22 09:40:58] {805} INFO - trial 1 config: {'early_stopping_rounds': 17, 'learning_rate': 0.06174502859383565, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-22 09:41:03] {197} INFO - result: {'pred_time': 0.00014563827053256886, 'wall_clock_time': 337.3034842014313, 'metric_for_logging': {'pred_time': 0.00014563827053256886}, 'val_loss': 0.23572294760450685, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb6126ccb80>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 17, 'learning_rate': 0.06174502859383565, 'n_estimators': 8192}, 'config/early_stopping_rounds': 17, 'config/learning_rate': 0.06174502859383565, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.145512580871582}\n",
      "[flaml.tune.tune: 09-22 09:41:03] {197} INFO - result: {'pred_time': 0.00014563827053256886, 'wall_clock_time': 337.3034842014313, 'metric_for_logging': {'pred_time': 0.00014563827053256886}, 'val_loss': 0.23572294760450685, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fb6126ccb80>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 17, 'learning_rate': 0.06174502859383565, 'n_estimators': 8192}, 'config/early_stopping_rounds': 17, 'config/learning_rate': 0.06174502859383565, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.146941900253296}\n",
      "[flaml.automl.logger: 09-22 09:41:03] {2391} INFO -  at 337.3s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-22 09:41:03] {2218} INFO - iteration 124, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:41:03] {805} INFO - trial 1 config: {'n_estimators': 183, 'num_leaves': 37, 'min_child_samples': 14, 'learning_rate': 0.1722353452665958, 'log_max_bin': 10, 'colsample_bytree': 0.8335453686029424, 'reg_alpha': 0.007704104902643929, 'reg_lambda': 1.366803167560063}\n",
      "[flaml.tune.tune: 09-22 09:41:05] {197} INFO - result: {'pred_time': 1.770941968900238e-05, 'wall_clock_time': 339.281396150589, 'metric_for_logging': {'pred_time': 1.770941968900238e-05}, 'val_loss': 0.21238979436130861, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6127ef3d0>, 'training_iteration': 0, 'config': {'n_estimators': 183, 'num_leaves': 37, 'min_child_samples': 14, 'learning_rate': 0.1722353452665958, 'log_max_bin': 10, 'colsample_bytree': 0.8335453686029424, 'reg_alpha': 0.007704104902643929, 'reg_lambda': 1.366803167560063}, 'config/n_estimators': 183, 'config/num_leaves': 37, 'config/min_child_samples': 14, 'config/learning_rate': 0.1722353452665958, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8335453686029424, 'config/reg_alpha': 0.007704104902643929, 'config/reg_lambda': 1.366803167560063, 'experiment_tag': 'exp', 'time_total_s': 1.9712958335876465}\n",
      "[flaml.tune.tune: 09-22 09:41:05] {197} INFO - result: {'pred_time': 1.770941968900238e-05, 'wall_clock_time': 339.281396150589, 'metric_for_logging': {'pred_time': 1.770941968900238e-05}, 'val_loss': 0.21238979436130861, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6127ef3d0>, 'training_iteration': 1, 'config': {'n_estimators': 183, 'num_leaves': 37, 'min_child_samples': 14, 'learning_rate': 0.1722353452665958, 'log_max_bin': 10, 'colsample_bytree': 0.8335453686029424, 'reg_alpha': 0.007704104902643929, 'reg_lambda': 1.366803167560063}, 'config/n_estimators': 183, 'config/num_leaves': 37, 'config/min_child_samples': 14, 'config/learning_rate': 0.1722353452665958, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8335453686029424, 'config/reg_alpha': 0.007704104902643929, 'config/reg_lambda': 1.366803167560063, 'experiment_tag': 'exp', 'time_total_s': 1.9731299877166748}\n",
      "[flaml.automl.logger: 09-22 09:41:05] {2391} INFO -  at 339.3s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-22 09:41:05] {2218} INFO - iteration 125, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:41:05] {805} INFO - trial 1 config: {'n_estimators': 58, 'num_leaves': 164, 'min_child_samples': 5, 'learning_rate': 0.08389408909662875, 'log_max_bin': 8, 'colsample_bytree': 0.8868216197727644, 'reg_alpha': 0.0024737385712432494, 'reg_lambda': 0.7449904363544727}\n",
      "[flaml.tune.tune: 09-22 09:41:07] {197} INFO - result: {'pred_time': 1.3793408682499292e-05, 'wall_clock_time': 341.1659994125366, 'metric_for_logging': {'pred_time': 1.3793408682499292e-05}, 'val_loss': 0.19760312151616505, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6127d9be0>, 'training_iteration': 0, 'config': {'n_estimators': 58, 'num_leaves': 164, 'min_child_samples': 5, 'learning_rate': 0.08389408909662875, 'log_max_bin': 8, 'colsample_bytree': 0.8868216197727644, 'reg_alpha': 0.0024737385712432494, 'reg_lambda': 0.7449904363544727}, 'config/n_estimators': 58, 'config/num_leaves': 164, 'config/min_child_samples': 5, 'config/learning_rate': 0.08389408909662875, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8868216197727644, 'config/reg_alpha': 0.0024737385712432494, 'config/reg_lambda': 0.7449904363544727, 'experiment_tag': 'exp', 'time_total_s': 1.8770496845245361}\n",
      "[flaml.tune.tune: 09-22 09:41:07] {197} INFO - result: {'pred_time': 1.3793408682499292e-05, 'wall_clock_time': 341.1659994125366, 'metric_for_logging': {'pred_time': 1.3793408682499292e-05}, 'val_loss': 0.19760312151616505, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6127d9be0>, 'training_iteration': 1, 'config': {'n_estimators': 58, 'num_leaves': 164, 'min_child_samples': 5, 'learning_rate': 0.08389408909662875, 'log_max_bin': 8, 'colsample_bytree': 0.8868216197727644, 'reg_alpha': 0.0024737385712432494, 'reg_lambda': 0.7449904363544727}, 'config/n_estimators': 58, 'config/num_leaves': 164, 'config/min_child_samples': 5, 'config/learning_rate': 0.08389408909662875, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8868216197727644, 'config/reg_alpha': 0.0024737385712432494, 'config/reg_lambda': 0.7449904363544727, 'experiment_tag': 'exp', 'time_total_s': 1.8792402744293213}\n",
      "[flaml.automl.logger: 09-22 09:41:07] {2391} INFO -  at 341.2s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-22 09:41:07] {2218} INFO - iteration 126, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:41:07] {805} INFO - trial 1 config: {'n_estimators': 140, 'num_leaves': 30, 'min_child_samples': 9, 'learning_rate': 0.49931321528129496, 'log_max_bin': 10, 'colsample_bytree': 0.6631602714293166, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.3362701749706174}\n",
      "[flaml.tune.tune: 09-22 09:41:09] {197} INFO - result: {'pred_time': 1.6183994119902874e-05, 'wall_clock_time': 342.8782048225403, 'metric_for_logging': {'pred_time': 1.6183994119902874e-05}, 'val_loss': 0.21155556144311766, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb612634e80>, 'training_iteration': 0, 'config': {'n_estimators': 140, 'num_leaves': 30, 'min_child_samples': 9, 'learning_rate': 0.49931321528129496, 'log_max_bin': 10, 'colsample_bytree': 0.6631602714293166, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.3362701749706174}, 'config/n_estimators': 140, 'config/num_leaves': 30, 'config/min_child_samples': 9, 'config/learning_rate': 0.49931321528129496, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.6631602714293166, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.3362701749706174, 'experiment_tag': 'exp', 'time_total_s': 1.704270362854004}\n",
      "[flaml.tune.tune: 09-22 09:41:09] {197} INFO - result: {'pred_time': 1.6183994119902874e-05, 'wall_clock_time': 342.8782048225403, 'metric_for_logging': {'pred_time': 1.6183994119902874e-05}, 'val_loss': 0.21155556144311766, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb612634e80>, 'training_iteration': 1, 'config': {'n_estimators': 140, 'num_leaves': 30, 'min_child_samples': 9, 'learning_rate': 0.49931321528129496, 'log_max_bin': 10, 'colsample_bytree': 0.6631602714293166, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.3362701749706174}, 'config/n_estimators': 140, 'config/num_leaves': 30, 'config/min_child_samples': 9, 'config/learning_rate': 0.49931321528129496, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.6631602714293166, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.3362701749706174, 'experiment_tag': 'exp', 'time_total_s': 1.705888032913208}\n",
      "[flaml.automl.logger: 09-22 09:41:09] {2391} INFO -  at 342.9s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-22 09:41:09] {2218} INFO - iteration 127, current learner lgbm\n",
      "[flaml.tune.tune: 09-22 09:41:09] {805} INFO - trial 1 config: {'n_estimators': 331, 'num_leaves': 86, 'min_child_samples': 6, 'learning_rate': 0.3096720505974023, 'log_max_bin': 8, 'colsample_bytree': 0.7864517246350571, 'reg_alpha': 0.0009765625, 'reg_lambda': 3.312526650778918}\n",
      "[flaml.tune.tune: 09-22 09:41:13] {197} INFO - result: {'pred_time': 2.4324671212132207e-05, 'wall_clock_time': 347.55897307395935, 'metric_for_logging': {'pred_time': 2.4324671212132207e-05}, 'val_loss': 0.2049279847255859, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6127cf880>, 'training_iteration': 0, 'config': {'n_estimators': 331, 'num_leaves': 86, 'min_child_samples': 6, 'learning_rate': 0.3096720505974023, 'log_max_bin': 8, 'colsample_bytree': 0.7864517246350571, 'reg_alpha': 0.0009765625, 'reg_lambda': 3.312526650778918}, 'config/n_estimators': 331, 'config/num_leaves': 86, 'config/min_child_samples': 6, 'config/learning_rate': 0.3096720505974023, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7864517246350571, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 3.312526650778918, 'experiment_tag': 'exp', 'time_total_s': 4.671325206756592}\n",
      "[flaml.tune.tune: 09-22 09:41:13] {197} INFO - result: {'pred_time': 2.4324671212132207e-05, 'wall_clock_time': 347.55897307395935, 'metric_for_logging': {'pred_time': 2.4324671212132207e-05}, 'val_loss': 0.2049279847255859, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fb6127cf880>, 'training_iteration': 1, 'config': {'n_estimators': 331, 'num_leaves': 86, 'min_child_samples': 6, 'learning_rate': 0.3096720505974023, 'log_max_bin': 8, 'colsample_bytree': 0.7864517246350571, 'reg_alpha': 0.0009765625, 'reg_lambda': 3.312526650778918}, 'config/n_estimators': 331, 'config/num_leaves': 86, 'config/min_child_samples': 6, 'config/learning_rate': 0.3096720505974023, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7864517246350571, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 3.312526650778918, 'experiment_tag': 'exp', 'time_total_s': 4.672997236251831}\n",
      "[flaml.automl.logger: 09-22 09:41:13] {2391} INFO -  at 347.6s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-22 09:41:13] {2218} INFO - iteration 128, current learner rf\n",
      "[flaml.tune.tune: 09-22 09:41:13] {805} INFO - trial 1 config: {'n_estimators': 96, 'max_features': 0.0791113601496617, 'max_leaves': 87, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-22 09:41:17] {197} INFO - result: {'pred_time': 0.00016521295109983596, 'wall_clock_time': 351.234525680542, 'metric_for_logging': {'pred_time': 0.00016521295109983596}, 'val_loss': 0.20387214137214132, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6127bd430>, 'training_iteration': 0, 'config': {'n_estimators': 96, 'max_features': 0.0791113601496617, 'max_leaves': 87, 'criterion': 'gini'}, 'config/n_estimators': 96, 'config/max_features': 0.0791113601496617, 'config/max_leaves': 87, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.667492628097534}\n",
      "[flaml.tune.tune: 09-22 09:41:17] {197} INFO - result: {'pred_time': 0.00016521295109983596, 'wall_clock_time': 351.234525680542, 'metric_for_logging': {'pred_time': 0.00016521295109983596}, 'val_loss': 0.20387214137214132, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fb6127bd430>, 'training_iteration': 1, 'config': {'n_estimators': 96, 'max_features': 0.0791113601496617, 'max_leaves': 87, 'criterion': 'gini'}, 'config/n_estimators': 96, 'config/max_features': 0.0791113601496617, 'config/max_leaves': 87, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.669039487838745}\n",
      "[flaml.automl.logger: 09-22 09:41:17] {2391} INFO -  at 351.2s,\testimator rf's best error=0.2012,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-22 09:41:17] {2218} INFO - iteration 129, current learner extra_tree\n",
      "[flaml.tune.tune: 09-22 09:41:17] {805} INFO - trial 1 config: {'n_estimators': 113, 'max_features': 0.09334685589808495, 'max_leaves': 148, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, task=\"classification\", time_budget=time_sec, verbose=9999, ensemble=True)\n",
    "# uses all cores by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea52c1-8ff3-4a48-be91-6015bbbb457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "accuracy_score(y_test,y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60425775-59ef-4b5c-a914-bf63d711070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccceaa-35a5-4018-8dc3-5fdffb920b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(automl.best_estimator)\n",
    "print(automl.best_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
