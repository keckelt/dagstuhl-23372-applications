{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55541fc6-cd46-46b2-b6a5-f89bdb44899a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install tpot autogluon flaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3789628-8882-402b-8a60-f9271bb6b8de",
   "metadata": {},
   "source": [
    "Random State for reproduceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c395ba-a71a-4bcf-8069-fc305f169202",
   "metadata": {},
   "outputs": [],
   "source": [
    "dagstuhl_seed=23372"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1303b68e-b938-41a9-b5e5-97dc019b210f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eb22754-a6e5-46b9-b3fc-739b2af1f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "870655ba-ff06-4298-99ed-58bc8cfbea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(dagstuhl_seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884ebf47-3b49-4ec4-8b4a-23959f8325ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label    0    1    2    3    4    5    6    7    8  ...  1014  1015  \\\n",
       "4306      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4307      0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4308      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4309      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4310      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "      1016  1017  1018  1019  1020  1021  1022  1023  \n",
       "4306   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "4307   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4308   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "4309   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4310   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/preprocessed.csv')\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df = df.replace(['inactive', 'active'], [0,1]) # swap -1 (inactive) and 0 (unknown)\n",
    "\n",
    "df_train = pd.read_csv('../data/preprocessed-train.csv')\n",
    "df_train = df_train.loc[:, ~df_train.columns.str.contains('^Unnamed')]\n",
    "df_train = df_train.replace(['inactive', 'active'], [0,1]) # swap -1 (inactive) and 0 (unknown)\n",
    "\n",
    "df_test = pd.read_csv('../data/preprocessed-test.csv')\n",
    "df_test = df_test.loc[:, ~df_test.columns.str.contains('^Unnamed')]\n",
    "df_test = df_test.replace(['inactive', 'active'], [0,1]) # swap -1 (inactive) and 0 (unknown)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a58bed2-9e3a-4962-8e78-ccc5f81c7d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3592, 1024)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_train['label']\n",
    "X_train = df_train.loc[:, df_train.columns != \"label\"]\n",
    "\n",
    "y_test = df_train['label']\n",
    "X_test = df_train.loc[:, df_train.columns != \"label\"]\n",
    "\n",
    "X_train.to_numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d40d74c-0227-460e-b1cd-24cac3726434",
   "metadata": {},
   "source": [
    "# AutoML Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165047b1-0dfc-4af9-9e03-dfcbaf08760f",
   "metadata": {},
   "source": [
    "### Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b4e45e-fc54-4069-a0b2-a153954f4ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) \\n[GCC 10.3.0]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e60c125-1e0a-45af-8867-bddba8b62fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tpot\n",
    "tpot.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "411d5837-f2d4-4996-a5e6-27012a509d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon import tabular\n",
    "tabular.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "419b5431-4b4d-4dc9-921d-4fc0cb1461fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flaml\n",
    "flaml.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a07c7f-b6a5-452c-9631-0eb1e734d3cf",
   "metadata": {},
   "source": [
    "### Time Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79ae1dff-2785-43a9-a751-8f378fabe79f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_min = 30\n",
    "time_sec = time_min * 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546170fd-da52-4552-b1dc-1e3d7c056245",
   "metadata": {},
   "source": [
    "## AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccbff795-2c98-4d67-97c0-b7dc2e32389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7704b97-ef64-4330-a55e-3270f217f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(df_train)\n",
    "test_data = TabularDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eed093c-2780-46f6-b3a5-766f532476d9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230925_120315/\"\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'auto_stack': True, 'verbosity': 4}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': True,\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 4}\n",
      "========================================\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20\n",
      "Saving AutogluonModels/ag-20230925_120315/learner.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/predictor.pkl\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230925_120315/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Jan 27 02:56:13 UTC 2023\n",
      "Disk Space Avail:   923.39 GB / 1081.10 GB (85.4%)\n",
      "Train Data Rows:    3592\n",
      "Train Data Columns: 1024\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14944.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 29.43 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 951 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\t0.5s = Fit runtime\n",
      "\t\t\t951 features in original data used to generate 951 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t951 features in original data used to generate 951 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t951 features in original data used to generate 951 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 951 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t951 features in original data used to generate 951 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\t65 duplicate columns removed: ['291', '553', '765', '773', '933', '986', '993', '514', '48', '76', '86', '103', '146', '163', '170', '174', '182', '195', '223', '234', '254', '262', '267', '298', '303', '330', '334', '336', '368', '375', '400', '439', '466', '488', '509', '515', '532', '536', '566', '581', '596', '613', '625', '630', '631', '645', '647', '660', '685', '712', '719', '746', '777', '818', '843', '876', '901', '907', '919', '963', '966', '988', '1006', '1012', '1018']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\t\t\t5.3s = Fit runtime\n",
      "\t\t\t886 features in original data used to generate 886 features in processed data.\n",
      "\tUseless Original Features (Count: 73): ['2', '16', '20', '21', '68', '78', '82', '93', '100', '109', '127', '153', '161', '168', '173', '185', '187', '201', '203', '205', '217', '230', '243', '311', '331', '340', '354', '365', '377', '388', '390', '405', '410', '411', '415', '436', '437', '443', '450', '454', '459', '465', '475', '477', '513', '522', '529', '530', '572', '595', '618', '638', '648', '651', '671', '689', '717', '768', '774', '776', '780', '793', '797', '817', '858', '866', '870', '903', '906', '912', '930', '1008', '1023']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 65): ['48', '76', '86', '103', '146', '163', '170', '174', '182', '195', '223', '234', '254', '262', '267', '291', '298', '303', '330', '334', '336', '368', '375', '400', '439', '466', '488', '509', '514', '515', '532', '536', '553', '566', '581', '596', '613', '625', '630', '631', '645', '647', '660', '685', '712', '719', '746', '765', '773', '777', '818', '843', '876', '901', '907', '919', '933', '963', '966', '986', '988', '993', '1006', '1012', '1018']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 65 | ['48', '76', '86', '103', '146', ...]\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('int8', 'int') : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', ['bool']) : 886 | ['0', '1', '3', '4', '5', ...]\n",
      "\t7.1s = Fit runtime\n",
      "\t886 features in original data used to generate 886 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.18 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 7.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving AutogluonModels/ag-20230925_120315/learner.pkl\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Saving AutogluonModels/ag-20230925_120315/utils/data/X.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/utils/data/y.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1792.74s of the 1792.71s of remaining time.\n",
      "\tDropped 886 of 886 features.\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1792.68s of the 1792.65s of remaining time.\n",
      "\tDropped 886 of 886 features.\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1792.64s of the 1792.61s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9357\t = Validation score   (accuracy)\n",
      "\t5.22s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1780.33s of the 1780.3s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9357\t = Validation score   (accuracy)\n",
      "\t7.07s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1768.44s of the 1768.42s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting RandomForestGini_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230925_120315/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 886 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving AutogluonModels/ag-20230925_120315/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/RandomForestGini_BAG_L1/model.pkl\n",
      "\t0.9329\t = Validation score   (accuracy)\n",
      "\t2.07s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1765.15s of the 1765.12s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting RandomForestEntr_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230925_120315/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 886 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving AutogluonModels/ag-20230925_120315/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "\t0.9335\t = Validation score   (accuracy)\n",
      "\t1.88s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1762.02s of the 1761.99s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9357\t = Validation score   (accuracy)\n",
      "\t17.74s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1739.52s of the 1739.48s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting ExtraTreesGini_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230925_120315/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 886 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving AutogluonModels/ag-20230925_120315/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "\t0.9323\t = Validation score   (accuracy)\n",
      "\t2.71s\t = Training   runtime\n",
      "\t1.11s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1735.33s of the 1735.3s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting ExtraTreesEntr_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230925_120315/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 886 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving AutogluonModels/ag-20230925_120315/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "\t0.9323\t = Validation score   (accuracy)\n",
      "\t1.81s\t = Training   runtime\n",
      "\t0.89s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1732.38s of the 1732.35s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9207\t = Validation score   (accuracy)\n",
      "\t25.71s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1702.01s of the 1701.97s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9354\t = Validation score   (accuracy)\n",
      "\t14.25s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1682.22s of the 1682.18s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t27.72s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1649.9s of the 1649.88s of remaining time.\n",
      "\tDropped 0 of 886 features.\n",
      "\tDropped 0 of 886 features.\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9368\t = Validation score   (accuracy)\n",
      "\t9.9s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Repeating k-fold bagging: 2/20\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1635.11s of the 1635.08s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9326\t = Validation score   (accuracy)\n",
      "\t12.01s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1622.86s of the 1622.82s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9326\t = Validation score   (accuracy)\n",
      "\t13.18s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1610.91s of the 1610.87s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9332\t = Validation score   (accuracy)\n",
      "\t36.71s\t = Training   runtime\n",
      "\t1.73s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1586.35s of the 1586.31s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9207\t = Validation score   (accuracy)\n",
      "\t59.87s\t = Training   runtime\n",
      "\t1.02s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1547.15s of the 1547.1s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9323\t = Validation score   (accuracy)\n",
      "\t29.73s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1525.72s of the 1525.69s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9329\t = Validation score   (accuracy)\n",
      "\t62.13s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1486.44s of the 1486.41s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9343\t = Validation score   (accuracy)\n",
      "\t21.64s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Repeating k-fold bagging: 3/20\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1469.25s of the 1469.22s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9332\t = Validation score   (accuracy)\n",
      "\t17.29s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1459.05s of the 1459.01s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9332\t = Validation score   (accuracy)\n",
      "\t18.89s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1448.42s of the 1448.38s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t52.11s\t = Training   runtime\n",
      "\t2.61s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1427.8s of the 1427.77s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9273\t = Validation score   (accuracy)\n",
      "\t85.85s\t = Training   runtime\n",
      "\t1.49s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1397.14s of the 1397.1s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9318\t = Validation score   (accuracy)\n",
      "\t48.28s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1371.79s of the 1371.77s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9354\t = Validation score   (accuracy)\n",
      "\t89.56s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1339.79s of the 1339.76s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9346\t = Validation score   (accuracy)\n",
      "\t31.59s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Repeating k-fold bagging: 4/20\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1324.93s of the 1324.9s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9337\t = Validation score   (accuracy)\n",
      "\t22.14s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1315.27s of the 1315.24s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9337\t = Validation score   (accuracy)\n",
      "\t23.69s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1305.43s of the 1305.4s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t68.39s\t = Training   runtime\n",
      "\t3.36s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1283.86s of the 1283.83s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9304\t = Validation score   (accuracy)\n",
      "\t110.51s\t = Training   runtime\n",
      "\t1.91s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1254.45s of the 1254.41s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9329\t = Validation score   (accuracy)\n",
      "\t61.9s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1235.08s of the 1235.05s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9329\t = Validation score   (accuracy)\n",
      "\t118.83s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1201.13s of the 1201.11s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t42.46s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Repeating k-fold bagging: 5/20\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1185.31s of the 1185.28s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9337\t = Validation score   (accuracy)\n",
      "\t27.7s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1174.95s of the 1174.91s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9337\t = Validation score   (accuracy)\n",
      "\t29.3s\t = Training   runtime\n",
      "\t1.33s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1164.5s of the 1164.46s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9335\t = Validation score   (accuracy)\n",
      "\t83.61s\t = Training   runtime\n",
      "\t4.14s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1144.11s of the 1144.08s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9273\t = Validation score   (accuracy)\n",
      "\t135.41s\t = Training   runtime\n",
      "\t2.32s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1114.71s of the 1114.68s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9343\t = Validation score   (accuracy)\n",
      "\t79.74s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1091.32s of the 1091.29s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9346\t = Validation score   (accuracy)\n",
      "\t146.2s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1059.28s of the 1059.25s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9349\t = Validation score   (accuracy)\n",
      "\t51.89s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Repeating k-fold bagging: 6/20\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1044.81s of the 1044.77s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9351\t = Validation score   (accuracy)\n",
      "\t32.45s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1035.21s of the 1035.16s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9351\t = Validation score   (accuracy)\n",
      "\t34.13s\t = Training   runtime\n",
      "\t1.51s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1025.23s of the 1025.2s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9332\t = Validation score   (accuracy)\n",
      "\t102.47s\t = Training   runtime\n",
      "\t5.09s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1001.29s of the 1001.26s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.929\t = Validation score   (accuracy)\n",
      "\t160.72s\t = Training   runtime\n",
      "\t2.71s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 971.44s of the 971.4s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t96.0s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 949.78s of the 949.75s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9335\t = Validation score   (accuracy)\n",
      "\t176.37s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 914.55s of the 914.52s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9346\t = Validation score   (accuracy)\n",
      "\t61.48s\t = Training   runtime\n",
      "\t1.21s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Repeating k-fold bagging: 7/20\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 900.08s of the 900.05s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9354\t = Validation score   (accuracy)\n",
      "\t37.7s\t = Training   runtime\n",
      "\t1.46s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 890.05s of the 890.01s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9354\t = Validation score   (accuracy)\n",
      "\t39.37s\t = Training   runtime\n",
      "\t1.75s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 879.81s of the 879.78s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9326\t = Validation score   (accuracy)\n",
      "\t120.51s\t = Training   runtime\n",
      "\t5.99s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 856.7s of the 856.67s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9301\t = Validation score   (accuracy)\n",
      "\t185.47s\t = Training   runtime\n",
      "\t3.1s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 827.46s of the 827.43s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9332\t = Validation score   (accuracy)\n",
      "\t110.87s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 807.2s of the 807.17s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9346\t = Validation score   (accuracy)\n",
      "\t199.34s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 779.42s of the 779.38s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9343\t = Validation score   (accuracy)\n",
      "\t71.57s\t = Training   runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Repeating k-fold bagging: 8/20\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 764.46s of the 764.43s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.936\t = Validation score   (accuracy)\n",
      "\t42.62s\t = Training   runtime\n",
      "\t1.68s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 754.78s of the 754.75s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.936\t = Validation score   (accuracy)\n",
      "\t44.42s\t = Training   runtime\n",
      "\t1.92s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 744.92s of the 744.89s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9329\t = Validation score   (accuracy)\n",
      "\t137.99s\t = Training   runtime\n",
      "\t6.82s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 722.43s of the 722.41s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9296\t = Validation score   (accuracy)\n",
      "\t210.61s\t = Training   runtime\n",
      "\t3.47s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 692.54s of the 692.51s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9346\t = Validation score   (accuracy)\n",
      "\t128.79s\t = Training   runtime\n",
      "\t1.06s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 669.13s of the 669.1s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9337\t = Validation score   (accuracy)\n",
      "\t222.03s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 641.67s of the 641.64s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S8F1 - S8F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9351\t = Validation score   (accuracy)\n",
      "\t81.98s\t = Training   runtime\n",
      "\t1.65s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Repeating k-fold bagging: 9/20\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 625.8s of the 625.77s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9357\t = Validation score   (accuracy)\n",
      "\t47.45s\t = Training   runtime\n",
      "\t1.89s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 616.22s of the 616.19s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9357\t = Validation score   (accuracy)\n",
      "\t49.64s\t = Training   runtime\n",
      "\t2.1s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 605.94s of the 605.91s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9329\t = Validation score   (accuracy)\n",
      "\t152.17s\t = Training   runtime\n",
      "\t7.53s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 586.39s of the 586.36s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9312\t = Validation score   (accuracy)\n",
      "\t235.4s\t = Training   runtime\n",
      "\t3.92s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 556.74s of the 556.71s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t141.75s\t = Training   runtime\n",
      "\t1.17s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 538.34s of the 538.31s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9337\t = Validation score   (accuracy)\n",
      "\t248.65s\t = Training   runtime\n",
      "\t1.33s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 507.22s of the 507.19s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S9F1 - S9F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9349\t = Validation score   (accuracy)\n",
      "\t90.74s\t = Training   runtime\n",
      "\t1.83s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Repeating k-fold bagging: 10/20\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 493.58s of the 493.54s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S10F1 - S10F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9351\t = Validation score   (accuracy)\n",
      "\t52.63s\t = Training   runtime\n",
      "\t2.06s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 483.21s of the 483.18s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S10F1 - S10F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9351\t = Validation score   (accuracy)\n",
      "\t55.29s\t = Training   runtime\n",
      "\t2.3s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 471.98s of the 471.94s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S10F1 - S10F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9329\t = Validation score   (accuracy)\n",
      "\t164.78s\t = Training   runtime\n",
      "\t8.29s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 454.36s of the 454.33s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S10F1 - S10F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9304\t = Validation score   (accuracy)\n",
      "\t260.25s\t = Training   runtime\n",
      "\t4.3s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 424.83s of the 424.8s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S10F1 - S10F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9343\t = Validation score   (accuracy)\n",
      "\t154.55s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 406.49s of the 406.46s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S10F1 - S10F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9335\t = Validation score   (accuracy)\n",
      "\t274.1s\t = Training   runtime\n",
      "\t1.46s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 376.05s of the 376.02s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S10F1 - S10F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9346\t = Validation score   (accuracy)\n",
      "\t99.85s\t = Training   runtime\n",
      "\t1.99s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Repeating k-fold bagging: 11/20\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 362.12s of the 362.09s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S11F1 - S11F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9351\t = Validation score   (accuracy)\n",
      "\t57.96s\t = Training   runtime\n",
      "\t2.28s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 351.6s of the 351.56s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S11F1 - S11F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9351\t = Validation score   (accuracy)\n",
      "\t60.73s\t = Training   runtime\n",
      "\t2.54s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 340.75s of the 340.71s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S11F1 - S11F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9326\t = Validation score   (accuracy)\n",
      "\t177.98s\t = Training   runtime\n",
      "\t8.94s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 322.55s of the 322.52s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S11F1 - S11F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9307\t = Validation score   (accuracy)\n",
      "\t285.17s\t = Training   runtime\n",
      "\t4.64s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 292.58s of the 292.55s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S11F1 - S11F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t173.11s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 268.56s of the 268.53s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S11F1 - S11F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9335\t = Validation score   (accuracy)\n",
      "\t301.01s\t = Training   runtime\n",
      "\t1.61s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 237.02s of the 236.99s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S11F1 - S11F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9354\t = Validation score   (accuracy)\n",
      "\t109.68s\t = Training   runtime\n",
      "\t2.15s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Repeating k-fold bagging: 12/20\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 221.24s of the 221.21s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S12F1 - S12F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9349\t = Validation score   (accuracy)\n",
      "\t63.22s\t = Training   runtime\n",
      "\t2.45s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 211.25s of the 211.22s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S12F1 - S12F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9349\t = Validation score   (accuracy)\n",
      "\t65.45s\t = Training   runtime\n",
      "\t2.71s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 201.11s of the 201.07s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S12F1 - S12F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9326\t = Validation score   (accuracy)\n",
      "\t192.27s\t = Training   runtime\n",
      "\t9.82s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 181.2s of the 181.17s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S12F1 - S12F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.9315\t = Validation score   (accuracy)\n",
      "\t310.18s\t = Training   runtime\n",
      "\t5.07s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 151.22s of the 151.19s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S12F1 - S12F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9337\t = Validation score   (accuracy)\n",
      "\t186.89s\t = Training   runtime\n",
      "\t1.53s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 132.1s of the 132.07s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S12F1 - S12F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.934\t = Validation score   (accuracy)\n",
      "\t329.64s\t = Training   runtime\n",
      "\t1.76s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 98.26s of the 98.23s of remaining time.\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 8 | 0\n",
      "\tDropped 0 of 886 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 1}, 'num_parallel_jobs': 8, 'batches': 1, 'cpu_per_job': 1}\n",
      "\tFitting 8 child models (S12F1 - S12F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Dispatching folds on node 9c9839e3d29ecf0e27be78dd80ab1b7a3da8037c5d7ed8d6178635ba\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 1}\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9351\t = Validation score   (accuracy)\n",
      "\t117.95s\t = Training   runtime\n",
      "\t2.3s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Not enough time left to finish repeated k-fold bagging, stopping early ...\n",
      "Completed 12/20 k-fold bagging repeats ...\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 84.89s of remaining time.\n",
      "\tDropped 0 of 11 features.\n",
      "\tDropped 0 of 11 features.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving AutogluonModels/ag-20230925_120315/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 11 features.\n",
      "Ensemble size: 41\n",
      "Ensemble indices: [10, 7, 9, 3, 7, 10, 7, 9, 4, 7, 9, 10, 7, 9, 10, 7, 9, 7, 7, 10, 4, 7, 3, 7, 10, 10, 7, 9, 7, 10, 7, 3, 10, 4, 7, 7, 4, 3, 10, 7, 7]\n",
      "Ensemble weights: \n",
      "[0.         0.         0.         0.09756098 0.09756098 0.\n",
      " 0.         0.41463415 0.         0.14634146 0.24390244]\n",
      "Saving AutogluonModels/ag-20230925_120315/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/WeightedEnsemble_L2/model.pkl\n",
      "\t0.9388\t = Validation score   (accuracy)\n",
      "\t2.08s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 1717.26s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/learner.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/predictor.pkl\n",
      "Saving AutogluonModels/ag-20230925_120315/__version__ with contents \"0.8.2\"\n",
      "Saving AutogluonModels/ag-20230925_120315/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230925_120315/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 51s, sys: 1min 31s, total: 4min 23s\n",
      "Wall time: 28min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = TabularPredictor(label='label').fit(train_data=train_data, verbosity=4, time_limit=time_sec, presets='best_quality')\n",
    "# model will decide how many cores to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea649d73-ee6c-4c7c-863f-83d85810f865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/WeightedEnsemble_L2/model.pkl\n",
      "Evaluation: accuracy on test data: 0.9429763560500696\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.9429763560500696,\n",
      "    \"balanced_accuracy\": 0.5948543187544415,\n",
      "    \"mcc\": 0.34841715179951094,\n",
      "    \"roc_auc\": 0.8373602945926739,\n",
      "    \"f1\": 0.3050847457627119,\n",
      "    \"precision\": 0.6923076923076923,\n",
      "    \"recall\": 0.1956521739130435\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9429763560500696,\n",
       " 'balanced_accuracy': 0.5948543187544415,\n",
       " 'mcc': 0.34841715179951094,\n",
       " 'roc_auc': 0.8373602945926739,\n",
       " 'f1': 0.3050847457627119,\n",
       " 'precision': 0.6923076923076923,\n",
       " 'recall': 0.1956521739130435}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6df09c9-9e76-48bc-afd4-f98fef699669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20230925_120315/models/WeightedEnsemble_L2/model.pkl\n",
      "Model scores:\n",
      "{'LightGBMXT_BAG_L1': 0.9415855354659249, 'LightGBM_BAG_L1': 0.9415855354659249, 'RandomForestGini_BAG_L1': 0.9415855354659249, 'RandomForestEntr_BAG_L1': 0.9415855354659249, 'CatBoost_BAG_L1': 0.9415855354659249, 'ExtraTreesGini_BAG_L1': 0.9429763560500696, 'ExtraTreesEntr_BAG_L1': 0.9429763560500696, 'NeuralNetFastAI_BAG_L1': 0.9346314325452016, 'XGBoost_BAG_L1': 0.9443671766342142, 'NeuralNetTorch_BAG_L1': 0.9318497913769124, 'LightGBMLarge_BAG_L1': 0.9388038942976356, 'WeightedEnsemble_L2': 0.9429763560500696}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.944367</td>\n",
       "      <td>0.933742</td>\n",
       "      <td>1.760444</td>\n",
       "      <td>1.530567</td>\n",
       "      <td>186.892907</td>\n",
       "      <td>1.760444</td>\n",
       "      <td>1.530567</td>\n",
       "      <td>186.892907</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.942976</td>\n",
       "      <td>0.932350</td>\n",
       "      <td>0.253660</td>\n",
       "      <td>1.114834</td>\n",
       "      <td>2.713726</td>\n",
       "      <td>0.253660</td>\n",
       "      <td>1.114834</td>\n",
       "      <td>2.713726</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.942976</td>\n",
       "      <td>0.932350</td>\n",
       "      <td>0.296739</td>\n",
       "      <td>0.886805</td>\n",
       "      <td>1.812422</td>\n",
       "      <td>0.296739</td>\n",
       "      <td>0.886805</td>\n",
       "      <td>1.812422</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.942976</td>\n",
       "      <td>0.938753</td>\n",
       "      <td>11.978904</td>\n",
       "      <td>19.820915</td>\n",
       "      <td>953.997609</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>2.077370</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.941586</td>\n",
       "      <td>0.932906</td>\n",
       "      <td>0.282792</td>\n",
       "      <td>0.914254</td>\n",
       "      <td>2.071538</td>\n",
       "      <td>0.282792</td>\n",
       "      <td>0.914254</td>\n",
       "      <td>2.071538</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.941586</td>\n",
       "      <td>0.933463</td>\n",
       "      <td>0.289093</td>\n",
       "      <td>0.856345</td>\n",
       "      <td>1.881582</td>\n",
       "      <td>0.289093</td>\n",
       "      <td>0.856345</td>\n",
       "      <td>1.881582</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.941586</td>\n",
       "      <td>0.934855</td>\n",
       "      <td>1.297155</td>\n",
       "      <td>2.449745</td>\n",
       "      <td>63.222678</td>\n",
       "      <td>1.297155</td>\n",
       "      <td>2.449745</td>\n",
       "      <td>63.222678</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.941586</td>\n",
       "      <td>0.934855</td>\n",
       "      <td>1.317754</td>\n",
       "      <td>2.708474</td>\n",
       "      <td>65.453110</td>\n",
       "      <td>1.317754</td>\n",
       "      <td>2.708474</td>\n",
       "      <td>65.453110</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.941586</td>\n",
       "      <td>0.932628</td>\n",
       "      <td>5.173592</td>\n",
       "      <td>9.818150</td>\n",
       "      <td>192.268285</td>\n",
       "      <td>5.173592</td>\n",
       "      <td>9.818150</td>\n",
       "      <td>192.268285</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.938804</td>\n",
       "      <td>0.935134</td>\n",
       "      <td>1.635441</td>\n",
       "      <td>2.300599</td>\n",
       "      <td>117.953072</td>\n",
       "      <td>1.635441</td>\n",
       "      <td>2.300599</td>\n",
       "      <td>117.953072</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.934631</td>\n",
       "      <td>0.931514</td>\n",
       "      <td>3.579875</td>\n",
       "      <td>5.074476</td>\n",
       "      <td>310.179357</td>\n",
       "      <td>3.579875</td>\n",
       "      <td>5.074476</td>\n",
       "      <td>310.179357</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.931850</td>\n",
       "      <td>0.934020</td>\n",
       "      <td>1.292718</td>\n",
       "      <td>1.761892</td>\n",
       "      <td>329.637943</td>\n",
       "      <td>1.292718</td>\n",
       "      <td>1.761892</td>\n",
       "      <td>329.637943</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_test  score_val  pred_time_test  \\\n",
       "0            XGBoost_BAG_L1    0.944367   0.933742        1.760444   \n",
       "1     ExtraTreesGini_BAG_L1    0.942976   0.932350        0.253660   \n",
       "2     ExtraTreesEntr_BAG_L1    0.942976   0.932350        0.296739   \n",
       "3       WeightedEnsemble_L2    0.942976   0.938753       11.978904   \n",
       "4   RandomForestGini_BAG_L1    0.941586   0.932906        0.282792   \n",
       "5   RandomForestEntr_BAG_L1    0.941586   0.933463        0.289093   \n",
       "6         LightGBMXT_BAG_L1    0.941586   0.934855        1.297155   \n",
       "7           LightGBM_BAG_L1    0.941586   0.934855        1.317754   \n",
       "8           CatBoost_BAG_L1    0.941586   0.932628        5.173592   \n",
       "9      LightGBMLarge_BAG_L1    0.938804   0.935134        1.635441   \n",
       "10   NeuralNetFastAI_BAG_L1    0.934631   0.931514        3.579875   \n",
       "11    NeuralNetTorch_BAG_L1    0.931850   0.934020        1.292718   \n",
       "\n",
       "    pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0        1.530567  186.892907                 1.760444   \n",
       "1        1.114834    2.713726                 0.253660   \n",
       "2        0.886805    1.812422                 0.296739   \n",
       "3       19.820915  953.997609                 0.008185   \n",
       "4        0.914254    2.071538                 0.282792   \n",
       "5        0.856345    1.881582                 0.289093   \n",
       "6        2.449745   63.222678                 1.297155   \n",
       "7        2.708474   65.453110                 1.317754   \n",
       "8        9.818150  192.268285                 5.173592   \n",
       "9        2.300599  117.953072                 1.635441   \n",
       "10       5.074476  310.179357                 3.579875   \n",
       "11       1.761892  329.637943                 1.292718   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 1.530567         186.892907            1       True   \n",
       "1                 1.114834           2.713726            1       True   \n",
       "2                 0.886805           1.812422            1       True   \n",
       "3                 0.009452           2.077370            2       True   \n",
       "4                 0.914254           2.071538            1       True   \n",
       "5                 0.856345           1.881582            1       True   \n",
       "6                 2.449745          63.222678            1       True   \n",
       "7                 2.708474          65.453110            1       True   \n",
       "8                 9.818150         192.268285            1       True   \n",
       "9                 2.300599         117.953072            1       True   \n",
       "10                5.074476         310.179357            1       True   \n",
       "11                1.761892         329.637943            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           9  \n",
       "1           6  \n",
       "2           7  \n",
       "3          12  \n",
       "4           3  \n",
       "5           4  \n",
       "6           1  \n",
       "7           2  \n",
       "8           5  \n",
       "9          11  \n",
       "10          8  \n",
       "11         10  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d889a-2da6-459e-b7f5-3d95cf2e4e16",
   "metadata": {},
   "source": [
    "# FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d18a7cb6-e526-4afb-8fec-0b35dc45fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe6b1cf3-1d3f-4995-9671-075b4c59bc79",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 09-25 12:32:28] {1679} INFO - task = classification\n",
      "[flaml.automl.logger: 09-25 12:32:28] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 09-25 12:32:28] {1788} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl.logger: 09-25 12:32:28] {1900} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl.logger: 09-25 12:32:28] {2218} INFO - iteration 0, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:28] {805} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}\n",
      "[flaml.tune.tune: 09-25 12:32:29] {197} INFO - result: {'pred_time': 1.0511825560754945e-05, 'wall_clock_time': 5.228039026260376, 'metric_for_logging': {'pred_time': 1.0511825560754945e-05}, 'val_loss': 0.3371834396384621, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524310400>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 20, 'config/learning_rate': 0.09999999999999995, 'config/log_max_bin': 8, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.0, 'experiment_tag': 'exp', 'time_total_s': 0.38694286346435547}\n",
      "[flaml.tune.tune: 09-25 12:32:29] {197} INFO - result: {'pred_time': 1.0511825560754945e-05, 'wall_clock_time': 5.228039026260376, 'metric_for_logging': {'pred_time': 1.0511825560754945e-05}, 'val_loss': 0.3371834396384621, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524310400>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 20, 'config/learning_rate': 0.09999999999999995, 'config/log_max_bin': 8, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.0, 'experiment_tag': 'exp', 'time_total_s': 0.388474702835083}\n",
      "[flaml.automl.logger: 09-25 12:32:29] {2344} INFO - Estimated sufficient time budget=3984s. Estimated necessary time budget=98s.\n",
      "[flaml.automl.logger: 09-25 12:32:29] {2391} INFO -  at 5.2s,\testimator lgbm's best error=0.3372,\tbest estimator lgbm's best error=0.3372\n",
      "[flaml.automl.logger: 09-25 12:32:29] {2218} INFO - iteration 1, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:29] {805} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 33, 'learning_rate': 0.03735454900037746, 'log_max_bin': 9, 'colsample_bytree': 0.8085131463835397, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.692397057684401}\n",
      "[flaml.tune.tune: 09-25 12:32:29] {197} INFO - result: {'pred_time': 1.0000522217204532e-05, 'wall_clock_time': 5.598014831542969, 'metric_for_logging': {'pred_time': 1.0000522217204532e-05}, 'val_loss': 0.36526976030349345, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5243b2310>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 33, 'learning_rate': 0.03735454900037746, 'log_max_bin': 9, 'colsample_bytree': 0.8085131463835397, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.692397057684401}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 33, 'config/learning_rate': 0.03735454900037746, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8085131463835397, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.692397057684401, 'experiment_tag': 'exp', 'time_total_s': 0.35916972160339355}\n",
      "[flaml.tune.tune: 09-25 12:32:29] {197} INFO - result: {'pred_time': 1.0000522217204532e-05, 'wall_clock_time': 5.598014831542969, 'metric_for_logging': {'pred_time': 1.0000522217204532e-05}, 'val_loss': 0.36526976030349345, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5243b2310>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 33, 'learning_rate': 0.03735454900037746, 'log_max_bin': 9, 'colsample_bytree': 0.8085131463835397, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.692397057684401}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 33, 'config/learning_rate': 0.03735454900037746, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8085131463835397, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.692397057684401, 'experiment_tag': 'exp', 'time_total_s': 0.3606686592102051}\n",
      "[flaml.automl.logger: 09-25 12:32:29] {2391} INFO -  at 5.6s,\testimator lgbm's best error=0.3372,\tbest estimator lgbm's best error=0.3372\n",
      "[flaml.automl.logger: 09-25 12:32:29] {2218} INFO - iteration 2, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:29] {805} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.26770501231052046, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.4442580148221913}\n",
      "[flaml.tune.tune: 09-25 12:32:30] {197} INFO - result: {'pred_time': 1.0396828575077675e-05, 'wall_clock_time': 6.026644229888916, 'metric_for_logging': {'pred_time': 1.0396828575077675e-05}, 'val_loss': 0.32027092396282797, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5243b2ac0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.26770501231052046, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.4442580148221913}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 12, 'config/learning_rate': 0.26770501231052046, 'config/log_max_bin': 7, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.001348364934537134, 'config/reg_lambda': 1.4442580148221913, 'experiment_tag': 'exp', 'time_total_s': 0.4221675395965576}\n",
      "[flaml.tune.tune: 09-25 12:32:30] {197} INFO - result: {'pred_time': 1.0396828575077675e-05, 'wall_clock_time': 6.026644229888916, 'metric_for_logging': {'pred_time': 1.0396828575077675e-05}, 'val_loss': 0.32027092396282797, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5243b2ac0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.26770501231052046, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.4442580148221913}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 12, 'config/learning_rate': 0.26770501231052046, 'config/log_max_bin': 7, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.001348364934537134, 'config/reg_lambda': 1.4442580148221913, 'experiment_tag': 'exp', 'time_total_s': 0.42348432540893555}\n",
      "[flaml.automl.logger: 09-25 12:32:30] {2391} INFO -  at 6.0s,\testimator lgbm's best error=0.3203,\tbest estimator lgbm's best error=0.3203\n",
      "[flaml.automl.logger: 09-25 12:32:30] {2218} INFO - iteration 3, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:32:30] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:32:31] {197} INFO - result: {'pred_time': 4.1325934951945794e-05, 'wall_clock_time': 7.452991962432861, 'metric_for_logging': {'pred_time': 4.1325934951945794e-05}, 'val_loss': 0.41041591556958873, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5243b2d00>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 0.9999999999999993, 'config/learning_rate': 0.09999999999999995, 'config/subsample': 1.0, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.0, 'experiment_tag': 'exp', 'time_total_s': 1.417604923248291}\n",
      "[flaml.tune.tune: 09-25 12:32:31] {197} INFO - result: {'pred_time': 4.1325934951945794e-05, 'wall_clock_time': 7.452991962432861, 'metric_for_logging': {'pred_time': 4.1325934951945794e-05}, 'val_loss': 0.41041591556958873, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5243b2d00>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 0.9999999999999993, 'config/learning_rate': 0.09999999999999995, 'config/subsample': 1.0, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.0, 'experiment_tag': 'exp', 'time_total_s': 1.41886568069458}\n",
      "[flaml.automl.logger: 09-25 12:32:31] {2391} INFO -  at 7.5s,\testimator xgboost's best error=0.4104,\tbest estimator lgbm's best error=0.3203\n",
      "[flaml.automl.logger: 09-25 12:32:31] {2218} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:32:31] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 4, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:32:31] {197} INFO - result: {'pred_time': 2.336740696058106e-05, 'wall_clock_time': 7.796917676925659, 'metric_for_logging': {'pred_time': 2.336740696058106e-05}, 'val_loss': 0.3686062460800092, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5243c2f70>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.32480955123901367}\n",
      "[flaml.tune.tune: 09-25 12:32:31] {197} INFO - result: {'pred_time': 2.336740696058106e-05, 'wall_clock_time': 7.796917676925659, 'metric_for_logging': {'pred_time': 2.336740696058106e-05}, 'val_loss': 0.3686062460800092, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5243c2f70>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.32604360580444336}\n",
      "[flaml.automl.logger: 09-25 12:32:31] {2391} INFO -  at 7.8s,\testimator extra_tree's best error=0.3686,\tbest estimator lgbm's best error=0.3203\n",
      "[flaml.automl.logger: 09-25 12:32:31] {2218} INFO - iteration 5, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:31] {805} INFO - trial 1 config: {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 9, 'learning_rate': 0.7260594590615893, 'log_max_bin': 9, 'colsample_bytree': 0.9285002286474459, 'reg_alpha': 0.0036840681931986645, 'reg_lambda': 0.7532480505730402}\n",
      "[flaml.tune.tune: 09-25 12:32:32] {197} INFO - result: {'pred_time': 1.2105677329484495e-05, 'wall_clock_time': 8.257425308227539, 'metric_for_logging': {'pred_time': 1.2105677329484495e-05}, 'val_loss': 0.29574750912831876, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5243829d0>, 'training_iteration': 0, 'config': {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 9, 'learning_rate': 0.7260594590615893, 'log_max_bin': 9, 'colsample_bytree': 0.9285002286474459, 'reg_alpha': 0.0036840681931986645, 'reg_lambda': 0.7532480505730402}, 'config/n_estimators': 9, 'config/num_leaves': 4, 'config/min_child_samples': 9, 'config/learning_rate': 0.7260594590615893, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.9285002286474459, 'config/reg_alpha': 0.0036840681931986645, 'config/reg_lambda': 0.7532480505730402, 'experiment_tag': 'exp', 'time_total_s': 0.45478248596191406}\n",
      "[flaml.tune.tune: 09-25 12:32:32] {197} INFO - result: {'pred_time': 1.2105677329484495e-05, 'wall_clock_time': 8.257425308227539, 'metric_for_logging': {'pred_time': 1.2105677329484495e-05}, 'val_loss': 0.29574750912831876, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5243829d0>, 'training_iteration': 1, 'config': {'n_estimators': 9, 'num_leaves': 4, 'min_child_samples': 9, 'learning_rate': 0.7260594590615893, 'log_max_bin': 9, 'colsample_bytree': 0.9285002286474459, 'reg_alpha': 0.0036840681931986645, 'reg_lambda': 0.7532480505730402}, 'config/n_estimators': 9, 'config/num_leaves': 4, 'config/min_child_samples': 9, 'config/learning_rate': 0.7260594590615893, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.9285002286474459, 'config/reg_alpha': 0.0036840681931986645, 'config/reg_lambda': 0.7532480505730402, 'experiment_tag': 'exp', 'time_total_s': 0.45671606063842773}\n",
      "[flaml.automl.logger: 09-25 12:32:32] {2391} INFO -  at 8.3s,\testimator lgbm's best error=0.2957,\tbest estimator lgbm's best error=0.2957\n",
      "[flaml.automl.logger: 09-25 12:32:32] {2218} INFO - iteration 6, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:32] {805} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.2677050123105203, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.444258014822189}\n",
      "[flaml.tune.tune: 09-25 12:32:32] {197} INFO - result: {'pred_time': 1.068708110326077e-05, 'wall_clock_time': 8.711172819137573, 'metric_for_logging': {'pred_time': 1.068708110326077e-05}, 'val_loss': 0.32027092396282797, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340dc670>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.2677050123105203, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.444258014822189}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 12, 'config/learning_rate': 0.2677050123105203, 'config/log_max_bin': 7, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.001348364934537134, 'config/reg_lambda': 1.444258014822189, 'experiment_tag': 'exp', 'time_total_s': 0.4456181526184082}\n",
      "[flaml.tune.tune: 09-25 12:32:32] {197} INFO - result: {'pred_time': 1.068708110326077e-05, 'wall_clock_time': 8.711172819137573, 'metric_for_logging': {'pred_time': 1.068708110326077e-05}, 'val_loss': 0.32027092396282797, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340dc670>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.2677050123105203, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.444258014822189}, 'config/n_estimators': 4, 'config/num_leaves': 4, 'config/min_child_samples': 12, 'config/learning_rate': 0.2677050123105203, 'config/log_max_bin': 7, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.001348364934537134, 'config/reg_lambda': 1.444258014822189, 'experiment_tag': 'exp', 'time_total_s': 0.4466726779937744}\n",
      "[flaml.automl.logger: 09-25 12:32:32] {2391} INFO -  at 8.7s,\testimator lgbm's best error=0.2957,\tbest estimator lgbm's best error=0.2957\n",
      "[flaml.automl.logger: 09-25 12:32:32] {2218} INFO - iteration 7, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:32] {805} INFO - trial 1 config: {'n_estimators': 10, 'num_leaves': 5, 'min_child_samples': 5, 'learning_rate': 0.7590459488450945, 'log_max_bin': 8, 'colsample_bytree': 0.8304072431299575, 'reg_alpha': 0.001951378031519758, 'reg_lambda': 0.04792552866398477}\n",
      "[flaml.tune.tune: 09-25 12:32:33] {197} INFO - result: {'pred_time': 1.0623365527375247e-05, 'wall_clock_time': 9.225453853607178, 'metric_for_logging': {'pred_time': 1.0623365527375247e-05}, 'val_loss': 0.3122745799657344, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1b310>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'num_leaves': 5, 'min_child_samples': 5, 'learning_rate': 0.7590459488450945, 'log_max_bin': 8, 'colsample_bytree': 0.8304072431299575, 'reg_alpha': 0.001951378031519758, 'reg_lambda': 0.04792552866398477}, 'config/n_estimators': 10, 'config/num_leaves': 5, 'config/min_child_samples': 5, 'config/learning_rate': 0.7590459488450945, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8304072431299575, 'config/reg_alpha': 0.001951378031519758, 'config/reg_lambda': 0.04792552866398477, 'experiment_tag': 'exp', 'time_total_s': 0.5083284378051758}\n",
      "[flaml.tune.tune: 09-25 12:32:33] {197} INFO - result: {'pred_time': 1.0623365527375247e-05, 'wall_clock_time': 9.225453853607178, 'metric_for_logging': {'pred_time': 1.0623365527375247e-05}, 'val_loss': 0.3122745799657344, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1b310>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'num_leaves': 5, 'min_child_samples': 5, 'learning_rate': 0.7590459488450945, 'log_max_bin': 8, 'colsample_bytree': 0.8304072431299575, 'reg_alpha': 0.001951378031519758, 'reg_lambda': 0.04792552866398477}, 'config/n_estimators': 10, 'config/num_leaves': 5, 'config/min_child_samples': 5, 'config/learning_rate': 0.7590459488450945, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8304072431299575, 'config/reg_alpha': 0.001951378031519758, 'config/reg_lambda': 0.04792552866398477, 'experiment_tag': 'exp', 'time_total_s': 0.5095629692077637}\n",
      "[flaml.automl.logger: 09-25 12:32:33] {2391} INFO -  at 9.2s,\testimator lgbm's best error=0.2957,\tbest estimator lgbm's best error=0.2957\n",
      "[flaml.automl.logger: 09-25 12:32:33] {2218} INFO - iteration 8, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:33] {805} INFO - trial 1 config: {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 15, 'learning_rate': 0.6945064905423671, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.006955268652669901, 'reg_lambda': 11.838839163780849}\n",
      "[flaml.tune.tune: 09-25 12:32:33] {197} INFO - result: {'pred_time': 1.0625893426954457e-05, 'wall_clock_time': 9.68837308883667, 'metric_for_logging': {'pred_time': 1.0625893426954457e-05}, 'val_loss': 0.2807560703362802, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1b820>, 'training_iteration': 0, 'config': {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 15, 'learning_rate': 0.6945064905423671, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.006955268652669901, 'reg_lambda': 11.838839163780849}, 'config/n_estimators': 8, 'config/num_leaves': 4, 'config/min_child_samples': 15, 'config/learning_rate': 0.6945064905423671, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.006955268652669901, 'config/reg_lambda': 11.838839163780849, 'experiment_tag': 'exp', 'time_total_s': 0.45589327812194824}\n",
      "[flaml.tune.tune: 09-25 12:32:33] {197} INFO - result: {'pred_time': 1.0625893426954457e-05, 'wall_clock_time': 9.68837308883667, 'metric_for_logging': {'pred_time': 1.0625893426954457e-05}, 'val_loss': 0.2807560703362802, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1b820>, 'training_iteration': 1, 'config': {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 15, 'learning_rate': 0.6945064905423671, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.006955268652669901, 'reg_lambda': 11.838839163780849}, 'config/n_estimators': 8, 'config/num_leaves': 4, 'config/min_child_samples': 15, 'config/learning_rate': 0.6945064905423671, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.006955268652669901, 'config/reg_lambda': 11.838839163780849, 'experiment_tag': 'exp', 'time_total_s': 0.4571568965911865}\n",
      "[flaml.automl.logger: 09-25 12:32:33] {2391} INFO -  at 9.7s,\testimator lgbm's best error=0.2808,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:33] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:32:33] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:32:35] {197} INFO - result: {'pred_time': 4.12732509495236e-05, 'wall_clock_time': 11.125219106674194, 'metric_for_logging': {'pred_time': 4.12732509495236e-05}, 'val_loss': 0.4495247741687022, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1b3a0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 3.815612027960909, 'config/learning_rate': 0.03859136192132085, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8148474110627004, 'config/colsample_bytree': 0.9777234800442423, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.525802807180917, 'experiment_tag': 'exp', 'time_total_s': 1.4310283660888672}\n",
      "[flaml.tune.tune: 09-25 12:32:35] {197} INFO - result: {'pred_time': 4.12732509495236e-05, 'wall_clock_time': 11.125219106674194, 'metric_for_logging': {'pred_time': 4.12732509495236e-05}, 'val_loss': 0.4495247741687022, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1b3a0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 3.815612027960909, 'config/learning_rate': 0.03859136192132085, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8148474110627004, 'config/colsample_bytree': 0.9777234800442423, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.525802807180917, 'experiment_tag': 'exp', 'time_total_s': 1.4322574138641357}\n",
      "[flaml.automl.logger: 09-25 12:32:35] {2391} INFO -  at 11.1s,\testimator xgboost's best error=0.4104,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:35] {2218} INFO - iteration 10, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:32:35] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 9, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:32:35] {197} INFO - result: {'pred_time': 2.3499344327964182e-05, 'wall_clock_time': 11.466482639312744, 'metric_for_logging': {'pred_time': 2.3499344327964182e-05}, 'val_loss': 0.33992101315939405, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5243b2fa0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.33524203300476074}\n",
      "[flaml.tune.tune: 09-25 12:32:35] {197} INFO - result: {'pred_time': 2.3499344327964182e-05, 'wall_clock_time': 11.466482639312744, 'metric_for_logging': {'pred_time': 2.3499344327964182e-05}, 'val_loss': 0.33992101315939405, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5243b2fa0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.33643484115600586}\n",
      "[flaml.automl.logger: 09-25 12:32:35] {2391} INFO -  at 11.5s,\testimator extra_tree's best error=0.3399,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:35] {2218} INFO - iteration 11, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:32:35] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.03397343291117424, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:32:35] {197} INFO - result: {'pred_time': 2.2069399432425945e-05, 'wall_clock_time': 11.794622421264648, 'metric_for_logging': {'pred_time': 2.2069399432425945e-05}, 'val_loss': 0.39872796190262455, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1b6a0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.03397343291117424, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.03397343291117424, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.32211923599243164}\n",
      "[flaml.tune.tune: 09-25 12:32:35] {197} INFO - result: {'pred_time': 2.2069399432425945e-05, 'wall_clock_time': 11.794622421264648, 'metric_for_logging': {'pred_time': 2.2069399432425945e-05}, 'val_loss': 0.39872796190262455, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1b6a0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.03397343291117424, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.03397343291117424, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3229179382324219}\n",
      "[flaml.automl.logger: 09-25 12:32:35] {2391} INFO -  at 11.8s,\testimator extra_tree's best error=0.3399,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:35] {2218} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:32:35] {805} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:32:36] {197} INFO - result: {'pred_time': 3.0049394367559743e-05, 'wall_clock_time': 12.279387474060059, 'metric_for_logging': {'pred_time': 3.0049394367559743e-05}, 'val_loss': 0.31615117597126596, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1b910>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 8, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.4785475730895996}\n",
      "[flaml.tune.tune: 09-25 12:32:36] {197} INFO - result: {'pred_time': 3.0049394367559743e-05, 'wall_clock_time': 12.279387474060059, 'metric_for_logging': {'pred_time': 3.0049394367559743e-05}, 'val_loss': 0.31615117597126596, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1b910>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 8, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.4796602725982666}\n",
      "[flaml.automl.logger: 09-25 12:32:36] {2391} INFO -  at 12.3s,\testimator extra_tree's best error=0.3162,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:36] {2218} INFO - iteration 13, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:32:36] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 4, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:32:36] {197} INFO - result: {'pred_time': 2.3006288543657073e-05, 'wall_clock_time': 12.618385076522827, 'metric_for_logging': {'pred_time': 2.3006288543657073e-05}, 'val_loss': 0.37391776218612804, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668041f40>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.32988691329956055}\n",
      "[flaml.tune.tune: 09-25 12:32:36] {197} INFO - result: {'pred_time': 2.3006288543657073e-05, 'wall_clock_time': 12.618385076522827, 'metric_for_logging': {'pred_time': 2.3006288543657073e-05}, 'val_loss': 0.37391776218612804, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668041f40>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.33136415481567383}\n",
      "[flaml.automl.logger: 09-25 12:32:36] {2391} INFO -  at 12.6s,\testimator rf's best error=0.3739,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:36] {2218} INFO - iteration 14, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:32:36] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 9, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:32:36] {197} INFO - result: {'pred_time': 2.4126619590692984e-05, 'wall_clock_time': 12.977581262588501, 'metric_for_logging': {'pred_time': 2.4126619590692984e-05}, 'val_loss': 0.37032468259979506, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668041460>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3522651195526123}\n",
      "[flaml.tune.tune: 09-25 12:32:36] {197} INFO - result: {'pred_time': 2.4126619590692984e-05, 'wall_clock_time': 12.977581262588501, 'metric_for_logging': {'pred_time': 2.4126619590692984e-05}, 'val_loss': 0.37032468259979506, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668041460>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.032427221756276076, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3536229133605957}\n",
      "[flaml.automl.logger: 09-25 12:32:36] {2391} INFO -  at 13.0s,\testimator rf's best error=0.3703,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:36] {2218} INFO - iteration 15, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:32:36] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:32:38] {197} INFO - result: {'pred_time': 5.2137920785270126e-05, 'wall_clock_time': 14.562121391296387, 'metric_for_logging': {'pred_time': 5.2137920785270126e-05}, 'val_loss': 0.3691610146070416, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680410a0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25912534572860507, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292954, 'experiment_tag': 'exp', 'time_total_s': 1.5779240131378174}\n",
      "[flaml.tune.tune: 09-25 12:32:38] {197} INFO - result: {'pred_time': 5.2137920785270126e-05, 'wall_clock_time': 14.562121391296387, 'metric_for_logging': {'pred_time': 5.2137920785270126e-05}, 'val_loss': 0.3691610146070416, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680410a0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25912534572860507, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292954, 'experiment_tag': 'exp', 'time_total_s': 1.5794272422790527}\n",
      "[flaml.automl.logger: 09-25 12:32:38] {2391} INFO -  at 14.6s,\testimator xgboost's best error=0.3692,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:38] {2218} INFO - iteration 16, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:32:38] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.03397343291117424, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:32:38] {197} INFO - result: {'pred_time': 2.4108326586894247e-05, 'wall_clock_time': 14.928755044937134, 'metric_for_logging': {'pred_time': 2.4108326586894247e-05}, 'val_loss': 0.3861720214044052, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680809d0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.03397343291117424, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.03397343291117424, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3606576919555664}\n",
      "[flaml.tune.tune: 09-25 12:32:38] {197} INFO - result: {'pred_time': 2.4108326586894247e-05, 'wall_clock_time': 14.928755044937134, 'metric_for_logging': {'pred_time': 2.4108326586894247e-05}, 'val_loss': 0.3861720214044052, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680809d0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.03397343291117424, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.03397343291117424, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.36196064949035645}\n",
      "[flaml.automl.logger: 09-25 12:32:38] {2391} INFO -  at 14.9s,\testimator rf's best error=0.3703,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:38] {2218} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:32:38] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:32:39] {197} INFO - result: {'pred_time': 2.723255405605365e-05, 'wall_clock_time': 15.301874160766602, 'metric_for_logging': {'pred_time': 2.723255405605365e-05}, 'val_loss': 0.28286896053012994, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668080bb0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.06028451938646044, 'config/max_leaves': 9, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.36655330657958984}\n",
      "[flaml.tune.tune: 09-25 12:32:39] {197} INFO - result: {'pred_time': 2.723255405605365e-05, 'wall_clock_time': 15.301874160766602, 'metric_for_logging': {'pred_time': 2.723255405605365e-05}, 'val_loss': 0.28286896053012994, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668080bb0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.06028451938646044, 'config/max_leaves': 9, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.3679044246673584}\n",
      "[flaml.automl.logger: 09-25 12:32:39] {2391} INFO -  at 15.3s,\testimator extra_tree's best error=0.2829,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:39] {2218} INFO - iteration 18, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:39] {805} INFO - trial 1 config: {'n_estimators': 4, 'num_leaves': 5, 'min_child_samples': 20, 'learning_rate': 1.0, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0617777062707411, 'reg_lambda': 61.136054010477544}\n",
      "[flaml.tune.tune: 09-25 12:32:39] {197} INFO - result: {'pred_time': 1.325057540761078e-05, 'wall_clock_time': 15.7705237865448, 'metric_for_logging': {'pred_time': 1.325057540761078e-05}, 'val_loss': 0.288079396718827, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'num_leaves': 5, 'min_child_samples': 20, 'learning_rate': 1.0, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0617777062707411, 'reg_lambda': 61.136054010477544}, 'config/n_estimators': 4, 'config/num_leaves': 5, 'config/min_child_samples': 20, 'config/learning_rate': 1.0, 'config/log_max_bin': 9, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0617777062707411, 'config/reg_lambda': 61.136054010477544, 'experiment_tag': 'exp', 'time_total_s': 0.45958399772644043}\n",
      "[flaml.tune.tune: 09-25 12:32:39] {197} INFO - result: {'pred_time': 1.325057540761078e-05, 'wall_clock_time': 15.7705237865448, 'metric_for_logging': {'pred_time': 1.325057540761078e-05}, 'val_loss': 0.288079396718827, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'num_leaves': 5, 'min_child_samples': 20, 'learning_rate': 1.0, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0617777062707411, 'reg_lambda': 61.136054010477544}, 'config/n_estimators': 4, 'config/num_leaves': 5, 'config/min_child_samples': 20, 'config/learning_rate': 1.0, 'config/log_max_bin': 9, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0617777062707411, 'config/reg_lambda': 61.136054010477544, 'experiment_tag': 'exp', 'time_total_s': 0.46085047721862793}\n",
      "[flaml.automl.logger: 09-25 12:32:39] {2391} INFO -  at 15.8s,\testimator lgbm's best error=0.2808,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:39] {2218} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:32:39] {805} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.0600075785575137, 'max_leaves': 6, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:32:40] {197} INFO - result: {'pred_time': 3.538251957205108e-05, 'wall_clock_time': 16.309875965118408, 'metric_for_logging': {'pred_time': 3.538251957205108e-05}, 'val_loss': 0.2817902162917155, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e155e0>, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_features': 0.0600075785575137, 'max_leaves': 6, 'criterion': 'entropy'}, 'config/n_estimators': 8, 'config/max_features': 0.0600075785575137, 'config/max_leaves': 6, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.5330376625061035}\n",
      "[flaml.tune.tune: 09-25 12:32:40] {197} INFO - result: {'pred_time': 3.538251957205108e-05, 'wall_clock_time': 16.309875965118408, 'metric_for_logging': {'pred_time': 3.538251957205108e-05}, 'val_loss': 0.2817902162917155, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e155e0>, 'training_iteration': 1, 'config': {'n_estimators': 8, 'max_features': 0.0600075785575137, 'max_leaves': 6, 'criterion': 'entropy'}, 'config/n_estimators': 8, 'config/max_features': 0.0600075785575137, 'config/max_leaves': 6, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.5349833965301514}\n",
      "[flaml.automl.logger: 09-25 12:32:40] {2391} INFO -  at 16.3s,\testimator extra_tree's best error=0.2818,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:40] {2218} INFO - iteration 20, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:32:40] {805} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:32:40] {197} INFO - result: {'pred_time': 3.1910052414348616e-05, 'wall_clock_time': 16.944851398468018, 'metric_for_logging': {'pred_time': 3.1910052414348616e-05}, 'val_loss': 0.2907738178727684, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e1b670>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 8, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.626683235168457}\n",
      "[flaml.tune.tune: 09-25 12:32:40] {197} INFO - result: {'pred_time': 3.1910052414348616e-05, 'wall_clock_time': 16.944851398468018, 'metric_for_logging': {'pred_time': 3.1910052414348616e-05}, 'val_loss': 0.2907738178727684, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e1b670>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 8, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.6282191276550293}\n",
      "[flaml.automl.logger: 09-25 12:32:40] {2391} INFO -  at 16.9s,\testimator rf's best error=0.2908,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:40] {2218} INFO - iteration 21, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:32:40] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:32:41] {197} INFO - result: {'pred_time': 2.7634845517296934e-05, 'wall_clock_time': 17.362505674362183, 'metric_for_logging': {'pred_time': 2.7634845517296934e-05}, 'val_loss': 0.3273635618088392, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.06028451938646044, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.40929603576660156}\n",
      "[flaml.tune.tune: 09-25 12:32:41] {197} INFO - result: {'pred_time': 2.7634845517296934e-05, 'wall_clock_time': 17.362505674362183, 'metric_for_logging': {'pred_time': 2.7634845517296934e-05}, 'val_loss': 0.3273635618088392, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.06028451938646044, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.4106299877166748}\n",
      "[flaml.automl.logger: 09-25 12:32:41] {2391} INFO -  at 17.4s,\testimator extra_tree's best error=0.2818,\tbest estimator lgbm's best error=0.2808\n",
      "[flaml.automl.logger: 09-25 12:32:41] {2218} INFO - iteration 22, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:41] {805} INFO - trial 1 config: {'n_estimators': 22, 'num_leaves': 4, 'min_child_samples': 11, 'learning_rate': 0.38363923015550033, 'log_max_bin': 10, 'colsample_bytree': 0.930646190497405, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.292560666768758}\n",
      "[flaml.tune.tune: 09-25 12:32:41] {197} INFO - result: {'pred_time': 1.2363565205907927e-05, 'wall_clock_time': 17.919417142868042, 'metric_for_logging': {'pred_time': 1.2363565205907927e-05}, 'val_loss': 0.25440871040571195, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e15a00>, 'training_iteration': 0, 'config': {'n_estimators': 22, 'num_leaves': 4, 'min_child_samples': 11, 'learning_rate': 0.38363923015550033, 'log_max_bin': 10, 'colsample_bytree': 0.930646190497405, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.292560666768758}, 'config/n_estimators': 22, 'config/num_leaves': 4, 'config/min_child_samples': 11, 'config/learning_rate': 0.38363923015550033, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.930646190497405, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.292560666768758, 'experiment_tag': 'exp', 'time_total_s': 0.5504703521728516}\n",
      "[flaml.tune.tune: 09-25 12:32:41] {197} INFO - result: {'pred_time': 1.2363565205907927e-05, 'wall_clock_time': 17.919417142868042, 'metric_for_logging': {'pred_time': 1.2363565205907927e-05}, 'val_loss': 0.25440871040571195, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e15a00>, 'training_iteration': 1, 'config': {'n_estimators': 22, 'num_leaves': 4, 'min_child_samples': 11, 'learning_rate': 0.38363923015550033, 'log_max_bin': 10, 'colsample_bytree': 0.930646190497405, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.292560666768758}, 'config/n_estimators': 22, 'config/num_leaves': 4, 'config/min_child_samples': 11, 'config/learning_rate': 0.38363923015550033, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.930646190497405, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.292560666768758, 'experiment_tag': 'exp', 'time_total_s': 0.5520827770233154}\n",
      "[flaml.automl.logger: 09-25 12:32:41] {2391} INFO -  at 17.9s,\testimator lgbm's best error=0.2544,\tbest estimator lgbm's best error=0.2544\n",
      "[flaml.automl.logger: 09-25 12:32:41] {2218} INFO - iteration 23, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:41] {805} INFO - trial 1 config: {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 13, 'learning_rate': 0.9243511266864246, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013805492389047578, 'reg_lambda': 3.1467717908237858}\n",
      "[flaml.tune.tune: 09-25 12:32:42] {197} INFO - result: {'pred_time': 1.5263636666479685e-05, 'wall_clock_time': 18.522305727005005, 'metric_for_logging': {'pred_time': 1.5263636666479685e-05}, 'val_loss': 0.26647333817498736, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340dc760>, 'training_iteration': 0, 'config': {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 13, 'learning_rate': 0.9243511266864246, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013805492389047578, 'reg_lambda': 3.1467717908237858}, 'config/n_estimators': 8, 'config/num_leaves': 4, 'config/min_child_samples': 13, 'config/learning_rate': 0.9243511266864246, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013805492389047578, 'config/reg_lambda': 3.1467717908237858, 'experiment_tag': 'exp', 'time_total_s': 0.5942842960357666}\n",
      "[flaml.tune.tune: 09-25 12:32:42] {197} INFO - result: {'pred_time': 1.5263636666479685e-05, 'wall_clock_time': 18.522305727005005, 'metric_for_logging': {'pred_time': 1.5263636666479685e-05}, 'val_loss': 0.26647333817498736, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340dc760>, 'training_iteration': 1, 'config': {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 13, 'learning_rate': 0.9243511266864246, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013805492389047578, 'reg_lambda': 3.1467717908237858}, 'config/n_estimators': 8, 'config/num_leaves': 4, 'config/min_child_samples': 13, 'config/learning_rate': 0.9243511266864246, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013805492389047578, 'config/reg_lambda': 3.1467717908237858, 'experiment_tag': 'exp', 'time_total_s': 0.5954711437225342}\n",
      "[flaml.automl.logger: 09-25 12:32:42] {2391} INFO -  at 18.5s,\testimator lgbm's best error=0.2544,\tbest estimator lgbm's best error=0.2544\n",
      "[flaml.automl.logger: 09-25 12:32:42] {2218} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:32:42] {805} INFO - trial 1 config: {'n_estimators': 23, 'max_features': 0.04701175335151481, 'max_leaves': 9, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:32:43] {197} INFO - result: {'pred_time': 5.478244134644467e-05, 'wall_clock_time': 19.39683246612549, 'metric_for_logging': {'pred_time': 5.478244134644467e-05}, 'val_loss': 0.2733014296732438, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1b3a0>, 'training_iteration': 0, 'config': {'n_estimators': 23, 'max_features': 0.04701175335151481, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 23, 'config/max_features': 0.04701175335151481, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.8672091960906982}\n",
      "[flaml.tune.tune: 09-25 12:32:43] {197} INFO - result: {'pred_time': 5.478244134644467e-05, 'wall_clock_time': 19.39683246612549, 'metric_for_logging': {'pred_time': 5.478244134644467e-05}, 'val_loss': 0.2733014296732438, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1b3a0>, 'training_iteration': 1, 'config': {'n_estimators': 23, 'max_features': 0.04701175335151481, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 23, 'config/max_features': 0.04701175335151481, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.8686249256134033}\n",
      "[flaml.automl.logger: 09-25 12:32:43] {2391} INFO -  at 19.4s,\testimator extra_tree's best error=0.2733,\tbest estimator lgbm's best error=0.2544\n",
      "[flaml.automl.logger: 09-25 12:32:43] {2218} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:32:43] {805} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.0600075785575137, 'max_leaves': 6, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:32:43] {197} INFO - result: {'pred_time': 3.607583288607536e-05, 'wall_clock_time': 19.923808574676514, 'metric_for_logging': {'pred_time': 3.607583288607536e-05}, 'val_loss': 0.3163425044234639, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e15d60>, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_features': 0.0600075785575137, 'max_leaves': 6, 'criterion': 'gini'}, 'config/n_estimators': 8, 'config/max_features': 0.0600075785575137, 'config/max_leaves': 6, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.5199105739593506}\n",
      "[flaml.tune.tune: 09-25 12:32:43] {197} INFO - result: {'pred_time': 3.607583288607536e-05, 'wall_clock_time': 19.923808574676514, 'metric_for_logging': {'pred_time': 3.607583288607536e-05}, 'val_loss': 0.3163425044234639, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e15d60>, 'training_iteration': 1, 'config': {'n_estimators': 8, 'max_features': 0.0600075785575137, 'max_leaves': 6, 'criterion': 'gini'}, 'config/n_estimators': 8, 'config/max_features': 0.0600075785575137, 'config/max_leaves': 6, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.5213794708251953}\n",
      "[flaml.automl.logger: 09-25 12:32:43] {2391} INFO -  at 19.9s,\testimator extra_tree's best error=0.2733,\tbest estimator lgbm's best error=0.2544\n",
      "[flaml.automl.logger: 09-25 12:32:43] {2218} INFO - iteration 26, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:43] {805} INFO - trial 1 config: {'n_estimators': 57, 'num_leaves': 13, 'min_child_samples': 9, 'learning_rate': 0.15922418945050276, 'log_max_bin': 10, 'colsample_bytree': 0.8345075630938922, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.6702305601383631}\n",
      "[flaml.tune.tune: 09-25 12:32:44] {197} INFO - result: {'pred_time': 1.3492614402961493e-05, 'wall_clock_time': 20.717637062072754, 'metric_for_logging': {'pred_time': 1.3492614402961493e-05}, 'val_loss': 0.21320537323161015, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e15700>, 'training_iteration': 0, 'config': {'n_estimators': 57, 'num_leaves': 13, 'min_child_samples': 9, 'learning_rate': 0.15922418945050276, 'log_max_bin': 10, 'colsample_bytree': 0.8345075630938922, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.6702305601383631}, 'config/n_estimators': 57, 'config/num_leaves': 13, 'config/min_child_samples': 9, 'config/learning_rate': 0.15922418945050276, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8345075630938922, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.6702305601383631, 'experiment_tag': 'exp', 'time_total_s': 0.7844395637512207}\n",
      "[flaml.tune.tune: 09-25 12:32:44] {197} INFO - result: {'pred_time': 1.3492614402961493e-05, 'wall_clock_time': 20.717637062072754, 'metric_for_logging': {'pred_time': 1.3492614402961493e-05}, 'val_loss': 0.21320537323161015, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e15700>, 'training_iteration': 1, 'config': {'n_estimators': 57, 'num_leaves': 13, 'min_child_samples': 9, 'learning_rate': 0.15922418945050276, 'log_max_bin': 10, 'colsample_bytree': 0.8345075630938922, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.6702305601383631}, 'config/n_estimators': 57, 'config/num_leaves': 13, 'config/min_child_samples': 9, 'config/learning_rate': 0.15922418945050276, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8345075630938922, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.6702305601383631, 'experiment_tag': 'exp', 'time_total_s': 0.7863857746124268}\n",
      "[flaml.automl.logger: 09-25 12:32:44] {2391} INFO -  at 20.7s,\testimator lgbm's best error=0.2132,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:44] {2218} INFO - iteration 27, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:32:44] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:32:46] {197} INFO - result: {'pred_time': 4.832741707302117e-05, 'wall_clock_time': 22.410253047943115, 'metric_for_logging': {'pred_time': 4.832741707302117e-05}, 'val_loss': 0.33463751059328267, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e15160>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 1.8630223791106992, 'config/learning_rate': 1.0, 'config/subsample': 0.8513627344387318, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.946138073111236, 'config/reg_alpha': 0.0018311776973217071, 'config/reg_lambda': 0.27901659190538414, 'experiment_tag': 'exp', 'time_total_s': 1.682615041732788}\n",
      "[flaml.tune.tune: 09-25 12:32:46] {197} INFO - result: {'pred_time': 4.832741707302117e-05, 'wall_clock_time': 22.410253047943115, 'metric_for_logging': {'pred_time': 4.832741707302117e-05}, 'val_loss': 0.33463751059328267, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e15160>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 1.8630223791106992, 'config/learning_rate': 1.0, 'config/subsample': 0.8513627344387318, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.946138073111236, 'config/reg_alpha': 0.0018311776973217071, 'config/reg_lambda': 0.27901659190538414, 'experiment_tag': 'exp', 'time_total_s': 1.6840450763702393}\n",
      "[flaml.automl.logger: 09-25 12:32:46] {2391} INFO -  at 22.4s,\testimator xgboost's best error=0.3346,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:46] {2218} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:32:46] {805} INFO - trial 1 config: {'n_estimators': 27, 'max_features': 0.0537726392498419, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:32:47] {197} INFO - result: {'pred_time': 5.550810813582371e-05, 'wall_clock_time': 23.3327796459198, 'metric_for_logging': {'pred_time': 5.550810813582371e-05}, 'val_loss': 0.30058924539809095, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1b820>, 'training_iteration': 0, 'config': {'n_estimators': 27, 'max_features': 0.0537726392498419, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 27, 'config/max_features': 0.0537726392498419, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.9149200916290283}\n",
      "[flaml.tune.tune: 09-25 12:32:47] {197} INFO - result: {'pred_time': 5.550810813582371e-05, 'wall_clock_time': 23.3327796459198, 'metric_for_logging': {'pred_time': 5.550810813582371e-05}, 'val_loss': 0.30058924539809095, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1b820>, 'training_iteration': 1, 'config': {'n_estimators': 27, 'max_features': 0.0537726392498419, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 27, 'config/max_features': 0.0537726392498419, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.9161643981933594}\n",
      "[flaml.automl.logger: 09-25 12:32:47] {2391} INFO -  at 23.3s,\testimator extra_tree's best error=0.2733,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:47] {2218} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:32:47] {805} INFO - trial 1 config: {'n_estimators': 20, 'max_features': 0.04110092017084993, 'max_leaves': 29, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:32:48] {197} INFO - result: {'pred_time': 4.7534579628406276e-05, 'wall_clock_time': 24.10836887359619, 'metric_for_logging': {'pred_time': 4.7534579628406276e-05}, 'val_loss': 0.24782855020861022, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1b910>, 'training_iteration': 0, 'config': {'n_estimators': 20, 'max_features': 0.04110092017084993, 'max_leaves': 29, 'criterion': 'entropy'}, 'config/n_estimators': 20, 'config/max_features': 0.04110092017084993, 'config/max_leaves': 29, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.769481897354126}\n",
      "[flaml.tune.tune: 09-25 12:32:48] {197} INFO - result: {'pred_time': 4.7534579628406276e-05, 'wall_clock_time': 24.10836887359619, 'metric_for_logging': {'pred_time': 4.7534579628406276e-05}, 'val_loss': 0.24782855020861022, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1b910>, 'training_iteration': 1, 'config': {'n_estimators': 20, 'max_features': 0.04110092017084993, 'max_leaves': 29, 'criterion': 'entropy'}, 'config/n_estimators': 20, 'config/max_features': 0.04110092017084993, 'config/max_leaves': 29, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7709720134735107}\n",
      "[flaml.automl.logger: 09-25 12:32:48] {2391} INFO -  at 24.1s,\testimator extra_tree's best error=0.2478,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:48] {2218} INFO - iteration 30, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:48] {805} INFO - trial 1 config: {'n_estimators': 72, 'num_leaves': 15, 'min_child_samples': 7, 'learning_rate': 0.6936087284316672, 'log_max_bin': 10, 'colsample_bytree': 0.7709706901317468, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.3174169729642264}\n",
      "[flaml.tune.tune: 09-25 12:32:49] {197} INFO - result: {'pred_time': 1.4757964198921225e-05, 'wall_clock_time': 25.052278995513916, 'metric_for_logging': {'pred_time': 1.4757964198921225e-05}, 'val_loss': 0.23905812166681736, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1b6a0>, 'training_iteration': 0, 'config': {'n_estimators': 72, 'num_leaves': 15, 'min_child_samples': 7, 'learning_rate': 0.6936087284316672, 'log_max_bin': 10, 'colsample_bytree': 0.7709706901317468, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.3174169729642264}, 'config/n_estimators': 72, 'config/num_leaves': 15, 'config/min_child_samples': 7, 'config/learning_rate': 0.6936087284316672, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7709706901317468, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.3174169729642264, 'experiment_tag': 'exp', 'time_total_s': 0.9363830089569092}\n",
      "[flaml.tune.tune: 09-25 12:32:49] {197} INFO - result: {'pred_time': 1.4757964198921225e-05, 'wall_clock_time': 25.052278995513916, 'metric_for_logging': {'pred_time': 1.4757964198921225e-05}, 'val_loss': 0.23905812166681736, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1b6a0>, 'training_iteration': 1, 'config': {'n_estimators': 72, 'num_leaves': 15, 'min_child_samples': 7, 'learning_rate': 0.6936087284316672, 'log_max_bin': 10, 'colsample_bytree': 0.7709706901317468, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.3174169729642264}, 'config/n_estimators': 72, 'config/num_leaves': 15, 'config/min_child_samples': 7, 'config/learning_rate': 0.6936087284316672, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7709706901317468, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.3174169729642264, 'experiment_tag': 'exp', 'time_total_s': 0.9377975463867188}\n",
      "[flaml.automl.logger: 09-25 12:32:49] {2391} INFO -  at 25.1s,\testimator lgbm's best error=0.2132,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:49] {2218} INFO - iteration 31, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:49] {805} INFO - trial 1 config: {'n_estimators': 45, 'num_leaves': 11, 'min_child_samples': 11, 'learning_rate': 0.03655136025103705, 'log_max_bin': 9, 'colsample_bytree': 0.8980444360560376, 'reg_alpha': 0.001538995396757784, 'reg_lambda': 8.788660851902563}\n",
      "[flaml.tune.tune: 09-25 12:32:49] {197} INFO - result: {'pred_time': 1.744150417584927e-05, 'wall_clock_time': 25.890039205551147, 'metric_for_logging': {'pred_time': 1.744150417584927e-05}, 'val_loss': 0.2755431362627764, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1b6a0>, 'training_iteration': 0, 'config': {'n_estimators': 45, 'num_leaves': 11, 'min_child_samples': 11, 'learning_rate': 0.03655136025103705, 'log_max_bin': 9, 'colsample_bytree': 0.8980444360560376, 'reg_alpha': 0.001538995396757784, 'reg_lambda': 8.788660851902563}, 'config/n_estimators': 45, 'config/num_leaves': 11, 'config/min_child_samples': 11, 'config/learning_rate': 0.03655136025103705, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8980444360560376, 'config/reg_alpha': 0.001538995396757784, 'config/reg_lambda': 8.788660851902563, 'experiment_tag': 'exp', 'time_total_s': 0.8275339603424072}\n",
      "[flaml.tune.tune: 09-25 12:32:49] {197} INFO - result: {'pred_time': 1.744150417584927e-05, 'wall_clock_time': 25.890039205551147, 'metric_for_logging': {'pred_time': 1.744150417584927e-05}, 'val_loss': 0.2755431362627764, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1b6a0>, 'training_iteration': 1, 'config': {'n_estimators': 45, 'num_leaves': 11, 'min_child_samples': 11, 'learning_rate': 0.03655136025103705, 'log_max_bin': 9, 'colsample_bytree': 0.8980444360560376, 'reg_alpha': 0.001538995396757784, 'reg_lambda': 8.788660851902563}, 'config/n_estimators': 45, 'config/num_leaves': 11, 'config/min_child_samples': 11, 'config/learning_rate': 0.03655136025103705, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8980444360560376, 'config/reg_alpha': 0.001538995396757784, 'config/reg_lambda': 8.788660851902563, 'experiment_tag': 'exp', 'time_total_s': 0.8294668197631836}\n",
      "[flaml.automl.logger: 09-25 12:32:49] {2391} INFO -  at 25.9s,\testimator lgbm's best error=0.2132,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:49] {2218} INFO - iteration 32, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:49] {805} INFO - trial 1 config: {'n_estimators': 84, 'num_leaves': 4, 'min_child_samples': 8, 'learning_rate': 0.2963869736609299, 'log_max_bin': 10, 'colsample_bytree': 0.9026377604690098, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.956628470408563}\n",
      "[flaml.tune.tune: 09-25 12:32:50] {197} INFO - result: {'pred_time': 1.4497701659742681e-05, 'wall_clock_time': 26.692344665527344, 'metric_for_logging': {'pred_time': 1.4497701659742681e-05}, 'val_loss': 0.23552549349026108, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 0, 'config': {'n_estimators': 84, 'num_leaves': 4, 'min_child_samples': 8, 'learning_rate': 0.2963869736609299, 'log_max_bin': 10, 'colsample_bytree': 0.9026377604690098, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.956628470408563}, 'config/n_estimators': 84, 'config/num_leaves': 4, 'config/min_child_samples': 8, 'config/learning_rate': 0.2963869736609299, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.9026377604690098, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.956628470408563, 'experiment_tag': 'exp', 'time_total_s': 0.7911078929901123}\n",
      "[flaml.tune.tune: 09-25 12:32:50] {197} INFO - result: {'pred_time': 1.4497701659742681e-05, 'wall_clock_time': 26.692344665527344, 'metric_for_logging': {'pred_time': 1.4497701659742681e-05}, 'val_loss': 0.23552549349026108, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 1, 'config': {'n_estimators': 84, 'num_leaves': 4, 'min_child_samples': 8, 'learning_rate': 0.2963869736609299, 'log_max_bin': 10, 'colsample_bytree': 0.9026377604690098, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.956628470408563}, 'config/n_estimators': 84, 'config/num_leaves': 4, 'config/min_child_samples': 8, 'config/learning_rate': 0.2963869736609299, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.9026377604690098, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.956628470408563, 'experiment_tag': 'exp', 'time_total_s': 0.792457103729248}\n",
      "[flaml.automl.logger: 09-25 12:32:50] {2391} INFO -  at 26.7s,\testimator lgbm's best error=0.2132,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:50] {2218} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:32:50] {805} INFO - trial 1 config: {'n_estimators': 12, 'max_features': 0.032427221756276076, 'max_leaves': 23, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:32:51] {197} INFO - result: {'pred_time': 4.062390672074825e-05, 'wall_clock_time': 27.346769094467163, 'metric_for_logging': {'pred_time': 4.062390672074825e-05}, 'val_loss': 0.2717199655542984, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1bac0>, 'training_iteration': 0, 'config': {'n_estimators': 12, 'max_features': 0.032427221756276076, 'max_leaves': 23, 'criterion': 'gini'}, 'config/n_estimators': 12, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 23, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.6457180976867676}\n",
      "[flaml.tune.tune: 09-25 12:32:51] {197} INFO - result: {'pred_time': 4.062390672074825e-05, 'wall_clock_time': 27.346769094467163, 'metric_for_logging': {'pred_time': 4.062390672074825e-05}, 'val_loss': 0.2717199655542984, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1bac0>, 'training_iteration': 1, 'config': {'n_estimators': 12, 'max_features': 0.032427221756276076, 'max_leaves': 23, 'criterion': 'gini'}, 'config/n_estimators': 12, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 23, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.6471078395843506}\n",
      "[flaml.automl.logger: 09-25 12:32:51] {2391} INFO -  at 27.3s,\testimator extra_tree's best error=0.2478,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:51] {2218} INFO - iteration 34, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:32:51] {805} INFO - trial 1 config: {'n_estimators': 39, 'num_leaves': 42, 'min_child_samples': 11, 'learning_rate': 0.085537978248575, 'log_max_bin': 9, 'colsample_bytree': 0.7663773657187746, 'reg_alpha': 0.006958608037974516, 'reg_lambda': 0.4683303882185497}\n",
      "[flaml.tune.tune: 09-25 12:32:52] {197} INFO - result: {'pred_time': 1.362177651198606e-05, 'wall_clock_time': 28.501019954681396, 'metric_for_logging': {'pred_time': 1.362177651198606e-05}, 'val_loss': 0.21463536682802054, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e15550>, 'training_iteration': 0, 'config': {'n_estimators': 39, 'num_leaves': 42, 'min_child_samples': 11, 'learning_rate': 0.085537978248575, 'log_max_bin': 9, 'colsample_bytree': 0.7663773657187746, 'reg_alpha': 0.006958608037974516, 'reg_lambda': 0.4683303882185497}, 'config/n_estimators': 39, 'config/num_leaves': 42, 'config/min_child_samples': 11, 'config/learning_rate': 0.085537978248575, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7663773657187746, 'config/reg_alpha': 0.006958608037974516, 'config/reg_lambda': 0.4683303882185497, 'experiment_tag': 'exp', 'time_total_s': 1.1489355564117432}\n",
      "[flaml.tune.tune: 09-25 12:32:52] {197} INFO - result: {'pred_time': 1.362177651198606e-05, 'wall_clock_time': 28.501019954681396, 'metric_for_logging': {'pred_time': 1.362177651198606e-05}, 'val_loss': 0.21463536682802054, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e15550>, 'training_iteration': 1, 'config': {'n_estimators': 39, 'num_leaves': 42, 'min_child_samples': 11, 'learning_rate': 0.085537978248575, 'log_max_bin': 9, 'colsample_bytree': 0.7663773657187746, 'reg_alpha': 0.006958608037974516, 'reg_lambda': 0.4683303882185497}, 'config/n_estimators': 39, 'config/num_leaves': 42, 'config/min_child_samples': 11, 'config/learning_rate': 0.085537978248575, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7663773657187746, 'config/reg_alpha': 0.006958608037974516, 'config/reg_lambda': 0.4683303882185497, 'experiment_tag': 'exp', 'time_total_s': 1.1531643867492676}\n",
      "[flaml.automl.logger: 09-25 12:32:52] {2391} INFO -  at 28.5s,\testimator lgbm's best error=0.2132,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:52] {2218} INFO - iteration 35, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:32:52] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:32:53] {197} INFO - result: {'pred_time': 5.9921083250767755e-05, 'wall_clock_time': 29.306530475616455, 'metric_for_logging': {'pred_time': 5.9921083250767755e-05}, 'val_loss': 0.34709469156620576, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5243b2d00>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.06028451938646044, 'config/max_leaves': 9, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7926316261291504}\n",
      "[flaml.tune.tune: 09-25 12:32:53] {197} INFO - result: {'pred_time': 5.9921083250767755e-05, 'wall_clock_time': 29.306530475616455, 'metric_for_logging': {'pred_time': 5.9921083250767755e-05}, 'val_loss': 0.34709469156620576, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5243b2d00>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.06028451938646044, 'max_leaves': 9, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.06028451938646044, 'config/max_leaves': 9, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7952060699462891}\n",
      "[flaml.automl.logger: 09-25 12:32:53] {2391} INFO -  at 29.3s,\testimator rf's best error=0.2908,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:53] {2218} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:32:53] {805} INFO - trial 1 config: {'n_estimators': 34, 'max_features': 0.05391196221275601, 'max_leaves': 36, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:32:54] {197} INFO - result: {'pred_time': 7.548960235943415e-05, 'wall_clock_time': 30.845149278640747, 'metric_for_logging': {'pred_time': 7.548960235943415e-05}, 'val_loss': 0.23562796737459407, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1b790>, 'training_iteration': 0, 'config': {'n_estimators': 34, 'max_features': 0.05391196221275601, 'max_leaves': 36, 'criterion': 'entropy'}, 'config/n_estimators': 34, 'config/max_features': 0.05391196221275601, 'config/max_leaves': 36, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.5233449935913086}\n",
      "[flaml.tune.tune: 09-25 12:32:54] {197} INFO - result: {'pred_time': 7.548960235943415e-05, 'wall_clock_time': 30.845149278640747, 'metric_for_logging': {'pred_time': 7.548960235943415e-05}, 'val_loss': 0.23562796737459407, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1b790>, 'training_iteration': 1, 'config': {'n_estimators': 34, 'max_features': 0.05391196221275601, 'max_leaves': 36, 'criterion': 'entropy'}, 'config/n_estimators': 34, 'config/max_features': 0.05391196221275601, 'config/max_leaves': 36, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.525421142578125}\n",
      "[flaml.automl.logger: 09-25 12:32:54] {2391} INFO -  at 30.8s,\testimator extra_tree's best error=0.2356,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:54] {2218} INFO - iteration 37, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:32:54] {805} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.032427221756276076, 'max_leaves': 5, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:32:55] {197} INFO - result: {'pred_time': 4.686170786656249e-05, 'wall_clock_time': 31.680855989456177, 'metric_for_logging': {'pred_time': 4.686170786656249e-05}, 'val_loss': 0.2875579448667905, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e1b3a0>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.032427221756276076, 'max_leaves': 5, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 5, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.8273153305053711}\n",
      "[flaml.tune.tune: 09-25 12:32:55] {197} INFO - result: {'pred_time': 4.686170786656249e-05, 'wall_clock_time': 31.680855989456177, 'metric_for_logging': {'pred_time': 4.686170786656249e-05}, 'val_loss': 0.2875579448667905, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e1b3a0>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.032427221756276076, 'max_leaves': 5, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 5, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.8290369510650635}\n",
      "[flaml.automl.logger: 09-25 12:32:55] {2391} INFO -  at 31.7s,\testimator rf's best error=0.2876,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:55] {2218} INFO - iteration 38, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:32:55] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:32:57] {197} INFO - result: {'pred_time': 5.511357282247454e-05, 'wall_clock_time': 33.79620432853699, 'metric_for_logging': {'pred_time': 5.511357282247454e-05}, 'val_loss': 0.3318375635467089, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e15580>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}, 'config/n_estimators': 4, 'config/max_leaves': 7, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292968, 'experiment_tag': 'exp', 'time_total_s': 2.1081128120422363}\n",
      "[flaml.tune.tune: 09-25 12:32:57] {197} INFO - result: {'pred_time': 5.511357282247454e-05, 'wall_clock_time': 33.79620432853699, 'metric_for_logging': {'pred_time': 5.511357282247454e-05}, 'val_loss': 0.3318375635467089, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e15580>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}, 'config/n_estimators': 4, 'config/max_leaves': 7, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292968, 'experiment_tag': 'exp', 'time_total_s': 2.1101415157318115}\n",
      "[flaml.automl.logger: 09-25 12:32:57] {2391} INFO -  at 33.8s,\testimator xgboost's best error=0.3318,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:57] {2218} INFO - iteration 39, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:32:57] {805} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.032576876548045676, 'max_leaves': 7, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:32:58] {197} INFO - result: {'pred_time': 3.6925148306921875e-05, 'wall_clock_time': 34.41000270843506, 'metric_for_logging': {'pred_time': 3.6925148306921875e-05}, 'val_loss': 0.3355473077736946, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.032576876548045676, 'max_leaves': 7, 'criterion': 'gini'}, 'config/n_estimators': 7, 'config/max_features': 0.032576876548045676, 'config/max_leaves': 7, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.6049036979675293}\n",
      "[flaml.tune.tune: 09-25 12:32:58] {197} INFO - result: {'pred_time': 3.6925148306921875e-05, 'wall_clock_time': 34.41000270843506, 'metric_for_logging': {'pred_time': 3.6925148306921875e-05}, 'val_loss': 0.3355473077736946, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.032576876548045676, 'max_leaves': 7, 'criterion': 'gini'}, 'config/n_estimators': 7, 'config/max_features': 0.032576876548045676, 'config/max_leaves': 7, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.6071901321411133}\n",
      "[flaml.automl.logger: 09-25 12:32:58] {2391} INFO -  at 34.4s,\testimator rf's best error=0.2876,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:32:58] {2218} INFO - iteration 40, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:32:58] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.08262716617929555, 'learning_rate': 0.13674064538052125, 'subsample': 0.8885937069868678, 'colsample_bylevel': 0.735249880070874, 'colsample_bytree': 0.8648827061331837, 'reg_alpha': 0.0018753066867999496, 'reg_lambda': 0.4131495174987749}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:33:00] {197} INFO - result: {'pred_time': 5.5914246404790445e-05, 'wall_clock_time': 36.3334264755249, 'metric_for_logging': {'pred_time': 5.5914246404790445e-05}, 'val_loss': 0.329268343998479, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1be50>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.08262716617929555, 'learning_rate': 0.13674064538052125, 'subsample': 0.8885937069868678, 'colsample_bylevel': 0.735249880070874, 'colsample_bytree': 0.8648827061331837, 'reg_alpha': 0.0018753066867999496, 'reg_lambda': 0.4131495174987749}, 'config/n_estimators': 4, 'config/max_leaves': 7, 'config/min_child_weight': 0.08262716617929555, 'config/learning_rate': 0.13674064538052125, 'config/subsample': 0.8885937069868678, 'config/colsample_bylevel': 0.735249880070874, 'config/colsample_bytree': 0.8648827061331837, 'config/reg_alpha': 0.0018753066867999496, 'config/reg_lambda': 0.4131495174987749, 'experiment_tag': 'exp', 'time_total_s': 1.9144775867462158}\n",
      "[flaml.tune.tune: 09-25 12:33:00] {197} INFO - result: {'pred_time': 5.5914246404790445e-05, 'wall_clock_time': 36.3334264755249, 'metric_for_logging': {'pred_time': 5.5914246404790445e-05}, 'val_loss': 0.329268343998479, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1be50>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 7, 'min_child_weight': 0.08262716617929555, 'learning_rate': 0.13674064538052125, 'subsample': 0.8885937069868678, 'colsample_bylevel': 0.735249880070874, 'colsample_bytree': 0.8648827061331837, 'reg_alpha': 0.0018753066867999496, 'reg_lambda': 0.4131495174987749}, 'config/n_estimators': 4, 'config/max_leaves': 7, 'config/min_child_weight': 0.08262716617929555, 'config/learning_rate': 0.13674064538052125, 'config/subsample': 0.8885937069868678, 'config/colsample_bylevel': 0.735249880070874, 'config/colsample_bytree': 0.8648827061331837, 'config/reg_alpha': 0.0018753066867999496, 'config/reg_lambda': 0.4131495174987749, 'experiment_tag': 'exp', 'time_total_s': 1.916316270828247}\n",
      "[flaml.automl.logger: 09-25 12:33:00] {2391} INFO -  at 36.3s,\testimator xgboost's best error=0.3293,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:33:00] {2218} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:33:00] {805} INFO - trial 1 config: {'n_estimators': 12, 'max_features': 0.05878478553813811, 'max_leaves': 55, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:33:01] {197} INFO - result: {'pred_time': 4.488479488816061e-05, 'wall_clock_time': 37.26496648788452, 'metric_for_logging': {'pred_time': 4.488479488816061e-05}, 'val_loss': 0.2443264377859581, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e15eb0>, 'training_iteration': 0, 'config': {'n_estimators': 12, 'max_features': 0.05878478553813811, 'max_leaves': 55, 'criterion': 'entropy'}, 'config/n_estimators': 12, 'config/max_features': 0.05878478553813811, 'config/max_leaves': 55, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.9226922988891602}\n",
      "[flaml.tune.tune: 09-25 12:33:01] {197} INFO - result: {'pred_time': 4.488479488816061e-05, 'wall_clock_time': 37.26496648788452, 'metric_for_logging': {'pred_time': 4.488479488816061e-05}, 'val_loss': 0.2443264377859581, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e15eb0>, 'training_iteration': 1, 'config': {'n_estimators': 12, 'max_features': 0.05878478553813811, 'max_leaves': 55, 'criterion': 'entropy'}, 'config/n_estimators': 12, 'config/max_features': 0.05878478553813811, 'config/max_leaves': 55, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.924445629119873}\n",
      "[flaml.automl.logger: 09-25 12:33:01] {2391} INFO -  at 37.3s,\testimator extra_tree's best error=0.2356,\tbest estimator lgbm's best error=0.2132\n",
      "[flaml.automl.logger: 09-25 12:33:01] {2218} INFO - iteration 42, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:33:01] {805} INFO - trial 1 config: {'n_estimators': 51, 'num_leaves': 38, 'min_child_samples': 8, 'learning_rate': 0.6308228540989652, 'log_max_bin': 10, 'colsample_bytree': 0.9220414673185544, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.8579939426349152}\n",
      "[flaml.tune.tune: 09-25 12:33:02] {197} INFO - result: {'pred_time': 1.787175761662761e-05, 'wall_clock_time': 38.805243253707886, 'metric_for_logging': {'pred_time': 1.787175761662761e-05}, 'val_loss': 0.20585452249620162, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340dc670>, 'training_iteration': 0, 'config': {'n_estimators': 51, 'num_leaves': 38, 'min_child_samples': 8, 'learning_rate': 0.6308228540989652, 'log_max_bin': 10, 'colsample_bytree': 0.9220414673185544, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.8579939426349152}, 'config/n_estimators': 51, 'config/num_leaves': 38, 'config/min_child_samples': 8, 'config/learning_rate': 0.6308228540989652, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.9220414673185544, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.8579939426349152, 'experiment_tag': 'exp', 'time_total_s': 1.5302248001098633}\n",
      "[flaml.tune.tune: 09-25 12:33:02] {197} INFO - result: {'pred_time': 1.787175761662761e-05, 'wall_clock_time': 38.805243253707886, 'metric_for_logging': {'pred_time': 1.787175761662761e-05}, 'val_loss': 0.20585452249620162, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340dc670>, 'training_iteration': 1, 'config': {'n_estimators': 51, 'num_leaves': 38, 'min_child_samples': 8, 'learning_rate': 0.6308228540989652, 'log_max_bin': 10, 'colsample_bytree': 0.9220414673185544, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.8579939426349152}, 'config/n_estimators': 51, 'config/num_leaves': 38, 'config/min_child_samples': 8, 'config/learning_rate': 0.6308228540989652, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.9220414673185544, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.8579939426349152, 'experiment_tag': 'exp', 'time_total_s': 1.53236722946167}\n",
      "[flaml.automl.logger: 09-25 12:33:02] {2391} INFO -  at 38.8s,\testimator lgbm's best error=0.2059,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:02] {2218} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:33:02] {805} INFO - trial 1 config: {'n_estimators': 93, 'max_features': 0.04944305984996691, 'max_leaves': 23, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:33:06] {197} INFO - result: {'pred_time': 0.00020151641622588834, 'wall_clock_time': 42.21319341659546, 'metric_for_logging': {'pred_time': 0.00020151641622588834}, 'val_loss': 0.25190466097512576, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668080f40>, 'training_iteration': 0, 'config': {'n_estimators': 93, 'max_features': 0.04944305984996691, 'max_leaves': 23, 'criterion': 'gini'}, 'config/n_estimators': 93, 'config/max_features': 0.04944305984996691, 'config/max_leaves': 23, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.398864984512329}\n",
      "[flaml.tune.tune: 09-25 12:33:06] {197} INFO - result: {'pred_time': 0.00020151641622588834, 'wall_clock_time': 42.21319341659546, 'metric_for_logging': {'pred_time': 0.00020151641622588834}, 'val_loss': 0.25190466097512576, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668080f40>, 'training_iteration': 1, 'config': {'n_estimators': 93, 'max_features': 0.04944305984996691, 'max_leaves': 23, 'criterion': 'gini'}, 'config/n_estimators': 93, 'config/max_features': 0.04944305984996691, 'config/max_leaves': 23, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.4006154537200928}\n",
      "[flaml.automl.logger: 09-25 12:33:06] {2391} INFO -  at 42.2s,\testimator extra_tree's best error=0.2356,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:06] {2218} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:33:06] {805} INFO - trial 1 config: {'n_estimators': 26, 'max_features': 0.06745889217551715, 'max_leaves': 88, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:33:07] {197} INFO - result: {'pred_time': 8.344392176731967e-05, 'wall_clock_time': 43.93689036369324, 'metric_for_logging': {'pred_time': 8.344392176731967e-05}, 'val_loss': 0.2178092563212503, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680cd940>, 'training_iteration': 0, 'config': {'n_estimators': 26, 'max_features': 0.06745889217551715, 'max_leaves': 88, 'criterion': 'entropy'}, 'config/n_estimators': 26, 'config/max_features': 0.06745889217551715, 'config/max_leaves': 88, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.7140576839447021}\n",
      "[flaml.tune.tune: 09-25 12:33:07] {197} INFO - result: {'pred_time': 8.344392176731967e-05, 'wall_clock_time': 43.93689036369324, 'metric_for_logging': {'pred_time': 8.344392176731967e-05}, 'val_loss': 0.2178092563212503, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680cd940>, 'training_iteration': 1, 'config': {'n_estimators': 26, 'max_features': 0.06745889217551715, 'max_leaves': 88, 'criterion': 'entropy'}, 'config/n_estimators': 26, 'config/max_features': 0.06745889217551715, 'config/max_leaves': 88, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.7161753177642822}\n",
      "[flaml.automl.logger: 09-25 12:33:07] {2391} INFO -  at 43.9s,\testimator extra_tree's best error=0.2178,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:07] {2218} INFO - iteration 45, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:33:07] {805} INFO - trial 1 config: {'n_estimators': 9, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292982}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:33:10] {197} INFO - result: {'pred_time': 6.5936803227524e-05, 'wall_clock_time': 46.762978315353394, 'metric_for_logging': {'pred_time': 6.5936803227524e-05}, 'val_loss': 0.2767818750015152, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5243b23a0>, 'training_iteration': 0, 'config': {'n_estimators': 9, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292982}, 'config/n_estimators': 9, 'config/max_leaves': 7, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292982, 'experiment_tag': 'exp', 'time_total_s': 2.8163211345672607}\n",
      "[flaml.tune.tune: 09-25 12:33:10] {197} INFO - result: {'pred_time': 6.5936803227524e-05, 'wall_clock_time': 46.762978315353394, 'metric_for_logging': {'pred_time': 6.5936803227524e-05}, 'val_loss': 0.2767818750015152, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5243b23a0>, 'training_iteration': 1, 'config': {'n_estimators': 9, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292982}, 'config/n_estimators': 9, 'config/max_leaves': 7, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292982, 'experiment_tag': 'exp', 'time_total_s': 2.8183560371398926}\n",
      "[flaml.automl.logger: 09-25 12:33:10] {2391} INFO -  at 46.8s,\testimator xgboost's best error=0.2768,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:10] {2218} INFO - iteration 46, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:33:10] {805} INFO - trial 1 config: {'n_estimators': 42, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:33:12] {197} INFO - result: {'pred_time': 9.640280621572767e-05, 'wall_clock_time': 48.70683813095093, 'metric_for_logging': {'pred_time': 9.640280621572767e-05}, 'val_loss': 0.25813705673150955, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e155e0>, 'training_iteration': 0, 'config': {'n_estimators': 42, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'gini'}, 'config/n_estimators': 42, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 8, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.9330384731292725}\n",
      "[flaml.tune.tune: 09-25 12:33:12] {197} INFO - result: {'pred_time': 9.640280621572767e-05, 'wall_clock_time': 48.70683813095093, 'metric_for_logging': {'pred_time': 9.640280621572767e-05}, 'val_loss': 0.25813705673150955, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e155e0>, 'training_iteration': 1, 'config': {'n_estimators': 42, 'max_features': 0.032427221756276076, 'max_leaves': 8, 'criterion': 'gini'}, 'config/n_estimators': 42, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 8, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.9347832202911377}\n",
      "[flaml.automl.logger: 09-25 12:33:12] {2391} INFO -  at 48.7s,\testimator rf's best error=0.2581,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:12] {2218} INFO - iteration 47, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:33:12] {805} INFO - trial 1 config: {'n_estimators': 15, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 1.0, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796909}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:33:15] {197} INFO - result: {'pred_time': 6.52690075855748e-05, 'wall_clock_time': 51.49481415748596, 'metric_for_logging': {'pred_time': 6.52690075855748e-05}, 'val_loss': 0.2535289787538663, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1b8b0>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 1.0, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796909}, 'config/n_estimators': 15, 'config/max_leaves': 5, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.6618201818236865, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.7979503033535307, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644693, 'config/reg_lambda': 0.8085739292796909, 'experiment_tag': 'exp', 'time_total_s': 2.7773146629333496}\n",
      "[flaml.tune.tune: 09-25 12:33:15] {197} INFO - result: {'pred_time': 6.52690075855748e-05, 'wall_clock_time': 51.49481415748596, 'metric_for_logging': {'pred_time': 6.52690075855748e-05}, 'val_loss': 0.2535289787538663, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1b8b0>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 1.0, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796909}, 'config/n_estimators': 15, 'config/max_leaves': 5, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.6618201818236865, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.7979503033535307, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644693, 'config/reg_lambda': 0.8085739292796909, 'experiment_tag': 'exp', 'time_total_s': 2.7787907123565674}\n",
      "[flaml.automl.logger: 09-25 12:33:15] {2391} INFO -  at 51.5s,\testimator xgboost's best error=0.2535,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:15] {2218} INFO - iteration 48, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:33:15] {805} INFO - trial 1 config: {'n_estimators': 57, 'num_leaves': 13, 'min_child_samples': 9, 'learning_rate': 0.15922418945050276, 'log_max_bin': 9, 'colsample_bytree': 0.8345075630938922, 'reg_alpha': 0.001858538296879656, 'reg_lambda': 1.6702305601383631}\n",
      "[flaml.tune.tune: 09-25 12:33:16] {197} INFO - result: {'pred_time': 1.8002750716347835e-05, 'wall_clock_time': 52.527512550354004, 'metric_for_logging': {'pred_time': 1.8002750716347835e-05}, 'val_loss': 0.21437559979538987, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1b5e0>, 'training_iteration': 0, 'config': {'n_estimators': 57, 'num_leaves': 13, 'min_child_samples': 9, 'learning_rate': 0.15922418945050276, 'log_max_bin': 9, 'colsample_bytree': 0.8345075630938922, 'reg_alpha': 0.001858538296879656, 'reg_lambda': 1.6702305601383631}, 'config/n_estimators': 57, 'config/num_leaves': 13, 'config/min_child_samples': 9, 'config/learning_rate': 0.15922418945050276, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8345075630938922, 'config/reg_alpha': 0.001858538296879656, 'config/reg_lambda': 1.6702305601383631, 'experiment_tag': 'exp', 'time_total_s': 1.0241858959197998}\n",
      "[flaml.tune.tune: 09-25 12:33:16] {197} INFO - result: {'pred_time': 1.8002750716347835e-05, 'wall_clock_time': 52.527512550354004, 'metric_for_logging': {'pred_time': 1.8002750716347835e-05}, 'val_loss': 0.21437559979538987, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1b5e0>, 'training_iteration': 1, 'config': {'n_estimators': 57, 'num_leaves': 13, 'min_child_samples': 9, 'learning_rate': 0.15922418945050276, 'log_max_bin': 9, 'colsample_bytree': 0.8345075630938922, 'reg_alpha': 0.001858538296879656, 'reg_lambda': 1.6702305601383631}, 'config/n_estimators': 57, 'config/num_leaves': 13, 'config/min_child_samples': 9, 'config/learning_rate': 0.15922418945050276, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8345075630938922, 'config/reg_alpha': 0.001858538296879656, 'config/reg_lambda': 1.6702305601383631, 'experiment_tag': 'exp', 'time_total_s': 1.0264301300048828}\n",
      "[flaml.automl.logger: 09-25 12:33:16] {2391} INFO -  at 52.5s,\testimator lgbm's best error=0.2059,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:16] {2218} INFO - iteration 49, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:33:16] {805} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.04139133127820161, 'max_leaves': 5, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:33:17] {197} INFO - result: {'pred_time': 5.3560334908351745e-05, 'wall_clock_time': 53.46717143058777, 'metric_for_logging': {'pred_time': 5.3560334908351745e-05}, 'val_loss': 0.3268777946439116, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.04139133127820161, 'max_leaves': 5, 'criterion': 'gini'}, 'config/n_estimators': 15, 'config/max_features': 0.04139133127820161, 'config/max_leaves': 5, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.9288449287414551}\n",
      "[flaml.tune.tune: 09-25 12:33:17] {197} INFO - result: {'pred_time': 5.3560334908351745e-05, 'wall_clock_time': 53.46717143058777, 'metric_for_logging': {'pred_time': 5.3560334908351745e-05}, 'val_loss': 0.3268777946439116, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.04139133127820161, 'max_leaves': 5, 'criterion': 'gini'}, 'config/n_estimators': 15, 'config/max_features': 0.04139133127820161, 'config/max_leaves': 5, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.930506706237793}\n",
      "[flaml.automl.logger: 09-25 12:33:17] {2391} INFO -  at 53.5s,\testimator rf's best error=0.2581,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:17] {2218} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:33:17] {805} INFO - trial 1 config: {'n_estimators': 34, 'max_features': 0.05391196221275601, 'max_leaves': 36, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:33:18] {197} INFO - result: {'pred_time': 9.033413972958472e-05, 'wall_clock_time': 54.97067642211914, 'metric_for_logging': {'pred_time': 9.033413972958472e-05}, 'val_loss': 0.2589976191737811, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1bac0>, 'training_iteration': 0, 'config': {'n_estimators': 34, 'max_features': 0.05391196221275601, 'max_leaves': 36, 'criterion': 'gini'}, 'config/n_estimators': 34, 'config/max_features': 0.05391196221275601, 'config/max_leaves': 36, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.4951343536376953}\n",
      "[flaml.tune.tune: 09-25 12:33:18] {197} INFO - result: {'pred_time': 9.033413972958472e-05, 'wall_clock_time': 54.97067642211914, 'metric_for_logging': {'pred_time': 9.033413972958472e-05}, 'val_loss': 0.2589976191737811, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5e1bac0>, 'training_iteration': 1, 'config': {'n_estimators': 34, 'max_features': 0.05391196221275601, 'max_leaves': 36, 'criterion': 'gini'}, 'config/n_estimators': 34, 'config/max_features': 0.05391196221275601, 'config/max_leaves': 36, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.4969756603240967}\n",
      "[flaml.automl.logger: 09-25 12:33:18] {2391} INFO -  at 55.0s,\testimator extra_tree's best error=0.2178,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:18] {2218} INFO - iteration 51, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:33:18] {805} INFO - trial 1 config: {'n_estimators': 49, 'max_features': 0.037090667185649066, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:33:20] {197} INFO - result: {'pred_time': 0.00011101879220205756, 'wall_clock_time': 56.95267868041992, 'metric_for_logging': {'pred_time': 0.00011101879220205756}, 'val_loss': 0.2796997594411388, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5242fc3d0>, 'training_iteration': 0, 'config': {'n_estimators': 49, 'max_features': 0.037090667185649066, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 49, 'config/max_features': 0.037090667185649066, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.9732599258422852}\n",
      "[flaml.tune.tune: 09-25 12:33:20] {197} INFO - result: {'pred_time': 0.00011101879220205756, 'wall_clock_time': 56.95267868041992, 'metric_for_logging': {'pred_time': 0.00011101879220205756}, 'val_loss': 0.2796997594411388, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5242fc3d0>, 'training_iteration': 1, 'config': {'n_estimators': 49, 'max_features': 0.037090667185649066, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 49, 'config/max_features': 0.037090667185649066, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.9754292964935303}\n",
      "[flaml.automl.logger: 09-25 12:33:20] {2391} INFO -  at 57.0s,\testimator rf's best error=0.2581,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:20] {2218} INFO - iteration 52, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:33:20] {805} INFO - trial 1 config: {'n_estimators': 36, 'max_features': 0.032427221756276076, 'max_leaves': 26, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:33:22] {197} INFO - result: {'pred_time': 7.502326769661816e-05, 'wall_clock_time': 58.3390154838562, 'metric_for_logging': {'pred_time': 7.502326769661816e-05}, 'val_loss': 0.23128626694968527, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5242fcdc0>, 'training_iteration': 0, 'config': {'n_estimators': 36, 'max_features': 0.032427221756276076, 'max_leaves': 26, 'criterion': 'entropy'}, 'config/n_estimators': 36, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 26, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.375831127166748}\n",
      "[flaml.tune.tune: 09-25 12:33:22] {197} INFO - result: {'pred_time': 7.502326769661816e-05, 'wall_clock_time': 58.3390154838562, 'metric_for_logging': {'pred_time': 7.502326769661816e-05}, 'val_loss': 0.23128626694968527, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5242fcdc0>, 'training_iteration': 1, 'config': {'n_estimators': 36, 'max_features': 0.032427221756276076, 'max_leaves': 26, 'criterion': 'entropy'}, 'config/n_estimators': 36, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 26, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.377629041671753}\n",
      "[flaml.automl.logger: 09-25 12:33:22] {2391} INFO -  at 58.3s,\testimator rf's best error=0.2313,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:22] {2218} INFO - iteration 53, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:33:22] {805} INFO - trial 1 config: {'n_estimators': 34, 'num_leaves': 113, 'min_child_samples': 6, 'learning_rate': 0.5548452475162691, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.6113984717644443}\n",
      "[flaml.tune.tune: 09-25 12:33:23] {197} INFO - result: {'pred_time': 1.747832849026179e-05, 'wall_clock_time': 59.700236320495605, 'metric_for_logging': {'pred_time': 1.747832849026179e-05}, 'val_loss': 0.21457818388103247, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5242fce80>, 'training_iteration': 0, 'config': {'n_estimators': 34, 'num_leaves': 113, 'min_child_samples': 6, 'learning_rate': 0.5548452475162691, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.6113984717644443}, 'config/n_estimators': 34, 'config/num_leaves': 113, 'config/min_child_samples': 6, 'config/learning_rate': 0.5548452475162691, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.6113984717644443, 'experiment_tag': 'exp', 'time_total_s': 1.3516998291015625}\n",
      "[flaml.tune.tune: 09-25 12:33:23] {197} INFO - result: {'pred_time': 1.747832849026179e-05, 'wall_clock_time': 59.700236320495605, 'metric_for_logging': {'pred_time': 1.747832849026179e-05}, 'val_loss': 0.21457818388103247, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5242fce80>, 'training_iteration': 1, 'config': {'n_estimators': 34, 'num_leaves': 113, 'min_child_samples': 6, 'learning_rate': 0.5548452475162691, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.6113984717644443}, 'config/n_estimators': 34, 'config/num_leaves': 113, 'config/min_child_samples': 6, 'config/learning_rate': 0.5548452475162691, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.6113984717644443, 'experiment_tag': 'exp', 'time_total_s': 1.3533592224121094}\n",
      "[flaml.automl.logger: 09-25 12:33:23] {2391} INFO -  at 59.7s,\testimator lgbm's best error=0.2059,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:23] {2218} INFO - iteration 54, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:33:23] {805} INFO - trial 1 config: {'n_estimators': 78, 'num_leaves': 13, 'min_child_samples': 11, 'learning_rate': 0.717204436795498, 'log_max_bin': 8, 'colsample_bytree': 0.8406254356509558, 'reg_alpha': 0.0017271108100233477, 'reg_lambda': 0.4568414445572454}\n",
      "[flaml.tune.tune: 09-25 12:33:24] {197} INFO - result: {'pred_time': 1.483976670786735e-05, 'wall_clock_time': 60.722363233566284, 'metric_for_logging': {'pred_time': 1.483976670786735e-05}, 'val_loss': 0.21961083301038326, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5242fcf10>, 'training_iteration': 0, 'config': {'n_estimators': 78, 'num_leaves': 13, 'min_child_samples': 11, 'learning_rate': 0.717204436795498, 'log_max_bin': 8, 'colsample_bytree': 0.8406254356509558, 'reg_alpha': 0.0017271108100233477, 'reg_lambda': 0.4568414445572454}, 'config/n_estimators': 78, 'config/num_leaves': 13, 'config/min_child_samples': 11, 'config/learning_rate': 0.717204436795498, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8406254356509558, 'config/reg_alpha': 0.0017271108100233477, 'config/reg_lambda': 0.4568414445572454, 'experiment_tag': 'exp', 'time_total_s': 1.012894630432129}\n",
      "[flaml.tune.tune: 09-25 12:33:24] {197} INFO - result: {'pred_time': 1.483976670786735e-05, 'wall_clock_time': 60.722363233566284, 'metric_for_logging': {'pred_time': 1.483976670786735e-05}, 'val_loss': 0.21961083301038326, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5242fcf10>, 'training_iteration': 1, 'config': {'n_estimators': 78, 'num_leaves': 13, 'min_child_samples': 11, 'learning_rate': 0.717204436795498, 'log_max_bin': 8, 'colsample_bytree': 0.8406254356509558, 'reg_alpha': 0.0017271108100233477, 'reg_lambda': 0.4568414445572454}, 'config/n_estimators': 78, 'config/num_leaves': 13, 'config/min_child_samples': 11, 'config/learning_rate': 0.717204436795498, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8406254356509558, 'config/reg_alpha': 0.0017271108100233477, 'config/reg_lambda': 0.4568414445572454, 'experiment_tag': 'exp', 'time_total_s': 1.0145716667175293}\n",
      "[flaml.automl.logger: 09-25 12:33:24] {2391} INFO -  at 60.7s,\testimator lgbm's best error=0.2059,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:24] {2218} INFO - iteration 55, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:33:24] {805} INFO - trial 1 config: {'n_estimators': 9, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9079647052885418, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292995}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:33:26] {197} INFO - result: {'pred_time': 5.7659811311873184e-05, 'wall_clock_time': 63.00070858001709, 'metric_for_logging': {'pred_time': 5.7659811311873184e-05}, 'val_loss': 0.2861053058017076, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5242fcb50>, 'training_iteration': 0, 'config': {'n_estimators': 9, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9079647052885418, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292995}, 'config/n_estimators': 9, 'config/max_leaves': 7, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9079647052885418, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292995, 'experiment_tag': 'exp', 'time_total_s': 2.2704896926879883}\n",
      "[flaml.tune.tune: 09-25 12:33:26] {197} INFO - result: {'pred_time': 5.7659811311873184e-05, 'wall_clock_time': 63.00070858001709, 'metric_for_logging': {'pred_time': 5.7659811311873184e-05}, 'val_loss': 0.2861053058017076, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5242fcb50>, 'training_iteration': 1, 'config': {'n_estimators': 9, 'max_leaves': 7, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9079647052885418, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292995}, 'config/n_estimators': 9, 'config/max_leaves': 7, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9079647052885418, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292995, 'experiment_tag': 'exp', 'time_total_s': 2.272395133972168}\n",
      "[flaml.automl.logger: 09-25 12:33:26] {2391} INFO -  at 63.0s,\testimator xgboost's best error=0.2535,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:26] {2218} INFO - iteration 56, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:33:26] {805} INFO - trial 1 config: {'n_estimators': 21, 'max_features': 0.032427221756276076, 'max_leaves': 21, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:33:28] {197} INFO - result: {'pred_time': 5.9088243143869805e-05, 'wall_clock_time': 64.13105750083923, 'metric_for_logging': {'pred_time': 5.9088243143869805e-05}, 'val_loss': 0.24985933921466152, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5242fc940>, 'training_iteration': 0, 'config': {'n_estimators': 21, 'max_features': 0.032427221756276076, 'max_leaves': 21, 'criterion': 'gini'}, 'config/n_estimators': 21, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 21, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.1182727813720703}\n",
      "[flaml.tune.tune: 09-25 12:33:28] {197} INFO - result: {'pred_time': 5.9088243143869805e-05, 'wall_clock_time': 64.13105750083923, 'metric_for_logging': {'pred_time': 5.9088243143869805e-05}, 'val_loss': 0.24985933921466152, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5242fc940>, 'training_iteration': 1, 'config': {'n_estimators': 21, 'max_features': 0.032427221756276076, 'max_leaves': 21, 'criterion': 'gini'}, 'config/n_estimators': 21, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 21, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.1198408603668213}\n",
      "[flaml.automl.logger: 09-25 12:33:28] {2391} INFO -  at 64.1s,\testimator rf's best error=0.2313,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:28] {2218} INFO - iteration 57, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:33:28] {805} INFO - trial 1 config: {'n_estimators': 61, 'max_features': 0.0425346962238793, 'max_leaves': 33, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:33:30] {197} INFO - result: {'pred_time': 0.00011485592217490653, 'wall_clock_time': 66.4173173904419, 'metric_for_logging': {'pred_time': 0.00011485592217490653}, 'val_loss': 0.21678672098462207, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5fe09d0>, 'training_iteration': 0, 'config': {'n_estimators': 61, 'max_features': 0.0425346962238793, 'max_leaves': 33, 'criterion': 'entropy'}, 'config/n_estimators': 61, 'config/max_features': 0.0425346962238793, 'config/max_leaves': 33, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.277780294418335}\n",
      "[flaml.tune.tune: 09-25 12:33:30] {197} INFO - result: {'pred_time': 0.00011485592217490653, 'wall_clock_time': 66.4173173904419, 'metric_for_logging': {'pred_time': 0.00011485592217490653}, 'val_loss': 0.21678672098462207, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5fe09d0>, 'training_iteration': 1, 'config': {'n_estimators': 61, 'max_features': 0.0425346962238793, 'max_leaves': 33, 'criterion': 'entropy'}, 'config/n_estimators': 61, 'config/max_features': 0.0425346962238793, 'config/max_leaves': 33, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.2794530391693115}\n",
      "[flaml.automl.logger: 09-25 12:33:30] {2391} INFO -  at 66.4s,\testimator rf's best error=0.2168,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:30] {2218} INFO - iteration 58, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:33:30] {805} INFO - trial 1 config: {'n_estimators': 15, 'max_leaves': 11, 'min_child_weight': 0.7694377042261122, 'learning_rate': 0.8060470431177518, 'subsample': 1.0, 'colsample_bylevel': 0.8256882078026019, 'colsample_bytree': 0.7967145599266738, 'reg_alpha': 0.058176484040363505, 'reg_lambda': 4.081433281365184}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:33:33] {197} INFO - result: {'pred_time': 5.831928422685715e-05, 'wall_clock_time': 69.54161334037781, 'metric_for_logging': {'pred_time': 5.831928422685715e-05}, 'val_loss': 0.24543571509463566, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5b2b970>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_leaves': 11, 'min_child_weight': 0.7694377042261122, 'learning_rate': 0.8060470431177518, 'subsample': 1.0, 'colsample_bylevel': 0.8256882078026019, 'colsample_bytree': 0.7967145599266738, 'reg_alpha': 0.058176484040363505, 'reg_lambda': 4.081433281365184}, 'config/n_estimators': 15, 'config/max_leaves': 11, 'config/min_child_weight': 0.7694377042261122, 'config/learning_rate': 0.8060470431177518, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8256882078026019, 'config/colsample_bytree': 0.7967145599266738, 'config/reg_alpha': 0.058176484040363505, 'config/reg_lambda': 4.081433281365184, 'experiment_tag': 'exp', 'time_total_s': 3.1148808002471924}\n",
      "[flaml.tune.tune: 09-25 12:33:33] {197} INFO - result: {'pred_time': 5.831928422685715e-05, 'wall_clock_time': 69.54161334037781, 'metric_for_logging': {'pred_time': 5.831928422685715e-05}, 'val_loss': 0.24543571509463566, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5b2b970>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_leaves': 11, 'min_child_weight': 0.7694377042261122, 'learning_rate': 0.8060470431177518, 'subsample': 1.0, 'colsample_bylevel': 0.8256882078026019, 'colsample_bytree': 0.7967145599266738, 'reg_alpha': 0.058176484040363505, 'reg_lambda': 4.081433281365184}, 'config/n_estimators': 15, 'config/max_leaves': 11, 'config/min_child_weight': 0.7694377042261122, 'config/learning_rate': 0.8060470431177518, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8256882078026019, 'config/colsample_bytree': 0.7967145599266738, 'config/reg_alpha': 0.058176484040363505, 'config/reg_lambda': 4.081433281365184, 'experiment_tag': 'exp', 'time_total_s': 3.116633176803589}\n",
      "[flaml.automl.logger: 09-25 12:33:33] {2391} INFO -  at 69.5s,\testimator xgboost's best error=0.2454,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:33] {2218} INFO - iteration 59, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:33:33] {805} INFO - trial 1 config: {'n_estimators': 29, 'num_leaves': 21, 'min_child_samples': 9, 'learning_rate': 1.0, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0015564673105246884, 'reg_lambda': 0.5579966124152358}\n",
      "[flaml.tune.tune: 09-25 12:33:34] {197} INFO - result: {'pred_time': 1.6691629755309058e-05, 'wall_clock_time': 70.58867144584656, 'metric_for_logging': {'pred_time': 1.6691629755309058e-05}, 'val_loss': 0.2301610715778632, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d647b520>, 'training_iteration': 0, 'config': {'n_estimators': 29, 'num_leaves': 21, 'min_child_samples': 9, 'learning_rate': 1.0, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0015564673105246884, 'reg_lambda': 0.5579966124152358}, 'config/n_estimators': 29, 'config/num_leaves': 21, 'config/min_child_samples': 9, 'config/learning_rate': 1.0, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0015564673105246884, 'config/reg_lambda': 0.5579966124152358, 'experiment_tag': 'exp', 'time_total_s': 1.0354552268981934}\n",
      "[flaml.tune.tune: 09-25 12:33:34] {197} INFO - result: {'pred_time': 1.6691629755309058e-05, 'wall_clock_time': 70.58867144584656, 'metric_for_logging': {'pred_time': 1.6691629755309058e-05}, 'val_loss': 0.2301610715778632, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d647b520>, 'training_iteration': 1, 'config': {'n_estimators': 29, 'num_leaves': 21, 'min_child_samples': 9, 'learning_rate': 1.0, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0015564673105246884, 'reg_lambda': 0.5579966124152358}, 'config/n_estimators': 29, 'config/num_leaves': 21, 'config/min_child_samples': 9, 'config/learning_rate': 1.0, 'config/log_max_bin': 10, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0015564673105246884, 'config/reg_lambda': 0.5579966124152358, 'experiment_tag': 'exp', 'time_total_s': 1.037501573562622}\n",
      "[flaml.automl.logger: 09-25 12:33:34] {2391} INFO -  at 70.6s,\testimator lgbm's best error=0.2059,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:34] {2218} INFO - iteration 60, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:33:34] {805} INFO - trial 1 config: {'n_estimators': 22, 'max_features': 0.0463791873421922, 'max_leaves': 51, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:33:35] {197} INFO - result: {'pred_time': 6.598663022680807e-05, 'wall_clock_time': 71.81781554222107, 'metric_for_logging': {'pred_time': 6.598663022680807e-05}, 'val_loss': 0.23814156244815915, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e15700>, 'training_iteration': 0, 'config': {'n_estimators': 22, 'max_features': 0.0463791873421922, 'max_leaves': 51, 'criterion': 'entropy'}, 'config/n_estimators': 22, 'config/max_features': 0.0463791873421922, 'config/max_leaves': 51, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.220322847366333}\n",
      "[flaml.tune.tune: 09-25 12:33:35] {197} INFO - result: {'pred_time': 6.598663022680807e-05, 'wall_clock_time': 71.81781554222107, 'metric_for_logging': {'pred_time': 6.598663022680807e-05}, 'val_loss': 0.23814156244815915, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e15700>, 'training_iteration': 1, 'config': {'n_estimators': 22, 'max_features': 0.0463791873421922, 'max_leaves': 51, 'criterion': 'entropy'}, 'config/n_estimators': 22, 'config/max_features': 0.0463791873421922, 'config/max_leaves': 51, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2218842506408691}\n",
      "[flaml.automl.logger: 09-25 12:33:35] {2391} INFO -  at 71.8s,\testimator rf's best error=0.2168,\tbest estimator lgbm's best error=0.2059\n",
      "[flaml.automl.logger: 09-25 12:33:35] {2218} INFO - iteration 61, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:33:35] {805} INFO - trial 1 config: {'n_estimators': 90, 'num_leaves': 70, 'min_child_samples': 7, 'learning_rate': 0.20466906793634726, 'log_max_bin': 9, 'colsample_bytree': 0.7749909456010404, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3192797038889443}\n",
      "[flaml.tune.tune: 09-25 12:33:38] {197} INFO - result: {'pred_time': 1.9720935001683866e-05, 'wall_clock_time': 74.27527213096619, 'metric_for_logging': {'pred_time': 1.9720935001683866e-05}, 'val_loss': 0.19715560618858974, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5cdfbb0>, 'training_iteration': 0, 'config': {'n_estimators': 90, 'num_leaves': 70, 'min_child_samples': 7, 'learning_rate': 0.20466906793634726, 'log_max_bin': 9, 'colsample_bytree': 0.7749909456010404, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3192797038889443}, 'config/n_estimators': 90, 'config/num_leaves': 70, 'config/min_child_samples': 7, 'config/learning_rate': 0.20466906793634726, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7749909456010404, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.3192797038889443, 'experiment_tag': 'exp', 'time_total_s': 2.4502317905426025}\n",
      "[flaml.tune.tune: 09-25 12:33:38] {197} INFO - result: {'pred_time': 1.9720935001683866e-05, 'wall_clock_time': 74.27527213096619, 'metric_for_logging': {'pred_time': 1.9720935001683866e-05}, 'val_loss': 0.19715560618858974, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5cdfbb0>, 'training_iteration': 1, 'config': {'n_estimators': 90, 'num_leaves': 70, 'min_child_samples': 7, 'learning_rate': 0.20466906793634726, 'log_max_bin': 9, 'colsample_bytree': 0.7749909456010404, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3192797038889443}, 'config/n_estimators': 90, 'config/num_leaves': 70, 'config/min_child_samples': 7, 'config/learning_rate': 0.20466906793634726, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7749909456010404, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.3192797038889443, 'experiment_tag': 'exp', 'time_total_s': 2.452254056930542}\n",
      "[flaml.automl.logger: 09-25 12:33:38] {2391} INFO -  at 74.3s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:33:38] {2218} INFO - iteration 62, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:33:38] {805} INFO - trial 1 config: {'n_estimators': 15, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 0.9661106209889765, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644698, 'reg_lambda': 0.8085739292796903}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:33:40] {197} INFO - result: {'pred_time': 5.73249182828448e-05, 'wall_clock_time': 76.76581621170044, 'metric_for_logging': {'pred_time': 5.73249182828448e-05}, 'val_loss': 0.24515036747045746, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 0.9661106209889765, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644698, 'reg_lambda': 0.8085739292796903}, 'config/n_estimators': 15, 'config/max_leaves': 5, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.6618201818236865, 'config/subsample': 0.9661106209889765, 'config/colsample_bylevel': 0.7979503033535307, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644698, 'config/reg_lambda': 0.8085739292796903, 'experiment_tag': 'exp', 'time_total_s': 2.481801748275757}\n",
      "[flaml.tune.tune: 09-25 12:33:40] {197} INFO - result: {'pred_time': 5.73249182828448e-05, 'wall_clock_time': 76.76581621170044, 'metric_for_logging': {'pred_time': 5.73249182828448e-05}, 'val_loss': 0.24515036747045746, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 0.9661106209889765, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644698, 'reg_lambda': 0.8085739292796903}, 'config/n_estimators': 15, 'config/max_leaves': 5, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.6618201818236865, 'config/subsample': 0.9661106209889765, 'config/colsample_bylevel': 0.7979503033535307, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644698, 'config/reg_lambda': 0.8085739292796903, 'experiment_tag': 'exp', 'time_total_s': 2.483430862426758}\n",
      "[flaml.automl.logger: 09-25 12:33:40] {2391} INFO -  at 76.8s,\testimator xgboost's best error=0.2452,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:33:40] {2218} INFO - iteration 63, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:33:40] {805} INFO - trial 1 config: {'n_estimators': 9, 'max_leaves': 4, 'min_child_weight': 0.10422622872469292, 'learning_rate': 1.0, 'subsample': 0.794741631646611, 'colsample_bylevel': 0.7539376453684443, 'colsample_bytree': 0.9485956837704628, 'reg_alpha': 0.0063736480220318815, 'reg_lambda': 2.33607966864803}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:33:42] {197} INFO - result: {'pred_time': 5.407276706879626e-05, 'wall_clock_time': 78.88985514640808, 'metric_for_logging': {'pred_time': 5.407276706879626e-05}, 'val_loss': 0.27641732667969554, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1bc40>, 'training_iteration': 0, 'config': {'n_estimators': 9, 'max_leaves': 4, 'min_child_weight': 0.10422622872469292, 'learning_rate': 1.0, 'subsample': 0.794741631646611, 'colsample_bylevel': 0.7539376453684443, 'colsample_bytree': 0.9485956837704628, 'reg_alpha': 0.0063736480220318815, 'reg_lambda': 2.33607966864803}, 'config/n_estimators': 9, 'config/max_leaves': 4, 'config/min_child_weight': 0.10422622872469292, 'config/learning_rate': 1.0, 'config/subsample': 0.794741631646611, 'config/colsample_bylevel': 0.7539376453684443, 'config/colsample_bytree': 0.9485956837704628, 'config/reg_alpha': 0.0063736480220318815, 'config/reg_lambda': 2.33607966864803, 'experiment_tag': 'exp', 'time_total_s': 2.1159956455230713}\n",
      "[flaml.tune.tune: 09-25 12:33:42] {197} INFO - result: {'pred_time': 5.407276706879626e-05, 'wall_clock_time': 78.88985514640808, 'metric_for_logging': {'pred_time': 5.407276706879626e-05}, 'val_loss': 0.27641732667969554, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1bc40>, 'training_iteration': 1, 'config': {'n_estimators': 9, 'max_leaves': 4, 'min_child_weight': 0.10422622872469292, 'learning_rate': 1.0, 'subsample': 0.794741631646611, 'colsample_bylevel': 0.7539376453684443, 'colsample_bytree': 0.9485956837704628, 'reg_alpha': 0.0063736480220318815, 'reg_lambda': 2.33607966864803}, 'config/n_estimators': 9, 'config/max_leaves': 4, 'config/min_child_weight': 0.10422622872469292, 'config/learning_rate': 1.0, 'config/subsample': 0.794741631646611, 'config/colsample_bylevel': 0.7539376453684443, 'config/colsample_bytree': 0.9485956837704628, 'config/reg_alpha': 0.0063736480220318815, 'config/reg_lambda': 2.33607966864803, 'experiment_tag': 'exp', 'time_total_s': 2.12091064453125}\n",
      "[flaml.automl.logger: 09-25 12:33:42] {2391} INFO -  at 78.9s,\testimator xgboost's best error=0.2452,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:33:42] {2218} INFO - iteration 64, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:33:42] {805} INFO - trial 1 config: {'n_estimators': 152, 'num_leaves': 39, 'min_child_samples': 3, 'learning_rate': 0.2528431582281467, 'log_max_bin': 10, 'colsample_bytree': 0.8251789580300279, 'reg_alpha': 0.004577823970660193, 'reg_lambda': 2.8288672134668276}\n",
      "[flaml.tune.tune: 09-25 12:33:45] {197} INFO - result: {'pred_time': 2.0088047851043235e-05, 'wall_clock_time': 81.46128129959106, 'metric_for_logging': {'pred_time': 2.0088047851043235e-05}, 'val_loss': 0.21041223151418054, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5243827c0>, 'training_iteration': 0, 'config': {'n_estimators': 152, 'num_leaves': 39, 'min_child_samples': 3, 'learning_rate': 0.2528431582281467, 'log_max_bin': 10, 'colsample_bytree': 0.8251789580300279, 'reg_alpha': 0.004577823970660193, 'reg_lambda': 2.8288672134668276}, 'config/n_estimators': 152, 'config/num_leaves': 39, 'config/min_child_samples': 3, 'config/learning_rate': 0.2528431582281467, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8251789580300279, 'config/reg_alpha': 0.004577823970660193, 'config/reg_lambda': 2.8288672134668276, 'experiment_tag': 'exp', 'time_total_s': 2.5578317642211914}\n",
      "[flaml.tune.tune: 09-25 12:33:45] {197} INFO - result: {'pred_time': 2.0088047851043235e-05, 'wall_clock_time': 81.46128129959106, 'metric_for_logging': {'pred_time': 2.0088047851043235e-05}, 'val_loss': 0.21041223151418054, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5243827c0>, 'training_iteration': 1, 'config': {'n_estimators': 152, 'num_leaves': 39, 'min_child_samples': 3, 'learning_rate': 0.2528431582281467, 'log_max_bin': 10, 'colsample_bytree': 0.8251789580300279, 'reg_alpha': 0.004577823970660193, 'reg_lambda': 2.8288672134668276}, 'config/n_estimators': 152, 'config/num_leaves': 39, 'config/min_child_samples': 3, 'config/learning_rate': 0.2528431582281467, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8251789580300279, 'config/reg_alpha': 0.004577823970660193, 'config/reg_lambda': 2.8288672134668276, 'experiment_tag': 'exp', 'time_total_s': 2.559597969055176}\n",
      "[flaml.automl.logger: 09-25 12:33:45] {2391} INFO -  at 81.5s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:33:45] {2218} INFO - iteration 65, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:33:45] {805} INFO - trial 1 config: {'n_estimators': 166, 'max_features': 0.039008884944644585, 'max_leaves': 22, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:33:50] {197} INFO - result: {'pred_time': 0.00023662198984200053, 'wall_clock_time': 86.47923707962036, 'metric_for_logging': {'pred_time': 0.00023662198984200053}, 'val_loss': 0.22886635337909703, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe66825deb0>, 'training_iteration': 0, 'config': {'n_estimators': 166, 'max_features': 0.039008884944644585, 'max_leaves': 22, 'criterion': 'gini'}, 'config/n_estimators': 166, 'config/max_features': 0.039008884944644585, 'config/max_leaves': 22, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 5.009031772613525}\n",
      "[flaml.tune.tune: 09-25 12:33:50] {197} INFO - result: {'pred_time': 0.00023662198984200053, 'wall_clock_time': 86.47923707962036, 'metric_for_logging': {'pred_time': 0.00023662198984200053}, 'val_loss': 0.22886635337909703, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe66825deb0>, 'training_iteration': 1, 'config': {'n_estimators': 166, 'max_features': 0.039008884944644585, 'max_leaves': 22, 'criterion': 'gini'}, 'config/n_estimators': 166, 'config/max_features': 0.039008884944644585, 'config/max_leaves': 22, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 5.01021146774292}\n",
      "[flaml.automl.logger: 09-25 12:33:50] {2391} INFO -  at 86.5s,\testimator rf's best error=0.2168,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:33:50] {2218} INFO - iteration 66, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:33:50] {805} INFO - trial 1 config: {'n_estimators': 25, 'max_leaves': 6, 'min_child_weight': 2.73397433954217, 'learning_rate': 0.42446153566346606, 'subsample': 1.0, 'colsample_bylevel': 0.841962961338617, 'colsample_bytree': 0.7512098613287459, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.279867081540575}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:33:52] {197} INFO - result: {'pred_time': 4.2983377785868355e-05, 'wall_clock_time': 88.82639241218567, 'metric_for_logging': {'pred_time': 4.2983377785868355e-05}, 'val_loss': 0.2449094536238464, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe668040d60>, 'training_iteration': 0, 'config': {'n_estimators': 25, 'max_leaves': 6, 'min_child_weight': 2.73397433954217, 'learning_rate': 0.42446153566346606, 'subsample': 1.0, 'colsample_bylevel': 0.841962961338617, 'colsample_bytree': 0.7512098613287459, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.279867081540575}, 'config/n_estimators': 25, 'config/max_leaves': 6, 'config/min_child_weight': 2.73397433954217, 'config/learning_rate': 0.42446153566346606, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.841962961338617, 'config/colsample_bytree': 0.7512098613287459, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.279867081540575, 'experiment_tag': 'exp', 'time_total_s': 2.3400208950042725}\n",
      "[flaml.tune.tune: 09-25 12:33:52] {197} INFO - result: {'pred_time': 4.2983377785868355e-05, 'wall_clock_time': 88.82639241218567, 'metric_for_logging': {'pred_time': 4.2983377785868355e-05}, 'val_loss': 0.2449094536238464, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe668040d60>, 'training_iteration': 1, 'config': {'n_estimators': 25, 'max_leaves': 6, 'min_child_weight': 2.73397433954217, 'learning_rate': 0.42446153566346606, 'subsample': 1.0, 'colsample_bylevel': 0.841962961338617, 'colsample_bytree': 0.7512098613287459, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.279867081540575}, 'config/n_estimators': 25, 'config/max_leaves': 6, 'config/min_child_weight': 2.73397433954217, 'config/learning_rate': 0.42446153566346606, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.841962961338617, 'config/colsample_bytree': 0.7512098613287459, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.279867081540575, 'experiment_tag': 'exp', 'time_total_s': 2.3413455486297607}\n",
      "[flaml.automl.logger: 09-25 12:33:52] {2391} INFO -  at 88.8s,\testimator xgboost's best error=0.2449,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:33:52] {2218} INFO - iteration 67, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:33:52] {805} INFO - trial 1 config: {'n_estimators': 46, 'max_features': 0.05322276111861016, 'max_leaves': 81, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:33:54] {197} INFO - result: {'pred_time': 7.521193381659059e-05, 'wall_clock_time': 90.41499710083008, 'metric_for_logging': {'pred_time': 7.521193381659059e-05}, 'val_loss': 0.20544409448082607, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668028520>, 'training_iteration': 0, 'config': {'n_estimators': 46, 'max_features': 0.05322276111861016, 'max_leaves': 81, 'criterion': 'entropy'}, 'config/n_estimators': 46, 'config/max_features': 0.05322276111861016, 'config/max_leaves': 81, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.5825514793395996}\n",
      "[flaml.tune.tune: 09-25 12:33:54] {197} INFO - result: {'pred_time': 7.521193381659059e-05, 'wall_clock_time': 90.41499710083008, 'metric_for_logging': {'pred_time': 7.521193381659059e-05}, 'val_loss': 0.20544409448082607, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668028520>, 'training_iteration': 1, 'config': {'n_estimators': 46, 'max_features': 0.05322276111861016, 'max_leaves': 81, 'criterion': 'entropy'}, 'config/n_estimators': 46, 'config/max_features': 0.05322276111861016, 'config/max_leaves': 81, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.584216833114624}\n",
      "[flaml.automl.logger: 09-25 12:33:54] {2391} INFO -  at 90.4s,\testimator rf's best error=0.2054,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:33:54] {2218} INFO - iteration 68, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:33:54] {805} INFO - trial 1 config: {'n_estimators': 53, 'num_leaves': 126, 'min_child_samples': 16, 'learning_rate': 0.16567356484344836, 'log_max_bin': 8, 'colsample_bytree': 0.724802933172053, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.615263568684897}\n",
      "[flaml.tune.tune: 09-25 12:33:55] {197} INFO - result: {'pred_time': 1.296843648754437e-05, 'wall_clock_time': 91.56636357307434, 'metric_for_logging': {'pred_time': 1.296843648754437e-05}, 'val_loss': 0.2129624723327872, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d619aaf0>, 'training_iteration': 0, 'config': {'n_estimators': 53, 'num_leaves': 126, 'min_child_samples': 16, 'learning_rate': 0.16567356484344836, 'log_max_bin': 8, 'colsample_bytree': 0.724802933172053, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.615263568684897}, 'config/n_estimators': 53, 'config/num_leaves': 126, 'config/min_child_samples': 16, 'config/learning_rate': 0.16567356484344836, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.724802933172053, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.615263568684897, 'experiment_tag': 'exp', 'time_total_s': 1.1439323425292969}\n",
      "[flaml.tune.tune: 09-25 12:33:55] {197} INFO - result: {'pred_time': 1.296843648754437e-05, 'wall_clock_time': 91.56636357307434, 'metric_for_logging': {'pred_time': 1.296843648754437e-05}, 'val_loss': 0.2129624723327872, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d619aaf0>, 'training_iteration': 1, 'config': {'n_estimators': 53, 'num_leaves': 126, 'min_child_samples': 16, 'learning_rate': 0.16567356484344836, 'log_max_bin': 8, 'colsample_bytree': 0.724802933172053, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.615263568684897}, 'config/n_estimators': 53, 'config/num_leaves': 126, 'config/min_child_samples': 16, 'config/learning_rate': 0.16567356484344836, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.724802933172053, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.615263568684897, 'experiment_tag': 'exp', 'time_total_s': 1.14509916305542}\n",
      "[flaml.automl.logger: 09-25 12:33:55] {2391} INFO -  at 91.6s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:33:55] {2218} INFO - iteration 69, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:33:55] {805} INFO - trial 1 config: {'n_estimators': 10, 'max_leaves': 11, 'min_child_weight': 2.3002955481543466, 'learning_rate': 1.0, 'subsample': 0.9728097438800569, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.7961300914414072, 'reg_alpha': 0.0030316436446129334, 'reg_lambda': 0.1544062642046082}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:33:57] {197} INFO - result: {'pred_time': 4.003639756846012e-05, 'wall_clock_time': 93.31024122238159, 'metric_for_logging': {'pred_time': 4.003639756846012e-05}, 'val_loss': 0.26922212836755566, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe66804eb50>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_leaves': 11, 'min_child_weight': 2.3002955481543466, 'learning_rate': 1.0, 'subsample': 0.9728097438800569, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.7961300914414072, 'reg_alpha': 0.0030316436446129334, 'reg_lambda': 0.1544062642046082}, 'config/n_estimators': 10, 'config/max_leaves': 11, 'config/min_child_weight': 2.3002955481543466, 'config/learning_rate': 1.0, 'config/subsample': 0.9728097438800569, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.7961300914414072, 'config/reg_alpha': 0.0030316436446129334, 'config/reg_lambda': 0.1544062642046082, 'experiment_tag': 'exp', 'time_total_s': 1.7373337745666504}\n",
      "[flaml.tune.tune: 09-25 12:33:57] {197} INFO - result: {'pred_time': 4.003639756846012e-05, 'wall_clock_time': 93.31024122238159, 'metric_for_logging': {'pred_time': 4.003639756846012e-05}, 'val_loss': 0.26922212836755566, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe66804eb50>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_leaves': 11, 'min_child_weight': 2.3002955481543466, 'learning_rate': 1.0, 'subsample': 0.9728097438800569, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.7961300914414072, 'reg_alpha': 0.0030316436446129334, 'reg_lambda': 0.1544062642046082}, 'config/n_estimators': 10, 'config/max_leaves': 11, 'config/min_child_weight': 2.3002955481543466, 'config/learning_rate': 1.0, 'config/subsample': 0.9728097438800569, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.7961300914414072, 'config/reg_alpha': 0.0030316436446129334, 'config/reg_lambda': 0.1544062642046082, 'experiment_tag': 'exp', 'time_total_s': 1.738569974899292}\n",
      "[flaml.automl.logger: 09-25 12:33:57] {2391} INFO -  at 93.3s,\testimator xgboost's best error=0.2449,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:33:57] {2218} INFO - iteration 70, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:33:57] {805} INFO - trial 1 config: {'n_estimators': 60, 'max_leaves': 4, 'min_child_weight': 3.2494153611140617, 'learning_rate': 0.15560707746676394, 'subsample': 1.0, 'colsample_bylevel': 0.6602366975169772, 'colsample_bytree': 0.7062896312160846, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5072694669061312}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:34:00] {197} INFO - result: {'pred_time': 4.176381836732005e-05, 'wall_clock_time': 96.96594142913818, 'metric_for_logging': {'pred_time': 4.176381836732005e-05}, 'val_loss': 0.2475491291083495, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe524310550>, 'training_iteration': 0, 'config': {'n_estimators': 60, 'max_leaves': 4, 'min_child_weight': 3.2494153611140617, 'learning_rate': 0.15560707746676394, 'subsample': 1.0, 'colsample_bylevel': 0.6602366975169772, 'colsample_bytree': 0.7062896312160846, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5072694669061312}, 'config/n_estimators': 60, 'config/max_leaves': 4, 'config/min_child_weight': 3.2494153611140617, 'config/learning_rate': 0.15560707746676394, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.6602366975169772, 'config/colsample_bytree': 0.7062896312160846, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5072694669061312, 'experiment_tag': 'exp', 'time_total_s': 3.6475560665130615}\n",
      "[flaml.tune.tune: 09-25 12:34:00] {197} INFO - result: {'pred_time': 4.176381836732005e-05, 'wall_clock_time': 96.96594142913818, 'metric_for_logging': {'pred_time': 4.176381836732005e-05}, 'val_loss': 0.2475491291083495, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe524310550>, 'training_iteration': 1, 'config': {'n_estimators': 60, 'max_leaves': 4, 'min_child_weight': 3.2494153611140617, 'learning_rate': 0.15560707746676394, 'subsample': 1.0, 'colsample_bylevel': 0.6602366975169772, 'colsample_bytree': 0.7062896312160846, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5072694669061312}, 'config/n_estimators': 60, 'config/max_leaves': 4, 'config/min_child_weight': 3.2494153611140617, 'config/learning_rate': 0.15560707746676394, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.6602366975169772, 'config/colsample_bytree': 0.7062896312160846, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5072694669061312, 'experiment_tag': 'exp', 'time_total_s': 3.648747444152832}\n",
      "[flaml.automl.logger: 09-25 12:34:00] {2391} INFO -  at 97.0s,\testimator xgboost's best error=0.2449,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:00] {2218} INFO - iteration 71, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:34:00] {805} INFO - trial 1 config: {'n_estimators': 16, 'max_leaves': 4, 'min_child_weight': 19.042454227847614, 'learning_rate': 0.25445569037444943, 'subsample': 0.9827721799620315, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8353833330765148, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5369588335339861}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:34:02] {197} INFO - result: {'pred_time': 4.300200589707988e-05, 'wall_clock_time': 98.91783952713013, 'metric_for_logging': {'pred_time': 4.300200589707988e-05}, 'val_loss': 0.28414628444613454, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe66805e040>, 'training_iteration': 0, 'config': {'n_estimators': 16, 'max_leaves': 4, 'min_child_weight': 19.042454227847614, 'learning_rate': 0.25445569037444943, 'subsample': 0.9827721799620315, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8353833330765148, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5369588335339861}, 'config/n_estimators': 16, 'config/max_leaves': 4, 'config/min_child_weight': 19.042454227847614, 'config/learning_rate': 0.25445569037444943, 'config/subsample': 0.9827721799620315, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.8353833330765148, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5369588335339861, 'experiment_tag': 'exp', 'time_total_s': 1.9460723400115967}\n",
      "[flaml.tune.tune: 09-25 12:34:02] {197} INFO - result: {'pred_time': 4.300200589707988e-05, 'wall_clock_time': 98.91783952713013, 'metric_for_logging': {'pred_time': 4.300200589707988e-05}, 'val_loss': 0.28414628444613454, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe66805e040>, 'training_iteration': 1, 'config': {'n_estimators': 16, 'max_leaves': 4, 'min_child_weight': 19.042454227847614, 'learning_rate': 0.25445569037444943, 'subsample': 0.9827721799620315, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8353833330765148, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5369588335339861}, 'config/n_estimators': 16, 'config/max_leaves': 4, 'config/min_child_weight': 19.042454227847614, 'config/learning_rate': 0.25445569037444943, 'config/subsample': 0.9827721799620315, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.8353833330765148, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5369588335339861, 'experiment_tag': 'exp', 'time_total_s': 1.9476313591003418}\n",
      "[flaml.automl.logger: 09-25 12:34:02] {2391} INFO -  at 98.9s,\testimator xgboost's best error=0.2449,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:02] {2218} INFO - iteration 72, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:34:02] {805} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.09999999999999996, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:34:05] {197} INFO - result: {'pred_time': 0.00010557388623022236, 'wall_clock_time': 101.87327170372009, 'metric_for_logging': {'pred_time': 0.00010557388623022236}, 'val_loss': 0.2506400083049259, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340dc550>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.09999999999999996, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.09999999999999996, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 2.9486424922943115}\n",
      "[flaml.tune.tune: 09-25 12:34:05] {197} INFO - result: {'pred_time': 0.00010557388623022236, 'wall_clock_time': 101.87327170372009, 'metric_for_logging': {'pred_time': 0.00010557388623022236}, 'val_loss': 0.2506400083049259, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340dc550>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.09999999999999996, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.09999999999999996, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 2.9502546787261963}\n",
      "[flaml.automl.logger: 09-25 12:34:05] {2391} INFO -  at 101.9s,\testimator catboost's best error=0.2506,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:05] {2218} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:34:05] {805} INFO - trial 1 config: {'n_estimators': 13, 'max_features': 0.042431336962006815, 'max_leaves': 106, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:34:06] {197} INFO - result: {'pred_time': 3.828681432816728e-05, 'wall_clock_time': 102.58148431777954, 'metric_for_logging': {'pred_time': 3.828681432816728e-05}, 'val_loss': 0.24954604298682265, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340c1880>, 'training_iteration': 0, 'config': {'n_estimators': 13, 'max_features': 0.042431336962006815, 'max_leaves': 106, 'criterion': 'entropy'}, 'config/n_estimators': 13, 'config/max_features': 0.042431336962006815, 'config/max_leaves': 106, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.6995398998260498}\n",
      "[flaml.tune.tune: 09-25 12:34:06] {197} INFO - result: {'pred_time': 3.828681432816728e-05, 'wall_clock_time': 102.58148431777954, 'metric_for_logging': {'pred_time': 3.828681432816728e-05}, 'val_loss': 0.24954604298682265, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340c1880>, 'training_iteration': 1, 'config': {'n_estimators': 13, 'max_features': 0.042431336962006815, 'max_leaves': 106, 'criterion': 'entropy'}, 'config/n_estimators': 13, 'config/max_features': 0.042431336962006815, 'config/max_leaves': 106, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7007246017456055}\n",
      "[flaml.automl.logger: 09-25 12:34:06] {2391} INFO -  at 102.6s,\testimator extra_tree's best error=0.2178,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:06] {2218} INFO - iteration 74, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:34:06] {805} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.06233639237958607, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:34:10] {197} INFO - result: {'pred_time': 8.180414956846724e-05, 'wall_clock_time': 106.94570279121399, 'metric_for_logging': {'pred_time': 8.180414956846724e-05}, 'val_loss': 0.24165679634195375, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340c1700>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.06233639237958607, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.06233639237958607, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.358644962310791}\n",
      "[flaml.tune.tune: 09-25 12:34:10] {197} INFO - result: {'pred_time': 8.180414956846724e-05, 'wall_clock_time': 106.94570279121399, 'metric_for_logging': {'pred_time': 8.180414956846724e-05}, 'val_loss': 0.24165679634195375, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340c1700>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.06233639237958607, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.06233639237958607, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.360793590545654}\n",
      "[flaml.automl.logger: 09-25 12:34:10] {2391} INFO -  at 106.9s,\testimator catboost's best error=0.2417,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:10] {2218} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:34:10] {805} INFO - trial 1 config: {'n_estimators': 51, 'max_features': 0.10724861527749564, 'max_leaves': 73, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:34:12] {197} INFO - result: {'pred_time': 9.017525965231931e-05, 'wall_clock_time': 108.94571137428284, 'metric_for_logging': {'pred_time': 9.017525965231931e-05}, 'val_loss': 0.23896158296458153, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340dc850>, 'training_iteration': 0, 'config': {'n_estimators': 51, 'max_features': 0.10724861527749564, 'max_leaves': 73, 'criterion': 'gini'}, 'config/n_estimators': 51, 'config/max_features': 0.10724861527749564, 'config/max_leaves': 73, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.9927093982696533}\n",
      "[flaml.tune.tune: 09-25 12:34:12] {197} INFO - result: {'pred_time': 9.017525965231931e-05, 'wall_clock_time': 108.94571137428284, 'metric_for_logging': {'pred_time': 9.017525965231931e-05}, 'val_loss': 0.23896158296458153, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340dc850>, 'training_iteration': 1, 'config': {'n_estimators': 51, 'max_features': 0.10724861527749564, 'max_leaves': 73, 'criterion': 'gini'}, 'config/n_estimators': 51, 'config/max_features': 0.10724861527749564, 'config/max_leaves': 73, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.994574785232544}\n",
      "[flaml.automl.logger: 09-25 12:34:12] {2391} INFO -  at 108.9s,\testimator extra_tree's best error=0.2178,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:12] {2218} INFO - iteration 76, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:34:12] {805} INFO - trial 1 config: {'n_estimators': 117, 'num_leaves': 32, 'min_child_samples': 7, 'learning_rate': 0.08299817666065698, 'log_max_bin': 9, 'colsample_bytree': 0.9826080761242381, 'reg_alpha': 0.001346442339014509, 'reg_lambda': 2.345883690252503}\n",
      "[flaml.tune.tune: 09-25 12:34:14] {197} INFO - result: {'pred_time': 1.3974572109577823e-05, 'wall_clock_time': 110.35927414894104, 'metric_for_logging': {'pred_time': 1.3974572109577823e-05}, 'val_loss': 0.20109939399669535, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340dca60>, 'training_iteration': 0, 'config': {'n_estimators': 117, 'num_leaves': 32, 'min_child_samples': 7, 'learning_rate': 0.08299817666065698, 'log_max_bin': 9, 'colsample_bytree': 0.9826080761242381, 'reg_alpha': 0.001346442339014509, 'reg_lambda': 2.345883690252503}, 'config/n_estimators': 117, 'config/num_leaves': 32, 'config/min_child_samples': 7, 'config/learning_rate': 0.08299817666065698, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.9826080761242381, 'config/reg_alpha': 0.001346442339014509, 'config/reg_lambda': 2.345883690252503, 'experiment_tag': 'exp', 'time_total_s': 1.4060182571411133}\n",
      "[flaml.tune.tune: 09-25 12:34:14] {197} INFO - result: {'pred_time': 1.3974572109577823e-05, 'wall_clock_time': 110.35927414894104, 'metric_for_logging': {'pred_time': 1.3974572109577823e-05}, 'val_loss': 0.20109939399669535, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340dca60>, 'training_iteration': 1, 'config': {'n_estimators': 117, 'num_leaves': 32, 'min_child_samples': 7, 'learning_rate': 0.08299817666065698, 'log_max_bin': 9, 'colsample_bytree': 0.9826080761242381, 'reg_alpha': 0.001346442339014509, 'reg_lambda': 2.345883690252503}, 'config/n_estimators': 117, 'config/num_leaves': 32, 'config/min_child_samples': 7, 'config/learning_rate': 0.08299817666065698, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.9826080761242381, 'config/reg_alpha': 0.001346442339014509, 'config/reg_lambda': 2.345883690252503, 'experiment_tag': 'exp', 'time_total_s': 1.407285451889038}\n",
      "[flaml.automl.logger: 09-25 12:34:14] {2391} INFO -  at 110.4s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:14] {2218} INFO - iteration 77, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:34:14] {805} INFO - trial 1 config: {'n_estimators': 69, 'num_leaves': 154, 'min_child_samples': 7, 'learning_rate': 0.5047029833101101, 'log_max_bin': 9, 'colsample_bytree': 0.5673738150778428, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.7419374388957709}\n",
      "[flaml.tune.tune: 09-25 12:34:15] {197} INFO - result: {'pred_time': 1.2933833783796832e-05, 'wall_clock_time': 111.93855667114258, 'metric_for_logging': {'pred_time': 1.2933833783796832e-05}, 'val_loss': 0.21094595633576146, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524310e80>, 'training_iteration': 0, 'config': {'n_estimators': 69, 'num_leaves': 154, 'min_child_samples': 7, 'learning_rate': 0.5047029833101101, 'log_max_bin': 9, 'colsample_bytree': 0.5673738150778428, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.7419374388957709}, 'config/n_estimators': 69, 'config/num_leaves': 154, 'config/min_child_samples': 7, 'config/learning_rate': 0.5047029833101101, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.5673738150778428, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.7419374388957709, 'experiment_tag': 'exp', 'time_total_s': 1.572615385055542}\n",
      "[flaml.tune.tune: 09-25 12:34:15] {197} INFO - result: {'pred_time': 1.2933833783796832e-05, 'wall_clock_time': 111.93855667114258, 'metric_for_logging': {'pred_time': 1.2933833783796832e-05}, 'val_loss': 0.21094595633576146, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524310e80>, 'training_iteration': 1, 'config': {'n_estimators': 69, 'num_leaves': 154, 'min_child_samples': 7, 'learning_rate': 0.5047029833101101, 'log_max_bin': 9, 'colsample_bytree': 0.5673738150778428, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.7419374388957709}, 'config/n_estimators': 69, 'config/num_leaves': 154, 'config/min_child_samples': 7, 'config/learning_rate': 0.5047029833101101, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.5673738150778428, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.7419374388957709, 'experiment_tag': 'exp', 'time_total_s': 1.5738301277160645}\n",
      "[flaml.automl.logger: 09-25 12:34:15] {2391} INFO -  at 111.9s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:15] {2218} INFO - iteration 78, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:34:15] {805} INFO - trial 1 config: {'n_estimators': 25, 'max_features': 0.12888040862416833, 'max_leaves': 118, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:34:17] {197} INFO - result: {'pred_time': 5.525091301176962e-05, 'wall_clock_time': 113.43174719810486, 'metric_for_logging': {'pred_time': 5.525091301176962e-05}, 'val_loss': 0.2118189735693484, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5b2b220>, 'training_iteration': 0, 'config': {'n_estimators': 25, 'max_features': 0.12888040862416833, 'max_leaves': 118, 'criterion': 'entropy'}, 'config/n_estimators': 25, 'config/max_features': 0.12888040862416833, 'config/max_leaves': 118, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.4874908924102783}\n",
      "[flaml.tune.tune: 09-25 12:34:17] {197} INFO - result: {'pred_time': 5.525091301176962e-05, 'wall_clock_time': 113.43174719810486, 'metric_for_logging': {'pred_time': 5.525091301176962e-05}, 'val_loss': 0.2118189735693484, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6d5b2b220>, 'training_iteration': 1, 'config': {'n_estimators': 25, 'max_features': 0.12888040862416833, 'max_leaves': 118, 'criterion': 'entropy'}, 'config/n_estimators': 25, 'config/max_features': 0.12888040862416833, 'config/max_leaves': 118, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.489025354385376}\n",
      "[flaml.automl.logger: 09-25 12:34:17] {2391} INFO -  at 113.4s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:17] {2218} INFO - iteration 79, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:34:17] {805} INFO - trial 1 config: {'early_stopping_rounds': 12, 'learning_rate': 0.10000000000000002, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:34:20] {197} INFO - result: {'pred_time': 7.691218560646089e-05, 'wall_clock_time': 116.57794904708862, 'metric_for_logging': {'pred_time': 7.691218560646089e-05}, 'val_loss': 0.2506400083049259, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6d5e1b550>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.10000000000000002, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.10000000000000002, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 3.1399614810943604}\n",
      "[flaml.tune.tune: 09-25 12:34:20] {197} INFO - result: {'pred_time': 7.691218560646089e-05, 'wall_clock_time': 116.57794904708862, 'metric_for_logging': {'pred_time': 7.691218560646089e-05}, 'val_loss': 0.2506400083049259, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6d5e1b550>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.10000000000000002, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.10000000000000002, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 3.1413369178771973}\n",
      "[flaml.automl.logger: 09-25 12:34:20] {2391} INFO -  at 116.6s,\testimator catboost's best error=0.2417,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:20] {2218} INFO - iteration 80, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:34:20] {805} INFO - trial 1 config: {'n_estimators': 63, 'num_leaves': 262, 'min_child_samples': 4, 'learning_rate': 0.1267824704459056, 'log_max_bin': 10, 'colsample_bytree': 0.7195975890246057, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.231060318119947}\n",
      "[flaml.tune.tune: 09-25 12:34:22] {197} INFO - result: {'pred_time': 1.2943319318705752e-05, 'wall_clock_time': 118.1113383769989, 'metric_for_logging': {'pred_time': 1.2943319318705752e-05}, 'val_loss': 0.2024917894483112, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524161a60>, 'training_iteration': 0, 'config': {'n_estimators': 63, 'num_leaves': 262, 'min_child_samples': 4, 'learning_rate': 0.1267824704459056, 'log_max_bin': 10, 'colsample_bytree': 0.7195975890246057, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.231060318119947}, 'config/n_estimators': 63, 'config/num_leaves': 262, 'config/min_child_samples': 4, 'config/learning_rate': 0.1267824704459056, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7195975890246057, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.231060318119947, 'experiment_tag': 'exp', 'time_total_s': 1.5266268253326416}\n",
      "[flaml.tune.tune: 09-25 12:34:22] {197} INFO - result: {'pred_time': 1.2943319318705752e-05, 'wall_clock_time': 118.1113383769989, 'metric_for_logging': {'pred_time': 1.2943319318705752e-05}, 'val_loss': 0.2024917894483112, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524161a60>, 'training_iteration': 1, 'config': {'n_estimators': 63, 'num_leaves': 262, 'min_child_samples': 4, 'learning_rate': 0.1267824704459056, 'log_max_bin': 10, 'colsample_bytree': 0.7195975890246057, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.231060318119947}, 'config/n_estimators': 63, 'config/num_leaves': 262, 'config/min_child_samples': 4, 'config/learning_rate': 0.1267824704459056, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7195975890246057, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.231060318119947, 'experiment_tag': 'exp', 'time_total_s': 1.5278587341308594}\n",
      "[flaml.automl.logger: 09-25 12:34:22] {2391} INFO -  at 118.1s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:22] {2218} INFO - iteration 81, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:34:22] {805} INFO - trial 1 config: {'n_estimators': 26, 'max_features': 0.06745889217551715, 'max_leaves': 88, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:34:23] {197} INFO - result: {'pred_time': 5.253371192011445e-05, 'wall_clock_time': 119.27665424346924, 'metric_for_logging': {'pred_time': 5.253371192011445e-05}, 'val_loss': 0.2289348828704151, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680626d0>, 'training_iteration': 0, 'config': {'n_estimators': 26, 'max_features': 0.06745889217551715, 'max_leaves': 88, 'criterion': 'gini'}, 'config/n_estimators': 26, 'config/max_features': 0.06745889217551715, 'config/max_leaves': 88, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.1579711437225342}\n",
      "[flaml.tune.tune: 09-25 12:34:23] {197} INFO - result: {'pred_time': 5.253371192011445e-05, 'wall_clock_time': 119.27665424346924, 'metric_for_logging': {'pred_time': 5.253371192011445e-05}, 'val_loss': 0.2289348828704151, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680626d0>, 'training_iteration': 1, 'config': {'n_estimators': 26, 'max_features': 0.06745889217551715, 'max_leaves': 88, 'criterion': 'gini'}, 'config/n_estimators': 26, 'config/max_features': 0.06745889217551715, 'config/max_leaves': 88, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.1599247455596924}\n",
      "[flaml.automl.logger: 09-25 12:34:23] {2391} INFO -  at 119.3s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:23] {2218} INFO - iteration 82, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:34:23] {805} INFO - trial 1 config: {'early_stopping_rounds': 13, 'learning_rate': 0.04171721859304757, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:34:29] {197} INFO - result: {'pred_time': 8.235401825168478e-05, 'wall_clock_time': 125.97139286994934, 'metric_for_logging': {'pred_time': 8.235401825168478e-05}, 'val_loss': 0.2335158867205344, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680662b0>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 13, 'learning_rate': 0.04171721859304757, 'n_estimators': 8192}, 'config/early_stopping_rounds': 13, 'config/learning_rate': 0.04171721859304757, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.687755346298218}\n",
      "[flaml.tune.tune: 09-25 12:34:29] {197} INFO - result: {'pred_time': 8.235401825168478e-05, 'wall_clock_time': 125.97139286994934, 'metric_for_logging': {'pred_time': 8.235401825168478e-05}, 'val_loss': 0.2335158867205344, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680662b0>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 13, 'learning_rate': 0.04171721859304757, 'n_estimators': 8192}, 'config/early_stopping_rounds': 13, 'config/learning_rate': 0.04171721859304757, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.689083814620972}\n",
      "[flaml.automl.logger: 09-25 12:34:29] {2391} INFO -  at 126.0s,\testimator catboost's best error=0.2335,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:29] {2218} INFO - iteration 83, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:34:29] {805} INFO - trial 1 config: {'n_estimators': 30, 'max_features': 0.13940024717324384, 'max_leaves': 90, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:34:31] {197} INFO - result: {'pred_time': 6.280120759961676e-05, 'wall_clock_time': 127.64096665382385, 'metric_for_logging': {'pred_time': 6.280120759961676e-05}, 'val_loss': 0.22645596813512858, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe524165430>, 'training_iteration': 0, 'config': {'n_estimators': 30, 'max_features': 0.13940024717324384, 'max_leaves': 90, 'criterion': 'entropy'}, 'config/n_estimators': 30, 'config/max_features': 0.13940024717324384, 'config/max_leaves': 90, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.6628565788269043}\n",
      "[flaml.tune.tune: 09-25 12:34:31] {197} INFO - result: {'pred_time': 6.280120759961676e-05, 'wall_clock_time': 127.64096665382385, 'metric_for_logging': {'pred_time': 6.280120759961676e-05}, 'val_loss': 0.22645596813512858, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe524165430>, 'training_iteration': 1, 'config': {'n_estimators': 30, 'max_features': 0.13940024717324384, 'max_leaves': 90, 'criterion': 'entropy'}, 'config/n_estimators': 30, 'config/max_features': 0.13940024717324384, 'config/max_leaves': 90, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.6643664836883545}\n",
      "[flaml.automl.logger: 09-25 12:34:31] {2391} INFO -  at 127.6s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:31] {2218} INFO - iteration 84, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:34:31] {805} INFO - trial 1 config: {'n_estimators': 39, 'max_leaves': 9, 'min_child_weight': 0.3925237576963254, 'learning_rate': 0.7080509576840613, 'subsample': 1.0, 'colsample_bylevel': 0.6511224730099325, 'colsample_bytree': 0.667036389580977, 'reg_alpha': 0.0017607866203119683, 'reg_lambda': 0.14586887939721607}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:34:34] {197} INFO - result: {'pred_time': 4.306400594099797e-05, 'wall_clock_time': 130.69889187812805, 'metric_for_logging': {'pred_time': 4.306400594099797e-05}, 'val_loss': 0.23953685838993186, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680cd190>, 'training_iteration': 0, 'config': {'n_estimators': 39, 'max_leaves': 9, 'min_child_weight': 0.3925237576963254, 'learning_rate': 0.7080509576840613, 'subsample': 1.0, 'colsample_bylevel': 0.6511224730099325, 'colsample_bytree': 0.667036389580977, 'reg_alpha': 0.0017607866203119683, 'reg_lambda': 0.14586887939721607}, 'config/n_estimators': 39, 'config/max_leaves': 9, 'config/min_child_weight': 0.3925237576963254, 'config/learning_rate': 0.7080509576840613, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.6511224730099325, 'config/colsample_bytree': 0.667036389580977, 'config/reg_alpha': 0.0017607866203119683, 'config/reg_lambda': 0.14586887939721607, 'experiment_tag': 'exp', 'time_total_s': 3.0514402389526367}\n",
      "[flaml.tune.tune: 09-25 12:34:34] {197} INFO - result: {'pred_time': 4.306400594099797e-05, 'wall_clock_time': 130.69889187812805, 'metric_for_logging': {'pred_time': 4.306400594099797e-05}, 'val_loss': 0.23953685838993186, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680cd190>, 'training_iteration': 1, 'config': {'n_estimators': 39, 'max_leaves': 9, 'min_child_weight': 0.3925237576963254, 'learning_rate': 0.7080509576840613, 'subsample': 1.0, 'colsample_bylevel': 0.6511224730099325, 'colsample_bytree': 0.667036389580977, 'reg_alpha': 0.0017607866203119683, 'reg_lambda': 0.14586887939721607}, 'config/n_estimators': 39, 'config/max_leaves': 9, 'config/min_child_weight': 0.3925237576963254, 'config/learning_rate': 0.7080509576840613, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.6511224730099325, 'config/colsample_bytree': 0.667036389580977, 'config/reg_alpha': 0.0017607866203119683, 'config/reg_lambda': 0.14586887939721607, 'experiment_tag': 'exp', 'time_total_s': 3.0529112815856934}\n",
      "[flaml.automl.logger: 09-25 12:34:34] {2391} INFO -  at 130.7s,\testimator xgboost's best error=0.2395,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:34] {2218} INFO - iteration 85, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:34:34] {805} INFO - trial 1 config: {'n_estimators': 21, 'max_features': 0.11915444960789649, 'max_leaves': 154, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:34:36] {197} INFO - result: {'pred_time': 4.8980447113869334e-05, 'wall_clock_time': 132.16025948524475, 'metric_for_logging': {'pred_time': 4.8980447113869334e-05}, 'val_loss': 0.22791214406656685, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680cd490>, 'training_iteration': 0, 'config': {'n_estimators': 21, 'max_features': 0.11915444960789649, 'max_leaves': 154, 'criterion': 'gini'}, 'config/n_estimators': 21, 'config/max_features': 0.11915444960789649, 'config/max_leaves': 154, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.453857660293579}\n",
      "[flaml.tune.tune: 09-25 12:34:36] {197} INFO - result: {'pred_time': 4.8980447113869334e-05, 'wall_clock_time': 132.16025948524475, 'metric_for_logging': {'pred_time': 4.8980447113869334e-05}, 'val_loss': 0.22791214406656685, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680cd490>, 'training_iteration': 1, 'config': {'n_estimators': 21, 'max_features': 0.11915444960789649, 'max_leaves': 154, 'criterion': 'gini'}, 'config/n_estimators': 21, 'config/max_features': 0.11915444960789649, 'config/max_leaves': 154, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.4553601741790771}\n",
      "[flaml.automl.logger: 09-25 12:34:36] {2391} INFO -  at 132.2s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:36] {2218} INFO - iteration 86, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:34:36] {805} INFO - trial 1 config: {'n_estimators': 22, 'max_leaves': 5, 'min_child_weight': 0.536080133994739, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.8033661308483006, 'colsample_bytree': 0.7015002807960694, 'reg_alpha': 0.0011278602966694493, 'reg_lambda': 0.3601200978211006}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:34:38] {197} INFO - result: {'pred_time': 4.2721487832823765e-05, 'wall_clock_time': 134.3170130252838, 'metric_for_logging': {'pred_time': 4.2721487832823765e-05}, 'val_loss': 0.2556985713657378, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5243823a0>, 'training_iteration': 0, 'config': {'n_estimators': 22, 'max_leaves': 5, 'min_child_weight': 0.536080133994739, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.8033661308483006, 'colsample_bytree': 0.7015002807960694, 'reg_alpha': 0.0011278602966694493, 'reg_lambda': 0.3601200978211006}, 'config/n_estimators': 22, 'config/max_leaves': 5, 'config/min_child_weight': 0.536080133994739, 'config/learning_rate': 1.0, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8033661308483006, 'config/colsample_bytree': 0.7015002807960694, 'config/reg_alpha': 0.0011278602966694493, 'config/reg_lambda': 0.3601200978211006, 'experiment_tag': 'exp', 'time_total_s': 2.1491942405700684}\n",
      "[flaml.tune.tune: 09-25 12:34:38] {197} INFO - result: {'pred_time': 4.2721487832823765e-05, 'wall_clock_time': 134.3170130252838, 'metric_for_logging': {'pred_time': 4.2721487832823765e-05}, 'val_loss': 0.2556985713657378, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5243823a0>, 'training_iteration': 1, 'config': {'n_estimators': 22, 'max_leaves': 5, 'min_child_weight': 0.536080133994739, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.8033661308483006, 'colsample_bytree': 0.7015002807960694, 'reg_alpha': 0.0011278602966694493, 'reg_lambda': 0.3601200978211006}, 'config/n_estimators': 22, 'config/max_leaves': 5, 'config/min_child_weight': 0.536080133994739, 'config/learning_rate': 1.0, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8033661308483006, 'config/colsample_bytree': 0.7015002807960694, 'config/reg_alpha': 0.0011278602966694493, 'config/reg_lambda': 0.3601200978211006, 'experiment_tag': 'exp', 'time_total_s': 2.150404453277588}\n",
      "[flaml.automl.logger: 09-25 12:34:38] {2391} INFO -  at 134.3s,\testimator xgboost's best error=0.2395,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:38] {2218} INFO - iteration 87, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:34:38] {805} INFO - trial 1 config: {'n_estimators': 53, 'max_features': 0.10027222567993475, 'max_leaves': 94, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:34:40] {197} INFO - result: {'pred_time': 9.185047703416737e-05, 'wall_clock_time': 136.65308237075806, 'metric_for_logging': {'pred_time': 9.185047703416737e-05}, 'val_loss': 0.2292641750850147, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52429dfd0>, 'training_iteration': 0, 'config': {'n_estimators': 53, 'max_features': 0.10027222567993475, 'max_leaves': 94, 'criterion': 'gini'}, 'config/n_estimators': 53, 'config/max_features': 0.10027222567993475, 'config/max_leaves': 94, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.329617738723755}\n",
      "[flaml.tune.tune: 09-25 12:34:40] {197} INFO - result: {'pred_time': 9.185047703416737e-05, 'wall_clock_time': 136.65308237075806, 'metric_for_logging': {'pred_time': 9.185047703416737e-05}, 'val_loss': 0.2292641750850147, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52429dfd0>, 'training_iteration': 1, 'config': {'n_estimators': 53, 'max_features': 0.10027222567993475, 'max_leaves': 94, 'criterion': 'gini'}, 'config/n_estimators': 53, 'config/max_features': 0.10027222567993475, 'config/max_leaves': 94, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.331538200378418}\n",
      "[flaml.automl.logger: 09-25 12:34:40] {2391} INFO -  at 136.7s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:40] {2218} INFO - iteration 88, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:34:40] {805} INFO - trial 1 config: {'n_estimators': 60, 'max_features': 0.0425346962238793, 'max_leaves': 33, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:34:42] {197} INFO - result: {'pred_time': 9.11286956619105e-05, 'wall_clock_time': 138.4781060218811, 'metric_for_logging': {'pred_time': 9.11286956619105e-05}, 'val_loss': 0.2205911250888762, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e15d60>, 'training_iteration': 0, 'config': {'n_estimators': 60, 'max_features': 0.0425346962238793, 'max_leaves': 33, 'criterion': 'gini'}, 'config/n_estimators': 60, 'config/max_features': 0.0425346962238793, 'config/max_leaves': 33, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.8181684017181396}\n",
      "[flaml.tune.tune: 09-25 12:34:42] {197} INFO - result: {'pred_time': 9.11286956619105e-05, 'wall_clock_time': 138.4781060218811, 'metric_for_logging': {'pred_time': 9.11286956619105e-05}, 'val_loss': 0.2205911250888762, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6d5e15d60>, 'training_iteration': 1, 'config': {'n_estimators': 60, 'max_features': 0.0425346962238793, 'max_leaves': 33, 'criterion': 'gini'}, 'config/n_estimators': 60, 'config/max_features': 0.0425346962238793, 'config/max_leaves': 33, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.8194925785064697}\n",
      "[flaml.automl.logger: 09-25 12:34:42] {2391} INFO -  at 138.5s,\testimator rf's best error=0.2054,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:42] {2218} INFO - iteration 89, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:34:42] {805} INFO - trial 1 config: {'n_estimators': 24, 'max_features': 0.033476875149333556, 'max_leaves': 98, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:34:43] {197} INFO - result: {'pred_time': 5.060512433096086e-05, 'wall_clock_time': 139.4457950592041, 'metric_for_logging': {'pred_time': 5.060512433096086e-05}, 'val_loss': 0.21591690294838725, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524231610>, 'training_iteration': 0, 'config': {'n_estimators': 24, 'max_features': 0.033476875149333556, 'max_leaves': 98, 'criterion': 'entropy'}, 'config/n_estimators': 24, 'config/max_features': 0.033476875149333556, 'config/max_leaves': 98, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.9616601467132568}\n",
      "[flaml.tune.tune: 09-25 12:34:43] {197} INFO - result: {'pred_time': 5.060512433096086e-05, 'wall_clock_time': 139.4457950592041, 'metric_for_logging': {'pred_time': 5.060512433096086e-05}, 'val_loss': 0.21591690294838725, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524231610>, 'training_iteration': 1, 'config': {'n_estimators': 24, 'max_features': 0.033476875149333556, 'max_leaves': 98, 'criterion': 'entropy'}, 'config/n_estimators': 24, 'config/max_features': 0.033476875149333556, 'config/max_leaves': 98, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.9630348682403564}\n",
      "[flaml.automl.logger: 09-25 12:34:43] {2391} INFO -  at 139.4s,\testimator rf's best error=0.2054,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:43] {2218} INFO - iteration 90, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:34:43] {805} INFO - trial 1 config: {'n_estimators': 12, 'max_features': 0.16565065365310247, 'max_leaves': 148, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:34:44] {197} INFO - result: {'pred_time': 3.7031893780577474e-05, 'wall_clock_time': 140.60511898994446, 'metric_for_logging': {'pred_time': 3.7031893780577474e-05}, 'val_loss': 0.23475650428424047, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe66804e8b0>, 'training_iteration': 0, 'config': {'n_estimators': 12, 'max_features': 0.16565065365310247, 'max_leaves': 148, 'criterion': 'entropy'}, 'config/n_estimators': 12, 'config/max_features': 0.16565065365310247, 'config/max_leaves': 148, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.152226209640503}\n",
      "[flaml.tune.tune: 09-25 12:34:44] {197} INFO - result: {'pred_time': 3.7031893780577474e-05, 'wall_clock_time': 140.60511898994446, 'metric_for_logging': {'pred_time': 3.7031893780577474e-05}, 'val_loss': 0.23475650428424047, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe66804e8b0>, 'training_iteration': 1, 'config': {'n_estimators': 12, 'max_features': 0.16565065365310247, 'max_leaves': 148, 'criterion': 'entropy'}, 'config/n_estimators': 12, 'config/max_features': 0.16565065365310247, 'config/max_leaves': 148, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.1534526348114014}\n",
      "[flaml.automl.logger: 09-25 12:34:44] {2391} INFO -  at 140.6s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:44] {2218} INFO - iteration 91, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:34:44] {805} INFO - trial 1 config: {'n_estimators': 90, 'max_features': 0.08461549318604882, 'max_leaves': 67, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:34:47] {197} INFO - result: {'pred_time': 0.00013640655935283791, 'wall_clock_time': 143.75781226158142, 'metric_for_logging': {'pred_time': 0.00013640655935283791}, 'val_loss': 0.21088511963699372, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5243b2730>, 'training_iteration': 0, 'config': {'n_estimators': 90, 'max_features': 0.08461549318604882, 'max_leaves': 67, 'criterion': 'gini'}, 'config/n_estimators': 90, 'config/max_features': 0.08461549318604882, 'config/max_leaves': 67, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.1463615894317627}\n",
      "[flaml.tune.tune: 09-25 12:34:47] {197} INFO - result: {'pred_time': 0.00013640655935283791, 'wall_clock_time': 143.75781226158142, 'metric_for_logging': {'pred_time': 0.00013640655935283791}, 'val_loss': 0.21088511963699372, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5243b2730>, 'training_iteration': 1, 'config': {'n_estimators': 90, 'max_features': 0.08461549318604882, 'max_leaves': 67, 'criterion': 'gini'}, 'config/n_estimators': 90, 'config/max_features': 0.08461549318604882, 'config/max_leaves': 67, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.1477341651916504}\n",
      "[flaml.automl.logger: 09-25 12:34:47] {2391} INFO -  at 143.8s,\testimator rf's best error=0.2054,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:47] {2218} INFO - iteration 92, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:34:47] {805} INFO - trial 1 config: {'n_estimators': 35, 'max_features': 0.0728059923666486, 'max_leaves': 93, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:34:49] {197} INFO - result: {'pred_time': 6.548735703616962e-05, 'wall_clock_time': 145.09496140480042, 'metric_for_logging': {'pred_time': 6.548735703616962e-05}, 'val_loss': 0.21948236727097292, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340dc2e0>, 'training_iteration': 0, 'config': {'n_estimators': 35, 'max_features': 0.0728059923666486, 'max_leaves': 93, 'criterion': 'entropy'}, 'config/n_estimators': 35, 'config/max_features': 0.0728059923666486, 'config/max_leaves': 93, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.3287336826324463}\n",
      "[flaml.tune.tune: 09-25 12:34:49] {197} INFO - result: {'pred_time': 6.548735703616962e-05, 'wall_clock_time': 145.09496140480042, 'metric_for_logging': {'pred_time': 6.548735703616962e-05}, 'val_loss': 0.21948236727097292, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340dc2e0>, 'training_iteration': 1, 'config': {'n_estimators': 35, 'max_features': 0.0728059923666486, 'max_leaves': 93, 'criterion': 'entropy'}, 'config/n_estimators': 35, 'config/max_features': 0.0728059923666486, 'config/max_leaves': 93, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.3307805061340332}\n",
      "[flaml.automl.logger: 09-25 12:34:49] {2391} INFO -  at 145.1s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:49] {2218} INFO - iteration 93, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:34:49] {805} INFO - trial 1 config: {'n_estimators': 70, 'max_leaves': 17, 'min_child_weight': 0.2874102034110366, 'learning_rate': 0.2207726291366051, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.4988788151715646, 'colsample_bytree': 0.6325724983658846, 'reg_alpha': 0.0027488949929569983, 'reg_lambda': 0.0590850944041725}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:34:54] {197} INFO - result: {'pred_time': 4.526935401318941e-05, 'wall_clock_time': 150.14738845825195, 'metric_for_logging': {'pred_time': 4.526935401318941e-05}, 'val_loss': 0.2092249007166548, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 0, 'config': {'n_estimators': 70, 'max_leaves': 17, 'min_child_weight': 0.2874102034110366, 'learning_rate': 0.2207726291366051, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.4988788151715646, 'colsample_bytree': 0.6325724983658846, 'reg_alpha': 0.0027488949929569983, 'reg_lambda': 0.0590850944041725}, 'config/n_estimators': 70, 'config/max_leaves': 17, 'config/min_child_weight': 0.2874102034110366, 'config/learning_rate': 0.2207726291366051, 'config/subsample': 0.8895588746662894, 'config/colsample_bylevel': 0.4988788151715646, 'config/colsample_bytree': 0.6325724983658846, 'config/reg_alpha': 0.0027488949929569983, 'config/reg_lambda': 0.0590850944041725, 'experiment_tag': 'exp', 'time_total_s': 5.043767690658569}\n",
      "[flaml.tune.tune: 09-25 12:34:54] {197} INFO - result: {'pred_time': 4.526935401318941e-05, 'wall_clock_time': 150.14738845825195, 'metric_for_logging': {'pred_time': 4.526935401318941e-05}, 'val_loss': 0.2092249007166548, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1bfd0>, 'training_iteration': 1, 'config': {'n_estimators': 70, 'max_leaves': 17, 'min_child_weight': 0.2874102034110366, 'learning_rate': 0.2207726291366051, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.4988788151715646, 'colsample_bytree': 0.6325724983658846, 'reg_alpha': 0.0027488949929569983, 'reg_lambda': 0.0590850944041725}, 'config/n_estimators': 70, 'config/max_leaves': 17, 'config/min_child_weight': 0.2874102034110366, 'config/learning_rate': 0.2207726291366051, 'config/subsample': 0.8895588746662894, 'config/colsample_bylevel': 0.4988788151715646, 'config/colsample_bytree': 0.6325724983658846, 'config/reg_alpha': 0.0027488949929569983, 'config/reg_lambda': 0.0590850944041725, 'experiment_tag': 'exp', 'time_total_s': 5.045118808746338}\n",
      "[flaml.automl.logger: 09-25 12:34:54] {2391} INFO -  at 150.1s,\testimator xgboost's best error=0.2092,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:54] {2218} INFO - iteration 94, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:34:54] {805} INFO - trial 1 config: {'n_estimators': 38, 'max_leaves': 4, 'min_child_weight': 0.41997083011127556, 'learning_rate': 0.38063336262834907, 'subsample': 0.937812919568431, 'colsample_bylevel': 0.6155645729889492, 'colsample_bytree': 0.69018429172989, 'reg_alpha': 0.003959831078561366, 'reg_lambda': 0.019458360917398984}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:34:56] {197} INFO - result: {'pred_time': 4.1555112306807366e-05, 'wall_clock_time': 152.8276824951172, 'metric_for_logging': {'pred_time': 4.1555112306807366e-05}, 'val_loss': 0.24032682203596747, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1b910>, 'training_iteration': 0, 'config': {'n_estimators': 38, 'max_leaves': 4, 'min_child_weight': 0.41997083011127556, 'learning_rate': 0.38063336262834907, 'subsample': 0.937812919568431, 'colsample_bylevel': 0.6155645729889492, 'colsample_bytree': 0.69018429172989, 'reg_alpha': 0.003959831078561366, 'reg_lambda': 0.019458360917398984}, 'config/n_estimators': 38, 'config/max_leaves': 4, 'config/min_child_weight': 0.41997083011127556, 'config/learning_rate': 0.38063336262834907, 'config/subsample': 0.937812919568431, 'config/colsample_bylevel': 0.6155645729889492, 'config/colsample_bytree': 0.69018429172989, 'config/reg_alpha': 0.003959831078561366, 'config/reg_lambda': 0.019458360917398984, 'experiment_tag': 'exp', 'time_total_s': 2.6744701862335205}\n",
      "[flaml.tune.tune: 09-25 12:34:56] {197} INFO - result: {'pred_time': 4.1555112306807366e-05, 'wall_clock_time': 152.8276824951172, 'metric_for_logging': {'pred_time': 4.1555112306807366e-05}, 'val_loss': 0.24032682203596747, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5e1b910>, 'training_iteration': 1, 'config': {'n_estimators': 38, 'max_leaves': 4, 'min_child_weight': 0.41997083011127556, 'learning_rate': 0.38063336262834907, 'subsample': 0.937812919568431, 'colsample_bylevel': 0.6155645729889492, 'colsample_bytree': 0.69018429172989, 'reg_alpha': 0.003959831078561366, 'reg_lambda': 0.019458360917398984}, 'config/n_estimators': 38, 'config/max_leaves': 4, 'config/min_child_weight': 0.41997083011127556, 'config/learning_rate': 0.38063336262834907, 'config/subsample': 0.937812919568431, 'config/colsample_bylevel': 0.6155645729889492, 'config/colsample_bytree': 0.69018429172989, 'config/reg_alpha': 0.003959831078561366, 'config/reg_lambda': 0.019458360917398984, 'experiment_tag': 'exp', 'time_total_s': 2.675588607788086}\n",
      "[flaml.automl.logger: 09-25 12:34:56] {2391} INFO -  at 152.8s,\testimator xgboost's best error=0.2092,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:56] {2218} INFO - iteration 95, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:34:56] {805} INFO - trial 1 config: {'n_estimators': 128, 'num_leaves': 19, 'min_child_samples': 13, 'learning_rate': 0.3304039369370558, 'log_max_bin': 8, 'colsample_bytree': 0.8303843021774752, 'reg_alpha': 0.0022190759769264894, 'reg_lambda': 0.7801218653559179}\n",
      "[flaml.tune.tune: 09-25 12:34:57] {197} INFO - result: {'pred_time': 1.3188537216128887e-05, 'wall_clock_time': 153.9616858959198, 'metric_for_logging': {'pred_time': 1.3188537216128887e-05}, 'val_loss': 0.21766874705405445, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1b370>, 'training_iteration': 0, 'config': {'n_estimators': 128, 'num_leaves': 19, 'min_child_samples': 13, 'learning_rate': 0.3304039369370558, 'log_max_bin': 8, 'colsample_bytree': 0.8303843021774752, 'reg_alpha': 0.0022190759769264894, 'reg_lambda': 0.7801218653559179}, 'config/n_estimators': 128, 'config/num_leaves': 19, 'config/min_child_samples': 13, 'config/learning_rate': 0.3304039369370558, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8303843021774752, 'config/reg_alpha': 0.0022190759769264894, 'config/reg_lambda': 0.7801218653559179, 'experiment_tag': 'exp', 'time_total_s': 1.126464605331421}\n",
      "[flaml.tune.tune: 09-25 12:34:57] {197} INFO - result: {'pred_time': 1.3188537216128887e-05, 'wall_clock_time': 153.9616858959198, 'metric_for_logging': {'pred_time': 1.3188537216128887e-05}, 'val_loss': 0.21766874705405445, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6d5e1b370>, 'training_iteration': 1, 'config': {'n_estimators': 128, 'num_leaves': 19, 'min_child_samples': 13, 'learning_rate': 0.3304039369370558, 'log_max_bin': 8, 'colsample_bytree': 0.8303843021774752, 'reg_alpha': 0.0022190759769264894, 'reg_lambda': 0.7801218653559179}, 'config/n_estimators': 128, 'config/num_leaves': 19, 'config/min_child_samples': 13, 'config/learning_rate': 0.3304039369370558, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8303843021774752, 'config/reg_alpha': 0.0022190759769264894, 'config/reg_lambda': 0.7801218653559179, 'experiment_tag': 'exp', 'time_total_s': 1.127532958984375}\n",
      "[flaml.automl.logger: 09-25 12:34:57] {2391} INFO -  at 154.0s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:34:57] {2218} INFO - iteration 96, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:34:57] {805} INFO - trial 1 config: {'n_estimators': 18, 'max_features': 0.22814275566061065, 'max_leaves': 150, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:35:00] {197} INFO - result: {'pred_time': 4.7478252579824184e-05, 'wall_clock_time': 156.1376597881317, 'metric_for_logging': {'pred_time': 4.7478252579824184e-05}, 'val_loss': 0.2614755901674942, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5243b2ac0>, 'training_iteration': 0, 'config': {'n_estimators': 18, 'max_features': 0.22814275566061065, 'max_leaves': 150, 'criterion': 'gini'}, 'config/n_estimators': 18, 'config/max_features': 0.22814275566061065, 'config/max_leaves': 150, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.170015811920166}\n",
      "[flaml.tune.tune: 09-25 12:35:00] {197} INFO - result: {'pred_time': 4.7478252579824184e-05, 'wall_clock_time': 156.1376597881317, 'metric_for_logging': {'pred_time': 4.7478252579824184e-05}, 'val_loss': 0.2614755901674942, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5243b2ac0>, 'training_iteration': 1, 'config': {'n_estimators': 18, 'max_features': 0.22814275566061065, 'max_leaves': 150, 'criterion': 'gini'}, 'config/n_estimators': 18, 'config/max_features': 0.22814275566061065, 'config/max_leaves': 150, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.1715736389160156}\n",
      "[flaml.automl.logger: 09-25 12:35:00] {2391} INFO -  at 156.1s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:00] {2218} INFO - iteration 97, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:35:00] {805} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.062336392379586096, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:35:04] {197} INFO - result: {'pred_time': 7.763898620055109e-05, 'wall_clock_time': 160.56410312652588, 'metric_for_logging': {'pred_time': 7.763898620055109e-05}, 'val_loss': 0.24165679634195375, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6d5e1b910>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.062336392379586096, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.062336392379586096, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.417818784713745}\n",
      "[flaml.tune.tune: 09-25 12:35:04] {197} INFO - result: {'pred_time': 7.763898620055109e-05, 'wall_clock_time': 160.56410312652588, 'metric_for_logging': {'pred_time': 7.763898620055109e-05}, 'val_loss': 0.24165679634195375, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6d5e1b910>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.062336392379586096, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.062336392379586096, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.419110298156738}\n",
      "[flaml.automl.logger: 09-25 12:35:04] {2391} INFO -  at 160.6s,\testimator catboost's best error=0.2335,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:04] {2218} INFO - iteration 98, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:35:04] {805} INFO - trial 1 config: {'early_stopping_rounds': 15, 'learning_rate': 0.025858503359419964, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:35:12] {197} INFO - result: {'pred_time': 7.97916859239756e-05, 'wall_clock_time': 168.93689370155334, 'metric_for_logging': {'pred_time': 7.97916859239756e-05}, 'val_loss': 0.24776746242263484, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340cd130>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 15, 'learning_rate': 0.025858503359419964, 'n_estimators': 8192}, 'config/early_stopping_rounds': 15, 'config/learning_rate': 0.025858503359419964, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 8.366975784301758}\n",
      "[flaml.tune.tune: 09-25 12:35:12] {197} INFO - result: {'pred_time': 7.97916859239756e-05, 'wall_clock_time': 168.93689370155334, 'metric_for_logging': {'pred_time': 7.97916859239756e-05}, 'val_loss': 0.24776746242263484, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340cd130>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 15, 'learning_rate': 0.025858503359419964, 'n_estimators': 8192}, 'config/early_stopping_rounds': 15, 'config/learning_rate': 0.025858503359419964, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 8.369144201278687}\n",
      "[flaml.automl.logger: 09-25 12:35:12] {2391} INFO -  at 168.9s,\testimator catboost's best error=0.2335,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:12] {2218} INFO - iteration 99, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:35:12] {805} INFO - trial 1 config: {'n_estimators': 45, 'max_features': 0.10168223906236107, 'max_leaves': 109, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:35:14] {197} INFO - result: {'pred_time': 8.218414225461133e-05, 'wall_clock_time': 170.92051029205322, 'metric_for_logging': {'pred_time': 8.218414225461133e-05}, 'val_loss': 0.20117203612331047, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668062a30>, 'training_iteration': 0, 'config': {'n_estimators': 45, 'max_features': 0.10168223906236107, 'max_leaves': 109, 'criterion': 'entropy'}, 'config/n_estimators': 45, 'config/max_features': 0.10168223906236107, 'config/max_leaves': 109, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.9746463298797607}\n",
      "[flaml.tune.tune: 09-25 12:35:14] {197} INFO - result: {'pred_time': 8.218414225461133e-05, 'wall_clock_time': 170.92051029205322, 'metric_for_logging': {'pred_time': 8.218414225461133e-05}, 'val_loss': 0.20117203612331047, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668062a30>, 'training_iteration': 1, 'config': {'n_estimators': 45, 'max_features': 0.10168223906236107, 'max_leaves': 109, 'criterion': 'entropy'}, 'config/n_estimators': 45, 'config/max_features': 0.10168223906236107, 'config/max_leaves': 109, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.9761335849761963}\n",
      "[flaml.automl.logger: 09-25 12:35:14] {2391} INFO -  at 170.9s,\testimator rf's best error=0.2012,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:14] {2218} INFO - iteration 100, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:35:14] {805} INFO - trial 1 config: {'n_estimators': 46, 'max_features': 0.05322276111861015, 'max_leaves': 81, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:35:16] {197} INFO - result: {'pred_time': 7.86924437369341e-05, 'wall_clock_time': 172.51062750816345, 'metric_for_logging': {'pred_time': 7.86924437369341e-05}, 'val_loss': 0.21397405940134578, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5340d31f0>, 'training_iteration': 0, 'config': {'n_estimators': 46, 'max_features': 0.05322276111861015, 'max_leaves': 81, 'criterion': 'gini'}, 'config/n_estimators': 46, 'config/max_features': 0.05322276111861015, 'config/max_leaves': 81, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.5828664302825928}\n",
      "[flaml.tune.tune: 09-25 12:35:16] {197} INFO - result: {'pred_time': 7.86924437369341e-05, 'wall_clock_time': 172.51062750816345, 'metric_for_logging': {'pred_time': 7.86924437369341e-05}, 'val_loss': 0.21397405940134578, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5340d31f0>, 'training_iteration': 1, 'config': {'n_estimators': 46, 'max_features': 0.05322276111861015, 'max_leaves': 81, 'criterion': 'gini'}, 'config/n_estimators': 46, 'config/max_features': 0.05322276111861015, 'config/max_leaves': 81, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.5842804908752441}\n",
      "[flaml.automl.logger: 09-25 12:35:16] {2391} INFO -  at 172.5s,\testimator rf's best error=0.2012,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:16] {2218} INFO - iteration 101, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:35:16] {805} INFO - trial 1 config: {'n_estimators': 38, 'max_features': 0.16432417704068714, 'max_leaves': 48, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:35:18] {197} INFO - result: {'pred_time': 7.313308251177444e-05, 'wall_clock_time': 174.47689867019653, 'metric_for_logging': {'pred_time': 7.313308251177444e-05}, 'val_loss': 0.2375450917992147, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680c44c0>, 'training_iteration': 0, 'config': {'n_estimators': 38, 'max_features': 0.16432417704068714, 'max_leaves': 48, 'criterion': 'entropy'}, 'config/n_estimators': 38, 'config/max_features': 0.16432417704068714, 'config/max_leaves': 48, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.9579176902770996}\n",
      "[flaml.tune.tune: 09-25 12:35:18] {197} INFO - result: {'pred_time': 7.313308251177444e-05, 'wall_clock_time': 174.47689867019653, 'metric_for_logging': {'pred_time': 7.313308251177444e-05}, 'val_loss': 0.2375450917992147, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680c44c0>, 'training_iteration': 1, 'config': {'n_estimators': 38, 'max_features': 0.16432417704068714, 'max_leaves': 48, 'criterion': 'entropy'}, 'config/n_estimators': 38, 'config/max_features': 0.16432417704068714, 'config/max_leaves': 48, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.9593267440795898}\n",
      "[flaml.automl.logger: 09-25 12:35:18] {2391} INFO -  at 174.5s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:18] {2218} INFO - iteration 102, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:35:18] {805} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.0673018969021706, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:35:22] {197} INFO - result: {'pred_time': 8.086027917595885e-05, 'wall_clock_time': 178.77258729934692, 'metric_for_logging': {'pred_time': 8.086027917595885e-05}, 'val_loss': 0.2414051679981215, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680c4b80>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 11, 'learning_rate': 0.0673018969021706, 'n_estimators': 8192}, 'config/early_stopping_rounds': 11, 'config/learning_rate': 0.0673018969021706, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.288284540176392}\n",
      "[flaml.tune.tune: 09-25 12:35:22] {197} INFO - result: {'pred_time': 8.086027917595885e-05, 'wall_clock_time': 178.77258729934692, 'metric_for_logging': {'pred_time': 8.086027917595885e-05}, 'val_loss': 0.2414051679981215, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680c4b80>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 11, 'learning_rate': 0.0673018969021706, 'n_estimators': 8192}, 'config/early_stopping_rounds': 11, 'config/learning_rate': 0.0673018969021706, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.290347576141357}\n",
      "[flaml.automl.logger: 09-25 12:35:22] {2391} INFO -  at 178.8s,\testimator catboost's best error=0.2335,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:22] {2218} INFO - iteration 103, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:35:22] {805} INFO - trial 1 config: {'n_estimators': 164, 'num_leaves': 121, 'min_child_samples': 5, 'learning_rate': 0.37924384644057557, 'log_max_bin': 8, 'colsample_bytree': 0.6676885310413292, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.2562927610768564}\n",
      "[flaml.tune.tune: 09-25 12:35:25] {197} INFO - result: {'pred_time': 1.8593761131477594e-05, 'wall_clock_time': 181.41966938972473, 'metric_for_logging': {'pred_time': 1.8593761131477594e-05}, 'val_loss': 0.20341136604255045, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe52413d5e0>, 'training_iteration': 0, 'config': {'n_estimators': 164, 'num_leaves': 121, 'min_child_samples': 5, 'learning_rate': 0.37924384644057557, 'log_max_bin': 8, 'colsample_bytree': 0.6676885310413292, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.2562927610768564}, 'config/n_estimators': 164, 'config/num_leaves': 121, 'config/min_child_samples': 5, 'config/learning_rate': 0.37924384644057557, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.6676885310413292, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.2562927610768564, 'experiment_tag': 'exp', 'time_total_s': 2.6393775939941406}\n",
      "[flaml.tune.tune: 09-25 12:35:25] {197} INFO - result: {'pred_time': 1.8593761131477594e-05, 'wall_clock_time': 181.41966938972473, 'metric_for_logging': {'pred_time': 1.8593761131477594e-05}, 'val_loss': 0.20341136604255045, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe52413d5e0>, 'training_iteration': 1, 'config': {'n_estimators': 164, 'num_leaves': 121, 'min_child_samples': 5, 'learning_rate': 0.37924384644057557, 'log_max_bin': 8, 'colsample_bytree': 0.6676885310413292, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.2562927610768564}, 'config/n_estimators': 164, 'config/num_leaves': 121, 'config/min_child_samples': 5, 'config/learning_rate': 0.37924384644057557, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.6676885310413292, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.2562927610768564, 'experiment_tag': 'exp', 'time_total_s': 2.641195297241211}\n",
      "[flaml.automl.logger: 09-25 12:35:25] {2391} INFO -  at 181.4s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:25] {2218} INFO - iteration 104, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:35:25] {805} INFO - trial 1 config: {'n_estimators': 130, 'max_leaves': 75, 'min_child_weight': 0.1966913392601255, 'learning_rate': 0.12805118668349444, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.38219305735418013, 'colsample_bytree': 0.574960705001879, 'reg_alpha': 0.001908269199465285, 'reg_lambda': 0.17941122562016018}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:35:40] {197} INFO - result: {'pred_time': 5.7092975275790874e-05, 'wall_clock_time': 196.30080604553223, 'metric_for_logging': {'pred_time': 5.7092975275790874e-05}, 'val_loss': 0.19876160325935438, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680df0a0>, 'training_iteration': 0, 'config': {'n_estimators': 130, 'max_leaves': 75, 'min_child_weight': 0.1966913392601255, 'learning_rate': 0.12805118668349444, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.38219305735418013, 'colsample_bytree': 0.574960705001879, 'reg_alpha': 0.001908269199465285, 'reg_lambda': 0.17941122562016018}, 'config/n_estimators': 130, 'config/max_leaves': 75, 'config/min_child_weight': 0.1966913392601255, 'config/learning_rate': 0.12805118668349444, 'config/subsample': 0.8413048297641477, 'config/colsample_bylevel': 0.38219305735418013, 'config/colsample_bytree': 0.574960705001879, 'config/reg_alpha': 0.001908269199465285, 'config/reg_lambda': 0.17941122562016018, 'experiment_tag': 'exp', 'time_total_s': 14.87317180633545}\n",
      "[flaml.tune.tune: 09-25 12:35:40] {197} INFO - result: {'pred_time': 5.7092975275790874e-05, 'wall_clock_time': 196.30080604553223, 'metric_for_logging': {'pred_time': 5.7092975275790874e-05}, 'val_loss': 0.19876160325935438, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680df0a0>, 'training_iteration': 1, 'config': {'n_estimators': 130, 'max_leaves': 75, 'min_child_weight': 0.1966913392601255, 'learning_rate': 0.12805118668349444, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.38219305735418013, 'colsample_bytree': 0.574960705001879, 'reg_alpha': 0.001908269199465285, 'reg_lambda': 0.17941122562016018}, 'config/n_estimators': 130, 'config/max_leaves': 75, 'config/min_child_weight': 0.1966913392601255, 'config/learning_rate': 0.12805118668349444, 'config/subsample': 0.8413048297641477, 'config/colsample_bylevel': 0.38219305735418013, 'config/colsample_bytree': 0.574960705001879, 'config/reg_alpha': 0.001908269199465285, 'config/reg_lambda': 0.17941122562016018, 'experiment_tag': 'exp', 'time_total_s': 14.874799728393555}\n",
      "[flaml.automl.logger: 09-25 12:35:40] {2391} INFO -  at 196.3s,\testimator xgboost's best error=0.1988,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:40] {2218} INFO - iteration 105, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:35:40] {805} INFO - trial 1 config: {'n_estimators': 55, 'max_features': 0.10998203225562961, 'max_leaves': 83, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:35:42] {197} INFO - result: {'pred_time': 9.305472551694952e-05, 'wall_clock_time': 198.55610370635986, 'metric_for_logging': {'pred_time': 9.305472551694952e-05}, 'val_loss': 0.20936369566429539, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe52413c700>, 'training_iteration': 0, 'config': {'n_estimators': 55, 'max_features': 0.10998203225562961, 'max_leaves': 83, 'criterion': 'entropy'}, 'config/n_estimators': 55, 'config/max_features': 0.10998203225562961, 'config/max_leaves': 83, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.247305393218994}\n",
      "[flaml.tune.tune: 09-25 12:35:42] {197} INFO - result: {'pred_time': 9.305472551694952e-05, 'wall_clock_time': 198.55610370635986, 'metric_for_logging': {'pred_time': 9.305472551694952e-05}, 'val_loss': 0.20936369566429539, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe52413c700>, 'training_iteration': 1, 'config': {'n_estimators': 55, 'max_features': 0.10998203225562961, 'max_leaves': 83, 'criterion': 'entropy'}, 'config/n_estimators': 55, 'config/max_features': 0.10998203225562961, 'config/max_leaves': 83, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.248706817626953}\n",
      "[flaml.automl.logger: 09-25 12:35:42] {2391} INFO -  at 198.6s,\testimator rf's best error=0.2012,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:42] {2218} INFO - iteration 106, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:35:42] {805} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.028185691492478487, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:35:48] {197} INFO - result: {'pred_time': 8.053833802996159e-05, 'wall_clock_time': 204.5597004890442, 'metric_for_logging': {'pred_time': 8.053833802996159e-05}, 'val_loss': 0.24546017445192855, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6681b02b0>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.028185691492478487, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.028185691492478487, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.997039794921875}\n",
      "[flaml.tune.tune: 09-25 12:35:48] {197} INFO - result: {'pred_time': 8.053833802996159e-05, 'wall_clock_time': 204.5597004890442, 'metric_for_logging': {'pred_time': 8.053833802996159e-05}, 'val_loss': 0.24546017445192855, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6681b02b0>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.028185691492478487, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.028185691492478487, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.999135494232178}\n",
      "[flaml.automl.logger: 09-25 12:35:48] {2391} INFO -  at 204.6s,\testimator catboost's best error=0.2335,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:48] {2218} INFO - iteration 107, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:35:48] {805} INFO - trial 1 config: {'n_estimators': 16, 'max_features': 0.10108165472826239, 'max_leaves': 288, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:35:49] {197} INFO - result: {'pred_time': 4.5127364439459246e-05, 'wall_clock_time': 205.86439633369446, 'metric_for_logging': {'pred_time': 4.5127364439459246e-05}, 'val_loss': 0.23374097341488648, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668034e20>, 'training_iteration': 0, 'config': {'n_estimators': 16, 'max_features': 0.10108165472826239, 'max_leaves': 288, 'criterion': 'gini'}, 'config/n_estimators': 16, 'config/max_features': 0.10108165472826239, 'config/max_leaves': 288, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.2967572212219238}\n",
      "[flaml.tune.tune: 09-25 12:35:49] {197} INFO - result: {'pred_time': 4.5127364439459246e-05, 'wall_clock_time': 205.86439633369446, 'metric_for_logging': {'pred_time': 4.5127364439459246e-05}, 'val_loss': 0.23374097341488648, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668034e20>, 'training_iteration': 1, 'config': {'n_estimators': 16, 'max_features': 0.10108165472826239, 'max_leaves': 288, 'criterion': 'gini'}, 'config/n_estimators': 16, 'config/max_features': 0.10108165472826239, 'config/max_leaves': 288, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.2980303764343262}\n",
      "[flaml.automl.logger: 09-25 12:35:49] {2391} INFO -  at 205.9s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:49] {2218} INFO - iteration 108, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:35:49] {805} INFO - trial 1 config: {'n_estimators': 37, 'max_features': 0.09400878969669989, 'max_leaves': 142, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:35:51] {197} INFO - result: {'pred_time': 6.980537233496717e-05, 'wall_clock_time': 207.73771619796753, 'metric_for_logging': {'pred_time': 6.980537233496717e-05}, 'val_loss': 0.21710812559763087, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680e3df0>, 'training_iteration': 0, 'config': {'n_estimators': 37, 'max_features': 0.09400878969669989, 'max_leaves': 142, 'criterion': 'gini'}, 'config/n_estimators': 37, 'config/max_features': 0.09400878969669989, 'config/max_leaves': 142, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.8641951084136963}\n",
      "[flaml.tune.tune: 09-25 12:35:51] {197} INFO - result: {'pred_time': 6.980537233496717e-05, 'wall_clock_time': 207.73771619796753, 'metric_for_logging': {'pred_time': 6.980537233496717e-05}, 'val_loss': 0.21710812559763087, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680e3df0>, 'training_iteration': 1, 'config': {'n_estimators': 37, 'max_features': 0.09400878969669989, 'max_leaves': 142, 'criterion': 'gini'}, 'config/n_estimators': 37, 'config/max_features': 0.09400878969669989, 'config/max_leaves': 142, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.8658638000488281}\n",
      "[flaml.automl.logger: 09-25 12:35:51] {2391} INFO -  at 207.7s,\testimator rf's best error=0.2012,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:51] {2218} INFO - iteration 109, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:35:51] {805} INFO - trial 1 config: {'n_estimators': 23, 'max_features': 0.19621836558561395, 'max_leaves': 101, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:35:53] {197} INFO - result: {'pred_time': 5.448436708980984e-05, 'wall_clock_time': 209.73134922981262, 'metric_for_logging': {'pred_time': 5.448436708980984e-05}, 'val_loss': 0.22422391108672962, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680e3a90>, 'training_iteration': 0, 'config': {'n_estimators': 23, 'max_features': 0.19621836558561395, 'max_leaves': 101, 'criterion': 'entropy'}, 'config/n_estimators': 23, 'config/max_features': 0.19621836558561395, 'config/max_leaves': 101, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.9876642227172852}\n",
      "[flaml.tune.tune: 09-25 12:35:53] {197} INFO - result: {'pred_time': 5.448436708980984e-05, 'wall_clock_time': 209.73134922981262, 'metric_for_logging': {'pred_time': 5.448436708980984e-05}, 'val_loss': 0.22422391108672962, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680e3a90>, 'training_iteration': 1, 'config': {'n_estimators': 23, 'max_features': 0.19621836558561395, 'max_leaves': 101, 'criterion': 'entropy'}, 'config/n_estimators': 23, 'config/max_features': 0.19621836558561395, 'config/max_leaves': 101, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.9893169403076172}\n",
      "[flaml.automl.logger: 09-25 12:35:53] {2391} INFO -  at 209.7s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:53] {2218} INFO - iteration 110, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:35:53] {805} INFO - trial 1 config: {'early_stopping_rounds': 17, 'learning_rate': 0.06174502859383565, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:35:58] {197} INFO - result: {'pred_time': 0.00011113396459263477, 'wall_clock_time': 214.47144103050232, 'metric_for_logging': {'pred_time': 0.00011113396459263477}, 'val_loss': 0.23572294760450685, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe668057790>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 17, 'learning_rate': 0.06174502859383565, 'n_estimators': 8192}, 'config/early_stopping_rounds': 17, 'config/learning_rate': 0.06174502859383565, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.732605695724487}\n",
      "[flaml.tune.tune: 09-25 12:35:58] {197} INFO - result: {'pred_time': 0.00011113396459263477, 'wall_clock_time': 214.47144103050232, 'metric_for_logging': {'pred_time': 0.00011113396459263477}, 'val_loss': 0.23572294760450685, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe668057790>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 17, 'learning_rate': 0.06174502859383565, 'n_estimators': 8192}, 'config/early_stopping_rounds': 17, 'config/learning_rate': 0.06174502859383565, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.7337751388549805}\n",
      "[flaml.automl.logger: 09-25 12:35:58] {2391} INFO -  at 214.5s,\testimator catboost's best error=0.2335,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:58] {2218} INFO - iteration 111, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:35:58] {805} INFO - trial 1 config: {'n_estimators': 49, 'num_leaves': 40, 'min_child_samples': 11, 'learning_rate': 0.1104551273885913, 'log_max_bin': 10, 'colsample_bytree': 0.8822933601607518, 'reg_alpha': 0.004996244283600559, 'reg_lambda': 0.7713976515452791}\n",
      "[flaml.tune.tune: 09-25 12:35:59] {197} INFO - result: {'pred_time': 1.133223454966954e-05, 'wall_clock_time': 215.31498384475708, 'metric_for_logging': {'pred_time': 1.133223454966954e-05}, 'val_loss': 0.21008136351089873, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe53409e640>, 'training_iteration': 0, 'config': {'n_estimators': 49, 'num_leaves': 40, 'min_child_samples': 11, 'learning_rate': 0.1104551273885913, 'log_max_bin': 10, 'colsample_bytree': 0.8822933601607518, 'reg_alpha': 0.004996244283600559, 'reg_lambda': 0.7713976515452791}, 'config/n_estimators': 49, 'config/num_leaves': 40, 'config/min_child_samples': 11, 'config/learning_rate': 0.1104551273885913, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8822933601607518, 'config/reg_alpha': 0.004996244283600559, 'config/reg_lambda': 0.7713976515452791, 'experiment_tag': 'exp', 'time_total_s': 0.8363268375396729}\n",
      "[flaml.tune.tune: 09-25 12:35:59] {197} INFO - result: {'pred_time': 1.133223454966954e-05, 'wall_clock_time': 215.31498384475708, 'metric_for_logging': {'pred_time': 1.133223454966954e-05}, 'val_loss': 0.21008136351089873, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe53409e640>, 'training_iteration': 1, 'config': {'n_estimators': 49, 'num_leaves': 40, 'min_child_samples': 11, 'learning_rate': 0.1104551273885913, 'log_max_bin': 10, 'colsample_bytree': 0.8822933601607518, 'reg_alpha': 0.004996244283600559, 'reg_lambda': 0.7713976515452791}, 'config/n_estimators': 49, 'config/num_leaves': 40, 'config/min_child_samples': 11, 'config/learning_rate': 0.1104551273885913, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8822933601607518, 'config/reg_alpha': 0.004996244283600559, 'config/reg_lambda': 0.7713976515452791, 'experiment_tag': 'exp', 'time_total_s': 0.8376164436340332}\n",
      "[flaml.automl.logger: 09-25 12:35:59] {2391} INFO -  at 215.3s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:35:59] {2218} INFO - iteration 112, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:35:59] {805} INFO - trial 1 config: {'n_estimators': 27, 'max_features': 0.0846514019090902, 'max_leaves': 138, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:36:00] {197} INFO - result: {'pred_time': 5.467256851149293e-05, 'wall_clock_time': 216.76830434799194, 'metric_for_logging': {'pred_time': 5.467256851149293e-05}, 'val_loss': 0.2285483600888399, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52414f520>, 'training_iteration': 0, 'config': {'n_estimators': 27, 'max_features': 0.0846514019090902, 'max_leaves': 138, 'criterion': 'gini'}, 'config/n_estimators': 27, 'config/max_features': 0.0846514019090902, 'config/max_leaves': 138, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.4462554454803467}\n",
      "[flaml.tune.tune: 09-25 12:36:00] {197} INFO - result: {'pred_time': 5.467256851149293e-05, 'wall_clock_time': 216.76830434799194, 'metric_for_logging': {'pred_time': 5.467256851149293e-05}, 'val_loss': 0.2285483600888399, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52414f520>, 'training_iteration': 1, 'config': {'n_estimators': 27, 'max_features': 0.0846514019090902, 'max_leaves': 138, 'criterion': 'gini'}, 'config/n_estimators': 27, 'config/max_features': 0.0846514019090902, 'config/max_leaves': 138, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.4477348327636719}\n",
      "[flaml.automl.logger: 09-25 12:36:00] {2391} INFO -  at 216.8s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:36:00] {2218} INFO - iteration 113, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:36:00] {805} INFO - trial 1 config: {'n_estimators': 122, 'max_leaves': 41, 'min_child_weight': 0.14284111713370123, 'learning_rate': 0.33871891376195123, 'subsample': 0.8552583010104474, 'colsample_bylevel': 0.40969897693864493, 'colsample_bytree': 0.5242912069083713, 'reg_alpha': 0.027316112801918414, 'reg_lambda': 0.023614300073837108}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:36:12] {197} INFO - result: {'pred_time': 4.6694417406065357e-05, 'wall_clock_time': 228.76751565933228, 'metric_for_logging': {'pred_time': 4.6694417406065357e-05}, 'val_loss': 0.19937655046350702, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe52414f7c0>, 'training_iteration': 0, 'config': {'n_estimators': 122, 'max_leaves': 41, 'min_child_weight': 0.14284111713370123, 'learning_rate': 0.33871891376195123, 'subsample': 0.8552583010104474, 'colsample_bylevel': 0.40969897693864493, 'colsample_bytree': 0.5242912069083713, 'reg_alpha': 0.027316112801918414, 'reg_lambda': 0.023614300073837108}, 'config/n_estimators': 122, 'config/max_leaves': 41, 'config/min_child_weight': 0.14284111713370123, 'config/learning_rate': 0.33871891376195123, 'config/subsample': 0.8552583010104474, 'config/colsample_bylevel': 0.40969897693864493, 'config/colsample_bytree': 0.5242912069083713, 'config/reg_alpha': 0.027316112801918414, 'config/reg_lambda': 0.023614300073837108, 'experiment_tag': 'exp', 'time_total_s': 11.991641998291016}\n",
      "[flaml.tune.tune: 09-25 12:36:12] {197} INFO - result: {'pred_time': 4.6694417406065357e-05, 'wall_clock_time': 228.76751565933228, 'metric_for_logging': {'pred_time': 4.6694417406065357e-05}, 'val_loss': 0.19937655046350702, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe52414f7c0>, 'training_iteration': 1, 'config': {'n_estimators': 122, 'max_leaves': 41, 'min_child_weight': 0.14284111713370123, 'learning_rate': 0.33871891376195123, 'subsample': 0.8552583010104474, 'colsample_bylevel': 0.40969897693864493, 'colsample_bytree': 0.5242912069083713, 'reg_alpha': 0.027316112801918414, 'reg_lambda': 0.023614300073837108}, 'config/n_estimators': 122, 'config/max_leaves': 41, 'config/min_child_weight': 0.14284111713370123, 'config/learning_rate': 0.33871891376195123, 'config/subsample': 0.8552583010104474, 'config/colsample_bylevel': 0.40969897693864493, 'config/colsample_bytree': 0.5242912069083713, 'config/reg_alpha': 0.027316112801918414, 'config/reg_lambda': 0.023614300073837108, 'experiment_tag': 'exp', 'time_total_s': 11.99297022819519}\n",
      "[flaml.automl.logger: 09-25 12:36:12] {2391} INFO -  at 228.8s,\testimator xgboost's best error=0.1988,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:36:12] {2218} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:36:12] {805} INFO - trial 1 config: {'n_estimators': 41, 'max_features': 0.21253721092088082, 'max_leaves': 74, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:36:15] {197} INFO - result: {'pred_time': 8.081451346053177e-05, 'wall_clock_time': 231.7155406475067, 'metric_for_logging': {'pred_time': 8.081451346053177e-05}, 'val_loss': 0.24538305171738456, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52414f5b0>, 'training_iteration': 0, 'config': {'n_estimators': 41, 'max_features': 0.21253721092088082, 'max_leaves': 74, 'criterion': 'gini'}, 'config/n_estimators': 41, 'config/max_features': 0.21253721092088082, 'config/max_leaves': 74, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.9423296451568604}\n",
      "[flaml.tune.tune: 09-25 12:36:15] {197} INFO - result: {'pred_time': 8.081451346053177e-05, 'wall_clock_time': 231.7155406475067, 'metric_for_logging': {'pred_time': 8.081451346053177e-05}, 'val_loss': 0.24538305171738456, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52414f5b0>, 'training_iteration': 1, 'config': {'n_estimators': 41, 'max_features': 0.21253721092088082, 'max_leaves': 74, 'criterion': 'gini'}, 'config/n_estimators': 41, 'config/max_features': 0.21253721092088082, 'config/max_leaves': 74, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.944028615951538}\n",
      "[flaml.automl.logger: 09-25 12:36:15] {2391} INFO -  at 231.7s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:36:15] {2218} INFO - iteration 115, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:36:15] {805} INFO - trial 1 config: {'n_estimators': 63, 'num_leaves': 27, 'min_child_samples': 7, 'learning_rate': 0.07277397200667446, 'log_max_bin': 8, 'colsample_bytree': 0.7299825924602295, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.1727447205932465}\n",
      "[flaml.tune.tune: 09-25 12:36:16] {197} INFO - result: {'pred_time': 1.2701301383027068e-05, 'wall_clock_time': 232.65967535972595, 'metric_for_logging': {'pred_time': 1.2701301383027068e-05}, 'val_loss': 0.2067156866819536, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe668034fd0>, 'training_iteration': 0, 'config': {'n_estimators': 63, 'num_leaves': 27, 'min_child_samples': 7, 'learning_rate': 0.07277397200667446, 'log_max_bin': 8, 'colsample_bytree': 0.7299825924602295, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.1727447205932465}, 'config/n_estimators': 63, 'config/num_leaves': 27, 'config/min_child_samples': 7, 'config/learning_rate': 0.07277397200667446, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7299825924602295, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.1727447205932465, 'experiment_tag': 'exp', 'time_total_s': 0.9368026256561279}\n",
      "[flaml.tune.tune: 09-25 12:36:16] {197} INFO - result: {'pred_time': 1.2701301383027068e-05, 'wall_clock_time': 232.65967535972595, 'metric_for_logging': {'pred_time': 1.2701301383027068e-05}, 'val_loss': 0.2067156866819536, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe668034fd0>, 'training_iteration': 1, 'config': {'n_estimators': 63, 'num_leaves': 27, 'min_child_samples': 7, 'learning_rate': 0.07277397200667446, 'log_max_bin': 8, 'colsample_bytree': 0.7299825924602295, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.1727447205932465}, 'config/n_estimators': 63, 'config/num_leaves': 27, 'config/min_child_samples': 7, 'config/learning_rate': 0.07277397200667446, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7299825924602295, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.1727447205932465, 'experiment_tag': 'exp', 'time_total_s': 0.9382071495056152}\n",
      "[flaml.automl.logger: 09-25 12:36:16] {2391} INFO -  at 232.7s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:36:16] {2218} INFO - iteration 116, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:36:16] {805} INFO - trial 1 config: {'n_estimators': 128, 'num_leaves': 180, 'min_child_samples': 7, 'learning_rate': 0.5756100184567533, 'log_max_bin': 10, 'colsample_bytree': 0.8199992987418515, 'reg_alpha': 0.0030765362612518886, 'reg_lambda': 10.075555021977012}\n",
      "[flaml.tune.tune: 09-25 12:36:18] {197} INFO - result: {'pred_time': 1.584401333274009e-05, 'wall_clock_time': 234.49020147323608, 'metric_for_logging': {'pred_time': 1.584401333274009e-05}, 'val_loss': 0.20251916661212016, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe66802e700>, 'training_iteration': 0, 'config': {'n_estimators': 128, 'num_leaves': 180, 'min_child_samples': 7, 'learning_rate': 0.5756100184567533, 'log_max_bin': 10, 'colsample_bytree': 0.8199992987418515, 'reg_alpha': 0.0030765362612518886, 'reg_lambda': 10.075555021977012}, 'config/n_estimators': 128, 'config/num_leaves': 180, 'config/min_child_samples': 7, 'config/learning_rate': 0.5756100184567533, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8199992987418515, 'config/reg_alpha': 0.0030765362612518886, 'config/reg_lambda': 10.075555021977012, 'experiment_tag': 'exp', 'time_total_s': 1.8229329586029053}\n",
      "[flaml.tune.tune: 09-25 12:36:18] {197} INFO - result: {'pred_time': 1.584401333274009e-05, 'wall_clock_time': 234.49020147323608, 'metric_for_logging': {'pred_time': 1.584401333274009e-05}, 'val_loss': 0.20251916661212016, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe66802e700>, 'training_iteration': 1, 'config': {'n_estimators': 128, 'num_leaves': 180, 'min_child_samples': 7, 'learning_rate': 0.5756100184567533, 'log_max_bin': 10, 'colsample_bytree': 0.8199992987418515, 'reg_alpha': 0.0030765362612518886, 'reg_lambda': 10.075555021977012}, 'config/n_estimators': 128, 'config/num_leaves': 180, 'config/min_child_samples': 7, 'config/learning_rate': 0.5756100184567533, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8199992987418515, 'config/reg_alpha': 0.0030765362612518886, 'config/reg_lambda': 10.075555021977012, 'experiment_tag': 'exp', 'time_total_s': 1.824380874633789}\n",
      "[flaml.automl.logger: 09-25 12:36:18] {2391} INFO -  at 234.5s,\testimator lgbm's best error=0.1972,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:36:18] {2218} INFO - iteration 117, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:36:18] {805} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.07815177236571483, 'max_leaves': 188, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:36:19] {197} INFO - result: {'pred_time': 4.123234198240749e-05, 'wall_clock_time': 235.38656282424927, 'metric_for_logging': {'pred_time': 4.123234198240749e-05}, 'val_loss': 0.2299553315857664, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52415f460>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.07815177236571483, 'max_leaves': 188, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.07815177236571483, 'config/max_leaves': 188, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.8886990547180176}\n",
      "[flaml.tune.tune: 09-25 12:36:19] {197} INFO - result: {'pred_time': 4.123234198240749e-05, 'wall_clock_time': 235.38656282424927, 'metric_for_logging': {'pred_time': 4.123234198240749e-05}, 'val_loss': 0.2299553315857664, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52415f460>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.07815177236571483, 'max_leaves': 188, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.07815177236571483, 'config/max_leaves': 188, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.889937162399292}\n",
      "[flaml.automl.logger: 09-25 12:36:19] {2391} INFO -  at 235.4s,\testimator extra_tree's best error=0.2118,\tbest estimator lgbm's best error=0.1972\n",
      "[flaml.automl.logger: 09-25 12:36:19] {2218} INFO - iteration 118, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:36:19] {805} INFO - trial 1 config: {'n_estimators': 139, 'max_leaves': 136, 'min_child_weight': 0.27084276373818733, 'learning_rate': 0.0484091845623208, 'subsample': 0.827351358517848, 'colsample_bylevel': 0.35468713776971533, 'colsample_bytree': 0.6256302030953867, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3630887969527579}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:36:35] {197} INFO - result: {'pred_time': 5.3988644855449657e-05, 'wall_clock_time': 251.22577333450317, 'metric_for_logging': {'pred_time': 5.3988644855449657e-05}, 'val_loss': 0.18431557783131994, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680665e0>, 'training_iteration': 0, 'config': {'n_estimators': 139, 'max_leaves': 136, 'min_child_weight': 0.27084276373818733, 'learning_rate': 0.0484091845623208, 'subsample': 0.827351358517848, 'colsample_bylevel': 0.35468713776971533, 'colsample_bytree': 0.6256302030953867, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3630887969527579}, 'config/n_estimators': 139, 'config/max_leaves': 136, 'config/min_child_weight': 0.27084276373818733, 'config/learning_rate': 0.0484091845623208, 'config/subsample': 0.827351358517848, 'config/colsample_bylevel': 0.35468713776971533, 'config/colsample_bytree': 0.6256302030953867, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.3630887969527579, 'experiment_tag': 'exp', 'time_total_s': 15.832673072814941}\n",
      "[flaml.tune.tune: 09-25 12:36:35] {197} INFO - result: {'pred_time': 5.3988644855449657e-05, 'wall_clock_time': 251.22577333450317, 'metric_for_logging': {'pred_time': 5.3988644855449657e-05}, 'val_loss': 0.18431557783131994, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680665e0>, 'training_iteration': 1, 'config': {'n_estimators': 139, 'max_leaves': 136, 'min_child_weight': 0.27084276373818733, 'learning_rate': 0.0484091845623208, 'subsample': 0.827351358517848, 'colsample_bylevel': 0.35468713776971533, 'colsample_bytree': 0.6256302030953867, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3630887969527579}, 'config/n_estimators': 139, 'config/max_leaves': 136, 'config/min_child_weight': 0.27084276373818733, 'config/learning_rate': 0.0484091845623208, 'config/subsample': 0.827351358517848, 'config/colsample_bylevel': 0.35468713776971533, 'config/colsample_bytree': 0.6256302030953867, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.3630887969527579, 'experiment_tag': 'exp', 'time_total_s': 15.834036111831665}\n",
      "[flaml.automl.logger: 09-25 12:36:35] {2391} INFO -  at 251.2s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:36:35] {2218} INFO - iteration 119, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:36:35] {805} INFO - trial 1 config: {'n_estimators': 44, 'num_leaves': 131, 'min_child_samples': 3, 'learning_rate': 0.24321040089125873, 'log_max_bin': 8, 'colsample_bytree': 0.7164365225991386, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.2734086212284228}\n",
      "[flaml.tune.tune: 09-25 12:36:36] {197} INFO - result: {'pred_time': 1.2158303879643533e-05, 'wall_clock_time': 252.5845513343811, 'metric_for_logging': {'pred_time': 1.2158303879643533e-05}, 'val_loss': 0.20709711845394, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680668b0>, 'training_iteration': 0, 'config': {'n_estimators': 44, 'num_leaves': 131, 'min_child_samples': 3, 'learning_rate': 0.24321040089125873, 'log_max_bin': 8, 'colsample_bytree': 0.7164365225991386, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.2734086212284228}, 'config/n_estimators': 44, 'config/num_leaves': 131, 'config/min_child_samples': 3, 'config/learning_rate': 0.24321040089125873, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7164365225991386, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.2734086212284228, 'experiment_tag': 'exp', 'time_total_s': 1.3509185314178467}\n",
      "[flaml.tune.tune: 09-25 12:36:36] {197} INFO - result: {'pred_time': 1.2158303879643533e-05, 'wall_clock_time': 252.5845513343811, 'metric_for_logging': {'pred_time': 1.2158303879643533e-05}, 'val_loss': 0.20709711845394, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680668b0>, 'training_iteration': 1, 'config': {'n_estimators': 44, 'num_leaves': 131, 'min_child_samples': 3, 'learning_rate': 0.24321040089125873, 'log_max_bin': 8, 'colsample_bytree': 0.7164365225991386, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.2734086212284228}, 'config/n_estimators': 44, 'config/num_leaves': 131, 'config/min_child_samples': 3, 'config/learning_rate': 0.24321040089125873, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7164365225991386, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.2734086212284228, 'experiment_tag': 'exp', 'time_total_s': 1.3519260883331299}\n",
      "[flaml.automl.logger: 09-25 12:36:36] {2391} INFO -  at 252.6s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:36:36] {2218} INFO - iteration 120, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:36:36] {805} INFO - trial 1 config: {'n_estimators': 62, 'max_leaves': 309, 'min_child_weight': 0.08786481946462457, 'learning_rate': 0.02398777014900063, 'subsample': 0.8857073593591062, 'colsample_bylevel': 0.4491830868977382, 'colsample_bytree': 0.7118212477763237, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.163353258094623}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:36:43] {197} INFO - result: {'pred_time': 4.996027957500785e-05, 'wall_clock_time': 259.17628931999207, 'metric_for_logging': {'pred_time': 4.996027957500785e-05}, 'val_loss': 0.2386212818746552, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5d89430>, 'training_iteration': 0, 'config': {'n_estimators': 62, 'max_leaves': 309, 'min_child_weight': 0.08786481946462457, 'learning_rate': 0.02398777014900063, 'subsample': 0.8857073593591062, 'colsample_bylevel': 0.4491830868977382, 'colsample_bytree': 0.7118212477763237, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.163353258094623}, 'config/n_estimators': 62, 'config/max_leaves': 309, 'config/min_child_weight': 0.08786481946462457, 'config/learning_rate': 0.02398777014900063, 'config/subsample': 0.8857073593591062, 'config/colsample_bylevel': 0.4491830868977382, 'config/colsample_bytree': 0.7118212477763237, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.163353258094623, 'experiment_tag': 'exp', 'time_total_s': 6.5857133865356445}\n",
      "[flaml.tune.tune: 09-25 12:36:43] {197} INFO - result: {'pred_time': 4.996027957500785e-05, 'wall_clock_time': 259.17628931999207, 'metric_for_logging': {'pred_time': 4.996027957500785e-05}, 'val_loss': 0.2386212818746552, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5d89430>, 'training_iteration': 1, 'config': {'n_estimators': 62, 'max_leaves': 309, 'min_child_weight': 0.08786481946462457, 'learning_rate': 0.02398777014900063, 'subsample': 0.8857073593591062, 'colsample_bylevel': 0.4491830868977382, 'colsample_bytree': 0.7118212477763237, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.163353258094623}, 'config/n_estimators': 62, 'config/max_leaves': 309, 'config/min_child_weight': 0.08786481946462457, 'config/learning_rate': 0.02398777014900063, 'config/subsample': 0.8857073593591062, 'config/colsample_bylevel': 0.4491830868977382, 'config/colsample_bytree': 0.7118212477763237, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.163353258094623, 'experiment_tag': 'exp', 'time_total_s': 6.58692479133606}\n",
      "[flaml.automl.logger: 09-25 12:36:43] {2391} INFO -  at 259.2s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:36:43] {2218} INFO - iteration 121, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:36:43] {805} INFO - trial 1 config: {'n_estimators': 311, 'max_leaves': 60, 'min_child_weight': 0.8348711477051795, 'learning_rate': 0.09769349695417481, 'subsample': 0.7689953576765899, 'colsample_bylevel': 0.26019118864169244, 'colsample_bytree': 0.5394391584144498, 'reg_alpha': 0.0044372497585360125, 'reg_lambda': 0.35984581637239343}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:37:15] {197} INFO - result: {'pred_time': 5.505372585292035e-05, 'wall_clock_time': 291.0205726623535, 'metric_for_logging': {'pred_time': 5.505372585292035e-05}, 'val_loss': 0.2060513662087875, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe668066d60>, 'training_iteration': 0, 'config': {'n_estimators': 311, 'max_leaves': 60, 'min_child_weight': 0.8348711477051795, 'learning_rate': 0.09769349695417481, 'subsample': 0.7689953576765899, 'colsample_bylevel': 0.26019118864169244, 'colsample_bytree': 0.5394391584144498, 'reg_alpha': 0.0044372497585360125, 'reg_lambda': 0.35984581637239343}, 'config/n_estimators': 311, 'config/max_leaves': 60, 'config/min_child_weight': 0.8348711477051795, 'config/learning_rate': 0.09769349695417481, 'config/subsample': 0.7689953576765899, 'config/colsample_bylevel': 0.26019118864169244, 'config/colsample_bytree': 0.5394391584144498, 'config/reg_alpha': 0.0044372497585360125, 'config/reg_lambda': 0.35984581637239343, 'experiment_tag': 'exp', 'time_total_s': 31.838290452957153}\n",
      "[flaml.tune.tune: 09-25 12:37:15] {197} INFO - result: {'pred_time': 5.505372585292035e-05, 'wall_clock_time': 291.0205726623535, 'metric_for_logging': {'pred_time': 5.505372585292035e-05}, 'val_loss': 0.2060513662087875, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe668066d60>, 'training_iteration': 1, 'config': {'n_estimators': 311, 'max_leaves': 60, 'min_child_weight': 0.8348711477051795, 'learning_rate': 0.09769349695417481, 'subsample': 0.7689953576765899, 'colsample_bylevel': 0.26019118864169244, 'colsample_bytree': 0.5394391584144498, 'reg_alpha': 0.0044372497585360125, 'reg_lambda': 0.35984581637239343}, 'config/n_estimators': 311, 'config/max_leaves': 60, 'config/min_child_weight': 0.8348711477051795, 'config/learning_rate': 0.09769349695417481, 'config/subsample': 0.7689953576765899, 'config/colsample_bylevel': 0.26019118864169244, 'config/colsample_bytree': 0.5394391584144498, 'config/reg_alpha': 0.0044372497585360125, 'config/reg_lambda': 0.35984581637239343, 'experiment_tag': 'exp', 'time_total_s': 31.83980703353882}\n",
      "[flaml.automl.logger: 09-25 12:37:15] {2391} INFO -  at 291.0s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:15] {2218} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:37:15] {805} INFO - trial 1 config: {'n_estimators': 17, 'max_features': 0.2319343679951419, 'max_leaves': 74, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:37:16] {197} INFO - result: {'pred_time': 4.654627148057936e-05, 'wall_clock_time': 292.66770696640015, 'metric_for_logging': {'pred_time': 4.654627148057936e-05}, 'val_loss': 0.2726623261480833, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6681b3280>, 'training_iteration': 0, 'config': {'n_estimators': 17, 'max_features': 0.2319343679951419, 'max_leaves': 74, 'criterion': 'gini'}, 'config/n_estimators': 17, 'config/max_features': 0.2319343679951419, 'config/max_leaves': 74, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.6399080753326416}\n",
      "[flaml.tune.tune: 09-25 12:37:16] {197} INFO - result: {'pred_time': 4.654627148057936e-05, 'wall_clock_time': 292.66770696640015, 'metric_for_logging': {'pred_time': 4.654627148057936e-05}, 'val_loss': 0.2726623261480833, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6681b3280>, 'training_iteration': 1, 'config': {'n_estimators': 17, 'max_features': 0.2319343679951419, 'max_leaves': 74, 'criterion': 'gini'}, 'config/n_estimators': 17, 'config/max_features': 0.2319343679951419, 'config/max_leaves': 74, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.6413276195526123}\n",
      "[flaml.automl.logger: 09-25 12:37:16] {2391} INFO -  at 292.7s,\testimator extra_tree's best error=0.2118,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:16] {2218} INFO - iteration 123, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:37:16] {805} INFO - trial 1 config: {'early_stopping_rounds': 16, 'learning_rate': 0.041576838730268885, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:37:20] {197} INFO - result: {'pred_time': 8.034200037025107e-05, 'wall_clock_time': 296.98345828056335, 'metric_for_logging': {'pred_time': 8.034200037025107e-05}, 'val_loss': 0.24860413261837544, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe668066a60>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 16, 'learning_rate': 0.041576838730268885, 'n_estimators': 8192}, 'config/early_stopping_rounds': 16, 'config/learning_rate': 0.041576838730268885, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.309484243392944}\n",
      "[flaml.tune.tune: 09-25 12:37:20] {197} INFO - result: {'pred_time': 8.034200037025107e-05, 'wall_clock_time': 296.98345828056335, 'metric_for_logging': {'pred_time': 8.034200037025107e-05}, 'val_loss': 0.24860413261837544, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe668066a60>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 16, 'learning_rate': 0.041576838730268885, 'n_estimators': 8192}, 'config/early_stopping_rounds': 16, 'config/learning_rate': 0.041576838730268885, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.310937404632568}\n",
      "[flaml.automl.logger: 09-25 12:37:20] {2391} INFO -  at 297.0s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:20] {2218} INFO - iteration 124, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:37:20] {805} INFO - trial 1 config: {'n_estimators': 183, 'num_leaves': 37, 'min_child_samples': 14, 'learning_rate': 0.1722353452665958, 'log_max_bin': 10, 'colsample_bytree': 0.8335453686029424, 'reg_alpha': 0.007704104902643929, 'reg_lambda': 1.366803167560063}\n",
      "[flaml.tune.tune: 09-25 12:37:22] {197} INFO - result: {'pred_time': 1.625361323911292e-05, 'wall_clock_time': 298.8307068347931, 'metric_for_logging': {'pred_time': 1.625361323911292e-05}, 'val_loss': 0.21238979436130861, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680a14c0>, 'training_iteration': 0, 'config': {'n_estimators': 183, 'num_leaves': 37, 'min_child_samples': 14, 'learning_rate': 0.1722353452665958, 'log_max_bin': 10, 'colsample_bytree': 0.8335453686029424, 'reg_alpha': 0.007704104902643929, 'reg_lambda': 1.366803167560063}, 'config/n_estimators': 183, 'config/num_leaves': 37, 'config/min_child_samples': 14, 'config/learning_rate': 0.1722353452665958, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8335453686029424, 'config/reg_alpha': 0.007704104902643929, 'config/reg_lambda': 1.366803167560063, 'experiment_tag': 'exp', 'time_total_s': 1.8409008979797363}\n",
      "[flaml.tune.tune: 09-25 12:37:22] {197} INFO - result: {'pred_time': 1.625361323911292e-05, 'wall_clock_time': 298.8307068347931, 'metric_for_logging': {'pred_time': 1.625361323911292e-05}, 'val_loss': 0.21238979436130861, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680a14c0>, 'training_iteration': 1, 'config': {'n_estimators': 183, 'num_leaves': 37, 'min_child_samples': 14, 'learning_rate': 0.1722353452665958, 'log_max_bin': 10, 'colsample_bytree': 0.8335453686029424, 'reg_alpha': 0.007704104902643929, 'reg_lambda': 1.366803167560063}, 'config/n_estimators': 183, 'config/num_leaves': 37, 'config/min_child_samples': 14, 'config/learning_rate': 0.1722353452665958, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8335453686029424, 'config/reg_alpha': 0.007704104902643929, 'config/reg_lambda': 1.366803167560063, 'experiment_tag': 'exp', 'time_total_s': 1.8420989513397217}\n",
      "[flaml.automl.logger: 09-25 12:37:22] {2391} INFO -  at 298.8s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:22] {2218} INFO - iteration 125, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:37:22] {805} INFO - trial 1 config: {'n_estimators': 58, 'num_leaves': 164, 'min_child_samples': 5, 'learning_rate': 0.08389408909662875, 'log_max_bin': 8, 'colsample_bytree': 0.8868216197727644, 'reg_alpha': 0.0024737385712432494, 'reg_lambda': 0.7449904363544727}\n",
      "[flaml.tune.tune: 09-25 12:37:24] {197} INFO - result: {'pred_time': 1.3532688187821125e-05, 'wall_clock_time': 300.37110447883606, 'metric_for_logging': {'pred_time': 1.3532688187821125e-05}, 'val_loss': 0.19760312151616505, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680d4370>, 'training_iteration': 0, 'config': {'n_estimators': 58, 'num_leaves': 164, 'min_child_samples': 5, 'learning_rate': 0.08389408909662875, 'log_max_bin': 8, 'colsample_bytree': 0.8868216197727644, 'reg_alpha': 0.0024737385712432494, 'reg_lambda': 0.7449904363544727}, 'config/n_estimators': 58, 'config/num_leaves': 164, 'config/min_child_samples': 5, 'config/learning_rate': 0.08389408909662875, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8868216197727644, 'config/reg_alpha': 0.0024737385712432494, 'config/reg_lambda': 0.7449904363544727, 'experiment_tag': 'exp', 'time_total_s': 1.531611680984497}\n",
      "[flaml.tune.tune: 09-25 12:37:24] {197} INFO - result: {'pred_time': 1.3532688187821125e-05, 'wall_clock_time': 300.37110447883606, 'metric_for_logging': {'pred_time': 1.3532688187821125e-05}, 'val_loss': 0.19760312151616505, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680d4370>, 'training_iteration': 1, 'config': {'n_estimators': 58, 'num_leaves': 164, 'min_child_samples': 5, 'learning_rate': 0.08389408909662875, 'log_max_bin': 8, 'colsample_bytree': 0.8868216197727644, 'reg_alpha': 0.0024737385712432494, 'reg_lambda': 0.7449904363544727}, 'config/n_estimators': 58, 'config/num_leaves': 164, 'config/min_child_samples': 5, 'config/learning_rate': 0.08389408909662875, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8868216197727644, 'config/reg_alpha': 0.0024737385712432494, 'config/reg_lambda': 0.7449904363544727, 'experiment_tag': 'exp', 'time_total_s': 1.5329694747924805}\n",
      "[flaml.automl.logger: 09-25 12:37:24] {2391} INFO -  at 300.4s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:24] {2218} INFO - iteration 126, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:37:24] {805} INFO - trial 1 config: {'n_estimators': 140, 'num_leaves': 30, 'min_child_samples': 9, 'learning_rate': 0.49931321528129496, 'log_max_bin': 10, 'colsample_bytree': 0.6631602714293166, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.3362701749706174}\n",
      "[flaml.tune.tune: 09-25 12:37:25] {197} INFO - result: {'pred_time': 1.5518380555550112e-05, 'wall_clock_time': 301.7757616043091, 'metric_for_logging': {'pred_time': 1.5518380555550112e-05}, 'val_loss': 0.21155556144311766, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680afe20>, 'training_iteration': 0, 'config': {'n_estimators': 140, 'num_leaves': 30, 'min_child_samples': 9, 'learning_rate': 0.49931321528129496, 'log_max_bin': 10, 'colsample_bytree': 0.6631602714293166, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.3362701749706174}, 'config/n_estimators': 140, 'config/num_leaves': 30, 'config/min_child_samples': 9, 'config/learning_rate': 0.49931321528129496, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.6631602714293166, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.3362701749706174, 'experiment_tag': 'exp', 'time_total_s': 1.398073434829712}\n",
      "[flaml.tune.tune: 09-25 12:37:25] {197} INFO - result: {'pred_time': 1.5518380555550112e-05, 'wall_clock_time': 301.7757616043091, 'metric_for_logging': {'pred_time': 1.5518380555550112e-05}, 'val_loss': 0.21155556144311766, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680afe20>, 'training_iteration': 1, 'config': {'n_estimators': 140, 'num_leaves': 30, 'min_child_samples': 9, 'learning_rate': 0.49931321528129496, 'log_max_bin': 10, 'colsample_bytree': 0.6631602714293166, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.3362701749706174}, 'config/n_estimators': 140, 'config/num_leaves': 30, 'config/min_child_samples': 9, 'config/learning_rate': 0.49931321528129496, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.6631602714293166, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.3362701749706174, 'experiment_tag': 'exp', 'time_total_s': 1.399165391921997}\n",
      "[flaml.automl.logger: 09-25 12:37:25] {2391} INFO -  at 301.8s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:25] {2218} INFO - iteration 127, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:37:25] {805} INFO - trial 1 config: {'n_estimators': 331, 'num_leaves': 86, 'min_child_samples': 6, 'learning_rate': 0.3096720505974023, 'log_max_bin': 8, 'colsample_bytree': 0.7864517246350571, 'reg_alpha': 0.0009765625, 'reg_lambda': 3.312526650778918}\n",
      "[flaml.tune.tune: 09-25 12:37:29] {197} INFO - result: {'pred_time': 2.28207798966171e-05, 'wall_clock_time': 305.88944149017334, 'metric_for_logging': {'pred_time': 2.28207798966171e-05}, 'val_loss': 0.2049279847255859, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe668057b50>, 'training_iteration': 0, 'config': {'n_estimators': 331, 'num_leaves': 86, 'min_child_samples': 6, 'learning_rate': 0.3096720505974023, 'log_max_bin': 8, 'colsample_bytree': 0.7864517246350571, 'reg_alpha': 0.0009765625, 'reg_lambda': 3.312526650778918}, 'config/n_estimators': 331, 'config/num_leaves': 86, 'config/min_child_samples': 6, 'config/learning_rate': 0.3096720505974023, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7864517246350571, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 3.312526650778918, 'experiment_tag': 'exp', 'time_total_s': 4.106334686279297}\n",
      "[flaml.tune.tune: 09-25 12:37:29] {197} INFO - result: {'pred_time': 2.28207798966171e-05, 'wall_clock_time': 305.88944149017334, 'metric_for_logging': {'pred_time': 2.28207798966171e-05}, 'val_loss': 0.2049279847255859, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe668057b50>, 'training_iteration': 1, 'config': {'n_estimators': 331, 'num_leaves': 86, 'min_child_samples': 6, 'learning_rate': 0.3096720505974023, 'log_max_bin': 8, 'colsample_bytree': 0.7864517246350571, 'reg_alpha': 0.0009765625, 'reg_lambda': 3.312526650778918}, 'config/n_estimators': 331, 'config/num_leaves': 86, 'config/min_child_samples': 6, 'config/learning_rate': 0.3096720505974023, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7864517246350571, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 3.312526650778918, 'experiment_tag': 'exp', 'time_total_s': 4.10741925239563}\n",
      "[flaml.automl.logger: 09-25 12:37:29] {2391} INFO -  at 305.9s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:29] {2218} INFO - iteration 128, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:37:29] {805} INFO - trial 1 config: {'n_estimators': 96, 'max_features': 0.0791113601496617, 'max_leaves': 87, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:37:33] {197} INFO - result: {'pred_time': 0.00014727142565315636, 'wall_clock_time': 309.1642174720764, 'metric_for_logging': {'pred_time': 0.00014727142565315636}, 'val_loss': 0.20387214137214132, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5241662e0>, 'training_iteration': 0, 'config': {'n_estimators': 96, 'max_features': 0.0791113601496617, 'max_leaves': 87, 'criterion': 'gini'}, 'config/n_estimators': 96, 'config/max_features': 0.0791113601496617, 'config/max_leaves': 87, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.2688417434692383}\n",
      "[flaml.tune.tune: 09-25 12:37:33] {197} INFO - result: {'pred_time': 0.00014727142565315636, 'wall_clock_time': 309.1642174720764, 'metric_for_logging': {'pred_time': 0.00014727142565315636}, 'val_loss': 0.20387214137214132, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5241662e0>, 'training_iteration': 1, 'config': {'n_estimators': 96, 'max_features': 0.0791113601496617, 'max_leaves': 87, 'criterion': 'gini'}, 'config/n_estimators': 96, 'config/max_features': 0.0791113601496617, 'config/max_leaves': 87, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.270286798477173}\n",
      "[flaml.automl.logger: 09-25 12:37:33] {2391} INFO -  at 309.2s,\testimator rf's best error=0.2012,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:33] {2218} INFO - iteration 129, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:37:33] {805} INFO - trial 1 config: {'n_estimators': 38, 'max_features': 0.07161577592278397, 'max_leaves': 188, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:37:34] {197} INFO - result: {'pred_time': 7.122581202142919e-05, 'wall_clock_time': 310.773597240448, 'metric_for_logging': {'pred_time': 7.122581202142919e-05}, 'val_loss': 0.20063667490579035, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668057250>, 'training_iteration': 0, 'config': {'n_estimators': 38, 'max_features': 0.07161577592278397, 'max_leaves': 188, 'criterion': 'entropy'}, 'config/n_estimators': 38, 'config/max_features': 0.07161577592278397, 'config/max_leaves': 188, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.6019906997680664}\n",
      "[flaml.tune.tune: 09-25 12:37:34] {197} INFO - result: {'pred_time': 7.122581202142919e-05, 'wall_clock_time': 310.773597240448, 'metric_for_logging': {'pred_time': 7.122581202142919e-05}, 'val_loss': 0.20063667490579035, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668057250>, 'training_iteration': 1, 'config': {'n_estimators': 38, 'max_features': 0.07161577592278397, 'max_leaves': 188, 'criterion': 'entropy'}, 'config/n_estimators': 38, 'config/max_features': 0.07161577592278397, 'config/max_leaves': 188, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.603628158569336}\n",
      "[flaml.automl.logger: 09-25 12:37:34] {2391} INFO -  at 310.8s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:34] {2218} INFO - iteration 130, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:37:34] {805} INFO - trial 1 config: {'n_estimators': 21, 'max_features': 0.13069270609398517, 'max_leaves': 137, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:37:36] {197} INFO - result: {'pred_time': 5.8504379624017064e-05, 'wall_clock_time': 312.11150074005127, 'metric_for_logging': {'pred_time': 5.8504379624017064e-05}, 'val_loss': 0.21435814923446106, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5241457f0>, 'training_iteration': 0, 'config': {'n_estimators': 21, 'max_features': 0.13069270609398517, 'max_leaves': 137, 'criterion': 'entropy'}, 'config/n_estimators': 21, 'config/max_features': 0.13069270609398517, 'config/max_leaves': 137, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.330989122390747}\n",
      "[flaml.tune.tune: 09-25 12:37:36] {197} INFO - result: {'pred_time': 5.8504379624017064e-05, 'wall_clock_time': 312.11150074005127, 'metric_for_logging': {'pred_time': 5.8504379624017064e-05}, 'val_loss': 0.21435814923446106, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5241457f0>, 'training_iteration': 1, 'config': {'n_estimators': 21, 'max_features': 0.13069270609398517, 'max_leaves': 137, 'criterion': 'entropy'}, 'config/n_estimators': 21, 'config/max_features': 0.13069270609398517, 'config/max_leaves': 137, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.3322231769561768}\n",
      "[flaml.automl.logger: 09-25 12:37:36] {2391} INFO -  at 312.1s,\testimator rf's best error=0.2012,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:36] {2218} INFO - iteration 131, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:37:36] {805} INFO - trial 1 config: {'n_estimators': 64, 'max_features': 0.05744144047980412, 'max_leaves': 86, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:37:38] {197} INFO - result: {'pred_time': 0.00010791671184141199, 'wall_clock_time': 314.2887237071991, 'metric_for_logging': {'pred_time': 0.00010791671184141199}, 'val_loss': 0.1974268712836929, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680a13d0>, 'training_iteration': 0, 'config': {'n_estimators': 64, 'max_features': 0.05744144047980412, 'max_leaves': 86, 'criterion': 'entropy'}, 'config/n_estimators': 64, 'config/max_features': 0.05744144047980412, 'config/max_leaves': 86, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.1704673767089844}\n",
      "[flaml.tune.tune: 09-25 12:37:38] {197} INFO - result: {'pred_time': 0.00010791671184141199, 'wall_clock_time': 314.2887237071991, 'metric_for_logging': {'pred_time': 0.00010791671184141199}, 'val_loss': 0.1974268712836929, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680a13d0>, 'training_iteration': 1, 'config': {'n_estimators': 64, 'max_features': 0.05744144047980412, 'max_leaves': 86, 'criterion': 'entropy'}, 'config/n_estimators': 64, 'config/max_features': 0.05744144047980412, 'config/max_leaves': 86, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.172459602355957}\n",
      "[flaml.automl.logger: 09-25 12:37:38] {2391} INFO -  at 314.3s,\testimator rf's best error=0.1974,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:38] {2218} INFO - iteration 132, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:37:38] {805} INFO - trial 1 config: {'n_estimators': 113, 'max_features': 0.09334685589808495, 'max_leaves': 148, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:37:42] {197} INFO - result: {'pred_time': 0.000175089358232311, 'wall_clock_time': 318.79645013809204, 'metric_for_logging': {'pred_time': 0.000175089358232311}, 'val_loss': 0.20206119653271076, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a1340>, 'training_iteration': 0, 'config': {'n_estimators': 113, 'max_features': 0.09334685589808495, 'max_leaves': 148, 'criterion': 'entropy'}, 'config/n_estimators': 113, 'config/max_features': 0.09334685589808495, 'config/max_leaves': 148, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 4.496312379837036}\n",
      "[flaml.tune.tune: 09-25 12:37:42] {197} INFO - result: {'pred_time': 0.000175089358232311, 'wall_clock_time': 318.79645013809204, 'metric_for_logging': {'pred_time': 0.000175089358232311}, 'val_loss': 0.20206119653271076, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a1340>, 'training_iteration': 1, 'config': {'n_estimators': 113, 'max_features': 0.09334685589808495, 'max_leaves': 148, 'criterion': 'entropy'}, 'config/n_estimators': 113, 'config/max_features': 0.09334685589808495, 'config/max_leaves': 148, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 4.497567176818848}\n",
      "[flaml.automl.logger: 09-25 12:37:42] {2391} INFO -  at 318.8s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:42] {2218} INFO - iteration 133, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:37:42] {805} INFO - trial 1 config: {'n_estimators': 25, 'num_leaves': 57, 'min_child_samples': 8, 'learning_rate': 0.13527028767731006, 'log_max_bin': 10, 'colsample_bytree': 0.7635301665670239, 'reg_alpha': 0.00596956133069734, 'reg_lambda': 0.5254294140347627}\n",
      "[flaml.tune.tune: 09-25 12:37:43] {197} INFO - result: {'pred_time': 1.1764652795418574e-05, 'wall_clock_time': 319.53900933265686, 'metric_for_logging': {'pred_time': 1.1764652795418574e-05}, 'val_loss': 0.20113488820385372, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340bc040>, 'training_iteration': 0, 'config': {'n_estimators': 25, 'num_leaves': 57, 'min_child_samples': 8, 'learning_rate': 0.13527028767731006, 'log_max_bin': 10, 'colsample_bytree': 0.7635301665670239, 'reg_alpha': 0.00596956133069734, 'reg_lambda': 0.5254294140347627}, 'config/n_estimators': 25, 'config/num_leaves': 57, 'config/min_child_samples': 8, 'config/learning_rate': 0.13527028767731006, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7635301665670239, 'config/reg_alpha': 0.00596956133069734, 'config/reg_lambda': 0.5254294140347627, 'experiment_tag': 'exp', 'time_total_s': 0.7348124980926514}\n",
      "[flaml.tune.tune: 09-25 12:37:43] {197} INFO - result: {'pred_time': 1.1764652795418574e-05, 'wall_clock_time': 319.53900933265686, 'metric_for_logging': {'pred_time': 1.1764652795418574e-05}, 'val_loss': 0.20113488820385372, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340bc040>, 'training_iteration': 1, 'config': {'n_estimators': 25, 'num_leaves': 57, 'min_child_samples': 8, 'learning_rate': 0.13527028767731006, 'log_max_bin': 10, 'colsample_bytree': 0.7635301665670239, 'reg_alpha': 0.00596956133069734, 'reg_lambda': 0.5254294140347627}, 'config/n_estimators': 25, 'config/num_leaves': 57, 'config/min_child_samples': 8, 'config/learning_rate': 0.13527028767731006, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7635301665670239, 'config/reg_alpha': 0.00596956133069734, 'config/reg_lambda': 0.5254294140347627, 'experiment_tag': 'exp', 'time_total_s': 0.7369680404663086}\n",
      "[flaml.automl.logger: 09-25 12:37:43] {2391} INFO -  at 319.5s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:43] {2218} INFO - iteration 134, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:37:43] {805} INFO - trial 1 config: {'n_estimators': 45, 'max_features': 0.10168223906236107, 'max_leaves': 109, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:37:45] {197} INFO - result: {'pred_time': 8.283495474894173e-05, 'wall_clock_time': 321.53032636642456, 'metric_for_logging': {'pred_time': 8.283495474894173e-05}, 'val_loss': 0.22726582827782224, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680bb7f0>, 'training_iteration': 0, 'config': {'n_estimators': 45, 'max_features': 0.10168223906236107, 'max_leaves': 109, 'criterion': 'gini'}, 'config/n_estimators': 45, 'config/max_features': 0.10168223906236107, 'config/max_leaves': 109, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.9832346439361572}\n",
      "[flaml.tune.tune: 09-25 12:37:45] {197} INFO - result: {'pred_time': 8.283495474894173e-05, 'wall_clock_time': 321.53032636642456, 'metric_for_logging': {'pred_time': 8.283495474894173e-05}, 'val_loss': 0.22726582827782224, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680bb7f0>, 'training_iteration': 1, 'config': {'n_estimators': 45, 'max_features': 0.10168223906236107, 'max_leaves': 109, 'criterion': 'gini'}, 'config/n_estimators': 45, 'config/max_features': 0.10168223906236107, 'config/max_leaves': 109, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.9852471351623535}\n",
      "[flaml.automl.logger: 09-25 12:37:45] {2391} INFO -  at 321.5s,\testimator rf's best error=0.1974,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:45] {2218} INFO - iteration 135, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:37:45] {805} INFO - trial 1 config: {'early_stopping_rounds': 10, 'learning_rate': 0.04185807243380236, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:37:49] {197} INFO - result: {'pred_time': 8.00812820000135e-05, 'wall_clock_time': 325.8995695114136, 'metric_for_logging': {'pred_time': 8.00812820000135e-05}, 'val_loss': 0.2470475824111506, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680d44c0>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.04185807243380236, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.04185807243380236, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.358441352844238}\n",
      "[flaml.tune.tune: 09-25 12:37:49] {197} INFO - result: {'pred_time': 8.00812820000135e-05, 'wall_clock_time': 325.8995695114136, 'metric_for_logging': {'pred_time': 8.00812820000135e-05}, 'val_loss': 0.2470475824111506, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680d44c0>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 10, 'learning_rate': 0.04185807243380236, 'n_estimators': 8192}, 'config/early_stopping_rounds': 10, 'config/learning_rate': 0.04185807243380236, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.359663009643555}\n",
      "[flaml.automl.logger: 09-25 12:37:49] {2391} INFO -  at 325.9s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:49] {2218} INFO - iteration 136, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:37:49] {805} INFO - trial 1 config: {'n_estimators': 13, 'max_features': 0.05494367551727712, 'max_leaves': 238, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:37:50] {197} INFO - result: {'pred_time': 3.841036486589926e-05, 'wall_clock_time': 326.70360112190247, 'metric_for_logging': {'pred_time': 3.841036486589926e-05}, 'val_loss': 0.23821346430042079, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe66804da60>, 'training_iteration': 0, 'config': {'n_estimators': 13, 'max_features': 0.05494367551727712, 'max_leaves': 238, 'criterion': 'gini'}, 'config/n_estimators': 13, 'config/max_features': 0.05494367551727712, 'config/max_leaves': 238, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.797123908996582}\n",
      "[flaml.tune.tune: 09-25 12:37:50] {197} INFO - result: {'pred_time': 3.841036486589926e-05, 'wall_clock_time': 326.70360112190247, 'metric_for_logging': {'pred_time': 3.841036486589926e-05}, 'val_loss': 0.23821346430042079, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe66804da60>, 'training_iteration': 1, 'config': {'n_estimators': 13, 'max_features': 0.05494367551727712, 'max_leaves': 238, 'criterion': 'gini'}, 'config/n_estimators': 13, 'config/max_features': 0.05494367551727712, 'config/max_leaves': 238, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.7984914779663086}\n",
      "[flaml.automl.logger: 09-25 12:37:50] {2391} INFO -  at 326.7s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:50] {2218} INFO - iteration 137, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:37:50] {805} INFO - trial 1 config: {'early_stopping_rounds': 12, 'learning_rate': 0.05350068715414498, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:37:53] {197} INFO - result: {'pred_time': 0.00010399455759926458, 'wall_clock_time': 329.70750069618225, 'metric_for_logging': {'pred_time': 0.00010399455759926458}, 'val_loss': 0.24926513700876515, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680a22e0>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.05350068715414498, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.05350068715414498, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 2.997929811477661}\n",
      "[flaml.tune.tune: 09-25 12:37:53] {197} INFO - result: {'pred_time': 0.00010399455759926458, 'wall_clock_time': 329.70750069618225, 'metric_for_logging': {'pred_time': 0.00010399455759926458}, 'val_loss': 0.24926513700876515, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680a22e0>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.05350068715414498, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.05350068715414498, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 2.9996697902679443}\n",
      "[flaml.automl.logger: 09-25 12:37:53] {2391} INFO -  at 329.7s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:53] {2218} INFO - iteration 138, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:37:53] {805} INFO - trial 1 config: {'n_estimators': 163, 'num_leaves': 63, 'min_child_samples': 13, 'learning_rate': 0.1042935375636779, 'log_max_bin': 10, 'colsample_bytree': 0.7579372076328836, 'reg_alpha': 0.0009765625, 'reg_lambda': 4.936106521144379}\n",
      "[flaml.tune.tune: 09-25 12:37:55] {197} INFO - result: {'pred_time': 1.692425710933691e-05, 'wall_clock_time': 331.6373643875122, 'metric_for_logging': {'pred_time': 1.692425710933691e-05}, 'val_loss': 0.2059932525074954, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe52414ba90>, 'training_iteration': 0, 'config': {'n_estimators': 163, 'num_leaves': 63, 'min_child_samples': 13, 'learning_rate': 0.1042935375636779, 'log_max_bin': 10, 'colsample_bytree': 0.7579372076328836, 'reg_alpha': 0.0009765625, 'reg_lambda': 4.936106521144379}, 'config/n_estimators': 163, 'config/num_leaves': 63, 'config/min_child_samples': 13, 'config/learning_rate': 0.1042935375636779, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7579372076328836, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 4.936106521144379, 'experiment_tag': 'exp', 'time_total_s': 1.9227638244628906}\n",
      "[flaml.tune.tune: 09-25 12:37:55] {197} INFO - result: {'pred_time': 1.692425710933691e-05, 'wall_clock_time': 331.6373643875122, 'metric_for_logging': {'pred_time': 1.692425710933691e-05}, 'val_loss': 0.2059932525074954, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe52414ba90>, 'training_iteration': 1, 'config': {'n_estimators': 163, 'num_leaves': 63, 'min_child_samples': 13, 'learning_rate': 0.1042935375636779, 'log_max_bin': 10, 'colsample_bytree': 0.7579372076328836, 'reg_alpha': 0.0009765625, 'reg_lambda': 4.936106521144379}, 'config/n_estimators': 163, 'config/num_leaves': 63, 'config/min_child_samples': 13, 'config/learning_rate': 0.1042935375636779, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7579372076328836, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 4.936106521144379, 'experiment_tag': 'exp', 'time_total_s': 1.9242210388183594}\n",
      "[flaml.automl.logger: 09-25 12:37:55] {2391} INFO -  at 331.6s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:37:55] {2218} INFO - iteration 139, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:37:55] {805} INFO - trial 1 config: {'n_estimators': 50, 'max_leaves': 62, 'min_child_weight': 0.06240551618417961, 'learning_rate': 0.06433584489767766, 'subsample': 0.7876576287141444, 'colsample_bylevel': 0.23669438273229557, 'colsample_bytree': 0.629534375080058, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5674254655546578}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:38:00] {197} INFO - result: {'pred_time': 4.574488907403912e-05, 'wall_clock_time': 336.5282280445099, 'metric_for_logging': {'pred_time': 4.574488907403912e-05}, 'val_loss': 0.20175921221648357, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680ed730>, 'training_iteration': 0, 'config': {'n_estimators': 50, 'max_leaves': 62, 'min_child_weight': 0.06240551618417961, 'learning_rate': 0.06433584489767766, 'subsample': 0.7876576287141444, 'colsample_bylevel': 0.23669438273229557, 'colsample_bytree': 0.629534375080058, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5674254655546578}, 'config/n_estimators': 50, 'config/max_leaves': 62, 'config/min_child_weight': 0.06240551618417961, 'config/learning_rate': 0.06433584489767766, 'config/subsample': 0.7876576287141444, 'config/colsample_bylevel': 0.23669438273229557, 'config/colsample_bytree': 0.629534375080058, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5674254655546578, 'experiment_tag': 'exp', 'time_total_s': 4.882739305496216}\n",
      "[flaml.tune.tune: 09-25 12:38:00] {197} INFO - result: {'pred_time': 4.574488907403912e-05, 'wall_clock_time': 336.5282280445099, 'metric_for_logging': {'pred_time': 4.574488907403912e-05}, 'val_loss': 0.20175921221648357, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680ed730>, 'training_iteration': 1, 'config': {'n_estimators': 50, 'max_leaves': 62, 'min_child_weight': 0.06240551618417961, 'learning_rate': 0.06433584489767766, 'subsample': 0.7876576287141444, 'colsample_bylevel': 0.23669438273229557, 'colsample_bytree': 0.629534375080058, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5674254655546578}, 'config/n_estimators': 50, 'config/max_leaves': 62, 'config/min_child_weight': 0.06240551618417961, 'config/learning_rate': 0.06433584489767766, 'config/subsample': 0.7876576287141444, 'config/colsample_bylevel': 0.23669438273229557, 'config/colsample_bytree': 0.629534375080058, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5674254655546578, 'experiment_tag': 'exp', 'time_total_s': 4.8841681480407715}\n",
      "[flaml.automl.logger: 09-25 12:38:00] {2391} INFO -  at 336.5s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:38:00] {2218} INFO - iteration 140, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:38:00] {805} INFO - trial 1 config: {'n_estimators': 99, 'max_features': 0.07323857470378452, 'max_leaves': 35, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:38:03] {197} INFO - result: {'pred_time': 0.00014161101799716619, 'wall_clock_time': 339.49311685562134, 'metric_for_logging': {'pred_time': 0.00014161101799716619}, 'val_loss': 0.20939444085995812, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680d5070>, 'training_iteration': 0, 'config': {'n_estimators': 99, 'max_features': 0.07323857470378452, 'max_leaves': 35, 'criterion': 'entropy'}, 'config/n_estimators': 99, 'config/max_features': 0.07323857470378452, 'config/max_leaves': 35, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.957988739013672}\n",
      "[flaml.tune.tune: 09-25 12:38:03] {197} INFO - result: {'pred_time': 0.00014161101799716619, 'wall_clock_time': 339.49311685562134, 'metric_for_logging': {'pred_time': 0.00014161101799716619}, 'val_loss': 0.20939444085995812, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680d5070>, 'training_iteration': 1, 'config': {'n_estimators': 99, 'max_features': 0.07323857470378452, 'max_leaves': 35, 'criterion': 'entropy'}, 'config/n_estimators': 99, 'config/max_features': 0.07323857470378452, 'config/max_leaves': 35, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.959683895111084}\n",
      "[flaml.automl.logger: 09-25 12:38:03] {2391} INFO -  at 339.5s,\testimator rf's best error=0.1974,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:38:03] {2218} INFO - iteration 141, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:38:03] {805} INFO - trial 1 config: {'n_estimators': 23, 'max_features': 0.05314037980050355, 'max_leaves': 219, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:38:04] {197} INFO - result: {'pred_time': 5.078303385397711e-05, 'wall_clock_time': 340.5711922645569, 'metric_for_logging': {'pred_time': 5.078303385397711e-05}, 'val_loss': 0.21756711734222983, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340bbc10>, 'training_iteration': 0, 'config': {'n_estimators': 23, 'max_features': 0.05314037980050355, 'max_leaves': 219, 'criterion': 'entropy'}, 'config/n_estimators': 23, 'config/max_features': 0.05314037980050355, 'config/max_leaves': 219, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.0712778568267822}\n",
      "[flaml.tune.tune: 09-25 12:38:04] {197} INFO - result: {'pred_time': 5.078303385397711e-05, 'wall_clock_time': 340.5711922645569, 'metric_for_logging': {'pred_time': 5.078303385397711e-05}, 'val_loss': 0.21756711734222983, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340bbc10>, 'training_iteration': 1, 'config': {'n_estimators': 23, 'max_features': 0.05314037980050355, 'max_leaves': 219, 'criterion': 'entropy'}, 'config/n_estimators': 23, 'config/max_features': 0.05314037980050355, 'config/max_leaves': 219, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.0730016231536865}\n",
      "[flaml.automl.logger: 09-25 12:38:04] {2391} INFO -  at 340.6s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:38:04] {2218} INFO - iteration 142, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:38:04] {805} INFO - trial 1 config: {'n_estimators': 42, 'max_features': 0.04505165614896081, 'max_leaves': 210, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:38:06] {197} INFO - result: {'pred_time': 7.710067715283626e-05, 'wall_clock_time': 342.2207534313202, 'metric_for_logging': {'pred_time': 7.710067715283626e-05}, 'val_loss': 0.2131142199170685, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5340b2c70>, 'training_iteration': 0, 'config': {'n_estimators': 42, 'max_features': 0.04505165614896081, 'max_leaves': 210, 'criterion': 'gini'}, 'config/n_estimators': 42, 'config/max_features': 0.04505165614896081, 'config/max_leaves': 210, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.6419508457183838}\n",
      "[flaml.tune.tune: 09-25 12:38:06] {197} INFO - result: {'pred_time': 7.710067715283626e-05, 'wall_clock_time': 342.2207534313202, 'metric_for_logging': {'pred_time': 7.710067715283626e-05}, 'val_loss': 0.2131142199170685, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5340b2c70>, 'training_iteration': 1, 'config': {'n_estimators': 42, 'max_features': 0.04505165614896081, 'max_leaves': 210, 'criterion': 'gini'}, 'config/n_estimators': 42, 'config/max_features': 0.04505165614896081, 'config/max_leaves': 210, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.643448829650879}\n",
      "[flaml.automl.logger: 09-25 12:38:06] {2391} INFO -  at 342.2s,\testimator rf's best error=0.1974,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:38:06] {2218} INFO - iteration 143, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:38:06] {805} INFO - trial 1 config: {'n_estimators': 63, 'max_features': 0.09651454092493718, 'max_leaves': 161, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:38:09] {197} INFO - result: {'pred_time': 0.00010351003310656937, 'wall_clock_time': 345.2160437107086, 'metric_for_logging': {'pred_time': 0.00010351003310656937}, 'val_loss': 0.2133191070784774, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340b2100>, 'training_iteration': 0, 'config': {'n_estimators': 63, 'max_features': 0.09651454092493718, 'max_leaves': 161, 'criterion': 'gini'}, 'config/n_estimators': 63, 'config/max_features': 0.09651454092493718, 'config/max_leaves': 161, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.9879684448242188}\n",
      "[flaml.tune.tune: 09-25 12:38:09] {197} INFO - result: {'pred_time': 0.00010351003310656937, 'wall_clock_time': 345.2160437107086, 'metric_for_logging': {'pred_time': 0.00010351003310656937}, 'val_loss': 0.2133191070784774, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340b2100>, 'training_iteration': 1, 'config': {'n_estimators': 63, 'max_features': 0.09651454092493718, 'max_leaves': 161, 'criterion': 'gini'}, 'config/n_estimators': 63, 'config/max_features': 0.09651454092493718, 'config/max_leaves': 161, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.9894769191741943}\n",
      "[flaml.automl.logger: 09-25 12:38:09] {2391} INFO -  at 345.2s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:38:09] {2218} INFO - iteration 144, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:38:09] {805} INFO - trial 1 config: {'n_estimators': 389, 'max_leaves': 297, 'min_child_weight': 1.1754698487364776, 'learning_rate': 0.03642524868859585, 'subsample': 0.8670450883215518, 'colsample_bylevel': 0.47267989280713507, 'colsample_bytree': 0.6217260311107154, 'reg_alpha': 0.005771390107656191, 'reg_lambda': 3.274458375888919}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:38:48] {197} INFO - result: {'pred_time': 5.9813253296369696e-05, 'wall_clock_time': 384.0696394443512, 'metric_for_logging': {'pred_time': 5.9813253296369696e-05}, 'val_loss': 0.19501552065270206, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680f70d0>, 'training_iteration': 0, 'config': {'n_estimators': 389, 'max_leaves': 297, 'min_child_weight': 1.1754698487364776, 'learning_rate': 0.03642524868859585, 'subsample': 0.8670450883215518, 'colsample_bylevel': 0.47267989280713507, 'colsample_bytree': 0.6217260311107154, 'reg_alpha': 0.005771390107656191, 'reg_lambda': 3.274458375888919}, 'config/n_estimators': 389, 'config/max_leaves': 297, 'config/min_child_weight': 1.1754698487364776, 'config/learning_rate': 0.03642524868859585, 'config/subsample': 0.8670450883215518, 'config/colsample_bylevel': 0.47267989280713507, 'config/colsample_bytree': 0.6217260311107154, 'config/reg_alpha': 0.005771390107656191, 'config/reg_lambda': 3.274458375888919, 'experiment_tag': 'exp', 'time_total_s': 38.84682774543762}\n",
      "[flaml.tune.tune: 09-25 12:38:48] {197} INFO - result: {'pred_time': 5.9813253296369696e-05, 'wall_clock_time': 384.0696394443512, 'metric_for_logging': {'pred_time': 5.9813253296369696e-05}, 'val_loss': 0.19501552065270206, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680f70d0>, 'training_iteration': 1, 'config': {'n_estimators': 389, 'max_leaves': 297, 'min_child_weight': 1.1754698487364776, 'learning_rate': 0.03642524868859585, 'subsample': 0.8670450883215518, 'colsample_bylevel': 0.47267989280713507, 'colsample_bytree': 0.6217260311107154, 'reg_alpha': 0.005771390107656191, 'reg_lambda': 3.274458375888919}, 'config/n_estimators': 389, 'config/max_leaves': 297, 'config/min_child_weight': 1.1754698487364776, 'config/learning_rate': 0.03642524868859585, 'config/subsample': 0.8670450883215518, 'config/colsample_bylevel': 0.47267989280713507, 'config/colsample_bytree': 0.6217260311107154, 'config/reg_alpha': 0.005771390107656191, 'config/reg_lambda': 3.274458375888919, 'experiment_tag': 'exp', 'time_total_s': 38.8482186794281}\n",
      "[flaml.automl.logger: 09-25 12:38:48] {2391} INFO -  at 384.1s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:38:48] {2218} INFO - iteration 145, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:38:48] {805} INFO - trial 1 config: {'n_estimators': 59, 'max_features': 0.0874536765374352, 'max_leaves': 74, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:38:50] {197} INFO - result: {'pred_time': 9.824991587351192e-05, 'wall_clock_time': 386.2334485054016, 'metric_for_logging': {'pred_time': 9.824991587351192e-05}, 'val_loss': 0.20589902553920547, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680f7490>, 'training_iteration': 0, 'config': {'n_estimators': 59, 'max_features': 0.0874536765374352, 'max_leaves': 74, 'criterion': 'entropy'}, 'config/n_estimators': 59, 'config/max_features': 0.0874536765374352, 'config/max_leaves': 74, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.1570205688476562}\n",
      "[flaml.tune.tune: 09-25 12:38:50] {197} INFO - result: {'pred_time': 9.824991587351192e-05, 'wall_clock_time': 386.2334485054016, 'metric_for_logging': {'pred_time': 9.824991587351192e-05}, 'val_loss': 0.20589902553920547, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680f7490>, 'training_iteration': 1, 'config': {'n_estimators': 59, 'max_features': 0.0874536765374352, 'max_leaves': 74, 'criterion': 'entropy'}, 'config/n_estimators': 59, 'config/max_features': 0.0874536765374352, 'config/max_leaves': 74, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.1583683490753174}\n",
      "[flaml.automl.logger: 09-25 12:38:50] {2391} INFO -  at 386.2s,\testimator rf's best error=0.1974,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:38:50] {2218} INFO - iteration 146, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:38:50] {805} INFO - trial 1 config: {'n_estimators': 50, 'num_leaves': 78, 'min_child_samples': 4, 'learning_rate': 0.4016493097125691, 'log_max_bin': 8, 'colsample_bytree': 0.7920446835691972, 'reg_alpha': 0.008948061409181867, 'reg_lambda': 0.3526056274591469}\n",
      "[flaml.tune.tune: 09-25 12:38:51] {197} INFO - result: {'pred_time': 1.2396945986842935e-05, 'wall_clock_time': 387.4612498283386, 'metric_for_logging': {'pred_time': 1.2396945986842935e-05}, 'val_loss': 0.20964651077094856, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340bed60>, 'training_iteration': 0, 'config': {'n_estimators': 50, 'num_leaves': 78, 'min_child_samples': 4, 'learning_rate': 0.4016493097125691, 'log_max_bin': 8, 'colsample_bytree': 0.7920446835691972, 'reg_alpha': 0.008948061409181867, 'reg_lambda': 0.3526056274591469}, 'config/n_estimators': 50, 'config/num_leaves': 78, 'config/min_child_samples': 4, 'config/learning_rate': 0.4016493097125691, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7920446835691972, 'config/reg_alpha': 0.008948061409181867, 'config/reg_lambda': 0.3526056274591469, 'experiment_tag': 'exp', 'time_total_s': 1.2210946083068848}\n",
      "[flaml.tune.tune: 09-25 12:38:51] {197} INFO - result: {'pred_time': 1.2396945986842935e-05, 'wall_clock_time': 387.4612498283386, 'metric_for_logging': {'pred_time': 1.2396945986842935e-05}, 'val_loss': 0.20964651077094856, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340bed60>, 'training_iteration': 1, 'config': {'n_estimators': 50, 'num_leaves': 78, 'min_child_samples': 4, 'learning_rate': 0.4016493097125691, 'log_max_bin': 8, 'colsample_bytree': 0.7920446835691972, 'reg_alpha': 0.008948061409181867, 'reg_lambda': 0.3526056274591469}, 'config/n_estimators': 50, 'config/num_leaves': 78, 'config/min_child_samples': 4, 'config/learning_rate': 0.4016493097125691, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7920446835691972, 'config/reg_alpha': 0.008948061409181867, 'config/reg_lambda': 0.3526056274591469, 'experiment_tag': 'exp', 'time_total_s': 1.2225689888000488}\n",
      "[flaml.automl.logger: 09-25 12:38:51] {2391} INFO -  at 387.5s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:38:51] {2218} INFO - iteration 147, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:38:51] {805} INFO - trial 1 config: {'n_estimators': 181, 'num_leaves': 251, 'min_child_samples': 7, 'learning_rate': 0.2504784930292783, 'log_max_bin': 10, 'colsample_bytree': 0.71201105760572, 'reg_alpha': 0.0034922118383222253, 'reg_lambda': 0.3268891253457054}\n",
      "[flaml.tune.tune: 09-25 12:38:54] {197} INFO - result: {'pred_time': 1.785252505588209e-05, 'wall_clock_time': 390.3381497859955, 'metric_for_logging': {'pred_time': 1.785252505588209e-05}, 'val_loss': 0.2006229560202574, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680c4c10>, 'training_iteration': 0, 'config': {'n_estimators': 181, 'num_leaves': 251, 'min_child_samples': 7, 'learning_rate': 0.2504784930292783, 'log_max_bin': 10, 'colsample_bytree': 0.71201105760572, 'reg_alpha': 0.0034922118383222253, 'reg_lambda': 0.3268891253457054}, 'config/n_estimators': 181, 'config/num_leaves': 251, 'config/min_child_samples': 7, 'config/learning_rate': 0.2504784930292783, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.71201105760572, 'config/reg_alpha': 0.0034922118383222253, 'config/reg_lambda': 0.3268891253457054, 'experiment_tag': 'exp', 'time_total_s': 2.8706603050231934}\n",
      "[flaml.tune.tune: 09-25 12:38:54] {197} INFO - result: {'pred_time': 1.785252505588209e-05, 'wall_clock_time': 390.3381497859955, 'metric_for_logging': {'pred_time': 1.785252505588209e-05}, 'val_loss': 0.2006229560202574, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680c4c10>, 'training_iteration': 1, 'config': {'n_estimators': 181, 'num_leaves': 251, 'min_child_samples': 7, 'learning_rate': 0.2504784930292783, 'log_max_bin': 10, 'colsample_bytree': 0.71201105760572, 'reg_alpha': 0.0034922118383222253, 'reg_lambda': 0.3268891253457054}, 'config/n_estimators': 181, 'config/num_leaves': 251, 'config/min_child_samples': 7, 'config/learning_rate': 0.2504784930292783, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.71201105760572, 'config/reg_alpha': 0.0034922118383222253, 'config/reg_lambda': 0.3268891253457054, 'experiment_tag': 'exp', 'time_total_s': 2.8726344108581543}\n",
      "[flaml.automl.logger: 09-25 12:38:54] {2391} INFO -  at 390.3s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:38:54] {2218} INFO - iteration 148, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:38:54] {805} INFO - trial 1 config: {'n_estimators': 45, 'num_leaves': 20, 'min_child_samples': 7, 'learning_rate': 0.16723762133556389, 'log_max_bin': 8, 'colsample_bytree': 0.8379708335963609, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.324432053995726}\n",
      "[flaml.tune.tune: 09-25 12:38:55] {197} INFO - result: {'pred_time': 1.1244273564526976e-05, 'wall_clock_time': 391.05310583114624, 'metric_for_logging': {'pred_time': 1.1244273564526976e-05}, 'val_loss': 0.21194985061176963, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe66811ac70>, 'training_iteration': 0, 'config': {'n_estimators': 45, 'num_leaves': 20, 'min_child_samples': 7, 'learning_rate': 0.16723762133556389, 'log_max_bin': 8, 'colsample_bytree': 0.8379708335963609, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.324432053995726}, 'config/n_estimators': 45, 'config/num_leaves': 20, 'config/min_child_samples': 7, 'config/learning_rate': 0.16723762133556389, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8379708335963609, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.324432053995726, 'experiment_tag': 'exp', 'time_total_s': 0.7071411609649658}\n",
      "[flaml.tune.tune: 09-25 12:38:55] {197} INFO - result: {'pred_time': 1.1244273564526976e-05, 'wall_clock_time': 391.05310583114624, 'metric_for_logging': {'pred_time': 1.1244273564526976e-05}, 'val_loss': 0.21194985061176963, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe66811ac70>, 'training_iteration': 1, 'config': {'n_estimators': 45, 'num_leaves': 20, 'min_child_samples': 7, 'learning_rate': 0.16723762133556389, 'log_max_bin': 8, 'colsample_bytree': 0.8379708335963609, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.324432053995726}, 'config/n_estimators': 45, 'config/num_leaves': 20, 'config/min_child_samples': 7, 'config/learning_rate': 0.16723762133556389, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.8379708335963609, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.324432053995726, 'experiment_tag': 'exp', 'time_total_s': 0.708916187286377}\n",
      "[flaml.automl.logger: 09-25 12:38:55] {2391} INFO -  at 391.1s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:38:55] {2218} INFO - iteration 149, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:38:55] {805} INFO - trial 1 config: {'n_estimators': 29, 'num_leaves': 56, 'min_child_samples': 6, 'learning_rate': 0.5433139733195963, 'log_max_bin': 7, 'colsample_bytree': 0.7567480723756149, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.8327025956621281}\n",
      "[flaml.tune.tune: 09-25 12:38:55] {197} INFO - result: {'pred_time': 1.1259912310714333e-05, 'wall_clock_time': 391.8234910964966, 'metric_for_logging': {'pred_time': 1.1259912310714333e-05}, 'val_loss': 0.21142089211804355, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340be5e0>, 'training_iteration': 0, 'config': {'n_estimators': 29, 'num_leaves': 56, 'min_child_samples': 6, 'learning_rate': 0.5433139733195963, 'log_max_bin': 7, 'colsample_bytree': 0.7567480723756149, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.8327025956621281}, 'config/n_estimators': 29, 'config/num_leaves': 56, 'config/min_child_samples': 6, 'config/learning_rate': 0.5433139733195963, 'config/log_max_bin': 7, 'config/colsample_bytree': 0.7567480723756149, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.8327025956621281, 'experiment_tag': 'exp', 'time_total_s': 0.7619271278381348}\n",
      "[flaml.tune.tune: 09-25 12:38:55] {197} INFO - result: {'pred_time': 1.1259912310714333e-05, 'wall_clock_time': 391.8234910964966, 'metric_for_logging': {'pred_time': 1.1259912310714333e-05}, 'val_loss': 0.21142089211804355, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340be5e0>, 'training_iteration': 1, 'config': {'n_estimators': 29, 'num_leaves': 56, 'min_child_samples': 6, 'learning_rate': 0.5433139733195963, 'log_max_bin': 7, 'colsample_bytree': 0.7567480723756149, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.8327025956621281}, 'config/n_estimators': 29, 'config/num_leaves': 56, 'config/min_child_samples': 6, 'config/learning_rate': 0.5433139733195963, 'config/log_max_bin': 7, 'config/colsample_bytree': 0.7567480723756149, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.8327025956621281, 'experiment_tag': 'exp', 'time_total_s': 0.763601541519165}\n",
      "[flaml.automl.logger: 09-25 12:38:55] {2391} INFO -  at 391.8s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:38:55] {2218} INFO - iteration 150, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:38:55] {805} INFO - trial 1 config: {'n_estimators': 283, 'num_leaves': 87, 'min_child_samples': 9, 'learning_rate': 0.07709985280517036, 'log_max_bin': 10, 'colsample_bytree': 0.793233818826466, 'reg_alpha': 0.001975258376030875, 'reg_lambda': 0.9496897866642053}\n",
      "[flaml.tune.tune: 09-25 12:38:59] {197} INFO - result: {'pred_time': 2.2088755580194155e-05, 'wall_clock_time': 395.98197865486145, 'metric_for_logging': {'pred_time': 2.2088755580194155e-05}, 'val_loss': 0.20365814147673214, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340bb1f0>, 'training_iteration': 0, 'config': {'n_estimators': 283, 'num_leaves': 87, 'min_child_samples': 9, 'learning_rate': 0.07709985280517036, 'log_max_bin': 10, 'colsample_bytree': 0.793233818826466, 'reg_alpha': 0.001975258376030875, 'reg_lambda': 0.9496897866642053}, 'config/n_estimators': 283, 'config/num_leaves': 87, 'config/min_child_samples': 9, 'config/learning_rate': 0.07709985280517036, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.793233818826466, 'config/reg_alpha': 0.001975258376030875, 'config/reg_lambda': 0.9496897866642053, 'experiment_tag': 'exp', 'time_total_s': 4.151623010635376}\n",
      "[flaml.tune.tune: 09-25 12:38:59] {197} INFO - result: {'pred_time': 2.2088755580194155e-05, 'wall_clock_time': 395.98197865486145, 'metric_for_logging': {'pred_time': 2.2088755580194155e-05}, 'val_loss': 0.20365814147673214, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340bb1f0>, 'training_iteration': 1, 'config': {'n_estimators': 283, 'num_leaves': 87, 'min_child_samples': 9, 'learning_rate': 0.07709985280517036, 'log_max_bin': 10, 'colsample_bytree': 0.793233818826466, 'reg_alpha': 0.001975258376030875, 'reg_lambda': 0.9496897866642053}, 'config/n_estimators': 283, 'config/num_leaves': 87, 'config/min_child_samples': 9, 'config/learning_rate': 0.07709985280517036, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.793233818826466, 'config/reg_alpha': 0.001975258376030875, 'config/reg_lambda': 0.9496897866642053, 'experiment_tag': 'exp', 'time_total_s': 4.152927875518799}\n",
      "[flaml.automl.logger: 09-25 12:38:59] {2391} INFO -  at 396.0s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:38:59] {2218} INFO - iteration 151, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:38:59] {805} INFO - trial 1 config: {'n_estimators': 69, 'max_features': 0.03772876355841365, 'max_leaves': 101, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:39:02] {197} INFO - result: {'pred_time': 0.00010336541818609338, 'wall_clock_time': 398.1315448284149, 'metric_for_logging': {'pred_time': 0.00010336541818609338}, 'val_loss': 0.20963022906426204, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe66811b3a0>, 'training_iteration': 0, 'config': {'n_estimators': 69, 'max_features': 0.03772876355841365, 'max_leaves': 101, 'criterion': 'gini'}, 'config/n_estimators': 69, 'config/max_features': 0.03772876355841365, 'config/max_leaves': 101, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.144092082977295}\n",
      "[flaml.tune.tune: 09-25 12:39:02] {197} INFO - result: {'pred_time': 0.00010336541818609338, 'wall_clock_time': 398.1315448284149, 'metric_for_logging': {'pred_time': 0.00010336541818609338}, 'val_loss': 0.20963022906426204, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe66811b3a0>, 'training_iteration': 1, 'config': {'n_estimators': 69, 'max_features': 0.03772876355841365, 'max_leaves': 101, 'criterion': 'gini'}, 'config/n_estimators': 69, 'config/max_features': 0.03772876355841365, 'config/max_leaves': 101, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.1454381942749023}\n",
      "[flaml.automl.logger: 09-25 12:39:02] {2391} INFO -  at 398.1s,\testimator rf's best error=0.1974,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:02] {2218} INFO - iteration 152, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:39:02] {805} INFO - trial 1 config: {'early_stopping_rounds': 14, 'learning_rate': 0.03252904625553547, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:39:08] {197} INFO - result: {'pred_time': 8.18125086880236e-05, 'wall_clock_time': 404.1295921802521, 'metric_for_logging': {'pred_time': 8.18125086880236e-05}, 'val_loss': 0.24378730593123396, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe66811b520>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 14, 'learning_rate': 0.03252904625553547, 'n_estimators': 8192}, 'config/early_stopping_rounds': 14, 'config/learning_rate': 0.03252904625553547, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.991636276245117}\n",
      "[flaml.tune.tune: 09-25 12:39:08] {197} INFO - result: {'pred_time': 8.18125086880236e-05, 'wall_clock_time': 404.1295921802521, 'metric_for_logging': {'pred_time': 8.18125086880236e-05}, 'val_loss': 0.24378730593123396, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe66811b520>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 14, 'learning_rate': 0.03252904625553547, 'n_estimators': 8192}, 'config/early_stopping_rounds': 14, 'config/learning_rate': 0.03252904625553547, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.993142127990723}\n",
      "[flaml.automl.logger: 09-25 12:39:08] {2391} INFO -  at 404.1s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:08] {2218} INFO - iteration 153, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:39:08] {805} INFO - trial 1 config: {'n_estimators': 106, 'max_features': 0.09472691529444735, 'max_leaves': 54, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:39:11] {197} INFO - result: {'pred_time': 0.00015398806102370402, 'wall_clock_time': 407.543447971344, 'metric_for_logging': {'pred_time': 0.00015398806102370402}, 'val_loss': 0.21782093620549386, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5242745e0>, 'training_iteration': 0, 'config': {'n_estimators': 106, 'max_features': 0.09472691529444735, 'max_leaves': 54, 'criterion': 'gini'}, 'config/n_estimators': 106, 'config/max_features': 0.09472691529444735, 'config/max_leaves': 54, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.4069302082061768}\n",
      "[flaml.tune.tune: 09-25 12:39:11] {197} INFO - result: {'pred_time': 0.00015398806102370402, 'wall_clock_time': 407.543447971344, 'metric_for_logging': {'pred_time': 0.00015398806102370402}, 'val_loss': 0.21782093620549386, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5242745e0>, 'training_iteration': 1, 'config': {'n_estimators': 106, 'max_features': 0.09472691529444735, 'max_leaves': 54, 'criterion': 'gini'}, 'config/n_estimators': 106, 'config/max_features': 0.09472691529444735, 'config/max_leaves': 54, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.408517360687256}\n",
      "[flaml.automl.logger: 09-25 12:39:11] {2391} INFO -  at 407.5s,\testimator rf's best error=0.1974,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:11] {2218} INFO - iteration 154, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:39:11] {805} INFO - trial 1 config: {'n_estimators': 139, 'num_leaves': 135, 'min_child_samples': 8, 'learning_rate': 0.26975511915446226, 'log_max_bin': 9, 'colsample_bytree': 0.6142489545755917, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.2137521995017067}\n",
      "[flaml.tune.tune: 09-25 12:39:13] {197} INFO - result: {'pred_time': 1.5522769095626386e-05, 'wall_clock_time': 409.7922616004944, 'metric_for_logging': {'pred_time': 1.5522769095626386e-05}, 'val_loss': 0.19968571673968977, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe52413de80>, 'training_iteration': 0, 'config': {'n_estimators': 139, 'num_leaves': 135, 'min_child_samples': 8, 'learning_rate': 0.26975511915446226, 'log_max_bin': 9, 'colsample_bytree': 0.6142489545755917, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.2137521995017067}, 'config/n_estimators': 139, 'config/num_leaves': 135, 'config/min_child_samples': 8, 'config/learning_rate': 0.26975511915446226, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.6142489545755917, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.2137521995017067, 'experiment_tag': 'exp', 'time_total_s': 2.2414779663085938}\n",
      "[flaml.tune.tune: 09-25 12:39:13] {197} INFO - result: {'pred_time': 1.5522769095626386e-05, 'wall_clock_time': 409.7922616004944, 'metric_for_logging': {'pred_time': 1.5522769095626386e-05}, 'val_loss': 0.19968571673968977, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe52413de80>, 'training_iteration': 1, 'config': {'n_estimators': 139, 'num_leaves': 135, 'min_child_samples': 8, 'learning_rate': 0.26975511915446226, 'log_max_bin': 9, 'colsample_bytree': 0.6142489545755917, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.2137521995017067}, 'config/n_estimators': 139, 'config/num_leaves': 135, 'config/min_child_samples': 8, 'config/learning_rate': 0.26975511915446226, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.6142489545755917, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.2137521995017067, 'experiment_tag': 'exp', 'time_total_s': 2.242661237716675}\n",
      "[flaml.automl.logger: 09-25 12:39:13] {2391} INFO -  at 409.8s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:13] {2218} INFO - iteration 155, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:39:13] {805} INFO - trial 1 config: {'n_estimators': 58, 'num_leaves': 36, 'min_child_samples': 6, 'learning_rate': 0.15528686721955096, 'log_max_bin': 9, 'colsample_bytree': 0.9357329366264893, 'reg_alpha': 0.013575172218183634, 'reg_lambda': 0.7862212118795716}\n",
      "[flaml.tune.tune: 09-25 12:39:14] {197} INFO - result: {'pred_time': 1.2096114391044172e-05, 'wall_clock_time': 410.78534960746765, 'metric_for_logging': {'pred_time': 1.2096114391044172e-05}, 'val_loss': 0.209478455505442, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524274af0>, 'training_iteration': 0, 'config': {'n_estimators': 58, 'num_leaves': 36, 'min_child_samples': 6, 'learning_rate': 0.15528686721955096, 'log_max_bin': 9, 'colsample_bytree': 0.9357329366264893, 'reg_alpha': 0.013575172218183634, 'reg_lambda': 0.7862212118795716}, 'config/n_estimators': 58, 'config/num_leaves': 36, 'config/min_child_samples': 6, 'config/learning_rate': 0.15528686721955096, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.9357329366264893, 'config/reg_alpha': 0.013575172218183634, 'config/reg_lambda': 0.7862212118795716, 'experiment_tag': 'exp', 'time_total_s': 0.9871656894683838}\n",
      "[flaml.tune.tune: 09-25 12:39:14] {197} INFO - result: {'pred_time': 1.2096114391044172e-05, 'wall_clock_time': 410.78534960746765, 'metric_for_logging': {'pred_time': 1.2096114391044172e-05}, 'val_loss': 0.209478455505442, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524274af0>, 'training_iteration': 1, 'config': {'n_estimators': 58, 'num_leaves': 36, 'min_child_samples': 6, 'learning_rate': 0.15528686721955096, 'log_max_bin': 9, 'colsample_bytree': 0.9357329366264893, 'reg_alpha': 0.013575172218183634, 'reg_lambda': 0.7862212118795716}, 'config/n_estimators': 58, 'config/num_leaves': 36, 'config/min_child_samples': 6, 'config/learning_rate': 0.15528686721955096, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.9357329366264893, 'config/reg_alpha': 0.013575172218183634, 'config/reg_lambda': 0.7862212118795716, 'experiment_tag': 'exp', 'time_total_s': 0.9884672164916992}\n",
      "[flaml.automl.logger: 09-25 12:39:14] {2391} INFO -  at 410.8s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:14] {2218} INFO - iteration 156, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:39:14] {805} INFO - trial 1 config: {'n_estimators': 81, 'max_features': 0.12059451916998122, 'max_leaves': 232, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:39:19] {197} INFO - result: {'pred_time': 0.00012980840911469755, 'wall_clock_time': 415.88819336891174, 'metric_for_logging': {'pred_time': 0.00012980840911469755}, 'val_loss': 0.20838340358580237, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668050b80>, 'training_iteration': 0, 'config': {'n_estimators': 81, 'max_features': 0.12059451916998122, 'max_leaves': 232, 'criterion': 'gini'}, 'config/n_estimators': 81, 'config/max_features': 0.12059451916998122, 'config/max_leaves': 232, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 5.09635853767395}\n",
      "[flaml.tune.tune: 09-25 12:39:19] {197} INFO - result: {'pred_time': 0.00012980840911469755, 'wall_clock_time': 415.88819336891174, 'metric_for_logging': {'pred_time': 0.00012980840911469755}, 'val_loss': 0.20838340358580237, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668050b80>, 'training_iteration': 1, 'config': {'n_estimators': 81, 'max_features': 0.12059451916998122, 'max_leaves': 232, 'criterion': 'gini'}, 'config/n_estimators': 81, 'config/max_features': 0.12059451916998122, 'config/max_leaves': 232, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 5.097606897354126}\n",
      "[flaml.automl.logger: 09-25 12:39:19] {2391} INFO -  at 415.9s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:19] {2218} INFO - iteration 157, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:39:19] {805} INFO - trial 1 config: {'early_stopping_rounds': 15, 'learning_rate': 0.03780111034356537, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:39:26] {197} INFO - result: {'pred_time': 0.0001332410298950515, 'wall_clock_time': 422.3049817085266, 'metric_for_logging': {'pred_time': 0.0001332410298950515}, 'val_loss': 0.24731961375514597, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe668050b80>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 15, 'learning_rate': 0.03780111034356537, 'n_estimators': 8192}, 'config/early_stopping_rounds': 15, 'config/learning_rate': 0.03780111034356537, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.410376071929932}\n",
      "[flaml.tune.tune: 09-25 12:39:26] {197} INFO - result: {'pred_time': 0.0001332410298950515, 'wall_clock_time': 422.3049817085266, 'metric_for_logging': {'pred_time': 0.0001332410298950515}, 'val_loss': 0.24731961375514597, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe668050b80>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 15, 'learning_rate': 0.03780111034356537, 'n_estimators': 8192}, 'config/early_stopping_rounds': 15, 'config/learning_rate': 0.03780111034356537, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.412339687347412}\n",
      "[flaml.automl.logger: 09-25 12:39:26] {2391} INFO -  at 422.3s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:26] {2218} INFO - iteration 158, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:39:26] {805} INFO - trial 1 config: {'n_estimators': 39, 'max_features': 0.034831906793741964, 'max_leaves': 137, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:39:27] {197} INFO - result: {'pred_time': 7.498633401969826e-05, 'wall_clock_time': 423.74680066108704, 'metric_for_logging': {'pred_time': 7.498633401969826e-05}, 'val_loss': 0.19409732936719443, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524272220>, 'training_iteration': 0, 'config': {'n_estimators': 39, 'max_features': 0.034831906793741964, 'max_leaves': 137, 'criterion': 'entropy'}, 'config/n_estimators': 39, 'config/max_features': 0.034831906793741964, 'config/max_leaves': 137, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.43367600440979}\n",
      "[flaml.tune.tune: 09-25 12:39:27] {197} INFO - result: {'pred_time': 7.498633401969826e-05, 'wall_clock_time': 423.74680066108704, 'metric_for_logging': {'pred_time': 7.498633401969826e-05}, 'val_loss': 0.19409732936719443, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524272220>, 'training_iteration': 1, 'config': {'n_estimators': 39, 'max_features': 0.034831906793741964, 'max_leaves': 137, 'criterion': 'entropy'}, 'config/n_estimators': 39, 'config/max_features': 0.034831906793741964, 'config/max_leaves': 137, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.435499668121338}\n",
      "[flaml.automl.logger: 09-25 12:39:27] {2391} INFO -  at 423.7s,\testimator rf's best error=0.1941,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:27] {2218} INFO - iteration 159, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:39:27] {805} INFO - trial 1 config: {'n_estimators': 26, 'max_features': 0.06268381963181695, 'max_leaves': 86, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:39:29] {197} INFO - result: {'pred_time': 5.992133181031787e-05, 'wall_clock_time': 425.1239185333252, 'metric_for_logging': {'pred_time': 5.992133181031787e-05}, 'val_loss': 0.2162398660337191, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680347c0>, 'training_iteration': 0, 'config': {'n_estimators': 26, 'max_features': 0.06268381963181695, 'max_leaves': 86, 'criterion': 'gini'}, 'config/n_estimators': 26, 'config/max_features': 0.06268381963181695, 'config/max_leaves': 86, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.3674252033233643}\n",
      "[flaml.tune.tune: 09-25 12:39:29] {197} INFO - result: {'pred_time': 5.992133181031787e-05, 'wall_clock_time': 425.1239185333252, 'metric_for_logging': {'pred_time': 5.992133181031787e-05}, 'val_loss': 0.2162398660337191, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680347c0>, 'training_iteration': 1, 'config': {'n_estimators': 26, 'max_features': 0.06268381963181695, 'max_leaves': 86, 'criterion': 'gini'}, 'config/n_estimators': 26, 'config/max_features': 0.06268381963181695, 'config/max_leaves': 86, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.3691716194152832}\n",
      "[flaml.automl.logger: 09-25 12:39:29] {2391} INFO -  at 425.1s,\testimator rf's best error=0.1941,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:29] {2218} INFO - iteration 160, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:39:29] {805} INFO - trial 1 config: {'n_estimators': 113, 'max_leaves': 94, 'min_child_weight': 0.0866958565548343, 'learning_rate': 0.021049716672829222, 'subsample': 0.9225449244414903, 'colsample_bylevel': 0.15760955106626134, 'colsample_bytree': 0.6540228989200387, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5299499894004405}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:39:39] {197} INFO - result: {'pred_time': 4.8260450179348886e-05, 'wall_clock_time': 435.4433891773224, 'metric_for_logging': {'pred_time': 4.8260450179348886e-05}, 'val_loss': 0.2028836283521441, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680347f0>, 'training_iteration': 0, 'config': {'n_estimators': 113, 'max_leaves': 94, 'min_child_weight': 0.0866958565548343, 'learning_rate': 0.021049716672829222, 'subsample': 0.9225449244414903, 'colsample_bylevel': 0.15760955106626134, 'colsample_bytree': 0.6540228989200387, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5299499894004405}, 'config/n_estimators': 113, 'config/max_leaves': 94, 'config/min_child_weight': 0.0866958565548343, 'config/learning_rate': 0.021049716672829222, 'config/subsample': 0.9225449244414903, 'config/colsample_bylevel': 0.15760955106626134, 'config/colsample_bytree': 0.6540228989200387, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5299499894004405, 'experiment_tag': 'exp', 'time_total_s': 10.311922788619995}\n",
      "[flaml.tune.tune: 09-25 12:39:39] {197} INFO - result: {'pred_time': 4.8260450179348886e-05, 'wall_clock_time': 435.4433891773224, 'metric_for_logging': {'pred_time': 4.8260450179348886e-05}, 'val_loss': 0.2028836283521441, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680347f0>, 'training_iteration': 1, 'config': {'n_estimators': 113, 'max_leaves': 94, 'min_child_weight': 0.0866958565548343, 'learning_rate': 0.021049716672829222, 'subsample': 0.9225449244414903, 'colsample_bylevel': 0.15760955106626134, 'colsample_bytree': 0.6540228989200387, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5299499894004405}, 'config/n_estimators': 113, 'config/max_leaves': 94, 'config/min_child_weight': 0.0866958565548343, 'config/learning_rate': 0.021049716672829222, 'config/subsample': 0.9225449244414903, 'config/colsample_bylevel': 0.15760955106626134, 'config/colsample_bytree': 0.6540228989200387, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5299499894004405, 'experiment_tag': 'exp', 'time_total_s': 10.312915563583374}\n",
      "[flaml.automl.logger: 09-25 12:39:39] {2391} INFO -  at 435.4s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:39] {2218} INFO - iteration 161, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:39:39] {805} INFO - trial 1 config: {'n_estimators': 59, 'max_features': 0.032427221756276076, 'max_leaves': 219, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:39:41] {197} INFO - result: {'pred_time': 9.238719764688281e-05, 'wall_clock_time': 437.3302729129791, 'metric_for_logging': {'pred_time': 9.238719764688281e-05}, 'val_loss': 0.20394508220595178, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680343a0>, 'training_iteration': 0, 'config': {'n_estimators': 59, 'max_features': 0.032427221756276076, 'max_leaves': 219, 'criterion': 'entropy'}, 'config/n_estimators': 59, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 219, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.8793363571166992}\n",
      "[flaml.tune.tune: 09-25 12:39:41] {197} INFO - result: {'pred_time': 9.238719764688281e-05, 'wall_clock_time': 437.3302729129791, 'metric_for_logging': {'pred_time': 9.238719764688281e-05}, 'val_loss': 0.20394508220595178, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680343a0>, 'training_iteration': 1, 'config': {'n_estimators': 59, 'max_features': 0.032427221756276076, 'max_leaves': 219, 'criterion': 'entropy'}, 'config/n_estimators': 59, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 219, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.8806238174438477}\n",
      "[flaml.automl.logger: 09-25 12:39:41] {2391} INFO -  at 437.3s,\testimator rf's best error=0.1941,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:41] {2218} INFO - iteration 162, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:39:41] {805} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.046039026666748646, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:39:45] {197} INFO - result: {'pred_time': 0.00010715906926526993, 'wall_clock_time': 441.63434314727783, 'metric_for_logging': {'pred_time': 0.00010715906926526993}, 'val_loss': 0.24671633777705743, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340d2340>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 11, 'learning_rate': 0.046039026666748646, 'n_estimators': 8192}, 'config/early_stopping_rounds': 11, 'config/learning_rate': 0.046039026666748646, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.29654335975647}\n",
      "[flaml.tune.tune: 09-25 12:39:45] {197} INFO - result: {'pred_time': 0.00010715906926526993, 'wall_clock_time': 441.63434314727783, 'metric_for_logging': {'pred_time': 0.00010715906926526993}, 'val_loss': 0.24671633777705743, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340d2340>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 11, 'learning_rate': 0.046039026666748646, 'n_estimators': 8192}, 'config/early_stopping_rounds': 11, 'config/learning_rate': 0.046039026666748646, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.297788143157959}\n",
      "[flaml.automl.logger: 09-25 12:39:45] {2391} INFO -  at 441.6s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:45] {2218} INFO - iteration 163, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:39:45] {805} INFO - trial 1 config: {'n_estimators': 18, 'max_features': 0.04252945653187767, 'max_leaves': 152, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:39:46] {197} INFO - result: {'pred_time': 4.205328568378423e-05, 'wall_clock_time': 442.5034122467041, 'metric_for_logging': {'pred_time': 4.205328568378423e-05}, 'val_loss': 0.2355686631736107, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340a4ac0>, 'training_iteration': 0, 'config': {'n_estimators': 18, 'max_features': 0.04252945653187767, 'max_leaves': 152, 'criterion': 'entropy'}, 'config/n_estimators': 18, 'config/max_features': 0.04252945653187767, 'config/max_leaves': 152, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.862382173538208}\n",
      "[flaml.tune.tune: 09-25 12:39:46] {197} INFO - result: {'pred_time': 4.205328568378423e-05, 'wall_clock_time': 442.5034122467041, 'metric_for_logging': {'pred_time': 4.205328568378423e-05}, 'val_loss': 0.2355686631736107, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340a4ac0>, 'training_iteration': 1, 'config': {'n_estimators': 18, 'max_features': 0.04252945653187767, 'max_leaves': 152, 'criterion': 'entropy'}, 'config/n_estimators': 18, 'config/max_features': 0.04252945653187767, 'config/max_leaves': 152, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.8637468814849854}\n",
      "[flaml.automl.logger: 09-25 12:39:46] {2391} INFO -  at 442.5s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:46] {2218} INFO - iteration 164, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:39:46] {805} INFO - trial 1 config: {'n_estimators': 57, 'max_features': 0.05589596391096185, 'max_leaves': 65, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:39:48] {197} INFO - result: {'pred_time': 9.142144551620156e-05, 'wall_clock_time': 444.2051978111267, 'metric_for_logging': {'pred_time': 9.142144551620156e-05}, 'val_loss': 0.21075416034186642, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe53409e940>, 'training_iteration': 0, 'config': {'n_estimators': 57, 'max_features': 0.05589596391096185, 'max_leaves': 65, 'criterion': 'entropy'}, 'config/n_estimators': 57, 'config/max_features': 0.05589596391096185, 'config/max_leaves': 65, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.6950395107269287}\n",
      "[flaml.tune.tune: 09-25 12:39:48] {197} INFO - result: {'pred_time': 9.142144551620156e-05, 'wall_clock_time': 444.2051978111267, 'metric_for_logging': {'pred_time': 9.142144551620156e-05}, 'val_loss': 0.21075416034186642, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe53409e940>, 'training_iteration': 1, 'config': {'n_estimators': 57, 'max_features': 0.05589596391096185, 'max_leaves': 65, 'criterion': 'entropy'}, 'config/n_estimators': 57, 'config/max_features': 0.05589596391096185, 'config/max_leaves': 65, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.6964442729949951}\n",
      "[flaml.automl.logger: 09-25 12:39:48] {2391} INFO -  at 444.2s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:48] {2218} INFO - iteration 165, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:39:48] {805} INFO - trial 1 config: {'n_estimators': 116, 'max_features': 0.04540129520675255, 'max_leaves': 108, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:39:51] {197} INFO - result: {'pred_time': 0.00016413915112104476, 'wall_clock_time': 447.625013589859, 'metric_for_logging': {'pred_time': 0.00016413915112104476}, 'val_loss': 0.1897455205176345, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe53409e940>, 'training_iteration': 0, 'config': {'n_estimators': 116, 'max_features': 0.04540129520675255, 'max_leaves': 108, 'criterion': 'entropy'}, 'config/n_estimators': 116, 'config/max_features': 0.04540129520675255, 'config/max_leaves': 108, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.4133598804473877}\n",
      "[flaml.tune.tune: 09-25 12:39:51] {197} INFO - result: {'pred_time': 0.00016413915112104476, 'wall_clock_time': 447.625013589859, 'metric_for_logging': {'pred_time': 0.00016413915112104476}, 'val_loss': 0.1897455205176345, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe53409e940>, 'training_iteration': 1, 'config': {'n_estimators': 116, 'max_features': 0.04540129520675255, 'max_leaves': 108, 'criterion': 'entropy'}, 'config/n_estimators': 116, 'config/max_features': 0.04540129520675255, 'config/max_leaves': 108, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.4154491424560547}\n",
      "[flaml.automl.logger: 09-25 12:39:51] {2391} INFO -  at 447.6s,\testimator rf's best error=0.1897,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:51] {2218} INFO - iteration 166, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:39:51] {805} INFO - trial 1 config: {'n_estimators': 39, 'max_features': 0.034831906793741964, 'max_leaves': 137, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:39:53] {197} INFO - result: {'pred_time': 7.322157959488388e-05, 'wall_clock_time': 449.0900993347168, 'metric_for_logging': {'pred_time': 7.322157959488388e-05}, 'val_loss': 0.19942314012778778, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680557c0>, 'training_iteration': 0, 'config': {'n_estimators': 39, 'max_features': 0.034831906793741964, 'max_leaves': 137, 'criterion': 'gini'}, 'config/n_estimators': 39, 'config/max_features': 0.034831906793741964, 'config/max_leaves': 137, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.4573557376861572}\n",
      "[flaml.tune.tune: 09-25 12:39:53] {197} INFO - result: {'pred_time': 7.322157959488388e-05, 'wall_clock_time': 449.0900993347168, 'metric_for_logging': {'pred_time': 7.322157959488388e-05}, 'val_loss': 0.19942314012778778, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680557c0>, 'training_iteration': 1, 'config': {'n_estimators': 39, 'max_features': 0.034831906793741964, 'max_leaves': 137, 'criterion': 'gini'}, 'config/n_estimators': 39, 'config/max_features': 0.034831906793741964, 'config/max_leaves': 137, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.4586191177368164}\n",
      "[flaml.automl.logger: 09-25 12:39:53] {2391} INFO -  at 449.1s,\testimator rf's best error=0.1897,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:53] {2218} INFO - iteration 167, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:39:53] {805} INFO - trial 1 config: {'n_estimators': 70, 'max_features': 0.033688695537180506, 'max_leaves': 126, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:39:55] {197} INFO - result: {'pred_time': 0.00010565589000682352, 'wall_clock_time': 451.3396751880646, 'metric_for_logging': {'pred_time': 0.00010565589000682352}, 'val_loss': 0.18891791976499622, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668055a60>, 'training_iteration': 0, 'config': {'n_estimators': 70, 'max_features': 0.033688695537180506, 'max_leaves': 126, 'criterion': 'entropy'}, 'config/n_estimators': 70, 'config/max_features': 0.033688695537180506, 'config/max_leaves': 126, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.2417819499969482}\n",
      "[flaml.tune.tune: 09-25 12:39:55] {197} INFO - result: {'pred_time': 0.00010565589000682352, 'wall_clock_time': 451.3396751880646, 'metric_for_logging': {'pred_time': 0.00010565589000682352}, 'val_loss': 0.18891791976499622, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668055a60>, 'training_iteration': 1, 'config': {'n_estimators': 70, 'max_features': 0.033688695537180506, 'max_leaves': 126, 'criterion': 'entropy'}, 'config/n_estimators': 70, 'config/max_features': 0.033688695537180506, 'config/max_leaves': 126, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.243496894836426}\n",
      "[flaml.automl.logger: 09-25 12:39:55] {2391} INFO -  at 451.3s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:55] {2218} INFO - iteration 168, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:39:55] {805} INFO - trial 1 config: {'early_stopping_rounds': 15, 'learning_rate': 0.036748255746789235, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:39:59] {197} INFO - result: {'pred_time': 0.00010928100265520132, 'wall_clock_time': 455.59358525276184, 'metric_for_logging': {'pred_time': 0.00010928100265520132}, 'val_loss': 0.2496260012751767, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe66803cd60>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 15, 'learning_rate': 0.036748255746789235, 'n_estimators': 8192}, 'config/early_stopping_rounds': 15, 'config/learning_rate': 0.036748255746789235, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.2460527420043945}\n",
      "[flaml.tune.tune: 09-25 12:39:59] {197} INFO - result: {'pred_time': 0.00010928100265520132, 'wall_clock_time': 455.59358525276184, 'metric_for_logging': {'pred_time': 0.00010928100265520132}, 'val_loss': 0.2496260012751767, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe66803cd60>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 15, 'learning_rate': 0.036748255746789235, 'n_estimators': 8192}, 'config/early_stopping_rounds': 15, 'config/learning_rate': 0.036748255746789235, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.247440338134766}\n",
      "[flaml.automl.logger: 09-25 12:39:59] {2391} INFO -  at 455.6s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:39:59] {2218} INFO - iteration 169, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:39:59] {805} INFO - trial 1 config: {'n_estimators': 116, 'max_features': 0.04540129520675254, 'max_leaves': 108, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:40:03] {197} INFO - result: {'pred_time': 0.00016504824423620854, 'wall_clock_time': 459.1099693775177, 'metric_for_logging': {'pred_time': 0.00016504824423620854}, 'val_loss': 0.2048616414246099, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe53409e280>, 'training_iteration': 0, 'config': {'n_estimators': 116, 'max_features': 0.04540129520675254, 'max_leaves': 108, 'criterion': 'gini'}, 'config/n_estimators': 116, 'config/max_features': 0.04540129520675254, 'config/max_leaves': 108, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.506991386413574}\n",
      "[flaml.tune.tune: 09-25 12:40:03] {197} INFO - result: {'pred_time': 0.00016504824423620854, 'wall_clock_time': 459.1099693775177, 'metric_for_logging': {'pred_time': 0.00016504824423620854}, 'val_loss': 0.2048616414246099, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe53409e280>, 'training_iteration': 1, 'config': {'n_estimators': 116, 'max_features': 0.04540129520675254, 'max_leaves': 108, 'criterion': 'gini'}, 'config/n_estimators': 116, 'config/max_features': 0.04540129520675254, 'config/max_leaves': 108, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.5083155632019043}\n",
      "[flaml.automl.logger: 09-25 12:40:03] {2391} INFO -  at 459.1s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:03] {2218} INFO - iteration 170, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:40:03] {805} INFO - trial 1 config: {'n_estimators': 31, 'num_leaves': 38, 'min_child_samples': 8, 'learning_rate': 0.15563589106848513, 'log_max_bin': 8, 'colsample_bytree': 0.6744538218227226, 'reg_alpha': 0.001035184753971376, 'reg_lambda': 12.989262104155147}\n",
      "[flaml.tune.tune: 09-25 12:40:03] {197} INFO - result: {'pred_time': 1.110008944365773e-05, 'wall_clock_time': 459.77997159957886, 'metric_for_logging': {'pred_time': 1.110008944365773e-05}, 'val_loss': 0.22637190154056724, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe53409eb80>, 'training_iteration': 0, 'config': {'n_estimators': 31, 'num_leaves': 38, 'min_child_samples': 8, 'learning_rate': 0.15563589106848513, 'log_max_bin': 8, 'colsample_bytree': 0.6744538218227226, 'reg_alpha': 0.001035184753971376, 'reg_lambda': 12.989262104155147}, 'config/n_estimators': 31, 'config/num_leaves': 38, 'config/min_child_samples': 8, 'config/learning_rate': 0.15563589106848513, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.6744538218227226, 'config/reg_alpha': 0.001035184753971376, 'config/reg_lambda': 12.989262104155147, 'experiment_tag': 'exp', 'time_total_s': 0.6626927852630615}\n",
      "[flaml.tune.tune: 09-25 12:40:03] {197} INFO - result: {'pred_time': 1.110008944365773e-05, 'wall_clock_time': 459.77997159957886, 'metric_for_logging': {'pred_time': 1.110008944365773e-05}, 'val_loss': 0.22637190154056724, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe53409eb80>, 'training_iteration': 1, 'config': {'n_estimators': 31, 'num_leaves': 38, 'min_child_samples': 8, 'learning_rate': 0.15563589106848513, 'log_max_bin': 8, 'colsample_bytree': 0.6744538218227226, 'reg_alpha': 0.001035184753971376, 'reg_lambda': 12.989262104155147}, 'config/n_estimators': 31, 'config/num_leaves': 38, 'config/min_child_samples': 8, 'config/learning_rate': 0.15563589106848513, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.6744538218227226, 'config/reg_alpha': 0.001035184753971376, 'config/reg_lambda': 12.989262104155147, 'experiment_tag': 'exp', 'time_total_s': 0.6641404628753662}\n",
      "[flaml.automl.logger: 09-25 12:40:03] {2391} INFO -  at 459.8s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:03] {2218} INFO - iteration 171, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:40:03] {805} INFO - trial 1 config: {'n_estimators': 149, 'max_features': 0.05672873033101733, 'max_leaves': 155, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:40:08] {197} INFO - result: {'pred_time': 0.00021416965389532876, 'wall_clock_time': 464.5896027088165, 'metric_for_logging': {'pred_time': 0.00021416965389532876}, 'val_loss': 0.19508857404284696, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524143be0>, 'training_iteration': 0, 'config': {'n_estimators': 149, 'max_features': 0.05672873033101733, 'max_leaves': 155, 'criterion': 'gini'}, 'config/n_estimators': 149, 'config/max_features': 0.05672873033101733, 'config/max_leaves': 155, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 4.80269718170166}\n",
      "[flaml.tune.tune: 09-25 12:40:08] {197} INFO - result: {'pred_time': 0.00021416965389532876, 'wall_clock_time': 464.5896027088165, 'metric_for_logging': {'pred_time': 0.00021416965389532876}, 'val_loss': 0.19508857404284696, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524143be0>, 'training_iteration': 1, 'config': {'n_estimators': 149, 'max_features': 0.05672873033101733, 'max_leaves': 155, 'criterion': 'gini'}, 'config/n_estimators': 149, 'config/max_features': 0.05672873033101733, 'config/max_leaves': 155, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 4.804124593734741}\n",
      "[flaml.automl.logger: 09-25 12:40:08] {2391} INFO -  at 464.6s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:08] {2218} INFO - iteration 172, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:40:08] {805} INFO - trial 1 config: {'n_estimators': 33, 'max_features': 0.032427221756276076, 'max_leaves': 102, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:40:09] {197} INFO - result: {'pred_time': 5.90218214001287e-05, 'wall_clock_time': 465.82931780815125, 'metric_for_logging': {'pred_time': 5.90218214001287e-05}, 'val_loss': 0.20982171769278213, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe52433cfa0>, 'training_iteration': 0, 'config': {'n_estimators': 33, 'max_features': 0.032427221756276076, 'max_leaves': 102, 'criterion': 'entropy'}, 'config/n_estimators': 33, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 102, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2330443859100342}\n",
      "[flaml.tune.tune: 09-25 12:40:09] {197} INFO - result: {'pred_time': 5.90218214001287e-05, 'wall_clock_time': 465.82931780815125, 'metric_for_logging': {'pred_time': 5.90218214001287e-05}, 'val_loss': 0.20982171769278213, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe52433cfa0>, 'training_iteration': 1, 'config': {'n_estimators': 33, 'max_features': 0.032427221756276076, 'max_leaves': 102, 'criterion': 'entropy'}, 'config/n_estimators': 33, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 102, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2343249320983887}\n",
      "[flaml.automl.logger: 09-25 12:40:09] {2391} INFO -  at 465.8s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:09] {2218} INFO - iteration 173, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:40:09] {805} INFO - trial 1 config: {'n_estimators': 105, 'max_features': 0.032427221756276076, 'max_leaves': 44, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:40:12] {197} INFO - result: {'pred_time': 0.00014302601107976648, 'wall_clock_time': 468.82063722610474, 'metric_for_logging': {'pred_time': 0.00014302601107976648}, 'val_loss': 0.20366460047869345, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524349df0>, 'training_iteration': 0, 'config': {'n_estimators': 105, 'max_features': 0.032427221756276076, 'max_leaves': 44, 'criterion': 'entropy'}, 'config/n_estimators': 105, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 44, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.9838814735412598}\n",
      "[flaml.tune.tune: 09-25 12:40:12] {197} INFO - result: {'pred_time': 0.00014302601107976648, 'wall_clock_time': 468.82063722610474, 'metric_for_logging': {'pred_time': 0.00014302601107976648}, 'val_loss': 0.20366460047869345, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524349df0>, 'training_iteration': 1, 'config': {'n_estimators': 105, 'max_features': 0.032427221756276076, 'max_leaves': 44, 'criterion': 'entropy'}, 'config/n_estimators': 105, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 44, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.985217332839966}\n",
      "[flaml.automl.logger: 09-25 12:40:12] {2391} INFO -  at 468.8s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:12] {2218} INFO - iteration 174, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:40:12] {805} INFO - trial 1 config: {'n_estimators': 47, 'max_features': 0.04316308194567988, 'max_leaves': 362, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:40:14] {197} INFO - result: {'pred_time': 8.007770601228299e-05, 'wall_clock_time': 470.59812593460083, 'metric_for_logging': {'pred_time': 8.007770601228299e-05}, 'val_loss': 0.21278368525370026, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe53409e490>, 'training_iteration': 0, 'config': {'n_estimators': 47, 'max_features': 0.04316308194567988, 'max_leaves': 362, 'criterion': 'gini'}, 'config/n_estimators': 47, 'config/max_features': 0.04316308194567988, 'config/max_leaves': 362, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.7708489894866943}\n",
      "[flaml.tune.tune: 09-25 12:40:14] {197} INFO - result: {'pred_time': 8.007770601228299e-05, 'wall_clock_time': 470.59812593460083, 'metric_for_logging': {'pred_time': 8.007770601228299e-05}, 'val_loss': 0.21278368525370026, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe53409e490>, 'training_iteration': 1, 'config': {'n_estimators': 47, 'max_features': 0.04316308194567988, 'max_leaves': 362, 'criterion': 'gini'}, 'config/n_estimators': 47, 'config/max_features': 0.04316308194567988, 'config/max_leaves': 362, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.7720952033996582}\n",
      "[flaml.automl.logger: 09-25 12:40:14] {2391} INFO -  at 470.6s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:14] {2218} INFO - iteration 175, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:40:14] {805} INFO - trial 1 config: {'n_estimators': 128, 'max_features': 0.04225632244929247, 'max_leaves': 306, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:40:18] {197} INFO - result: {'pred_time': 0.00018122377190612127, 'wall_clock_time': 474.62741208076477, 'metric_for_logging': {'pred_time': 0.00018122377190612127}, 'val_loss': 0.19952584778296925, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe53409e910>, 'training_iteration': 0, 'config': {'n_estimators': 128, 'max_features': 0.04225632244929247, 'max_leaves': 306, 'criterion': 'entropy'}, 'config/n_estimators': 128, 'config/max_features': 0.04225632244929247, 'config/max_leaves': 306, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 4.022369623184204}\n",
      "[flaml.tune.tune: 09-25 12:40:18] {197} INFO - result: {'pred_time': 0.00018122377190612127, 'wall_clock_time': 474.62741208076477, 'metric_for_logging': {'pred_time': 0.00018122377190612127}, 'val_loss': 0.19952584778296925, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe53409e910>, 'training_iteration': 1, 'config': {'n_estimators': 128, 'max_features': 0.04225632244929247, 'max_leaves': 306, 'criterion': 'entropy'}, 'config/n_estimators': 128, 'config/max_features': 0.04225632244929247, 'config/max_leaves': 306, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 4.023607969284058}\n",
      "[flaml.automl.logger: 09-25 12:40:18] {2391} INFO -  at 474.6s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:18] {2218} INFO - iteration 176, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:40:18] {805} INFO - trial 1 config: {'n_estimators': 25, 'max_features': 0.09175652412385689, 'max_leaves': 541, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:40:20] {197} INFO - result: {'pred_time': 5.490453922864163e-05, 'wall_clock_time': 476.4403591156006, 'metric_for_logging': {'pred_time': 5.490453922864163e-05}, 'val_loss': 0.25989358924141526, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52434cc70>, 'training_iteration': 0, 'config': {'n_estimators': 25, 'max_features': 0.09175652412385689, 'max_leaves': 541, 'criterion': 'gini'}, 'config/n_estimators': 25, 'config/max_features': 0.09175652412385689, 'config/max_leaves': 541, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.8068201541900635}\n",
      "[flaml.tune.tune: 09-25 12:40:20] {197} INFO - result: {'pred_time': 5.490453922864163e-05, 'wall_clock_time': 476.4403591156006, 'metric_for_logging': {'pred_time': 5.490453922864163e-05}, 'val_loss': 0.25989358924141526, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52434cc70>, 'training_iteration': 1, 'config': {'n_estimators': 25, 'max_features': 0.09175652412385689, 'max_leaves': 541, 'criterion': 'gini'}, 'config/n_estimators': 25, 'config/max_features': 0.09175652412385689, 'config/max_leaves': 541, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.8081927299499512}\n",
      "[flaml.automl.logger: 09-25 12:40:20] {2391} INFO -  at 476.4s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:20] {2218} INFO - iteration 177, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:40:20] {805} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.04735806616596135, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:40:25] {197} INFO - result: {'pred_time': 0.00010714767081015182, 'wall_clock_time': 481.58285784721375, 'metric_for_logging': {'pred_time': 0.00010714767081015182}, 'val_loss': 0.23958163416559222, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe524338730>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 11, 'learning_rate': 0.04735806616596135, 'n_estimators': 8192}, 'config/early_stopping_rounds': 11, 'config/learning_rate': 0.04735806616596135, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.135153293609619}\n",
      "[flaml.tune.tune: 09-25 12:40:25] {197} INFO - result: {'pred_time': 0.00010714767081015182, 'wall_clock_time': 481.58285784721375, 'metric_for_logging': {'pred_time': 0.00010714767081015182}, 'val_loss': 0.23958163416559222, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe524338730>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 11, 'learning_rate': 0.04735806616596135, 'n_estimators': 8192}, 'config/early_stopping_rounds': 11, 'config/learning_rate': 0.04735806616596135, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.136646270751953}\n",
      "[flaml.automl.logger: 09-25 12:40:25] {2391} INFO -  at 481.6s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:25] {2218} INFO - iteration 178, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:40:25] {805} INFO - trial 1 config: {'n_estimators': 38, 'max_features': 0.032427221756276076, 'max_leaves': 52, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:40:26] {197} INFO - result: {'pred_time': 6.476430672630609e-05, 'wall_clock_time': 482.85073041915894, 'metric_for_logging': {'pred_time': 6.476430672630609e-05}, 'val_loss': 0.21772758371334083, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe534070310>, 'training_iteration': 0, 'config': {'n_estimators': 38, 'max_features': 0.032427221756276076, 'max_leaves': 52, 'criterion': 'gini'}, 'config/n_estimators': 38, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 52, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.2612578868865967}\n",
      "[flaml.tune.tune: 09-25 12:40:26] {197} INFO - result: {'pred_time': 6.476430672630609e-05, 'wall_clock_time': 482.85073041915894, 'metric_for_logging': {'pred_time': 6.476430672630609e-05}, 'val_loss': 0.21772758371334083, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe534070310>, 'training_iteration': 1, 'config': {'n_estimators': 38, 'max_features': 0.032427221756276076, 'max_leaves': 52, 'criterion': 'gini'}, 'config/n_estimators': 38, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 52, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.2624990940093994}\n",
      "[flaml.automl.logger: 09-25 12:40:26] {2391} INFO -  at 482.9s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:26] {2218} INFO - iteration 179, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:40:26] {805} INFO - trial 1 config: {'early_stopping_rounds': 14, 'learning_rate': 0.05021144611777528, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:40:32] {197} INFO - result: {'pred_time': 7.853393183446123e-05, 'wall_clock_time': 488.25477600097656, 'metric_for_logging': {'pred_time': 7.853393183446123e-05}, 'val_loss': 0.23671741745205016, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe534070e80>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 14, 'learning_rate': 0.05021144611777528, 'n_estimators': 8192}, 'config/early_stopping_rounds': 14, 'config/learning_rate': 0.05021144611777528, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.396994352340698}\n",
      "[flaml.tune.tune: 09-25 12:40:32] {197} INFO - result: {'pred_time': 7.853393183446123e-05, 'wall_clock_time': 488.25477600097656, 'metric_for_logging': {'pred_time': 7.853393183446123e-05}, 'val_loss': 0.23671741745205016, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe534070e80>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 14, 'learning_rate': 0.05021144611777528, 'n_estimators': 8192}, 'config/early_stopping_rounds': 14, 'config/learning_rate': 0.05021144611777528, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.3982179164886475}\n",
      "[flaml.automl.logger: 09-25 12:40:32] {2391} INFO -  at 488.3s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:32] {2218} INFO - iteration 180, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:40:32] {805} INFO - trial 1 config: {'n_estimators': 70, 'max_features': 0.08982892544799043, 'max_leaves': 456, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:40:35] {197} INFO - result: {'pred_time': 0.00012034126539567781, 'wall_clock_time': 491.61340165138245, 'metric_for_logging': {'pred_time': 0.00012034126539567781}, 'val_loss': 0.21837212457527294, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340c5ee0>, 'training_iteration': 0, 'config': {'n_estimators': 70, 'max_features': 0.08982892544799043, 'max_leaves': 456, 'criterion': 'entropy'}, 'config/n_estimators': 70, 'config/max_features': 0.08982892544799043, 'config/max_leaves': 456, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.3506295680999756}\n",
      "[flaml.tune.tune: 09-25 12:40:35] {197} INFO - result: {'pred_time': 0.00012034126539567781, 'wall_clock_time': 491.61340165138245, 'metric_for_logging': {'pred_time': 0.00012034126539567781}, 'val_loss': 0.21837212457527294, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340c5ee0>, 'training_iteration': 1, 'config': {'n_estimators': 70, 'max_features': 0.08982892544799043, 'max_leaves': 456, 'criterion': 'entropy'}, 'config/n_estimators': 70, 'config/max_features': 0.08982892544799043, 'config/max_leaves': 456, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.352083921432495}\n",
      "[flaml.automl.logger: 09-25 12:40:35] {2391} INFO -  at 491.6s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:35] {2218} INFO - iteration 181, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:40:35] {805} INFO - trial 1 config: {'n_estimators': 170, 'max_leaves': 197, 'min_child_weight': 0.8461281263533346, 'learning_rate': 0.11132924905415667, 'subsample': 0.7321577925942058, 'colsample_bylevel': 0.5517647244731693, 'colsample_bytree': 0.5972375072707348, 'reg_alpha': 0.0028599691201832457, 'reg_lambda': 3.506012087065385}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:40:52] {197} INFO - result: {'pred_time': 4.8656166866405245e-05, 'wall_clock_time': 508.90710639953613, 'metric_for_logging': {'pred_time': 4.8656166866405245e-05}, 'val_loss': 0.20202538197290823, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680b9c40>, 'training_iteration': 0, 'config': {'n_estimators': 170, 'max_leaves': 197, 'min_child_weight': 0.8461281263533346, 'learning_rate': 0.11132924905415667, 'subsample': 0.7321577925942058, 'colsample_bylevel': 0.5517647244731693, 'colsample_bytree': 0.5972375072707348, 'reg_alpha': 0.0028599691201832457, 'reg_lambda': 3.506012087065385}, 'config/n_estimators': 170, 'config/max_leaves': 197, 'config/min_child_weight': 0.8461281263533346, 'config/learning_rate': 0.11132924905415667, 'config/subsample': 0.7321577925942058, 'config/colsample_bylevel': 0.5517647244731693, 'config/colsample_bytree': 0.5972375072707348, 'config/reg_alpha': 0.0028599691201832457, 'config/reg_lambda': 3.506012087065385, 'experiment_tag': 'exp', 'time_total_s': 17.28697395324707}\n",
      "[flaml.tune.tune: 09-25 12:40:52] {197} INFO - result: {'pred_time': 4.8656166866405245e-05, 'wall_clock_time': 508.90710639953613, 'metric_for_logging': {'pred_time': 4.8656166866405245e-05}, 'val_loss': 0.20202538197290823, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680b9c40>, 'training_iteration': 1, 'config': {'n_estimators': 170, 'max_leaves': 197, 'min_child_weight': 0.8461281263533346, 'learning_rate': 0.11132924905415667, 'subsample': 0.7321577925942058, 'colsample_bylevel': 0.5517647244731693, 'colsample_bytree': 0.5972375072707348, 'reg_alpha': 0.0028599691201832457, 'reg_lambda': 3.506012087065385}, 'config/n_estimators': 170, 'config/max_leaves': 197, 'config/min_child_weight': 0.8461281263533346, 'config/learning_rate': 0.11132924905415667, 'config/subsample': 0.7321577925942058, 'config/colsample_bylevel': 0.5517647244731693, 'config/colsample_bytree': 0.5972375072707348, 'config/reg_alpha': 0.0028599691201832457, 'config/reg_lambda': 3.506012087065385, 'experiment_tag': 'exp', 'time_total_s': 17.288249492645264}\n",
      "[flaml.automl.logger: 09-25 12:40:52] {2391} INFO -  at 508.9s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:52] {2218} INFO - iteration 182, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:40:52] {805} INFO - trial 1 config: {'n_estimators': 91, 'max_features': 0.032427221756276076, 'max_leaves': 114, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:40:55] {197} INFO - result: {'pred_time': 0.00012915541500460562, 'wall_clock_time': 511.68486309051514, 'metric_for_logging': {'pred_time': 0.00012915541500460562}, 'val_loss': 0.19561283114506506, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680b9fd0>, 'training_iteration': 0, 'config': {'n_estimators': 91, 'max_features': 0.032427221756276076, 'max_leaves': 114, 'criterion': 'gini'}, 'config/n_estimators': 91, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 114, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.771711826324463}\n",
      "[flaml.tune.tune: 09-25 12:40:55] {197} INFO - result: {'pred_time': 0.00012915541500460562, 'wall_clock_time': 511.68486309051514, 'metric_for_logging': {'pred_time': 0.00012915541500460562}, 'val_loss': 0.19561283114506506, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680b9fd0>, 'training_iteration': 1, 'config': {'n_estimators': 91, 'max_features': 0.032427221756276076, 'max_leaves': 114, 'criterion': 'gini'}, 'config/n_estimators': 91, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 114, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.7734341621398926}\n",
      "[flaml.automl.logger: 09-25 12:40:55] {2391} INFO -  at 511.7s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:55] {2218} INFO - iteration 183, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:40:55] {805} INFO - trial 1 config: {'n_estimators': 260, 'num_leaves': 128, 'min_child_samples': 6, 'learning_rate': 0.2691501753377718, 'log_max_bin': 10, 'colsample_bytree': 0.8755280693793583, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.13399521259460387}\n",
      "[flaml.tune.tune: 09-25 12:40:59] {197} INFO - result: {'pred_time': 1.9942796429690294e-05, 'wall_clock_time': 515.5593845844269, 'metric_for_logging': {'pred_time': 1.9942796429690294e-05}, 'val_loss': 0.2047763800012675, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe668034400>, 'training_iteration': 0, 'config': {'n_estimators': 260, 'num_leaves': 128, 'min_child_samples': 6, 'learning_rate': 0.2691501753377718, 'log_max_bin': 10, 'colsample_bytree': 0.8755280693793583, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.13399521259460387}, 'config/n_estimators': 260, 'config/num_leaves': 128, 'config/min_child_samples': 6, 'config/learning_rate': 0.2691501753377718, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8755280693793583, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.13399521259460387, 'experiment_tag': 'exp', 'time_total_s': 3.8663952350616455}\n",
      "[flaml.tune.tune: 09-25 12:40:59] {197} INFO - result: {'pred_time': 1.9942796429690294e-05, 'wall_clock_time': 515.5593845844269, 'metric_for_logging': {'pred_time': 1.9942796429690294e-05}, 'val_loss': 0.2047763800012675, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe668034400>, 'training_iteration': 1, 'config': {'n_estimators': 260, 'num_leaves': 128, 'min_child_samples': 6, 'learning_rate': 0.2691501753377718, 'log_max_bin': 10, 'colsample_bytree': 0.8755280693793583, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.13399521259460387}, 'config/n_estimators': 260, 'config/num_leaves': 128, 'config/min_child_samples': 6, 'config/learning_rate': 0.2691501753377718, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.8755280693793583, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.13399521259460387, 'experiment_tag': 'exp', 'time_total_s': 3.8676979541778564}\n",
      "[flaml.automl.logger: 09-25 12:40:59] {2391} INFO -  at 515.6s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:40:59] {2218} INFO - iteration 184, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:40:59] {805} INFO - trial 1 config: {'n_estimators': 54, 'max_features': 0.05254516063517704, 'max_leaves': 139, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:41:01] {197} INFO - result: {'pred_time': 8.847824560228932e-05, 'wall_clock_time': 517.4858756065369, 'metric_for_logging': {'pred_time': 8.847824560228932e-05}, 'val_loss': 0.19608520410619362, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680ca3a0>, 'training_iteration': 0, 'config': {'n_estimators': 54, 'max_features': 0.05254516063517704, 'max_leaves': 139, 'criterion': 'entropy'}, 'config/n_estimators': 54, 'config/max_features': 0.05254516063517704, 'config/max_leaves': 139, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.9180829524993896}\n",
      "[flaml.tune.tune: 09-25 12:41:01] {197} INFO - result: {'pred_time': 8.847824560228932e-05, 'wall_clock_time': 517.4858756065369, 'metric_for_logging': {'pred_time': 8.847824560228932e-05}, 'val_loss': 0.19608520410619362, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680ca3a0>, 'training_iteration': 1, 'config': {'n_estimators': 54, 'max_features': 0.05254516063517704, 'max_leaves': 139, 'criterion': 'entropy'}, 'config/n_estimators': 54, 'config/max_features': 0.05254516063517704, 'config/max_leaves': 139, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.9194519519805908}\n",
      "[flaml.automl.logger: 09-25 12:41:01] {2391} INFO -  at 517.5s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:41:01] {2218} INFO - iteration 185, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:41:01] {805} INFO - trial 1 config: {'n_estimators': 41, 'max_leaves': 133, 'min_child_weight': 0.1400017906783948, 'learning_rate': 0.10170648341587941, 'subsample': 0.7758468992658346, 'colsample_bylevel': 0.24556128001058317, 'colsample_bytree': 0.5053608424032824, 'reg_alpha': 0.0037353858748974938, 'reg_lambda': 3.0222918334131723}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:41:06] {197} INFO - result: {'pred_time': 4.417799433207417e-05, 'wall_clock_time': 522.3651509284973, 'metric_for_logging': {'pred_time': 4.417799433207417e-05}, 'val_loss': 0.197085245492292, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5340c5850>, 'training_iteration': 0, 'config': {'n_estimators': 41, 'max_leaves': 133, 'min_child_weight': 0.1400017906783948, 'learning_rate': 0.10170648341587941, 'subsample': 0.7758468992658346, 'colsample_bylevel': 0.24556128001058317, 'colsample_bytree': 0.5053608424032824, 'reg_alpha': 0.0037353858748974938, 'reg_lambda': 3.0222918334131723}, 'config/n_estimators': 41, 'config/max_leaves': 133, 'config/min_child_weight': 0.1400017906783948, 'config/learning_rate': 0.10170648341587941, 'config/subsample': 0.7758468992658346, 'config/colsample_bylevel': 0.24556128001058317, 'config/colsample_bytree': 0.5053608424032824, 'config/reg_alpha': 0.0037353858748974938, 'config/reg_lambda': 3.0222918334131723, 'experiment_tag': 'exp', 'time_total_s': 4.871018886566162}\n",
      "[flaml.tune.tune: 09-25 12:41:06] {197} INFO - result: {'pred_time': 4.417799433207417e-05, 'wall_clock_time': 522.3651509284973, 'metric_for_logging': {'pred_time': 4.417799433207417e-05}, 'val_loss': 0.197085245492292, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5340c5850>, 'training_iteration': 1, 'config': {'n_estimators': 41, 'max_leaves': 133, 'min_child_weight': 0.1400017906783948, 'learning_rate': 0.10170648341587941, 'subsample': 0.7758468992658346, 'colsample_bylevel': 0.24556128001058317, 'colsample_bytree': 0.5053608424032824, 'reg_alpha': 0.0037353858748974938, 'reg_lambda': 3.0222918334131723}, 'config/n_estimators': 41, 'config/max_leaves': 133, 'config/min_child_weight': 0.1400017906783948, 'config/learning_rate': 0.10170648341587941, 'config/subsample': 0.7758468992658346, 'config/colsample_bylevel': 0.24556128001058317, 'config/colsample_bytree': 0.5053608424032824, 'config/reg_alpha': 0.0037353858748974938, 'config/reg_lambda': 3.0222918334131723, 'experiment_tag': 'exp', 'time_total_s': 4.872289419174194}\n",
      "[flaml.automl.logger: 09-25 12:41:06] {2391} INFO -  at 522.4s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:41:06] {2218} INFO - iteration 186, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:41:06] {805} INFO - trial 1 config: {'n_estimators': 56, 'max_features': 0.06499445935745328, 'max_leaves': 143, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:41:08] {197} INFO - result: {'pred_time': 9.575081992178263e-05, 'wall_clock_time': 524.5605609416962, 'metric_for_logging': {'pred_time': 9.575081992178263e-05}, 'val_loss': 0.19933132013341914, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668034ac0>, 'training_iteration': 0, 'config': {'n_estimators': 56, 'max_features': 0.06499445935745328, 'max_leaves': 143, 'criterion': 'entropy'}, 'config/n_estimators': 56, 'config/max_features': 0.06499445935745328, 'config/max_leaves': 143, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.1896049976348877}\n",
      "[flaml.tune.tune: 09-25 12:41:08] {197} INFO - result: {'pred_time': 9.575081992178263e-05, 'wall_clock_time': 524.5605609416962, 'metric_for_logging': {'pred_time': 9.575081992178263e-05}, 'val_loss': 0.19933132013341914, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668034ac0>, 'training_iteration': 1, 'config': {'n_estimators': 56, 'max_features': 0.06499445935745328, 'max_leaves': 143, 'criterion': 'entropy'}, 'config/n_estimators': 56, 'config/max_features': 0.06499445935745328, 'config/max_leaves': 143, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.1910817623138428}\n",
      "[flaml.automl.logger: 09-25 12:41:08] {2391} INFO -  at 524.6s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:41:08] {2218} INFO - iteration 187, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:41:08] {805} INFO - trial 1 config: {'n_estimators': 21, 'max_features': 0.05709541036413613, 'max_leaves': 77, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:41:09] {197} INFO - result: {'pred_time': 4.79551136610758e-05, 'wall_clock_time': 525.448002576828, 'metric_for_logging': {'pred_time': 4.79551136610758e-05}, 'val_loss': 0.23404357679095308, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680af640>, 'training_iteration': 0, 'config': {'n_estimators': 21, 'max_features': 0.05709541036413613, 'max_leaves': 77, 'criterion': 'gini'}, 'config/n_estimators': 21, 'config/max_features': 0.05709541036413613, 'config/max_leaves': 77, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.8790543079376221}\n",
      "[flaml.tune.tune: 09-25 12:41:09] {197} INFO - result: {'pred_time': 4.79551136610758e-05, 'wall_clock_time': 525.448002576828, 'metric_for_logging': {'pred_time': 4.79551136610758e-05}, 'val_loss': 0.23404357679095308, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680af640>, 'training_iteration': 1, 'config': {'n_estimators': 21, 'max_features': 0.05709541036413613, 'max_leaves': 77, 'criterion': 'gini'}, 'config/n_estimators': 21, 'config/max_features': 0.05709541036413613, 'config/max_leaves': 77, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.8804054260253906}\n",
      "[flaml.automl.logger: 09-25 12:41:09] {2391} INFO -  at 525.4s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:41:09] {2218} INFO - iteration 188, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:41:09] {805} INFO - trial 1 config: {'n_estimators': 22, 'num_leaves': 57, 'min_child_samples': 11, 'learning_rate': 0.25518056484611246, 'log_max_bin': 8, 'colsample_bytree': 0.778849648247964, 'reg_alpha': 0.0019352652586410964, 'reg_lambda': 7.217727284447096}\n",
      "[flaml.tune.tune: 09-25 12:41:10] {197} INFO - result: {'pred_time': 1.1269075946688966e-05, 'wall_clock_time': 526.0651352405548, 'metric_for_logging': {'pred_time': 1.1269075946688966e-05}, 'val_loss': 0.23144700172436306, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524329730>, 'training_iteration': 0, 'config': {'n_estimators': 22, 'num_leaves': 57, 'min_child_samples': 11, 'learning_rate': 0.25518056484611246, 'log_max_bin': 8, 'colsample_bytree': 0.778849648247964, 'reg_alpha': 0.0019352652586410964, 'reg_lambda': 7.217727284447096}, 'config/n_estimators': 22, 'config/num_leaves': 57, 'config/min_child_samples': 11, 'config/learning_rate': 0.25518056484611246, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.778849648247964, 'config/reg_alpha': 0.0019352652586410964, 'config/reg_lambda': 7.217727284447096, 'experiment_tag': 'exp', 'time_total_s': 0.6094508171081543}\n",
      "[flaml.tune.tune: 09-25 12:41:10] {197} INFO - result: {'pred_time': 1.1269075946688966e-05, 'wall_clock_time': 526.0651352405548, 'metric_for_logging': {'pred_time': 1.1269075946688966e-05}, 'val_loss': 0.23144700172436306, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524329730>, 'training_iteration': 1, 'config': {'n_estimators': 22, 'num_leaves': 57, 'min_child_samples': 11, 'learning_rate': 0.25518056484611246, 'log_max_bin': 8, 'colsample_bytree': 0.778849648247964, 'reg_alpha': 0.0019352652586410964, 'reg_lambda': 7.217727284447096}, 'config/n_estimators': 22, 'config/num_leaves': 57, 'config/min_child_samples': 11, 'config/learning_rate': 0.25518056484611246, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.778849648247964, 'config/reg_alpha': 0.0019352652586410964, 'config/reg_lambda': 7.217727284447096, 'experiment_tag': 'exp', 'time_total_s': 0.6109654903411865}\n",
      "[flaml.automl.logger: 09-25 12:41:10] {2391} INFO -  at 526.1s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:41:10] {2218} INFO - iteration 189, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:41:10] {805} INFO - trial 1 config: {'n_estimators': 88, 'max_features': 0.032427221756276076, 'max_leaves': 111, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:41:12] {197} INFO - result: {'pred_time': 0.00012836150499458905, 'wall_clock_time': 528.6861984729767, 'metric_for_logging': {'pred_time': 0.00012836150499458905}, 'val_loss': 0.19600356613100248, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680342e0>, 'training_iteration': 0, 'config': {'n_estimators': 88, 'max_features': 0.032427221756276076, 'max_leaves': 111, 'criterion': 'gini'}, 'config/n_estimators': 88, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 111, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.613970994949341}\n",
      "[flaml.tune.tune: 09-25 12:41:12] {197} INFO - result: {'pred_time': 0.00012836150499458905, 'wall_clock_time': 528.6861984729767, 'metric_for_logging': {'pred_time': 0.00012836150499458905}, 'val_loss': 0.19600356613100248, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680342e0>, 'training_iteration': 1, 'config': {'n_estimators': 88, 'max_features': 0.032427221756276076, 'max_leaves': 111, 'criterion': 'gini'}, 'config/n_estimators': 88, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 111, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.6158089637756348}\n",
      "[flaml.automl.logger: 09-25 12:41:12] {2391} INFO -  at 528.7s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:41:12] {2218} INFO - iteration 190, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:41:12] {805} INFO - trial 1 config: {'n_estimators': 50, 'max_features': 0.045915590352319464, 'max_leaves': 171, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:41:14] {197} INFO - result: {'pred_time': 8.695807460609476e-05, 'wall_clock_time': 530.3519263267517, 'metric_for_logging': {'pred_time': 8.695807460609476e-05}, 'val_loss': 0.21092586503006294, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680b9940>, 'training_iteration': 0, 'config': {'n_estimators': 50, 'max_features': 0.045915590352319464, 'max_leaves': 171, 'criterion': 'gini'}, 'config/n_estimators': 50, 'config/max_features': 0.045915590352319464, 'config/max_leaves': 171, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.6593079566955566}\n",
      "[flaml.tune.tune: 09-25 12:41:14] {197} INFO - result: {'pred_time': 8.695807460609476e-05, 'wall_clock_time': 530.3519263267517, 'metric_for_logging': {'pred_time': 8.695807460609476e-05}, 'val_loss': 0.21092586503006294, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680b9940>, 'training_iteration': 1, 'config': {'n_estimators': 50, 'max_features': 0.045915590352319464, 'max_leaves': 171, 'criterion': 'gini'}, 'config/n_estimators': 50, 'config/max_features': 0.045915590352319464, 'config/max_leaves': 171, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.6605312824249268}\n",
      "[flaml.automl.logger: 09-25 12:41:14] {2391} INFO -  at 530.4s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:41:14] {2218} INFO - iteration 191, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:41:14] {805} INFO - trial 1 config: {'n_estimators': 55, 'max_features': 0.05633817245568366, 'max_leaves': 63, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:41:16] {197} INFO - result: {'pred_time': 8.611258576460249e-05, 'wall_clock_time': 532.2388434410095, 'metric_for_logging': {'pred_time': 8.611258576460249e-05}, 'val_loss': 0.22043203969740705, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680e4df0>, 'training_iteration': 0, 'config': {'n_estimators': 55, 'max_features': 0.05633817245568366, 'max_leaves': 63, 'criterion': 'gini'}, 'config/n_estimators': 55, 'config/max_features': 0.05633817245568366, 'config/max_leaves': 63, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.8801381587982178}\n",
      "[flaml.tune.tune: 09-25 12:41:16] {197} INFO - result: {'pred_time': 8.611258576460249e-05, 'wall_clock_time': 532.2388434410095, 'metric_for_logging': {'pred_time': 8.611258576460249e-05}, 'val_loss': 0.22043203969740705, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680e4df0>, 'training_iteration': 1, 'config': {'n_estimators': 55, 'max_features': 0.05633817245568366, 'max_leaves': 63, 'criterion': 'gini'}, 'config/n_estimators': 55, 'config/max_features': 0.05633817245568366, 'config/max_leaves': 63, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.8815643787384033}\n",
      "[flaml.automl.logger: 09-25 12:41:16] {2391} INFO -  at 532.2s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:41:16] {2218} INFO - iteration 192, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:41:16] {805} INFO - trial 1 config: {'n_estimators': 474, 'max_leaves': 139, 'min_child_weight': 0.5239633172824825, 'learning_rate': 0.02304129561147482, 'subsample': 0.8788558177698614, 'colsample_bylevel': 0.4638129955288475, 'colsample_bytree': 0.745899563787491, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6147689140528187}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:42:12] {197} INFO - result: {'pred_time': 7.487922332699355e-05, 'wall_clock_time': 588.1717338562012, 'metric_for_logging': {'pred_time': 7.487922332699355e-05}, 'val_loss': 0.1924058327731491, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680afa30>, 'training_iteration': 0, 'config': {'n_estimators': 474, 'max_leaves': 139, 'min_child_weight': 0.5239633172824825, 'learning_rate': 0.02304129561147482, 'subsample': 0.8788558177698614, 'colsample_bylevel': 0.4638129955288475, 'colsample_bytree': 0.745899563787491, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6147689140528187}, 'config/n_estimators': 474, 'config/max_leaves': 139, 'config/min_child_weight': 0.5239633172824825, 'config/learning_rate': 0.02304129561147482, 'config/subsample': 0.8788558177698614, 'config/colsample_bylevel': 0.4638129955288475, 'config/colsample_bytree': 0.745899563787491, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.6147689140528187, 'experiment_tag': 'exp', 'time_total_s': 55.92627501487732}\n",
      "[flaml.tune.tune: 09-25 12:42:12] {197} INFO - result: {'pred_time': 7.487922332699355e-05, 'wall_clock_time': 588.1717338562012, 'metric_for_logging': {'pred_time': 7.487922332699355e-05}, 'val_loss': 0.1924058327731491, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680afa30>, 'training_iteration': 1, 'config': {'n_estimators': 474, 'max_leaves': 139, 'min_child_weight': 0.5239633172824825, 'learning_rate': 0.02304129561147482, 'subsample': 0.8788558177698614, 'colsample_bylevel': 0.4638129955288475, 'colsample_bytree': 0.745899563787491, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6147689140528187}, 'config/n_estimators': 474, 'config/max_leaves': 139, 'config/min_child_weight': 0.5239633172824825, 'config/learning_rate': 0.02304129561147482, 'config/subsample': 0.8788558177698614, 'config/colsample_bylevel': 0.4638129955288475, 'config/colsample_bytree': 0.745899563787491, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.6147689140528187, 'experiment_tag': 'exp', 'time_total_s': 55.92769765853882}\n",
      "[flaml.automl.logger: 09-25 12:42:12] {2391} INFO -  at 588.2s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:42:12] {2218} INFO - iteration 193, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:42:12] {805} INFO - trial 1 config: {'early_stopping_rounds': 12, 'learning_rate': 0.03465995229569825, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:42:18] {197} INFO - result: {'pred_time': 7.799147587869656e-05, 'wall_clock_time': 594.4599125385284, 'metric_for_logging': {'pred_time': 7.799147587869656e-05}, 'val_loss': 0.2506641732841133, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680d11f0>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.03465995229569825, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.03465995229569825, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.280949592590332}\n",
      "[flaml.tune.tune: 09-25 12:42:18] {197} INFO - result: {'pred_time': 7.799147587869656e-05, 'wall_clock_time': 594.4599125385284, 'metric_for_logging': {'pred_time': 7.799147587869656e-05}, 'val_loss': 0.2506641732841133, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680d11f0>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.03465995229569825, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.03465995229569825, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.282386064529419}\n",
      "[flaml.automl.logger: 09-25 12:42:18] {2391} INFO -  at 594.5s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:42:18] {2218} INFO - iteration 194, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:42:18] {805} INFO - trial 1 config: {'n_estimators': 29, 'max_features': 0.11170104362522518, 'max_leaves': 207, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:42:20] {197} INFO - result: {'pred_time': 5.9943217427904e-05, 'wall_clock_time': 596.2077262401581, 'metric_for_logging': {'pred_time': 5.9943217427904e-05}, 'val_loss': 0.21548273853371303, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680e7580>, 'training_iteration': 0, 'config': {'n_estimators': 29, 'max_features': 0.11170104362522518, 'max_leaves': 207, 'criterion': 'entropy'}, 'config/n_estimators': 29, 'config/max_features': 0.11170104362522518, 'config/max_leaves': 207, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.739903450012207}\n",
      "[flaml.tune.tune: 09-25 12:42:20] {197} INFO - result: {'pred_time': 5.9943217427904e-05, 'wall_clock_time': 596.2077262401581, 'metric_for_logging': {'pred_time': 5.9943217427904e-05}, 'val_loss': 0.21548273853371303, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680e7580>, 'training_iteration': 1, 'config': {'n_estimators': 29, 'max_features': 0.11170104362522518, 'max_leaves': 207, 'criterion': 'entropy'}, 'config/n_estimators': 29, 'config/max_features': 0.11170104362522518, 'config/max_leaves': 207, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.7418909072875977}\n",
      "[flaml.automl.logger: 09-25 12:42:20] {2391} INFO -  at 596.2s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:42:20] {2218} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:42:20] {805} INFO - trial 1 config: {'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.29999999999999993, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:42:23] {197} INFO - result: {'pred_time': 4.6609031889498035e-05, 'wall_clock_time': 599.3706154823303, 'metric_for_logging': {'pred_time': 4.6609031889498035e-05}, 'val_loss': 0.2587999659214052, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe53409b7f0>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.29999999999999993, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'config/n_estimators': 10, 'config/max_depth': 6, 'config/min_child_weight': 0.9999999999999993, 'config/learning_rate': 0.29999999999999993, 'config/subsample': 1.0, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.0, 'experiment_tag': 'exp', 'time_total_s': 3.1527416706085205}\n",
      "[flaml.tune.tune: 09-25 12:42:23] {197} INFO - result: {'pred_time': 4.6609031889498035e-05, 'wall_clock_time': 599.3706154823303, 'metric_for_logging': {'pred_time': 4.6609031889498035e-05}, 'val_loss': 0.2587999659214052, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe53409b7f0>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.29999999999999993, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'config/n_estimators': 10, 'config/max_depth': 6, 'config/min_child_weight': 0.9999999999999993, 'config/learning_rate': 0.29999999999999993, 'config/subsample': 1.0, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.0, 'experiment_tag': 'exp', 'time_total_s': 3.1542508602142334}\n",
      "[flaml.automl.logger: 09-25 12:42:23] {2391} INFO -  at 599.4s,\testimator xgb_limitdepth's best error=0.2588,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:42:23] {2218} INFO - iteration 196, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:42:23] {805} INFO - trial 1 config: {'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.11577408576396257, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:42:26] {197} INFO - result: {'pred_time': 4.736658403836414e-05, 'wall_clock_time': 602.1306340694427, 'metric_for_logging': {'pred_time': 4.736658403836414e-05}, 'val_loss': 0.3146692592719579, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6681b3f40>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.11577408576396257, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}, 'config/n_estimators': 10, 'config/max_depth': 6, 'config/min_child_weight': 3.815612027960909, 'config/learning_rate': 0.11577408576396257, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8148474110627004, 'config/colsample_bytree': 0.9777234800442423, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.525802807180917, 'experiment_tag': 'exp', 'time_total_s': 2.7522149085998535}\n",
      "[flaml.tune.tune: 09-25 12:42:26] {197} INFO - result: {'pred_time': 4.736658403836414e-05, 'wall_clock_time': 602.1306340694427, 'metric_for_logging': {'pred_time': 4.736658403836414e-05}, 'val_loss': 0.3146692592719579, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6681b3f40>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.11577408576396257, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}, 'config/n_estimators': 10, 'config/max_depth': 6, 'config/min_child_weight': 3.815612027960909, 'config/learning_rate': 0.11577408576396257, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8148474110627004, 'config/colsample_bytree': 0.9777234800442423, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.525802807180917, 'experiment_tag': 'exp', 'time_total_s': 2.7533724308013916}\n",
      "[flaml.automl.logger: 09-25 12:42:26] {2391} INFO -  at 602.1s,\testimator xgb_limitdepth's best error=0.2588,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:42:26] {2218} INFO - iteration 197, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:42:26] {805} INFO - trial 1 config: {'n_estimators': 90, 'max_features': 0.032427221756276076, 'max_leaves': 253, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:42:28] {197} INFO - result: {'pred_time': 0.0001302044027179677, 'wall_clock_time': 604.884599685669, 'metric_for_logging': {'pred_time': 0.0001302044027179677}, 'val_loss': 0.19451473154621582, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6681b3e80>, 'training_iteration': 0, 'config': {'n_estimators': 90, 'max_features': 0.032427221756276076, 'max_leaves': 253, 'criterion': 'entropy'}, 'config/n_estimators': 90, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 253, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.7470760345458984}\n",
      "[flaml.tune.tune: 09-25 12:42:28] {197} INFO - result: {'pred_time': 0.0001302044027179677, 'wall_clock_time': 604.884599685669, 'metric_for_logging': {'pred_time': 0.0001302044027179677}, 'val_loss': 0.19451473154621582, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6681b3e80>, 'training_iteration': 1, 'config': {'n_estimators': 90, 'max_features': 0.032427221756276076, 'max_leaves': 253, 'criterion': 'entropy'}, 'config/n_estimators': 90, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 253, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.748654365539551}\n",
      "[flaml.automl.logger: 09-25 12:42:28] {2391} INFO -  at 604.9s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:42:28] {2218} INFO - iteration 198, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:42:28] {805} INFO - trial 1 config: {'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.7773760371858154, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:42:32] {197} INFO - result: {'pred_time': 4.69369985956038e-05, 'wall_clock_time': 608.1364815235138, 'metric_for_logging': {'pred_time': 4.69369985956038e-05}, 'val_loss': 0.25592671872656875, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe668037340>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.7773760371858154, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}, 'config/n_estimators': 10, 'config/max_depth': 6, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.7773760371858154, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292954, 'experiment_tag': 'exp', 'time_total_s': 3.2454192638397217}\n",
      "[flaml.tune.tune: 09-25 12:42:32] {197} INFO - result: {'pred_time': 4.69369985956038e-05, 'wall_clock_time': 608.1364815235138, 'metric_for_logging': {'pred_time': 4.69369985956038e-05}, 'val_loss': 0.25592671872656875, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe668037340>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.7773760371858154, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}, 'config/n_estimators': 10, 'config/max_depth': 6, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.7773760371858154, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292954, 'experiment_tag': 'exp', 'time_total_s': 3.246659278869629}\n",
      "[flaml.automl.logger: 09-25 12:42:32] {2391} INFO -  at 608.1s,\testimator xgb_limitdepth's best error=0.2559,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:42:32] {2218} INFO - iteration 199, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:42:32] {805} INFO - trial 1 config: {'n_estimators': 10, 'max_depth': 5, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:42:35] {197} INFO - result: {'pred_time': 4.7243685426795205e-05, 'wall_clock_time': 611.0505118370056, 'metric_for_logging': {'pred_time': 4.7243685426795205e-05}, 'val_loss': 0.2954136670403537, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe52415a520>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_depth': 5, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}, 'config/n_estimators': 10, 'config/max_depth': 5, 'config/min_child_weight': 1.8630223791106992, 'config/learning_rate': 1.0, 'config/subsample': 0.8513627344387318, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.946138073111236, 'config/reg_alpha': 0.0018311776973217071, 'config/reg_lambda': 0.27901659190538414, 'experiment_tag': 'exp', 'time_total_s': 2.9063336849212646}\n",
      "[flaml.tune.tune: 09-25 12:42:35] {197} INFO - result: {'pred_time': 4.7243685426795205e-05, 'wall_clock_time': 611.0505118370056, 'metric_for_logging': {'pred_time': 4.7243685426795205e-05}, 'val_loss': 0.2954136670403537, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe52415a520>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_depth': 5, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}, 'config/n_estimators': 10, 'config/max_depth': 5, 'config/min_child_weight': 1.8630223791106992, 'config/learning_rate': 1.0, 'config/subsample': 0.8513627344387318, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.946138073111236, 'config/reg_alpha': 0.0018311776973217071, 'config/reg_lambda': 0.27901659190538414, 'experiment_tag': 'exp', 'time_total_s': 2.9076335430145264}\n",
      "[flaml.automl.logger: 09-25 12:42:35] {2391} INFO -  at 611.1s,\testimator xgb_limitdepth's best error=0.2559,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:42:35] {2218} INFO - iteration 200, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:42:35] {805} INFO - trial 1 config: {'n_estimators': 10, 'max_depth': 7, 'min_child_weight': 0.03686833371983711, 'learning_rate': 0.20037430545841078, 'subsample': 1.0, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.001060223120782963, 'reg_lambda': 0.11737597287343557}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:42:38] {197} INFO - result: {'pred_time': 4.915471802434087e-05, 'wall_clock_time': 614.5179784297943, 'metric_for_logging': {'pred_time': 4.915471802434087e-05}, 'val_loss': 0.2801230664986286, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe52415aa60>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_depth': 7, 'min_child_weight': 0.03686833371983711, 'learning_rate': 0.20037430545841078, 'subsample': 1.0, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.001060223120782963, 'reg_lambda': 0.11737597287343557}, 'config/n_estimators': 10, 'config/max_depth': 7, 'config/min_child_weight': 0.03686833371983711, 'config/learning_rate': 0.20037430545841078, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.001060223120782963, 'config/reg_lambda': 0.11737597287343557, 'experiment_tag': 'exp', 'time_total_s': 3.4604275226593018}\n",
      "[flaml.tune.tune: 09-25 12:42:38] {197} INFO - result: {'pred_time': 4.915471802434087e-05, 'wall_clock_time': 614.5179784297943, 'metric_for_logging': {'pred_time': 4.915471802434087e-05}, 'val_loss': 0.2801230664986286, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe52415aa60>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_depth': 7, 'min_child_weight': 0.03686833371983711, 'learning_rate': 0.20037430545841078, 'subsample': 1.0, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.001060223120782963, 'reg_lambda': 0.11737597287343557}, 'config/n_estimators': 10, 'config/max_depth': 7, 'config/min_child_weight': 0.03686833371983711, 'config/learning_rate': 0.20037430545841078, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.001060223120782963, 'config/reg_lambda': 0.11737597287343557, 'experiment_tag': 'exp', 'time_total_s': 3.4619789123535156}\n",
      "[flaml.automl.logger: 09-25 12:42:38] {2391} INFO -  at 614.5s,\testimator xgb_limitdepth's best error=0.2559,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:42:38] {2218} INFO - iteration 201, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:42:38] {805} INFO - trial 1 config: {'n_estimators': 4, 'max_depth': 6, 'min_child_weight': 0.08262716617929555, 'learning_rate': 0.41239927569263257, 'subsample': 0.8885937069868678, 'colsample_bylevel': 0.8184166881476597, 'colsample_bytree': 0.8648827061331837, 'reg_alpha': 0.0018753066867999496, 'reg_lambda': 0.41314951749877454}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:42:40] {197} INFO - result: {'pred_time': 4.646260676089746e-05, 'wall_clock_time': 616.1309475898743, 'metric_for_logging': {'pred_time': 4.646260676089746e-05}, 'val_loss': 0.3047877741655852, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe52415a790>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_depth': 6, 'min_child_weight': 0.08262716617929555, 'learning_rate': 0.41239927569263257, 'subsample': 0.8885937069868678, 'colsample_bylevel': 0.8184166881476597, 'colsample_bytree': 0.8648827061331837, 'reg_alpha': 0.0018753066867999496, 'reg_lambda': 0.41314951749877454}, 'config/n_estimators': 4, 'config/max_depth': 6, 'config/min_child_weight': 0.08262716617929555, 'config/learning_rate': 0.41239927569263257, 'config/subsample': 0.8885937069868678, 'config/colsample_bylevel': 0.8184166881476597, 'config/colsample_bytree': 0.8648827061331837, 'config/reg_alpha': 0.0018753066867999496, 'config/reg_lambda': 0.41314951749877454, 'experiment_tag': 'exp', 'time_total_s': 1.6030139923095703}\n",
      "[flaml.tune.tune: 09-25 12:42:40] {197} INFO - result: {'pred_time': 4.646260676089746e-05, 'wall_clock_time': 616.1309475898743, 'metric_for_logging': {'pred_time': 4.646260676089746e-05}, 'val_loss': 0.3047877741655852, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe52415a790>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_depth': 6, 'min_child_weight': 0.08262716617929555, 'learning_rate': 0.41239927569263257, 'subsample': 0.8885937069868678, 'colsample_bylevel': 0.8184166881476597, 'colsample_bytree': 0.8648827061331837, 'reg_alpha': 0.0018753066867999496, 'reg_lambda': 0.41314951749877454}, 'config/n_estimators': 4, 'config/max_depth': 6, 'config/min_child_weight': 0.08262716617929555, 'config/learning_rate': 0.41239927569263257, 'config/subsample': 0.8885937069868678, 'config/colsample_bylevel': 0.8184166881476597, 'config/colsample_bytree': 0.8648827061331837, 'config/reg_alpha': 0.0018753066867999496, 'config/reg_lambda': 0.41314951749877454, 'experiment_tag': 'exp', 'time_total_s': 1.604386806488037}\n",
      "[flaml.automl.logger: 09-25 12:42:40] {2391} INFO -  at 616.1s,\testimator xgb_limitdepth's best error=0.2559,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:42:40] {2218} INFO - iteration 202, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:42:40] {805} INFO - trial 1 config: {'n_estimators': 362, 'num_leaves': 86, 'min_child_samples': 4, 'learning_rate': 0.16415602573493282, 'log_max_bin': 10, 'colsample_bytree': 0.771132242954117, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.2411422416643202}\n",
      "[flaml.tune.tune: 09-25 12:42:45] {197} INFO - result: {'pred_time': 2.6227769485874373e-05, 'wall_clock_time': 621.8617267608643, 'metric_for_logging': {'pred_time': 2.6227769485874373e-05}, 'val_loss': 0.20961920287257615, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe52415a850>, 'training_iteration': 0, 'config': {'n_estimators': 362, 'num_leaves': 86, 'min_child_samples': 4, 'learning_rate': 0.16415602573493282, 'log_max_bin': 10, 'colsample_bytree': 0.771132242954117, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.2411422416643202}, 'config/n_estimators': 362, 'config/num_leaves': 86, 'config/min_child_samples': 4, 'config/learning_rate': 0.16415602573493282, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.771132242954117, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.2411422416643202, 'experiment_tag': 'exp', 'time_total_s': 5.724454879760742}\n",
      "[flaml.tune.tune: 09-25 12:42:45] {197} INFO - result: {'pred_time': 2.6227769485874373e-05, 'wall_clock_time': 621.8617267608643, 'metric_for_logging': {'pred_time': 2.6227769485874373e-05}, 'val_loss': 0.20961920287257615, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe52415a850>, 'training_iteration': 1, 'config': {'n_estimators': 362, 'num_leaves': 86, 'min_child_samples': 4, 'learning_rate': 0.16415602573493282, 'log_max_bin': 10, 'colsample_bytree': 0.771132242954117, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.2411422416643202}, 'config/n_estimators': 362, 'config/num_leaves': 86, 'config/min_child_samples': 4, 'config/learning_rate': 0.16415602573493282, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.771132242954117, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.2411422416643202, 'experiment_tag': 'exp', 'time_total_s': 5.725786447525024}\n",
      "[flaml.automl.logger: 09-25 12:42:45] {2391} INFO -  at 621.9s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:42:45] {2218} INFO - iteration 203, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:42:45] {805} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.0421528960868391, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:42:50] {197} INFO - result: {'pred_time': 7.699770468568504e-05, 'wall_clock_time': 626.6776027679443, 'metric_for_logging': {'pred_time': 7.699770468568504e-05}, 'val_loss': 0.24326605321732755, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe668055b50>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 11, 'learning_rate': 0.0421528960868391, 'n_estimators': 8192}, 'config/early_stopping_rounds': 11, 'config/learning_rate': 0.0421528960868391, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.80899977684021}\n",
      "[flaml.tune.tune: 09-25 12:42:50] {197} INFO - result: {'pred_time': 7.699770468568504e-05, 'wall_clock_time': 626.6776027679443, 'metric_for_logging': {'pred_time': 7.699770468568504e-05}, 'val_loss': 0.24326605321732755, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe668055b50>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 11, 'learning_rate': 0.0421528960868391, 'n_estimators': 8192}, 'config/early_stopping_rounds': 11, 'config/learning_rate': 0.0421528960868391, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.810728311538696}\n",
      "[flaml.automl.logger: 09-25 12:42:50] {2391} INFO -  at 626.7s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:42:50] {2218} INFO - iteration 204, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:42:50] {805} INFO - trial 1 config: {'n_estimators': 22, 'max_depth': 6, 'min_child_weight': 0.8312826637613695, 'learning_rate': 1.0, 'subsample': 0.9647550813352507, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0010352743615901622, 'reg_lambda': 0.07926874541931893}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:42:56] {197} INFO - result: {'pred_time': 4.6524338940566074e-05, 'wall_clock_time': 632.8647060394287, 'metric_for_logging': {'pred_time': 4.6524338940566074e-05}, 'val_loss': 0.2648229852502716, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe66807daf0>, 'training_iteration': 0, 'config': {'n_estimators': 22, 'max_depth': 6, 'min_child_weight': 0.8312826637613695, 'learning_rate': 1.0, 'subsample': 0.9647550813352507, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0010352743615901622, 'reg_lambda': 0.07926874541931893}, 'config/n_estimators': 22, 'config/max_depth': 6, 'config/min_child_weight': 0.8312826637613695, 'config/learning_rate': 1.0, 'config/subsample': 0.9647550813352507, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0010352743615901622, 'config/reg_lambda': 0.07926874541931893, 'experiment_tag': 'exp', 'time_total_s': 6.179196834564209}\n",
      "[flaml.tune.tune: 09-25 12:42:56] {197} INFO - result: {'pred_time': 4.6524338940566074e-05, 'wall_clock_time': 632.8647060394287, 'metric_for_logging': {'pred_time': 4.6524338940566074e-05}, 'val_loss': 0.2648229852502716, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe66807daf0>, 'training_iteration': 1, 'config': {'n_estimators': 22, 'max_depth': 6, 'min_child_weight': 0.8312826637613695, 'learning_rate': 1.0, 'subsample': 0.9647550813352507, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0010352743615901622, 'reg_lambda': 0.07926874541931893}, 'config/n_estimators': 22, 'config/max_depth': 6, 'config/min_child_weight': 0.8312826637613695, 'config/learning_rate': 1.0, 'config/subsample': 0.9647550813352507, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0010352743615901622, 'config/reg_lambda': 0.07926874541931893, 'experiment_tag': 'exp', 'time_total_s': 6.180368661880493}\n",
      "[flaml.automl.logger: 09-25 12:42:56] {2391} INFO -  at 632.9s,\testimator xgb_limitdepth's best error=0.2559,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:42:56] {2218} INFO - iteration 205, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:42:56] {805} INFO - trial 1 config: {'n_estimators': 17, 'max_depth': 6, 'min_child_weight': 0.533808799890526, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.8811171114303163, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796896}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:43:00] {197} INFO - result: {'pred_time': 4.794255729346407e-05, 'wall_clock_time': 636.8900847434998, 'metric_for_logging': {'pred_time': 4.794255729346407e-05}, 'val_loss': 0.244356672149026, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680b95e0>, 'training_iteration': 0, 'config': {'n_estimators': 17, 'max_depth': 6, 'min_child_weight': 0.533808799890526, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.8811171114303163, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796896}, 'config/n_estimators': 17, 'config/max_depth': 6, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 1.0, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8811171114303163, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644693, 'config/reg_lambda': 0.8085739292796896, 'experiment_tag': 'exp', 'time_total_s': 4.0191261768341064}\n",
      "[flaml.tune.tune: 09-25 12:43:00] {197} INFO - result: {'pred_time': 4.794255729346407e-05, 'wall_clock_time': 636.8900847434998, 'metric_for_logging': {'pred_time': 4.794255729346407e-05}, 'val_loss': 0.244356672149026, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680b95e0>, 'training_iteration': 1, 'config': {'n_estimators': 17, 'max_depth': 6, 'min_child_weight': 0.533808799890526, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.8811171114303163, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796896}, 'config/n_estimators': 17, 'config/max_depth': 6, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 1.0, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8811171114303163, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644693, 'config/reg_lambda': 0.8085739292796896, 'experiment_tag': 'exp', 'time_total_s': 4.020737886428833}\n",
      "[flaml.automl.logger: 09-25 12:43:00] {2391} INFO -  at 636.9s,\testimator xgb_limitdepth's best error=0.2444,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:00] {2218} INFO - iteration 206, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:43:00] {805} INFO - trial 1 config: {'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.38946718731417634, 'subsample': 0.9079647052885418, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292968}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:43:04] {197} INFO - result: {'pred_time': 4.708622604608882e-05, 'wall_clock_time': 640.1858162879944, 'metric_for_logging': {'pred_time': 4.708622604608882e-05}, 'val_loss': 0.25684084499676707, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680b9d30>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.38946718731417634, 'subsample': 0.9079647052885418, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292968}, 'config/n_estimators': 10, 'config/max_depth': 6, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.38946718731417634, 'config/subsample': 0.9079647052885418, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292968, 'experiment_tag': 'exp', 'time_total_s': 3.28545880317688}\n",
      "[flaml.tune.tune: 09-25 12:43:04] {197} INFO - result: {'pred_time': 4.708622604608882e-05, 'wall_clock_time': 640.1858162879944, 'metric_for_logging': {'pred_time': 4.708622604608882e-05}, 'val_loss': 0.25684084499676707, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680b9d30>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_depth': 6, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.38946718731417634, 'subsample': 0.9079647052885418, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292968}, 'config/n_estimators': 10, 'config/max_depth': 6, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.38946718731417634, 'config/subsample': 0.9079647052885418, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292968, 'experiment_tag': 'exp', 'time_total_s': 3.287522554397583}\n",
      "[flaml.automl.logger: 09-25 12:43:04] {2391} INFO -  at 640.2s,\testimator xgb_limitdepth's best error=0.2444,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:04] {2218} INFO - iteration 207, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:43:04] {805} INFO - trial 1 config: {'n_estimators': 30, 'max_features': 0.13816589106066116, 'max_leaves': 214, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:43:06] {197} INFO - result: {'pred_time': 6.077665856675758e-05, 'wall_clock_time': 642.2352364063263, 'metric_for_logging': {'pred_time': 6.077665856675758e-05}, 'val_loss': 0.2261498495381554, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680b93a0>, 'training_iteration': 0, 'config': {'n_estimators': 30, 'max_features': 0.13816589106066116, 'max_leaves': 214, 'criterion': 'entropy'}, 'config/n_estimators': 30, 'config/max_features': 0.13816589106066116, 'config/max_leaves': 214, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.040268659591675}\n",
      "[flaml.tune.tune: 09-25 12:43:06] {197} INFO - result: {'pred_time': 6.077665856675758e-05, 'wall_clock_time': 642.2352364063263, 'metric_for_logging': {'pred_time': 6.077665856675758e-05}, 'val_loss': 0.2261498495381554, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680b93a0>, 'training_iteration': 1, 'config': {'n_estimators': 30, 'max_features': 0.13816589106066116, 'max_leaves': 214, 'criterion': 'entropy'}, 'config/n_estimators': 30, 'config/max_features': 0.13816589106066116, 'config/max_leaves': 214, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.042206048965454}\n",
      "[flaml.automl.logger: 09-25 12:43:06] {2391} INFO -  at 642.2s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:06] {2218} INFO - iteration 208, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:43:06] {805} INFO - trial 1 config: {'n_estimators': 17, 'max_depth': 7, 'min_child_weight': 0.7694377042261122, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.9088550158793876, 'colsample_bytree': 0.7967145599266738, 'reg_alpha': 0.058176484040363505, 'reg_lambda': 4.081433281365178}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:43:10] {197} INFO - result: {'pred_time': 4.726887805945858e-05, 'wall_clock_time': 646.6657824516296, 'metric_for_logging': {'pred_time': 4.726887805945858e-05}, 'val_loss': 0.2308546393816259, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680b9460>, 'training_iteration': 0, 'config': {'n_estimators': 17, 'max_depth': 7, 'min_child_weight': 0.7694377042261122, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.9088550158793876, 'colsample_bytree': 0.7967145599266738, 'reg_alpha': 0.058176484040363505, 'reg_lambda': 4.081433281365178}, 'config/n_estimators': 17, 'config/max_depth': 7, 'config/min_child_weight': 0.7694377042261122, 'config/learning_rate': 1.0, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.9088550158793876, 'config/colsample_bytree': 0.7967145599266738, 'config/reg_alpha': 0.058176484040363505, 'config/reg_lambda': 4.081433281365178, 'experiment_tag': 'exp', 'time_total_s': 4.4235076904296875}\n",
      "[flaml.tune.tune: 09-25 12:43:10] {197} INFO - result: {'pred_time': 4.726887805945858e-05, 'wall_clock_time': 646.6657824516296, 'metric_for_logging': {'pred_time': 4.726887805945858e-05}, 'val_loss': 0.2308546393816259, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680b9460>, 'training_iteration': 1, 'config': {'n_estimators': 17, 'max_depth': 7, 'min_child_weight': 0.7694377042261122, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.9088550158793876, 'colsample_bytree': 0.7967145599266738, 'reg_alpha': 0.058176484040363505, 'reg_lambda': 4.081433281365178}, 'config/n_estimators': 17, 'config/max_depth': 7, 'config/min_child_weight': 0.7694377042261122, 'config/learning_rate': 1.0, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.9088550158793876, 'config/colsample_bytree': 0.7967145599266738, 'config/reg_alpha': 0.058176484040363505, 'config/reg_lambda': 4.081433281365178, 'experiment_tag': 'exp', 'time_total_s': 4.425228595733643}\n",
      "[flaml.automl.logger: 09-25 12:43:10] {2391} INFO -  at 646.7s,\testimator xgb_limitdepth's best error=0.2309,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:10] {2218} INFO - iteration 209, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:43:10] {805} INFO - trial 1 config: {'n_estimators': 17, 'max_depth': 6, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.8210689282647788, 'subsample': 0.9661106209889765, 'colsample_bylevel': 0.8811171114303163, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644698, 'reg_lambda': 0.8085739292796891}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:43:14] {197} INFO - result: {'pred_time': 4.694219017422661e-05, 'wall_clock_time': 650.750892162323, 'metric_for_logging': {'pred_time': 4.694219017422661e-05}, 'val_loss': 0.24797237988767223, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680b9a90>, 'training_iteration': 0, 'config': {'n_estimators': 17, 'max_depth': 6, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.8210689282647788, 'subsample': 0.9661106209889765, 'colsample_bylevel': 0.8811171114303163, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644698, 'reg_lambda': 0.8085739292796891}, 'config/n_estimators': 17, 'config/max_depth': 6, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.8210689282647788, 'config/subsample': 0.9661106209889765, 'config/colsample_bylevel': 0.8811171114303163, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644698, 'config/reg_lambda': 0.8085739292796891, 'experiment_tag': 'exp', 'time_total_s': 4.078531742095947}\n",
      "[flaml.tune.tune: 09-25 12:43:14] {197} INFO - result: {'pred_time': 4.694219017422661e-05, 'wall_clock_time': 650.750892162323, 'metric_for_logging': {'pred_time': 4.694219017422661e-05}, 'val_loss': 0.24797237988767223, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680b9a90>, 'training_iteration': 1, 'config': {'n_estimators': 17, 'max_depth': 6, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.8210689282647788, 'subsample': 0.9661106209889765, 'colsample_bylevel': 0.8811171114303163, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644698, 'reg_lambda': 0.8085739292796891}, 'config/n_estimators': 17, 'config/max_depth': 6, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.8210689282647788, 'config/subsample': 0.9661106209889765, 'config/colsample_bylevel': 0.8811171114303163, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644698, 'config/reg_lambda': 0.8085739292796891, 'experiment_tag': 'exp', 'time_total_s': 4.0799055099487305}\n",
      "[flaml.automl.logger: 09-25 12:43:14] {2391} INFO -  at 650.8s,\testimator xgb_limitdepth's best error=0.2309,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:14] {2218} INFO - iteration 210, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:43:14] {805} INFO - trial 1 config: {'n_estimators': 48, 'max_features': 0.03712073451450197, 'max_leaves': 165, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:43:16] {197} INFO - result: {'pred_time': 8.196018880681646e-05, 'wall_clock_time': 652.2805018424988, 'metric_for_logging': {'pred_time': 8.196018880681646e-05}, 'val_loss': 0.214997629390433, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680b90a0>, 'training_iteration': 0, 'config': {'n_estimators': 48, 'max_features': 0.03712073451450197, 'max_leaves': 165, 'criterion': 'gini'}, 'config/n_estimators': 48, 'config/max_features': 0.03712073451450197, 'config/max_leaves': 165, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.5221037864685059}\n",
      "[flaml.tune.tune: 09-25 12:43:16] {197} INFO - result: {'pred_time': 8.196018880681646e-05, 'wall_clock_time': 652.2805018424988, 'metric_for_logging': {'pred_time': 8.196018880681646e-05}, 'val_loss': 0.214997629390433, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680b90a0>, 'training_iteration': 1, 'config': {'n_estimators': 48, 'max_features': 0.03712073451450197, 'max_leaves': 165, 'criterion': 'gini'}, 'config/n_estimators': 48, 'config/max_features': 0.03712073451450197, 'config/max_leaves': 165, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.523364782333374}\n",
      "[flaml.automl.logger: 09-25 12:43:16] {2391} INFO -  at 652.3s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:16] {2218} INFO - iteration 211, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:43:16] {805} INFO - trial 1 config: {'n_estimators': 10, 'max_depth': 7, 'min_child_weight': 0.15023279902189693, 'learning_rate': 1.0, 'subsample': 0.8286310106576346, 'colsample_bylevel': 0.8648423578943012, 'colsample_bytree': 0.8954074711475323, 'reg_alpha': 0.16394177411347696, 'reg_lambda': 11.791813911233042}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:43:19] {197} INFO - result: {'pred_time': 4.7228849442053436e-05, 'wall_clock_time': 655.5182414054871, 'metric_for_logging': {'pred_time': 4.7228849442053436e-05}, 'val_loss': 0.2552109340340225, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe534064d30>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_depth': 7, 'min_child_weight': 0.15023279902189693, 'learning_rate': 1.0, 'subsample': 0.8286310106576346, 'colsample_bylevel': 0.8648423578943012, 'colsample_bytree': 0.8954074711475323, 'reg_alpha': 0.16394177411347696, 'reg_lambda': 11.791813911233042}, 'config/n_estimators': 10, 'config/max_depth': 7, 'config/min_child_weight': 0.15023279902189693, 'config/learning_rate': 1.0, 'config/subsample': 0.8286310106576346, 'config/colsample_bylevel': 0.8648423578943012, 'config/colsample_bytree': 0.8954074711475323, 'config/reg_alpha': 0.16394177411347696, 'config/reg_lambda': 11.791813911233042, 'experiment_tag': 'exp', 'time_total_s': 3.228609800338745}\n",
      "[flaml.tune.tune: 09-25 12:43:19] {197} INFO - result: {'pred_time': 4.7228849442053436e-05, 'wall_clock_time': 655.5182414054871, 'metric_for_logging': {'pred_time': 4.7228849442053436e-05}, 'val_loss': 0.2552109340340225, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe534064d30>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_depth': 7, 'min_child_weight': 0.15023279902189693, 'learning_rate': 1.0, 'subsample': 0.8286310106576346, 'colsample_bylevel': 0.8648423578943012, 'colsample_bytree': 0.8954074711475323, 'reg_alpha': 0.16394177411347696, 'reg_lambda': 11.791813911233042}, 'config/n_estimators': 10, 'config/max_depth': 7, 'config/min_child_weight': 0.15023279902189693, 'config/learning_rate': 1.0, 'config/subsample': 0.8286310106576346, 'config/colsample_bylevel': 0.8648423578943012, 'config/colsample_bytree': 0.8954074711475323, 'config/reg_alpha': 0.16394177411347696, 'config/reg_lambda': 11.791813911233042, 'experiment_tag': 'exp', 'time_total_s': 3.2300007343292236}\n",
      "[flaml.automl.logger: 09-25 12:43:19] {2391} INFO -  at 655.5s,\testimator xgb_limitdepth's best error=0.2309,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:19] {2218} INFO - iteration 212, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:43:19] {805} INFO - trial 1 config: {'n_estimators': 28, 'max_depth': 7, 'min_child_weight': 3.940779806668313, 'learning_rate': 0.6413547778096401, 'subsample': 1.0, 'colsample_bylevel': 0.9528676738644739, 'colsample_bytree': 0.6980216487058154, 'reg_alpha': 0.020644544769632598, 'reg_lambda': 1.41268321868331}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:43:26] {197} INFO - result: {'pred_time': 4.885183948384118e-05, 'wall_clock_time': 662.0434250831604, 'metric_for_logging': {'pred_time': 4.885183948384118e-05}, 'val_loss': 0.24410044631184064, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe534064220>, 'training_iteration': 0, 'config': {'n_estimators': 28, 'max_depth': 7, 'min_child_weight': 3.940779806668313, 'learning_rate': 0.6413547778096401, 'subsample': 1.0, 'colsample_bylevel': 0.9528676738644739, 'colsample_bytree': 0.6980216487058154, 'reg_alpha': 0.020644544769632598, 'reg_lambda': 1.41268321868331}, 'config/n_estimators': 28, 'config/max_depth': 7, 'config/min_child_weight': 3.940779806668313, 'config/learning_rate': 0.6413547778096401, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.9528676738644739, 'config/colsample_bytree': 0.6980216487058154, 'config/reg_alpha': 0.020644544769632598, 'config/reg_lambda': 1.41268321868331, 'experiment_tag': 'exp', 'time_total_s': 6.519021272659302}\n",
      "[flaml.tune.tune: 09-25 12:43:26] {197} INFO - result: {'pred_time': 4.885183948384118e-05, 'wall_clock_time': 662.0434250831604, 'metric_for_logging': {'pred_time': 4.885183948384118e-05}, 'val_loss': 0.24410044631184064, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe534064220>, 'training_iteration': 1, 'config': {'n_estimators': 28, 'max_depth': 7, 'min_child_weight': 3.940779806668313, 'learning_rate': 0.6413547778096401, 'subsample': 1.0, 'colsample_bylevel': 0.9528676738644739, 'colsample_bytree': 0.6980216487058154, 'reg_alpha': 0.020644544769632598, 'reg_lambda': 1.41268321868331}, 'config/n_estimators': 28, 'config/max_depth': 7, 'config/min_child_weight': 3.940779806668313, 'config/learning_rate': 0.6413547778096401, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.9528676738644739, 'config/colsample_bytree': 0.6980216487058154, 'config/reg_alpha': 0.020644544769632598, 'config/reg_lambda': 1.41268321868331, 'experiment_tag': 'exp', 'time_total_s': 6.520682096481323}\n",
      "[flaml.automl.logger: 09-25 12:43:26] {2391} INFO -  at 662.0s,\testimator xgb_limitdepth's best error=0.2309,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:26] {2218} INFO - iteration 213, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:43:26] {805} INFO - trial 1 config: {'n_estimators': 30, 'max_features': 0.11976426721635763, 'max_leaves': 94, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:43:27] {197} INFO - result: {'pred_time': 5.981563368587774e-05, 'wall_clock_time': 663.7414600849152, 'metric_for_logging': {'pred_time': 5.981563368587774e-05}, 'val_loss': 0.24404509456983217, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe534064d60>, 'training_iteration': 0, 'config': {'n_estimators': 30, 'max_features': 0.11976426721635763, 'max_leaves': 94, 'criterion': 'gini'}, 'config/n_estimators': 30, 'config/max_features': 0.11976426721635763, 'config/max_leaves': 94, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.6909124851226807}\n",
      "[flaml.tune.tune: 09-25 12:43:27] {197} INFO - result: {'pred_time': 5.981563368587774e-05, 'wall_clock_time': 663.7414600849152, 'metric_for_logging': {'pred_time': 5.981563368587774e-05}, 'val_loss': 0.24404509456983217, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe534064d60>, 'training_iteration': 1, 'config': {'n_estimators': 30, 'max_features': 0.11976426721635763, 'max_leaves': 94, 'criterion': 'gini'}, 'config/n_estimators': 30, 'config/max_features': 0.11976426721635763, 'config/max_leaves': 94, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.6926143169403076}\n",
      "[flaml.automl.logger: 09-25 12:43:27] {2391} INFO -  at 663.7s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:27] {2218} INFO - iteration 214, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:43:27] {805} INFO - trial 1 config: {'n_estimators': 7, 'max_depth': 8, 'min_child_weight': 0.6473850540637559, 'learning_rate': 1.0, 'subsample': 0.9728097438800569, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8416347900393352, 'reg_alpha': 0.1806032569414592, 'reg_lambda': 2.251779173552381}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:43:30] {197} INFO - result: {'pred_time': 4.765758039785793e-05, 'wall_clock_time': 666.4094364643097, 'metric_for_logging': {'pred_time': 4.765758039785793e-05}, 'val_loss': 0.2682269701947363, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340718b0>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_depth': 8, 'min_child_weight': 0.6473850540637559, 'learning_rate': 1.0, 'subsample': 0.9728097438800569, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8416347900393352, 'reg_alpha': 0.1806032569414592, 'reg_lambda': 2.251779173552381}, 'config/n_estimators': 7, 'config/max_depth': 8, 'config/min_child_weight': 0.6473850540637559, 'config/learning_rate': 1.0, 'config/subsample': 0.9728097438800569, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.8416347900393352, 'config/reg_alpha': 0.1806032569414592, 'config/reg_lambda': 2.251779173552381, 'experiment_tag': 'exp', 'time_total_s': 2.659358263015747}\n",
      "[flaml.tune.tune: 09-25 12:43:30] {197} INFO - result: {'pred_time': 4.765758039785793e-05, 'wall_clock_time': 666.4094364643097, 'metric_for_logging': {'pred_time': 4.765758039785793e-05}, 'val_loss': 0.2682269701947363, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340718b0>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_depth': 8, 'min_child_weight': 0.6473850540637559, 'learning_rate': 1.0, 'subsample': 0.9728097438800569, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8416347900393352, 'reg_alpha': 0.1806032569414592, 'reg_lambda': 2.251779173552381}, 'config/n_estimators': 7, 'config/max_depth': 8, 'config/min_child_weight': 0.6473850540637559, 'config/learning_rate': 1.0, 'config/subsample': 0.9728097438800569, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.8416347900393352, 'config/reg_alpha': 0.1806032569414592, 'config/reg_lambda': 2.251779173552381, 'experiment_tag': 'exp', 'time_total_s': 2.6605799198150635}\n",
      "[flaml.automl.logger: 09-25 12:43:30] {2391} INFO -  at 666.4s,\testimator xgb_limitdepth's best error=0.2309,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:30] {2218} INFO - iteration 215, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:43:30] {805} INFO - trial 1 config: {'n_estimators': 41, 'max_depth': 6, 'min_child_weight': 0.9145011565658502, 'learning_rate': 0.36659877136696994, 'subsample': 1.0, 'colsample_bylevel': 0.7271287520577477, 'colsample_bytree': 0.7517943298140125, 'reg_alpha': 0.018739990366816717, 'reg_lambda': 7.397749222431835}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:43:37] {197} INFO - result: {'pred_time': 4.885934485537758e-05, 'wall_clock_time': 673.3821969032288, 'metric_for_logging': {'pred_time': 4.885934485537758e-05}, 'val_loss': 0.2285249656876344, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe534071760>, 'training_iteration': 0, 'config': {'n_estimators': 41, 'max_depth': 6, 'min_child_weight': 0.9145011565658502, 'learning_rate': 0.36659877136696994, 'subsample': 1.0, 'colsample_bylevel': 0.7271287520577477, 'colsample_bytree': 0.7517943298140125, 'reg_alpha': 0.018739990366816717, 'reg_lambda': 7.397749222431835}, 'config/n_estimators': 41, 'config/max_depth': 6, 'config/min_child_weight': 0.9145011565658502, 'config/learning_rate': 0.36659877136696994, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.7271287520577477, 'config/colsample_bytree': 0.7517943298140125, 'config/reg_alpha': 0.018739990366816717, 'config/reg_lambda': 7.397749222431835, 'experiment_tag': 'exp', 'time_total_s': 6.965161561965942}\n",
      "[flaml.tune.tune: 09-25 12:43:37] {197} INFO - result: {'pred_time': 4.885934485537758e-05, 'wall_clock_time': 673.3821969032288, 'metric_for_logging': {'pred_time': 4.885934485537758e-05}, 'val_loss': 0.2285249656876344, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe534071760>, 'training_iteration': 1, 'config': {'n_estimators': 41, 'max_depth': 6, 'min_child_weight': 0.9145011565658502, 'learning_rate': 0.36659877136696994, 'subsample': 1.0, 'colsample_bylevel': 0.7271287520577477, 'colsample_bytree': 0.7517943298140125, 'reg_alpha': 0.018739990366816717, 'reg_lambda': 7.397749222431835}, 'config/n_estimators': 41, 'config/max_depth': 6, 'config/min_child_weight': 0.9145011565658502, 'config/learning_rate': 0.36659877136696994, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.7271287520577477, 'config/colsample_bytree': 0.7517943298140125, 'config/reg_alpha': 0.018739990366816717, 'config/reg_lambda': 7.397749222431835, 'experiment_tag': 'exp', 'time_total_s': 6.966642618179321}\n",
      "[flaml.automl.logger: 09-25 12:43:37] {2391} INFO -  at 673.4s,\testimator xgb_limitdepth's best error=0.2285,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:37] {2218} INFO - iteration 216, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:43:37] {805} INFO - trial 1 config: {'early_stopping_rounds': 15, 'learning_rate': 0.04128604410844918, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:43:41] {197} INFO - result: {'pred_time': 0.00010754991544133493, 'wall_clock_time': 677.8337452411652, 'metric_for_logging': {'pred_time': 0.00010754991544133493}, 'val_loss': 0.2515937197721305, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe534071040>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 15, 'learning_rate': 0.04128604410844918, 'n_estimators': 8192}, 'config/early_stopping_rounds': 15, 'config/learning_rate': 0.04128604410844918, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.4456822872161865}\n",
      "[flaml.tune.tune: 09-25 12:43:41] {197} INFO - result: {'pred_time': 0.00010754991544133493, 'wall_clock_time': 677.8337452411652, 'metric_for_logging': {'pred_time': 0.00010754991544133493}, 'val_loss': 0.2515937197721305, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe534071040>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 15, 'learning_rate': 0.04128604410844918, 'n_estimators': 8192}, 'config/early_stopping_rounds': 15, 'config/learning_rate': 0.04128604410844918, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.446943044662476}\n",
      "[flaml.automl.logger: 09-25 12:43:41] {2391} INFO -  at 677.8s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:41] {2218} INFO - iteration 217, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:43:41] {805} INFO - trial 1 config: {'n_estimators': 26, 'max_depth': 5, 'min_child_weight': 6.369608581672032, 'learning_rate': 0.21976819009712747, 'subsample': 0.9827721799620315, 'colsample_bylevel': 0.9179692403864321, 'colsample_bytree': 0.8359678015617814, 'reg_alpha': 0.01039352050468898, 'reg_lambda': 14.193476315213063}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:43:47] {197} INFO - result: {'pred_time': 4.904387173375973e-05, 'wall_clock_time': 683.0733389854431, 'metric_for_logging': {'pred_time': 4.904387173375973e-05}, 'val_loss': 0.25285567109030377, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe53406b220>, 'training_iteration': 0, 'config': {'n_estimators': 26, 'max_depth': 5, 'min_child_weight': 6.369608581672032, 'learning_rate': 0.21976819009712747, 'subsample': 0.9827721799620315, 'colsample_bylevel': 0.9179692403864321, 'colsample_bytree': 0.8359678015617814, 'reg_alpha': 0.01039352050468898, 'reg_lambda': 14.193476315213063}, 'config/n_estimators': 26, 'config/max_depth': 5, 'config/min_child_weight': 6.369608581672032, 'config/learning_rate': 0.21976819009712747, 'config/subsample': 0.9827721799620315, 'config/colsample_bylevel': 0.9179692403864321, 'config/colsample_bytree': 0.8359678015617814, 'config/reg_alpha': 0.01039352050468898, 'config/reg_lambda': 14.193476315213063, 'experiment_tag': 'exp', 'time_total_s': 5.231369972229004}\n",
      "[flaml.tune.tune: 09-25 12:43:47] {197} INFO - result: {'pred_time': 4.904387173375973e-05, 'wall_clock_time': 683.0733389854431, 'metric_for_logging': {'pred_time': 4.904387173375973e-05}, 'val_loss': 0.25285567109030377, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe53406b220>, 'training_iteration': 1, 'config': {'n_estimators': 26, 'max_depth': 5, 'min_child_weight': 6.369608581672032, 'learning_rate': 0.21976819009712747, 'subsample': 0.9827721799620315, 'colsample_bylevel': 0.9179692403864321, 'colsample_bytree': 0.8359678015617814, 'reg_alpha': 0.01039352050468898, 'reg_lambda': 14.193476315213063}, 'config/n_estimators': 26, 'config/max_depth': 5, 'config/min_child_weight': 6.369608581672032, 'config/learning_rate': 0.21976819009712747, 'config/subsample': 0.9827721799620315, 'config/colsample_bylevel': 0.9179692403864321, 'config/colsample_bytree': 0.8359678015617814, 'config/reg_alpha': 0.01039352050468898, 'config/reg_lambda': 14.193476315213063, 'experiment_tag': 'exp', 'time_total_s': 5.2329301834106445}\n",
      "[flaml.automl.logger: 09-25 12:43:47] {2391} INFO -  at 683.1s,\testimator xgb_limitdepth's best error=0.2285,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:47] {2218} INFO - iteration 218, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:43:47] {805} INFO - trial 1 config: {'n_estimators': 151, 'max_features': 0.032427221756276076, 'max_leaves': 67, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:43:51] {197} INFO - result: {'pred_time': 0.00019699500282759893, 'wall_clock_time': 687.2371516227722, 'metric_for_logging': {'pred_time': 0.00019699500282759893}, 'val_loss': 0.1904099059271473, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5340db8e0>, 'training_iteration': 0, 'config': {'n_estimators': 151, 'max_features': 0.032427221756276076, 'max_leaves': 67, 'criterion': 'entropy'}, 'config/n_estimators': 151, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 67, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 4.156416654586792}\n",
      "[flaml.tune.tune: 09-25 12:43:51] {197} INFO - result: {'pred_time': 0.00019699500282759893, 'wall_clock_time': 687.2371516227722, 'metric_for_logging': {'pred_time': 0.00019699500282759893}, 'val_loss': 0.1904099059271473, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5340db8e0>, 'training_iteration': 1, 'config': {'n_estimators': 151, 'max_features': 0.032427221756276076, 'max_leaves': 67, 'criterion': 'entropy'}, 'config/n_estimators': 151, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 67, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 4.157739639282227}\n",
      "[flaml.automl.logger: 09-25 12:43:51] {2391} INFO -  at 687.2s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:51] {2218} INFO - iteration 219, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:43:51] {805} INFO - trial 1 config: {'n_estimators': 22, 'num_leaves': 33, 'min_child_samples': 8, 'learning_rate': 0.30187558578949736, 'log_max_bin': 9, 'colsample_bytree': 0.8276828351687129, 'reg_alpha': 0.004756653941987422, 'reg_lambda': 3.0055535012813395}\n",
      "[flaml.tune.tune: 09-25 12:43:51] {197} INFO - result: {'pred_time': 1.0662325274057998e-05, 'wall_clock_time': 687.8182580471039, 'metric_for_logging': {'pred_time': 1.0662325274057998e-05}, 'val_loss': 0.20720053175075667, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340bbc10>, 'training_iteration': 0, 'config': {'n_estimators': 22, 'num_leaves': 33, 'min_child_samples': 8, 'learning_rate': 0.30187558578949736, 'log_max_bin': 9, 'colsample_bytree': 0.8276828351687129, 'reg_alpha': 0.004756653941987422, 'reg_lambda': 3.0055535012813395}, 'config/n_estimators': 22, 'config/num_leaves': 33, 'config/min_child_samples': 8, 'config/learning_rate': 0.30187558578949736, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8276828351687129, 'config/reg_alpha': 0.004756653941987422, 'config/reg_lambda': 3.0055535012813395, 'experiment_tag': 'exp', 'time_total_s': 0.573758602142334}\n",
      "[flaml.tune.tune: 09-25 12:43:51] {197} INFO - result: {'pred_time': 1.0662325274057998e-05, 'wall_clock_time': 687.8182580471039, 'metric_for_logging': {'pred_time': 1.0662325274057998e-05}, 'val_loss': 0.20720053175075667, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340bbc10>, 'training_iteration': 1, 'config': {'n_estimators': 22, 'num_leaves': 33, 'min_child_samples': 8, 'learning_rate': 0.30187558578949736, 'log_max_bin': 9, 'colsample_bytree': 0.8276828351687129, 'reg_alpha': 0.004756653941987422, 'reg_lambda': 3.0055535012813395}, 'config/n_estimators': 22, 'config/num_leaves': 33, 'config/min_child_samples': 8, 'config/learning_rate': 0.30187558578949736, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8276828351687129, 'config/reg_alpha': 0.004756653941987422, 'config/reg_lambda': 3.0055535012813395, 'experiment_tag': 'exp', 'time_total_s': 0.5751688480377197}\n",
      "[flaml.automl.logger: 09-25 12:43:51] {2391} INFO -  at 687.8s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:51] {2218} INFO - iteration 220, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:43:51] {805} INFO - trial 1 config: {'n_estimators': 367, 'num_leaves': 149, 'min_child_samples': 6, 'learning_rate': 0.13876387936566456, 'log_max_bin': 9, 'colsample_bytree': 0.7222990560333681, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5790943120298089}\n",
      "[flaml.tune.tune: 09-25 12:43:57] {197} INFO - result: {'pred_time': 2.5907761673189463e-05, 'wall_clock_time': 693.3230097293854, 'metric_for_logging': {'pred_time': 2.5907761673189463e-05}, 'val_loss': 0.2015703600036433, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe53406bf70>, 'training_iteration': 0, 'config': {'n_estimators': 367, 'num_leaves': 149, 'min_child_samples': 6, 'learning_rate': 0.13876387936566456, 'log_max_bin': 9, 'colsample_bytree': 0.7222990560333681, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5790943120298089}, 'config/n_estimators': 367, 'config/num_leaves': 149, 'config/min_child_samples': 6, 'config/learning_rate': 0.13876387936566456, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7222990560333681, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5790943120298089, 'experiment_tag': 'exp', 'time_total_s': 5.496340036392212}\n",
      "[flaml.tune.tune: 09-25 12:43:57] {197} INFO - result: {'pred_time': 2.5907761673189463e-05, 'wall_clock_time': 693.3230097293854, 'metric_for_logging': {'pred_time': 2.5907761673189463e-05}, 'val_loss': 0.2015703600036433, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe53406bf70>, 'training_iteration': 1, 'config': {'n_estimators': 367, 'num_leaves': 149, 'min_child_samples': 6, 'learning_rate': 0.13876387936566456, 'log_max_bin': 9, 'colsample_bytree': 0.7222990560333681, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5790943120298089}, 'config/n_estimators': 367, 'config/num_leaves': 149, 'config/min_child_samples': 6, 'config/learning_rate': 0.13876387936566456, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7222990560333681, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5790943120298089, 'experiment_tag': 'exp', 'time_total_s': 5.497647523880005}\n",
      "[flaml.automl.logger: 09-25 12:43:57] {2391} INFO -  at 693.3s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:57] {2218} INFO - iteration 221, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:43:57] {805} INFO - trial 1 config: {'n_estimators': 49, 'max_features': 0.04282428707852437, 'max_leaves': 378, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:43:59] {197} INFO - result: {'pred_time': 8.377205445689313e-05, 'wall_clock_time': 695.0851764678955, 'metric_for_logging': {'pred_time': 8.377205445689313e-05}, 'val_loss': 0.21653365105389097, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680d23d0>, 'training_iteration': 0, 'config': {'n_estimators': 49, 'max_features': 0.04282428707852437, 'max_leaves': 378, 'criterion': 'entropy'}, 'config/n_estimators': 49, 'config/max_features': 0.04282428707852437, 'config/max_leaves': 378, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.7547309398651123}\n",
      "[flaml.tune.tune: 09-25 12:43:59] {197} INFO - result: {'pred_time': 8.377205445689313e-05, 'wall_clock_time': 695.0851764678955, 'metric_for_logging': {'pred_time': 8.377205445689313e-05}, 'val_loss': 0.21653365105389097, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680d23d0>, 'training_iteration': 1, 'config': {'n_estimators': 49, 'max_features': 0.04282428707852437, 'max_leaves': 378, 'criterion': 'entropy'}, 'config/n_estimators': 49, 'config/max_features': 0.04282428707852437, 'config/max_leaves': 378, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.7560770511627197}\n",
      "[flaml.automl.logger: 09-25 12:43:59] {2391} INFO -  at 695.1s,\testimator extra_tree's best error=0.2006,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:43:59] {2218} INFO - iteration 222, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:43:59] {805} INFO - trial 1 config: {'n_estimators': 398, 'num_leaves': 47, 'min_child_samples': 6, 'learning_rate': 0.08692086717706049, 'log_max_bin': 10, 'colsample_bytree': 0.7952499779389052, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.3411470134681796}\n",
      "[flaml.tune.tune: 09-25 12:44:03] {197} INFO - result: {'pred_time': 2.5034125009793205e-05, 'wall_clock_time': 699.6266887187958, 'metric_for_logging': {'pred_time': 2.5034125009793205e-05}, 'val_loss': 0.2086693226498324, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524273790>, 'training_iteration': 0, 'config': {'n_estimators': 398, 'num_leaves': 47, 'min_child_samples': 6, 'learning_rate': 0.08692086717706049, 'log_max_bin': 10, 'colsample_bytree': 0.7952499779389052, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.3411470134681796}, 'config/n_estimators': 398, 'config/num_leaves': 47, 'config/min_child_samples': 6, 'config/learning_rate': 0.08692086717706049, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7952499779389052, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.3411470134681796, 'experiment_tag': 'exp', 'time_total_s': 4.533957481384277}\n",
      "[flaml.tune.tune: 09-25 12:44:03] {197} INFO - result: {'pred_time': 2.5034125009793205e-05, 'wall_clock_time': 699.6266887187958, 'metric_for_logging': {'pred_time': 2.5034125009793205e-05}, 'val_loss': 0.2086693226498324, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524273790>, 'training_iteration': 1, 'config': {'n_estimators': 398, 'num_leaves': 47, 'min_child_samples': 6, 'learning_rate': 0.08692086717706049, 'log_max_bin': 10, 'colsample_bytree': 0.7952499779389052, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.3411470134681796}, 'config/n_estimators': 398, 'config/num_leaves': 47, 'config/min_child_samples': 6, 'config/learning_rate': 0.08692086717706049, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7952499779389052, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.3411470134681796, 'experiment_tag': 'exp', 'time_total_s': 4.535233736038208}\n",
      "[flaml.automl.logger: 09-25 12:44:03] {2391} INFO -  at 699.6s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:44:03] {2218} INFO - iteration 223, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:44:03] {805} INFO - trial 1 config: {'n_estimators': 65, 'max_depth': 7, 'min_child_weight': 0.13129729317539074, 'learning_rate': 0.6115291712980646, 'subsample': 1.0, 'colsample_bylevel': 0.5362882637290634, 'colsample_bytree': 0.6676208580662436, 'reg_alpha': 0.033789055285930035, 'reg_lambda': 3.8557638976247723}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:44:12] {197} INFO - result: {'pred_time': 4.963048769732633e-05, 'wall_clock_time': 708.6764755249023, 'metric_for_logging': {'pred_time': 4.963048769732633e-05}, 'val_loss': 0.21962362979979178, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524283070>, 'training_iteration': 0, 'config': {'n_estimators': 65, 'max_depth': 7, 'min_child_weight': 0.13129729317539074, 'learning_rate': 0.6115291712980646, 'subsample': 1.0, 'colsample_bylevel': 0.5362882637290634, 'colsample_bytree': 0.6676208580662436, 'reg_alpha': 0.033789055285930035, 'reg_lambda': 3.8557638976247723}, 'config/n_estimators': 65, 'config/max_depth': 7, 'config/min_child_weight': 0.13129729317539074, 'config/learning_rate': 0.6115291712980646, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.5362882637290634, 'config/colsample_bytree': 0.6676208580662436, 'config/reg_alpha': 0.033789055285930035, 'config/reg_lambda': 3.8557638976247723, 'experiment_tag': 'exp', 'time_total_s': 9.04391598701477}\n",
      "[flaml.tune.tune: 09-25 12:44:12] {197} INFO - result: {'pred_time': 4.963048769732633e-05, 'wall_clock_time': 708.6764755249023, 'metric_for_logging': {'pred_time': 4.963048769732633e-05}, 'val_loss': 0.21962362979979178, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524283070>, 'training_iteration': 1, 'config': {'n_estimators': 65, 'max_depth': 7, 'min_child_weight': 0.13129729317539074, 'learning_rate': 0.6115291712980646, 'subsample': 1.0, 'colsample_bylevel': 0.5362882637290634, 'colsample_bytree': 0.6676208580662436, 'reg_alpha': 0.033789055285930035, 'reg_lambda': 3.8557638976247723}, 'config/n_estimators': 65, 'config/max_depth': 7, 'config/min_child_weight': 0.13129729317539074, 'config/learning_rate': 0.6115291712980646, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.5362882637290634, 'config/colsample_bytree': 0.6676208580662436, 'config/reg_alpha': 0.033789055285930035, 'config/reg_lambda': 3.8557638976247723, 'experiment_tag': 'exp', 'time_total_s': 9.045747756958008}\n",
      "[flaml.automl.logger: 09-25 12:44:12] {2391} INFO -  at 708.7s,\testimator xgb_limitdepth's best error=0.2196,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:44:12] {2218} INFO - iteration 224, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:44:12] {805} INFO - trial 1 config: {'n_estimators': 36, 'max_depth': 6, 'min_child_weight': 0.17931620478642143, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.6885319215674311, 'colsample_bytree': 0.702084749281336, 'reg_alpha': 0.021643357280973333, 'reg_lambda': 9.519083698494503}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:44:18] {197} INFO - result: {'pred_time': 4.817871362042832e-05, 'wall_clock_time': 714.4777946472168, 'metric_for_logging': {'pred_time': 4.817871362042832e-05}, 'val_loss': 0.2286405653721995, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524283250>, 'training_iteration': 0, 'config': {'n_estimators': 36, 'max_depth': 6, 'min_child_weight': 0.17931620478642143, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.6885319215674311, 'colsample_bytree': 0.702084749281336, 'reg_alpha': 0.021643357280973333, 'reg_lambda': 9.519083698494503}, 'config/n_estimators': 36, 'config/max_depth': 6, 'config/min_child_weight': 0.17931620478642143, 'config/learning_rate': 1.0, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.6885319215674311, 'config/colsample_bytree': 0.702084749281336, 'config/reg_alpha': 0.021643357280973333, 'config/reg_lambda': 9.519083698494503, 'experiment_tag': 'exp', 'time_total_s': 5.794494152069092}\n",
      "[flaml.tune.tune: 09-25 12:44:18] {197} INFO - result: {'pred_time': 4.817871362042832e-05, 'wall_clock_time': 714.4777946472168, 'metric_for_logging': {'pred_time': 4.817871362042832e-05}, 'val_loss': 0.2286405653721995, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524283250>, 'training_iteration': 1, 'config': {'n_estimators': 36, 'max_depth': 6, 'min_child_weight': 0.17931620478642143, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.6885319215674311, 'colsample_bytree': 0.702084749281336, 'reg_alpha': 0.021643357280973333, 'reg_lambda': 9.519083698494503}, 'config/n_estimators': 36, 'config/max_depth': 6, 'config/min_child_weight': 0.17931620478642143, 'config/learning_rate': 1.0, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.6885319215674311, 'config/colsample_bytree': 0.702084749281336, 'config/reg_alpha': 0.021643357280973333, 'config/reg_lambda': 9.519083698494503, 'experiment_tag': 'exp', 'time_total_s': 5.795995473861694}\n",
      "[flaml.automl.logger: 09-25 12:44:18] {2391} INFO -  at 714.5s,\testimator xgb_limitdepth's best error=0.2196,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:44:18] {2218} INFO - iteration 225, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:44:18] {805} INFO - trial 1 config: {'n_estimators': 20, 'num_leaves': 103, 'min_child_samples': 8, 'learning_rate': 0.4819260176569922, 'log_max_bin': 8, 'colsample_bytree': 0.7547319132631758, 'reg_alpha': 0.0011754888204348985, 'reg_lambda': 5.101902899277895}\n",
      "[flaml.tune.tune: 09-25 12:44:19] {197} INFO - result: {'pred_time': 1.0971647704730294e-05, 'wall_clock_time': 715.164431810379, 'metric_for_logging': {'pred_time': 1.0971647704730294e-05}, 'val_loss': 0.2096857886025802, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524283460>, 'training_iteration': 0, 'config': {'n_estimators': 20, 'num_leaves': 103, 'min_child_samples': 8, 'learning_rate': 0.4819260176569922, 'log_max_bin': 8, 'colsample_bytree': 0.7547319132631758, 'reg_alpha': 0.0011754888204348985, 'reg_lambda': 5.101902899277895}, 'config/n_estimators': 20, 'config/num_leaves': 103, 'config/min_child_samples': 8, 'config/learning_rate': 0.4819260176569922, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7547319132631758, 'config/reg_alpha': 0.0011754888204348985, 'config/reg_lambda': 5.101902899277895, 'experiment_tag': 'exp', 'time_total_s': 0.6792473793029785}\n",
      "[flaml.tune.tune: 09-25 12:44:19] {197} INFO - result: {'pred_time': 1.0971647704730294e-05, 'wall_clock_time': 715.164431810379, 'metric_for_logging': {'pred_time': 1.0971647704730294e-05}, 'val_loss': 0.2096857886025802, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe524283460>, 'training_iteration': 1, 'config': {'n_estimators': 20, 'num_leaves': 103, 'min_child_samples': 8, 'learning_rate': 0.4819260176569922, 'log_max_bin': 8, 'colsample_bytree': 0.7547319132631758, 'reg_alpha': 0.0011754888204348985, 'reg_lambda': 5.101902899277895}, 'config/n_estimators': 20, 'config/num_leaves': 103, 'config/min_child_samples': 8, 'config/learning_rate': 0.4819260176569922, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7547319132631758, 'config/reg_alpha': 0.0011754888204348985, 'config/reg_lambda': 5.101902899277895, 'experiment_tag': 'exp', 'time_total_s': 0.6809937953948975}\n",
      "[flaml.automl.logger: 09-25 12:44:19] {2391} INFO -  at 715.2s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:44:19] {2218} INFO - iteration 226, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:44:19] {805} INFO - trial 1 config: {'n_estimators': 32, 'max_features': 0.047139426238373784, 'max_leaves': 237, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:44:20] {197} INFO - result: {'pred_time': 5.884624164951402e-05, 'wall_clock_time': 716.4500513076782, 'metric_for_logging': {'pred_time': 5.884624164951402e-05}, 'val_loss': 0.2077326418218472, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5340d2fa0>, 'training_iteration': 0, 'config': {'n_estimators': 32, 'max_features': 0.047139426238373784, 'max_leaves': 237, 'criterion': 'gini'}, 'config/n_estimators': 32, 'config/max_features': 0.047139426238373784, 'config/max_leaves': 237, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.2779607772827148}\n",
      "[flaml.tune.tune: 09-25 12:44:20] {197} INFO - result: {'pred_time': 5.884624164951402e-05, 'wall_clock_time': 716.4500513076782, 'metric_for_logging': {'pred_time': 5.884624164951402e-05}, 'val_loss': 0.2077326418218472, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5340d2fa0>, 'training_iteration': 1, 'config': {'n_estimators': 32, 'max_features': 0.047139426238373784, 'max_leaves': 237, 'criterion': 'gini'}, 'config/n_estimators': 32, 'config/max_features': 0.047139426238373784, 'config/max_leaves': 237, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.279620885848999}\n",
      "[flaml.automl.logger: 09-25 12:44:20] {2391} INFO -  at 716.5s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:44:20] {2218} INFO - iteration 227, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:44:20] {805} INFO - trial 1 config: {'early_stopping_rounds': 12, 'learning_rate': 0.03647031057613702, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:44:26] {197} INFO - result: {'pred_time': 0.00013495003724356744, 'wall_clock_time': 722.4951477050781, 'metric_for_logging': {'pred_time': 0.00013495003724356744}, 'val_loss': 0.24641417163905918, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340cb4f0>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.03647031057613702, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.03647031057613702, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.038118600845337}\n",
      "[flaml.tune.tune: 09-25 12:44:26] {197} INFO - result: {'pred_time': 0.00013495003724356744, 'wall_clock_time': 722.4951477050781, 'metric_for_logging': {'pred_time': 0.00013495003724356744}, 'val_loss': 0.24641417163905918, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340cb4f0>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.03647031057613702, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.03647031057613702, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.039977073669434}\n",
      "[flaml.automl.logger: 09-25 12:44:26] {2391} INFO -  at 722.5s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:44:26] {2218} INFO - iteration 228, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:44:26] {805} INFO - trial 1 config: {'n_estimators': 129, 'max_features': 0.04578986454516365, 'max_leaves': 63, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:44:30] {197} INFO - result: {'pred_time': 0.00017750294415678044, 'wall_clock_time': 726.2446012496948, 'metric_for_logging': {'pred_time': 0.00017750294415678044}, 'val_loss': 0.19940845585523248, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe66809e940>, 'training_iteration': 0, 'config': {'n_estimators': 129, 'max_features': 0.04578986454516365, 'max_leaves': 63, 'criterion': 'entropy'}, 'config/n_estimators': 129, 'config/max_features': 0.04578986454516365, 'config/max_leaves': 63, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.741603136062622}\n",
      "[flaml.tune.tune: 09-25 12:44:30] {197} INFO - result: {'pred_time': 0.00017750294415678044, 'wall_clock_time': 726.2446012496948, 'metric_for_logging': {'pred_time': 0.00017750294415678044}, 'val_loss': 0.19940845585523248, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe66809e940>, 'training_iteration': 1, 'config': {'n_estimators': 129, 'max_features': 0.04578986454516365, 'max_leaves': 63, 'criterion': 'entropy'}, 'config/n_estimators': 129, 'config/max_features': 0.04578986454516365, 'config/max_leaves': 63, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.7432544231414795}\n",
      "[flaml.automl.logger: 09-25 12:44:30] {2391} INFO -  at 726.2s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:44:30] {2218} INFO - iteration 229, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:44:30] {805} INFO - trial 1 config: {'n_estimators': 116, 'max_depth': 8, 'min_child_weight': 0.0961373190767526, 'learning_rate': 0.1906768170793791, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.38404460589069533, 'colsample_bytree': 0.6331569668511512, 'reg_alpha': 0.05275060806390257, 'reg_lambda': 1.5618010834990204}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:44:44] {197} INFO - result: {'pred_time': 4.8305310975447635e-05, 'wall_clock_time': 740.4708256721497, 'metric_for_logging': {'pred_time': 4.8305310975447635e-05}, 'val_loss': 0.20248124378559162, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe52414f250>, 'training_iteration': 0, 'config': {'n_estimators': 116, 'max_depth': 8, 'min_child_weight': 0.0961373190767526, 'learning_rate': 0.1906768170793791, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.38404460589069533, 'colsample_bytree': 0.6331569668511512, 'reg_alpha': 0.05275060806390257, 'reg_lambda': 1.5618010834990204}, 'config/n_estimators': 116, 'config/max_depth': 8, 'config/min_child_weight': 0.0961373190767526, 'config/learning_rate': 0.1906768170793791, 'config/subsample': 0.8895588746662894, 'config/colsample_bylevel': 0.38404460589069533, 'config/colsample_bytree': 0.6331569668511512, 'config/reg_alpha': 0.05275060806390257, 'config/reg_lambda': 1.5618010834990204, 'experiment_tag': 'exp', 'time_total_s': 14.218582391738892}\n",
      "[flaml.tune.tune: 09-25 12:44:44] {197} INFO - result: {'pred_time': 4.8305310975447635e-05, 'wall_clock_time': 740.4708256721497, 'metric_for_logging': {'pred_time': 4.8305310975447635e-05}, 'val_loss': 0.20248124378559162, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe52414f250>, 'training_iteration': 1, 'config': {'n_estimators': 116, 'max_depth': 8, 'min_child_weight': 0.0961373190767526, 'learning_rate': 0.1906768170793791, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.38404460589069533, 'colsample_bytree': 0.6331569668511512, 'reg_alpha': 0.05275060806390257, 'reg_lambda': 1.5618010834990204}, 'config/n_estimators': 116, 'config/max_depth': 8, 'config/min_child_weight': 0.0961373190767526, 'config/learning_rate': 0.1906768170793791, 'config/subsample': 0.8895588746662894, 'config/colsample_bylevel': 0.38404460589069533, 'config/colsample_bytree': 0.6331569668511512, 'config/reg_alpha': 0.05275060806390257, 'config/reg_lambda': 1.5618010834990204, 'experiment_tag': 'exp', 'time_total_s': 14.2201669216156}\n",
      "[flaml.automl.logger: 09-25 12:44:44] {2391} INFO -  at 740.5s,\testimator xgb_limitdepth's best error=0.2025,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:44:44] {2218} INFO - iteration 230, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:44:44] {805} INFO - trial 1 config: {'early_stopping_rounds': 14, 'learning_rate': 0.047718988394873485, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:44:48] {197} INFO - result: {'pred_time': 0.00010725611278817643, 'wall_clock_time': 744.4514870643616, 'metric_for_logging': {'pred_time': 0.00010725611278817643}, 'val_loss': 0.24108595823363438, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe52414f4f0>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 14, 'learning_rate': 0.047718988394873485, 'n_estimators': 8192}, 'config/early_stopping_rounds': 14, 'config/learning_rate': 0.047718988394873485, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 3.9739816188812256}\n",
      "[flaml.tune.tune: 09-25 12:44:48] {197} INFO - result: {'pred_time': 0.00010725611278817643, 'wall_clock_time': 744.4514870643616, 'metric_for_logging': {'pred_time': 0.00010725611278817643}, 'val_loss': 0.24108595823363438, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe52414f4f0>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 14, 'learning_rate': 0.047718988394873485, 'n_estimators': 8192}, 'config/early_stopping_rounds': 14, 'config/learning_rate': 0.047718988394873485, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 3.9751360416412354}\n",
      "[flaml.automl.logger: 09-25 12:44:48] {2391} INFO -  at 744.5s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:44:48] {2218} INFO - iteration 231, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:44:48] {805} INFO - trial 1 config: {'n_estimators': 63, 'max_depth': 6, 'min_child_weight': 0.14047820577752654, 'learning_rate': 0.3287452722016841, 'subsample': 0.937812919568431, 'colsample_bylevel': 0.5007303637080798, 'colsample_bytree': 0.6907687602151568, 'reg_alpha': 0.07598816897685652, 'reg_lambda': 0.514344429341601}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:44:56] {197} INFO - result: {'pred_time': 4.729708019314835e-05, 'wall_clock_time': 752.4201762676239, 'metric_for_logging': {'pred_time': 4.729708019314835e-05}, 'val_loss': 0.2180918419861449, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340cb070>, 'training_iteration': 0, 'config': {'n_estimators': 63, 'max_depth': 6, 'min_child_weight': 0.14047820577752654, 'learning_rate': 0.3287452722016841, 'subsample': 0.937812919568431, 'colsample_bylevel': 0.5007303637080798, 'colsample_bytree': 0.6907687602151568, 'reg_alpha': 0.07598816897685652, 'reg_lambda': 0.514344429341601}, 'config/n_estimators': 63, 'config/max_depth': 6, 'config/min_child_weight': 0.14047820577752654, 'config/learning_rate': 0.3287452722016841, 'config/subsample': 0.937812919568431, 'config/colsample_bylevel': 0.5007303637080798, 'config/colsample_bytree': 0.6907687602151568, 'config/reg_alpha': 0.07598816897685652, 'config/reg_lambda': 0.514344429341601, 'experiment_tag': 'exp', 'time_total_s': 7.961425304412842}\n",
      "[flaml.tune.tune: 09-25 12:44:56] {197} INFO - result: {'pred_time': 4.729708019314835e-05, 'wall_clock_time': 752.4201762676239, 'metric_for_logging': {'pred_time': 4.729708019314835e-05}, 'val_loss': 0.2180918419861449, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340cb070>, 'training_iteration': 1, 'config': {'n_estimators': 63, 'max_depth': 6, 'min_child_weight': 0.14047820577752654, 'learning_rate': 0.3287452722016841, 'subsample': 0.937812919568431, 'colsample_bylevel': 0.5007303637080798, 'colsample_bytree': 0.6907687602151568, 'reg_alpha': 0.07598816897685652, 'reg_lambda': 0.514344429341601}, 'config/n_estimators': 63, 'config/max_depth': 6, 'config/min_child_weight': 0.14047820577752654, 'config/learning_rate': 0.3287452722016841, 'config/subsample': 0.937812919568431, 'config/colsample_bylevel': 0.5007303637080798, 'config/colsample_bytree': 0.6907687602151568, 'config/reg_alpha': 0.07598816897685652, 'config/reg_lambda': 0.514344429341601, 'experiment_tag': 'exp', 'time_total_s': 7.9629926681518555}\n",
      "[flaml.automl.logger: 09-25 12:44:56] {2391} INFO -  at 752.4s,\testimator xgb_limitdepth's best error=0.2025,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:44:56] {2218} INFO - iteration 232, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:44:56] {805} INFO - trial 1 config: {'n_estimators': 71, 'max_features': 0.05457990594757908, 'max_leaves': 113, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:44:58] {197} INFO - result: {'pred_time': 0.00011132274700263827, 'wall_clock_time': 754.6882894039154, 'metric_for_logging': {'pred_time': 0.00011132274700263827}, 'val_loss': 0.2002990405351725, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340cbaf0>, 'training_iteration': 0, 'config': {'n_estimators': 71, 'max_features': 0.05457990594757908, 'max_leaves': 113, 'criterion': 'entropy'}, 'config/n_estimators': 71, 'config/max_features': 0.05457990594757908, 'config/max_leaves': 113, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.2611284255981445}\n",
      "[flaml.tune.tune: 09-25 12:44:58] {197} INFO - result: {'pred_time': 0.00011132274700263827, 'wall_clock_time': 754.6882894039154, 'metric_for_logging': {'pred_time': 0.00011132274700263827}, 'val_loss': 0.2002990405351725, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340cbaf0>, 'training_iteration': 1, 'config': {'n_estimators': 71, 'max_features': 0.05457990594757908, 'max_leaves': 113, 'criterion': 'entropy'}, 'config/n_estimators': 71, 'config/max_features': 0.05457990594757908, 'config/max_leaves': 113, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.2625739574432373}\n",
      "[flaml.automl.logger: 09-25 12:44:58] {2391} INFO -  at 754.7s,\testimator extra_tree's best error=0.2003,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:44:58] {2218} INFO - iteration 233, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:44:58] {805} INFO - trial 1 config: {'n_estimators': 215, 'max_depth': 10, 'min_child_weight': 0.06579229901257695, 'learning_rate': 0.1105951983066625, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.26735884807331084, 'colsample_bytree': 0.5755451734871456, 'reg_alpha': 0.036619209129239036, 'reg_lambda': 4.742391450688205}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:45:22] {197} INFO - result: {'pred_time': 5.152769720646118e-05, 'wall_clock_time': 778.4943144321442, 'metric_for_logging': {'pred_time': 5.152769720646118e-05}, 'val_loss': 0.20126754017308737, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340d2d60>, 'training_iteration': 0, 'config': {'n_estimators': 215, 'max_depth': 10, 'min_child_weight': 0.06579229901257695, 'learning_rate': 0.1105951983066625, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.26735884807331084, 'colsample_bytree': 0.5755451734871456, 'reg_alpha': 0.036619209129239036, 'reg_lambda': 4.742391450688205}, 'config/n_estimators': 215, 'config/max_depth': 10, 'config/min_child_weight': 0.06579229901257695, 'config/learning_rate': 0.1105951983066625, 'config/subsample': 0.8413048297641477, 'config/colsample_bylevel': 0.26735884807331084, 'config/colsample_bytree': 0.5755451734871456, 'config/reg_alpha': 0.036619209129239036, 'config/reg_lambda': 4.742391450688205, 'experiment_tag': 'exp', 'time_total_s': 23.797990322113037}\n",
      "[flaml.tune.tune: 09-25 12:45:22] {197} INFO - result: {'pred_time': 5.152769720646118e-05, 'wall_clock_time': 778.4943144321442, 'metric_for_logging': {'pred_time': 5.152769720646118e-05}, 'val_loss': 0.20126754017308737, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340d2d60>, 'training_iteration': 1, 'config': {'n_estimators': 215, 'max_depth': 10, 'min_child_weight': 0.06579229901257695, 'learning_rate': 0.1105951983066625, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.26735884807331084, 'colsample_bytree': 0.5755451734871456, 'reg_alpha': 0.036619209129239036, 'reg_lambda': 4.742391450688205}, 'config/n_estimators': 215, 'config/max_depth': 10, 'config/min_child_weight': 0.06579229901257695, 'config/learning_rate': 0.1105951983066625, 'config/subsample': 0.8413048297641477, 'config/colsample_bylevel': 0.26735884807331084, 'config/colsample_bytree': 0.5755451734871456, 'config/reg_alpha': 0.036619209129239036, 'config/reg_lambda': 4.742391450688205, 'experiment_tag': 'exp', 'time_total_s': 23.7995707988739}\n",
      "[flaml.automl.logger: 09-25 12:45:22] {2391} INFO -  at 778.5s,\testimator xgb_limitdepth's best error=0.2013,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:45:22] {2218} INFO - iteration 234, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:45:22] {805} INFO - trial 1 config: {'n_estimators': 201, 'max_depth': 9, 'min_child_weight': 0.04777966088950308, 'learning_rate': 0.2925446175700998, 'subsample': 0.8552583010104474, 'colsample_bylevel': 0.29486476765777564, 'colsample_bytree': 0.524875675393638, 'reg_alpha': 0.5241893793452336, 'reg_lambda': 0.6241987054993229}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:45:42] {197} INFO - result: {'pred_time': 4.9760144801010535e-05, 'wall_clock_time': 798.9691896438599, 'metric_for_logging': {'pred_time': 4.9760144801010535e-05}, 'val_loss': 0.2093054391030403, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340d2a00>, 'training_iteration': 0, 'config': {'n_estimators': 201, 'max_depth': 9, 'min_child_weight': 0.04777966088950308, 'learning_rate': 0.2925446175700998, 'subsample': 0.8552583010104474, 'colsample_bylevel': 0.29486476765777564, 'colsample_bytree': 0.524875675393638, 'reg_alpha': 0.5241893793452336, 'reg_lambda': 0.6241987054993229}, 'config/n_estimators': 201, 'config/max_depth': 9, 'config/min_child_weight': 0.04777966088950308, 'config/learning_rate': 0.2925446175700998, 'config/subsample': 0.8552583010104474, 'config/colsample_bylevel': 0.29486476765777564, 'config/colsample_bytree': 0.524875675393638, 'config/reg_alpha': 0.5241893793452336, 'config/reg_lambda': 0.6241987054993229, 'experiment_tag': 'exp', 'time_total_s': 20.46778106689453}\n",
      "[flaml.tune.tune: 09-25 12:45:42] {197} INFO - result: {'pred_time': 4.9760144801010535e-05, 'wall_clock_time': 798.9691896438599, 'metric_for_logging': {'pred_time': 4.9760144801010535e-05}, 'val_loss': 0.2093054391030403, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340d2a00>, 'training_iteration': 1, 'config': {'n_estimators': 201, 'max_depth': 9, 'min_child_weight': 0.04777966088950308, 'learning_rate': 0.2925446175700998, 'subsample': 0.8552583010104474, 'colsample_bylevel': 0.29486476765777564, 'colsample_bytree': 0.524875675393638, 'reg_alpha': 0.5241893793452336, 'reg_lambda': 0.6241987054993229}, 'config/n_estimators': 201, 'config/max_depth': 9, 'config/min_child_weight': 0.04777966088950308, 'config/learning_rate': 0.2925446175700998, 'config/subsample': 0.8552583010104474, 'config/colsample_bylevel': 0.29486476765777564, 'config/colsample_bytree': 0.524875675393638, 'config/reg_alpha': 0.5241893793452336, 'config/reg_lambda': 0.6241987054993229, 'experiment_tag': 'exp', 'time_total_s': 20.469473838806152}\n",
      "[flaml.automl.logger: 09-25 12:45:42] {2391} INFO -  at 799.0s,\testimator xgb_limitdepth's best error=0.2013,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:45:42] {2218} INFO - iteration 235, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:45:42] {805} INFO - trial 1 config: {'n_estimators': 229, 'max_depth': 10, 'min_child_weight': 0.09059559085969378, 'learning_rate': 0.04181002539060261, 'subsample': 0.827351358517848, 'colsample_bylevel': 0.239852928488846, 'colsample_bytree': 0.6262146715806534, 'reg_alpha': 0.0025581717793022587, 'reg_lambda': 36.030636515930695}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:46:08] {197} INFO - result: {'pred_time': 5.894605054751193e-05, 'wall_clock_time': 824.1559679508209, 'metric_for_logging': {'pred_time': 5.894605054751193e-05}, 'val_loss': 0.21213374168771465, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340d2730>, 'training_iteration': 0, 'config': {'n_estimators': 229, 'max_depth': 10, 'min_child_weight': 0.09059559085969378, 'learning_rate': 0.04181002539060261, 'subsample': 0.827351358517848, 'colsample_bylevel': 0.239852928488846, 'colsample_bytree': 0.6262146715806534, 'reg_alpha': 0.0025581717793022587, 'reg_lambda': 36.030636515930695}, 'config/n_estimators': 229, 'config/max_depth': 10, 'config/min_child_weight': 0.09059559085969378, 'config/learning_rate': 0.04181002539060261, 'config/subsample': 0.827351358517848, 'config/colsample_bylevel': 0.239852928488846, 'config/colsample_bytree': 0.6262146715806534, 'config/reg_alpha': 0.0025581717793022587, 'config/reg_lambda': 36.030636515930695, 'experiment_tag': 'exp', 'time_total_s': 25.17882537841797}\n",
      "[flaml.tune.tune: 09-25 12:46:08] {197} INFO - result: {'pred_time': 5.894605054751193e-05, 'wall_clock_time': 824.1559679508209, 'metric_for_logging': {'pred_time': 5.894605054751193e-05}, 'val_loss': 0.21213374168771465, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340d2730>, 'training_iteration': 1, 'config': {'n_estimators': 229, 'max_depth': 10, 'min_child_weight': 0.09059559085969378, 'learning_rate': 0.04181002539060261, 'subsample': 0.827351358517848, 'colsample_bylevel': 0.239852928488846, 'colsample_bytree': 0.6262146715806534, 'reg_alpha': 0.0025581717793022587, 'reg_lambda': 36.030636515930695}, 'config/n_estimators': 229, 'config/max_depth': 10, 'config/min_child_weight': 0.09059559085969378, 'config/learning_rate': 0.04181002539060261, 'config/subsample': 0.827351358517848, 'config/colsample_bylevel': 0.239852928488846, 'config/colsample_bytree': 0.6262146715806534, 'config/reg_alpha': 0.0025581717793022587, 'config/reg_lambda': 36.030636515930695, 'experiment_tag': 'exp', 'time_total_s': 25.179917097091675}\n",
      "[flaml.automl.logger: 09-25 12:46:08] {2391} INFO -  at 824.2s,\testimator xgb_limitdepth's best error=0.2013,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:46:08] {2218} INFO - iteration 236, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:46:08] {805} INFO - trial 1 config: {'early_stopping_rounds': 13, 'learning_rate': 0.034720303608372693, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:46:14] {197} INFO - result: {'pred_time': 7.74566301309935e-05, 'wall_clock_time': 830.382318019867, 'metric_for_logging': {'pred_time': 7.74566301309935e-05}, 'val_loss': 0.24894665020227236, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340bb280>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 13, 'learning_rate': 0.034720303608372693, 'n_estimators': 8192}, 'config/early_stopping_rounds': 13, 'config/learning_rate': 0.034720303608372693, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.21955943107605}\n",
      "[flaml.tune.tune: 09-25 12:46:14] {197} INFO - result: {'pred_time': 7.74566301309935e-05, 'wall_clock_time': 830.382318019867, 'metric_for_logging': {'pred_time': 7.74566301309935e-05}, 'val_loss': 0.24894665020227236, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340bb280>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 13, 'learning_rate': 0.034720303608372693, 'n_estimators': 8192}, 'config/early_stopping_rounds': 13, 'config/learning_rate': 0.034720303608372693, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.221140384674072}\n",
      "[flaml.automl.logger: 09-25 12:46:14] {2391} INFO -  at 830.4s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:46:14] {2218} INFO - iteration 237, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:46:14] {805} INFO - trial 1 config: {'n_estimators': 38, 'max_features': 0.07161577592278397, 'max_leaves': 189, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:46:16] {197} INFO - result: {'pred_time': 7.05653780279915e-05, 'wall_clock_time': 832.1144790649414, 'metric_for_logging': {'pred_time': 7.05653780279915e-05}, 'val_loss': 0.21914325235164817, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe524283190>, 'training_iteration': 0, 'config': {'n_estimators': 38, 'max_features': 0.07161577592278397, 'max_leaves': 189, 'criterion': 'gini'}, 'config/n_estimators': 38, 'config/max_features': 0.07161577592278397, 'config/max_leaves': 189, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.7252147197723389}\n",
      "[flaml.tune.tune: 09-25 12:46:16] {197} INFO - result: {'pred_time': 7.05653780279915e-05, 'wall_clock_time': 832.1144790649414, 'metric_for_logging': {'pred_time': 7.05653780279915e-05}, 'val_loss': 0.21914325235164817, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe524283190>, 'training_iteration': 1, 'config': {'n_estimators': 38, 'max_features': 0.07161577592278397, 'max_leaves': 189, 'criterion': 'gini'}, 'config/n_estimators': 38, 'config/max_features': 0.07161577592278397, 'config/max_leaves': 189, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.7271394729614258}\n",
      "[flaml.automl.logger: 09-25 12:46:16] {2391} INFO -  at 832.1s,\testimator extra_tree's best error=0.2003,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:46:16] {2218} INFO - iteration 238, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:46:16] {805} INFO - trial 1 config: {'n_estimators': 96, 'max_depth': 10, 'min_child_weight': 0.021343854253720315, 'learning_rate': 0.054802249212606416, 'subsample': 0.8996608306054059, 'colsample_bylevel': 0.3618547972013337, 'colsample_bytree': 0.6617362181680826, 'reg_alpha': 0.008059259307294694, 'reg_lambda': 17.964084513651596}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:46:30] {197} INFO - result: {'pred_time': 4.831460180075728e-05, 'wall_clock_time': 846.1414380073547, 'metric_for_logging': {'pred_time': 4.831460180075728e-05}, 'val_loss': 0.2168300681606529, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5242ec1c0>, 'training_iteration': 0, 'config': {'n_estimators': 96, 'max_depth': 10, 'min_child_weight': 0.021343854253720315, 'learning_rate': 0.054802249212606416, 'subsample': 0.8996608306054059, 'colsample_bylevel': 0.3618547972013337, 'colsample_bytree': 0.6617362181680826, 'reg_alpha': 0.008059259307294694, 'reg_lambda': 17.964084513651596}, 'config/n_estimators': 96, 'config/max_depth': 10, 'config/min_child_weight': 0.021343854253720315, 'config/learning_rate': 0.054802249212606416, 'config/subsample': 0.8996608306054059, 'config/colsample_bylevel': 0.3618547972013337, 'config/colsample_bytree': 0.6617362181680826, 'config/reg_alpha': 0.008059259307294694, 'config/reg_lambda': 17.964084513651596, 'experiment_tag': 'exp', 'time_total_s': 14.018798589706421}\n",
      "[flaml.tune.tune: 09-25 12:46:30] {197} INFO - result: {'pred_time': 4.831460180075728e-05, 'wall_clock_time': 846.1414380073547, 'metric_for_logging': {'pred_time': 4.831460180075728e-05}, 'val_loss': 0.2168300681606529, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5242ec1c0>, 'training_iteration': 1, 'config': {'n_estimators': 96, 'max_depth': 10, 'min_child_weight': 0.021343854253720315, 'learning_rate': 0.054802249212606416, 'subsample': 0.8996608306054059, 'colsample_bylevel': 0.3618547972013337, 'colsample_bytree': 0.6617362181680826, 'reg_alpha': 0.008059259307294694, 'reg_lambda': 17.964084513651596}, 'config/n_estimators': 96, 'config/max_depth': 10, 'config/min_child_weight': 0.021343854253720315, 'config/learning_rate': 0.054802249212606416, 'config/subsample': 0.8996608306054059, 'config/colsample_bylevel': 0.3618547972013337, 'config/colsample_bytree': 0.6617362181680826, 'config/reg_alpha': 0.008059259307294694, 'config/reg_lambda': 17.964084513651596, 'experiment_tag': 'exp', 'time_total_s': 14.020574569702148}\n",
      "[flaml.automl.logger: 09-25 12:46:30] {2391} INFO -  at 846.1s,\testimator xgb_limitdepth's best error=0.2013,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:46:30] {2218} INFO - iteration 239, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:46:30] {805} INFO - trial 1 config: {'n_estimators': 38, 'max_features': 0.032427221756276076, 'max_leaves': 250, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:46:31] {197} INFO - result: {'pred_time': 6.856354434532295e-05, 'wall_clock_time': 847.506995677948, 'metric_for_logging': {'pred_time': 6.856354434532295e-05}, 'val_loss': 0.20537524896595363, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5242ecac0>, 'training_iteration': 0, 'config': {'n_estimators': 38, 'max_features': 0.032427221756276076, 'max_leaves': 250, 'criterion': 'gini'}, 'config/n_estimators': 38, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 250, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.358079433441162}\n",
      "[flaml.tune.tune: 09-25 12:46:31] {197} INFO - result: {'pred_time': 6.856354434532295e-05, 'wall_clock_time': 847.506995677948, 'metric_for_logging': {'pred_time': 6.856354434532295e-05}, 'val_loss': 0.20537524896595363, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5242ecac0>, 'training_iteration': 1, 'config': {'n_estimators': 38, 'max_features': 0.032427221756276076, 'max_leaves': 250, 'criterion': 'gini'}, 'config/n_estimators': 38, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 250, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.3592579364776611}\n",
      "[flaml.automl.logger: 09-25 12:46:31] {2391} INFO -  at 847.5s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:46:31] {2218} INFO - iteration 240, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:46:31] {805} INFO - trial 1 config: {'n_estimators': 104, 'max_leaves': 533, 'min_child_weight': 0.39575629898055714, 'learning_rate': 0.03781103413154359, 'subsample': 0.883813924071108, 'colsample_bylevel': 0.22266065224352719, 'colsample_bytree': 0.6376648140491118, 'reg_alpha': 0.0009765625, 'reg_lambda': 3.5839788396195975}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:46:41] {197} INFO - result: {'pred_time': 5.0218589014339784e-05, 'wall_clock_time': 857.8283817768097, 'metric_for_logging': {'pred_time': 5.0218589014339784e-05}, 'val_loss': 0.19626809083330823, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe52433c760>, 'training_iteration': 0, 'config': {'n_estimators': 104, 'max_leaves': 533, 'min_child_weight': 0.39575629898055714, 'learning_rate': 0.03781103413154359, 'subsample': 0.883813924071108, 'colsample_bylevel': 0.22266065224352719, 'colsample_bytree': 0.6376648140491118, 'reg_alpha': 0.0009765625, 'reg_lambda': 3.5839788396195975}, 'config/n_estimators': 104, 'config/max_leaves': 533, 'config/min_child_weight': 0.39575629898055714, 'config/learning_rate': 0.03781103413154359, 'config/subsample': 0.883813924071108, 'config/colsample_bylevel': 0.22266065224352719, 'config/colsample_bytree': 0.6376648140491118, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 3.5839788396195975, 'experiment_tag': 'exp', 'time_total_s': 10.314484119415283}\n",
      "[flaml.tune.tune: 09-25 12:46:41] {197} INFO - result: {'pred_time': 5.0218589014339784e-05, 'wall_clock_time': 857.8283817768097, 'metric_for_logging': {'pred_time': 5.0218589014339784e-05}, 'val_loss': 0.19626809083330823, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe52433c760>, 'training_iteration': 1, 'config': {'n_estimators': 104, 'max_leaves': 533, 'min_child_weight': 0.39575629898055714, 'learning_rate': 0.03781103413154359, 'subsample': 0.883813924071108, 'colsample_bylevel': 0.22266065224352719, 'colsample_bytree': 0.6376648140491118, 'reg_alpha': 0.0009765625, 'reg_lambda': 3.5839788396195975}, 'config/n_estimators': 104, 'config/max_leaves': 533, 'config/min_child_weight': 0.39575629898055714, 'config/learning_rate': 0.03781103413154359, 'config/subsample': 0.883813924071108, 'config/colsample_bylevel': 0.22266065224352719, 'config/colsample_bytree': 0.6376648140491118, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 3.5839788396195975, 'experiment_tag': 'exp', 'time_total_s': 10.315792083740234}\n",
      "[flaml.automl.logger: 09-25 12:46:41] {2391} INFO -  at 857.8s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:46:41] {2218} INFO - iteration 241, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:46:41] {805} INFO - trial 1 config: {'n_estimators': 116, 'max_features': 0.06995329429219267, 'max_leaves': 65, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:46:45] {197} INFO - result: {'pred_time': 0.00017047337766991808, 'wall_clock_time': 861.1902666091919, 'metric_for_logging': {'pred_time': 0.00017047337766991808}, 'val_loss': 0.21548778625240392, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52433c1c0>, 'training_iteration': 0, 'config': {'n_estimators': 116, 'max_features': 0.06995329429219267, 'max_leaves': 65, 'criterion': 'entropy'}, 'config/n_estimators': 116, 'config/max_features': 0.06995329429219267, 'config/max_leaves': 65, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.3560500144958496}\n",
      "[flaml.tune.tune: 09-25 12:46:45] {197} INFO - result: {'pred_time': 0.00017047337766991808, 'wall_clock_time': 861.1902666091919, 'metric_for_logging': {'pred_time': 0.00017047337766991808}, 'val_loss': 0.21548778625240392, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52433c1c0>, 'training_iteration': 1, 'config': {'n_estimators': 116, 'max_features': 0.06995329429219267, 'max_leaves': 65, 'criterion': 'entropy'}, 'config/n_estimators': 116, 'config/max_features': 0.06995329429219267, 'config/max_leaves': 65, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.3573319911956787}\n",
      "[flaml.automl.logger: 09-25 12:46:45] {2391} INFO -  at 861.2s,\testimator extra_tree's best error=0.2003,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:46:45] {2218} INFO - iteration 242, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:46:45] {805} INFO - trial 1 config: {'n_estimators': 294, 'num_leaves': 90, 'min_child_samples': 9, 'learning_rate': 0.08967988153242518, 'log_max_bin': 9, 'colsample_bytree': 0.8188792731083071, 'reg_alpha': 0.008110414105028607, 'reg_lambda': 2.7164416469541837}\n",
      "[flaml.tune.tune: 09-25 12:46:49] {197} INFO - result: {'pred_time': 2.3316460196367194e-05, 'wall_clock_time': 865.1181960105896, 'metric_for_logging': {'pred_time': 2.3316460196367194e-05}, 'val_loss': 0.20443729105648148, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe52413fc40>, 'training_iteration': 0, 'config': {'n_estimators': 294, 'num_leaves': 90, 'min_child_samples': 9, 'learning_rate': 0.08967988153242518, 'log_max_bin': 9, 'colsample_bytree': 0.8188792731083071, 'reg_alpha': 0.008110414105028607, 'reg_lambda': 2.7164416469541837}, 'config/n_estimators': 294, 'config/num_leaves': 90, 'config/min_child_samples': 9, 'config/learning_rate': 0.08967988153242518, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8188792731083071, 'config/reg_alpha': 0.008110414105028607, 'config/reg_lambda': 2.7164416469541837, 'experiment_tag': 'exp', 'time_total_s': 3.921844720840454}\n",
      "[flaml.tune.tune: 09-25 12:46:49] {197} INFO - result: {'pred_time': 2.3316460196367194e-05, 'wall_clock_time': 865.1181960105896, 'metric_for_logging': {'pred_time': 2.3316460196367194e-05}, 'val_loss': 0.20443729105648148, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe52413fc40>, 'training_iteration': 1, 'config': {'n_estimators': 294, 'num_leaves': 90, 'min_child_samples': 9, 'learning_rate': 0.08967988153242518, 'log_max_bin': 9, 'colsample_bytree': 0.8188792731083071, 'reg_alpha': 0.008110414105028607, 'reg_lambda': 2.7164416469541837}, 'config/n_estimators': 294, 'config/num_leaves': 90, 'config/min_child_samples': 9, 'config/learning_rate': 0.08967988153242518, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8188792731083071, 'config/reg_alpha': 0.008110414105028607, 'config/reg_lambda': 2.7164416469541837, 'experiment_tag': 'exp', 'time_total_s': 3.923153877258301}\n",
      "[flaml.automl.logger: 09-25 12:46:49] {2391} INFO -  at 865.1s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:46:49] {2218} INFO - iteration 243, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:46:49] {805} INFO - trial 1 config: {'n_estimators': 43, 'max_features': 0.04258507284594107, 'max_leaves': 197, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:46:50] {197} INFO - result: {'pred_time': 7.873367063120424e-05, 'wall_clock_time': 866.617121219635, 'metric_for_logging': {'pred_time': 7.873367063120424e-05}, 'val_loss': 0.206558229028244, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5241552b0>, 'training_iteration': 0, 'config': {'n_estimators': 43, 'max_features': 0.04258507284594107, 'max_leaves': 197, 'criterion': 'gini'}, 'config/n_estimators': 43, 'config/max_features': 0.04258507284594107, 'config/max_leaves': 197, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.4921088218688965}\n",
      "[flaml.tune.tune: 09-25 12:46:50] {197} INFO - result: {'pred_time': 7.873367063120424e-05, 'wall_clock_time': 866.617121219635, 'metric_for_logging': {'pred_time': 7.873367063120424e-05}, 'val_loss': 0.206558229028244, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5241552b0>, 'training_iteration': 1, 'config': {'n_estimators': 43, 'max_features': 0.04258507284594107, 'max_leaves': 197, 'criterion': 'gini'}, 'config/n_estimators': 43, 'config/max_features': 0.04258507284594107, 'config/max_leaves': 197, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.4934663772583008}\n",
      "[flaml.automl.logger: 09-25 12:46:50] {2391} INFO -  at 866.6s,\testimator extra_tree's best error=0.2003,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:46:50] {2218} INFO - iteration 244, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:46:50] {805} INFO - trial 1 config: {'early_stopping_rounds': 13, 'learning_rate': 0.050124167886609144, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:46:57] {197} INFO - result: {'pred_time': 0.0001580298435320352, 'wall_clock_time': 873.0673825740814, 'metric_for_logging': {'pred_time': 0.0001580298435320352}, 'val_loss': 0.2424998129833212, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680b9ca0>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 13, 'learning_rate': 0.050124167886609144, 'n_estimators': 8192}, 'config/early_stopping_rounds': 13, 'config/learning_rate': 0.050124167886609144, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.444232940673828}\n",
      "[flaml.tune.tune: 09-25 12:46:57] {197} INFO - result: {'pred_time': 0.0001580298435320352, 'wall_clock_time': 873.0673825740814, 'metric_for_logging': {'pred_time': 0.0001580298435320352}, 'val_loss': 0.2424998129833212, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680b9ca0>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 13, 'learning_rate': 0.050124167886609144, 'n_estimators': 8192}, 'config/early_stopping_rounds': 13, 'config/learning_rate': 0.050124167886609144, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.445915222167969}\n",
      "[flaml.automl.logger: 09-25 12:46:57] {2391} INFO -  at 873.1s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:46:57] {2218} INFO - iteration 245, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:46:57] {805} INFO - trial 1 config: {'n_estimators': 37, 'max_features': 0.04143002183489998, 'max_leaves': 66, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:46:58] {197} INFO - result: {'pred_time': 6.256594048959379e-05, 'wall_clock_time': 874.2894756793976, 'metric_for_logging': {'pred_time': 6.256594048959379e-05}, 'val_loss': 0.21678376421629797, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5242aa580>, 'training_iteration': 0, 'config': {'n_estimators': 37, 'max_features': 0.04143002183489998, 'max_leaves': 66, 'criterion': 'entropy'}, 'config/n_estimators': 37, 'config/max_features': 0.04143002183489998, 'config/max_leaves': 66, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2149438858032227}\n",
      "[flaml.tune.tune: 09-25 12:46:58] {197} INFO - result: {'pred_time': 6.256594048959379e-05, 'wall_clock_time': 874.2894756793976, 'metric_for_logging': {'pred_time': 6.256594048959379e-05}, 'val_loss': 0.21678376421629797, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5242aa580>, 'training_iteration': 1, 'config': {'n_estimators': 37, 'max_features': 0.04143002183489998, 'max_leaves': 66, 'criterion': 'entropy'}, 'config/n_estimators': 37, 'config/max_features': 0.04143002183489998, 'config/max_leaves': 66, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.216080904006958}\n",
      "[flaml.automl.logger: 09-25 12:46:58] {2391} INFO -  at 874.3s,\testimator extra_tree's best error=0.2003,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:46:58] {2218} INFO - iteration 246, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:46:58] {805} INFO - trial 1 config: {'n_estimators': 36, 'max_features': 0.032427221756276076, 'max_leaves': 73, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:46:59] {197} INFO - result: {'pred_time': 6.181089573483677e-05, 'wall_clock_time': 875.5692954063416, 'metric_for_logging': {'pred_time': 6.181089573483677e-05}, 'val_loss': 0.21064406725950952, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668036850>, 'training_iteration': 0, 'config': {'n_estimators': 36, 'max_features': 0.032427221756276076, 'max_leaves': 73, 'criterion': 'entropy'}, 'config/n_estimators': 36, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 73, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2727041244506836}\n",
      "[flaml.tune.tune: 09-25 12:46:59] {197} INFO - result: {'pred_time': 6.181089573483677e-05, 'wall_clock_time': 875.5692954063416, 'metric_for_logging': {'pred_time': 6.181089573483677e-05}, 'val_loss': 0.21064406725950952, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe668036850>, 'training_iteration': 1, 'config': {'n_estimators': 36, 'max_features': 0.032427221756276076, 'max_leaves': 73, 'criterion': 'entropy'}, 'config/n_estimators': 36, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 73, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2739262580871582}\n",
      "[flaml.automl.logger: 09-25 12:46:59] {2391} INFO -  at 875.6s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:46:59] {2218} INFO - iteration 247, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:46:59] {805} INFO - trial 1 config: {'n_estimators': 480, 'max_depth': 9, 'min_child_weight': 0.20280435566626104, 'learning_rate': 0.22318970597426468, 'subsample': 0.7829488289228895, 'colsample_bylevel': 0.17286289894528797, 'colsample_bytree': 0.4893541288062087, 'reg_alpha': 0.16638830271129162, 'reg_lambda': 1.251957852595792}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:47:36] {197} INFO - result: {'pred_time': 5.434694109158793e-05, 'wall_clock_time': 912.4215445518494, 'metric_for_logging': {'pred_time': 5.434694109158793e-05}, 'val_loss': 0.20358470279759638, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340db190>, 'training_iteration': 0, 'config': {'n_estimators': 480, 'max_depth': 9, 'min_child_weight': 0.20280435566626104, 'learning_rate': 0.22318970597426468, 'subsample': 0.7829488289228895, 'colsample_bylevel': 0.17286289894528797, 'colsample_bytree': 0.4893541288062087, 'reg_alpha': 0.16638830271129162, 'reg_lambda': 1.251957852595792}, 'config/n_estimators': 480, 'config/max_depth': 9, 'config/min_child_weight': 0.20280435566626104, 'config/learning_rate': 0.22318970597426468, 'config/subsample': 0.7829488289228895, 'config/colsample_bylevel': 0.17286289894528797, 'config/colsample_bytree': 0.4893541288062087, 'config/reg_alpha': 0.16638830271129162, 'config/reg_lambda': 1.251957852595792, 'experiment_tag': 'exp', 'time_total_s': 36.845414876937866}\n",
      "[flaml.tune.tune: 09-25 12:47:36] {197} INFO - result: {'pred_time': 5.434694109158793e-05, 'wall_clock_time': 912.4215445518494, 'metric_for_logging': {'pred_time': 5.434694109158793e-05}, 'val_loss': 0.20358470279759638, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340db190>, 'training_iteration': 1, 'config': {'n_estimators': 480, 'max_depth': 9, 'min_child_weight': 0.20280435566626104, 'learning_rate': 0.22318970597426468, 'subsample': 0.7829488289228895, 'colsample_bylevel': 0.17286289894528797, 'colsample_bytree': 0.4893541288062087, 'reg_alpha': 0.16638830271129162, 'reg_lambda': 1.251957852595792}, 'config/n_estimators': 480, 'config/max_depth': 9, 'config/min_child_weight': 0.20280435566626104, 'config/learning_rate': 0.22318970597426468, 'config/subsample': 0.7829488289228895, 'config/colsample_bylevel': 0.17286289894528797, 'config/colsample_bytree': 0.4893541288062087, 'config/reg_alpha': 0.16638830271129162, 'config/reg_lambda': 1.251957852595792, 'experiment_tag': 'exp', 'time_total_s': 36.84683847427368}\n",
      "[flaml.automl.logger: 09-25 12:47:36] {2391} INFO -  at 912.4s,\testimator xgb_limitdepth's best error=0.2013,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:47:36] {2218} INFO - iteration 248, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:47:36] {805} INFO - trial 1 config: {'n_estimators': 138, 'max_features': 0.07190356174847934, 'max_leaves': 193, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:47:41] {197} INFO - result: {'pred_time': 0.00020768582026767205, 'wall_clock_time': 917.95361328125, 'metric_for_logging': {'pred_time': 0.00020768582026767205}, 'val_loss': 0.21016346902778685, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340dba30>, 'training_iteration': 0, 'config': {'n_estimators': 138, 'max_features': 0.07190356174847934, 'max_leaves': 193, 'criterion': 'gini'}, 'config/n_estimators': 138, 'config/max_features': 0.07190356174847934, 'config/max_leaves': 193, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 5.525831460952759}\n",
      "[flaml.tune.tune: 09-25 12:47:41] {197} INFO - result: {'pred_time': 0.00020768582026767205, 'wall_clock_time': 917.95361328125, 'metric_for_logging': {'pred_time': 0.00020768582026767205}, 'val_loss': 0.21016346902778685, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340dba30>, 'training_iteration': 1, 'config': {'n_estimators': 138, 'max_features': 0.07190356174847934, 'max_leaves': 193, 'criterion': 'gini'}, 'config/n_estimators': 138, 'config/max_features': 0.07190356174847934, 'config/max_leaves': 193, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 5.527149438858032}\n",
      "[flaml.automl.logger: 09-25 12:47:41] {2391} INFO -  at 918.0s,\testimator extra_tree's best error=0.2003,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:47:41] {2218} INFO - iteration 249, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:47:41] {805} INFO - trial 1 config: {'n_estimators': 137, 'max_features': 0.044557216969785256, 'max_leaves': 216, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:47:46] {197} INFO - result: {'pred_time': 0.00019225136250515312, 'wall_clock_time': 922.3198742866516, 'metric_for_logging': {'pred_time': 0.00019225136250515312}, 'val_loss': 0.1964867704747765, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680b1370>, 'training_iteration': 0, 'config': {'n_estimators': 137, 'max_features': 0.044557216969785256, 'max_leaves': 216, 'criterion': 'gini'}, 'config/n_estimators': 137, 'config/max_features': 0.044557216969785256, 'config/max_leaves': 216, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 4.358011960983276}\n",
      "[flaml.tune.tune: 09-25 12:47:46] {197} INFO - result: {'pred_time': 0.00019225136250515312, 'wall_clock_time': 922.3198742866516, 'metric_for_logging': {'pred_time': 0.00019225136250515312}, 'val_loss': 0.1964867704747765, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680b1370>, 'training_iteration': 1, 'config': {'n_estimators': 137, 'max_features': 0.044557216969785256, 'max_leaves': 216, 'criterion': 'gini'}, 'config/n_estimators': 137, 'config/max_features': 0.044557216969785256, 'config/max_leaves': 216, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 4.3595921993255615}\n",
      "[flaml.automl.logger: 09-25 12:47:46] {2391} INFO -  at 922.3s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:47:46] {2218} INFO - iteration 250, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:47:46] {805} INFO - trial 1 config: {'n_estimators': 55, 'max_features': 0.037848050436577005, 'max_leaves': 115, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:47:47] {197} INFO - result: {'pred_time': 8.947616933773662e-05, 'wall_clock_time': 923.8960139751434, 'metric_for_logging': {'pred_time': 8.947616933773662e-05}, 'val_loss': 0.2175574504847368, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a14c0>, 'training_iteration': 0, 'config': {'n_estimators': 55, 'max_features': 0.037848050436577005, 'max_leaves': 115, 'criterion': 'gini'}, 'config/n_estimators': 55, 'config/max_features': 0.037848050436577005, 'config/max_leaves': 115, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.569209098815918}\n",
      "[flaml.tune.tune: 09-25 12:47:47] {197} INFO - result: {'pred_time': 8.947616933773662e-05, 'wall_clock_time': 923.8960139751434, 'metric_for_logging': {'pred_time': 8.947616933773662e-05}, 'val_loss': 0.2175574504847368, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a14c0>, 'training_iteration': 1, 'config': {'n_estimators': 55, 'max_features': 0.037848050436577005, 'max_leaves': 115, 'criterion': 'gini'}, 'config/n_estimators': 55, 'config/max_features': 0.037848050436577005, 'config/max_leaves': 115, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.571051836013794}\n",
      "[flaml.automl.logger: 09-25 12:47:47] {2391} INFO -  at 923.9s,\testimator extra_tree's best error=0.2003,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:47:47] {2218} INFO - iteration 251, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:47:47] {805} INFO - trial 1 config: {'n_estimators': 91, 'max_features': 0.07870857544534592, 'max_leaves': 111, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:47:50] {197} INFO - result: {'pred_time': 0.00013932564972932447, 'wall_clock_time': 926.9652709960938, 'metric_for_logging': {'pred_time': 0.00013932564972932447}, 'val_loss': 0.20160239526806242, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680360a0>, 'training_iteration': 0, 'config': {'n_estimators': 91, 'max_features': 0.07870857544534592, 'max_leaves': 111, 'criterion': 'entropy'}, 'config/n_estimators': 91, 'config/max_features': 0.07870857544534592, 'config/max_leaves': 111, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.062289237976074}\n",
      "[flaml.tune.tune: 09-25 12:47:50] {197} INFO - result: {'pred_time': 0.00013932564972932447, 'wall_clock_time': 926.9652709960938, 'metric_for_logging': {'pred_time': 0.00013932564972932447}, 'val_loss': 0.20160239526806242, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680360a0>, 'training_iteration': 1, 'config': {'n_estimators': 91, 'max_features': 0.07870857544534592, 'max_leaves': 111, 'criterion': 'entropy'}, 'config/n_estimators': 91, 'config/max_features': 0.07870857544534592, 'config/max_leaves': 111, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.0635499954223633}\n",
      "[flaml.automl.logger: 09-25 12:47:50] {2391} INFO -  at 927.0s,\testimator extra_tree's best error=0.2003,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:47:50] {2218} INFO - iteration 252, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:47:50] {805} INFO - trial 1 config: {'n_estimators': 28, 'num_leaves': 54, 'min_child_samples': 5, 'learning_rate': 0.4670994949384199, 'log_max_bin': 9, 'colsample_bytree': 0.7311026180937739, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6407275264111922}\n",
      "[flaml.tune.tune: 09-25 12:47:51] {197} INFO - result: {'pred_time': 1.1420741423679144e-05, 'wall_clock_time': 927.7944669723511, 'metric_for_logging': {'pred_time': 1.1420741423679144e-05}, 'val_loss': 0.21105439137673015, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340d0370>, 'training_iteration': 0, 'config': {'n_estimators': 28, 'num_leaves': 54, 'min_child_samples': 5, 'learning_rate': 0.4670994949384199, 'log_max_bin': 9, 'colsample_bytree': 0.7311026180937739, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6407275264111922}, 'config/n_estimators': 28, 'config/num_leaves': 54, 'config/min_child_samples': 5, 'config/learning_rate': 0.4670994949384199, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7311026180937739, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.6407275264111922, 'experiment_tag': 'exp', 'time_total_s': 0.8209693431854248}\n",
      "[flaml.tune.tune: 09-25 12:47:51] {197} INFO - result: {'pred_time': 1.1420741423679144e-05, 'wall_clock_time': 927.7944669723511, 'metric_for_logging': {'pred_time': 1.1420741423679144e-05}, 'val_loss': 0.21105439137673015, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340d0370>, 'training_iteration': 1, 'config': {'n_estimators': 28, 'num_leaves': 54, 'min_child_samples': 5, 'learning_rate': 0.4670994949384199, 'log_max_bin': 9, 'colsample_bytree': 0.7311026180937739, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6407275264111922}, 'config/n_estimators': 28, 'config/num_leaves': 54, 'config/min_child_samples': 5, 'config/learning_rate': 0.4670994949384199, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7311026180937739, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.6407275264111922, 'experiment_tag': 'exp', 'time_total_s': 0.8222689628601074}\n",
      "[flaml.automl.logger: 09-25 12:47:51] {2391} INFO -  at 927.8s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:47:51] {2218} INFO - iteration 253, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:47:51] {805} INFO - trial 1 config: {'early_stopping_rounds': 11, 'learning_rate': 0.04290307222977751, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:47:56] {197} INFO - result: {'pred_time': 0.00011134910974023695, 'wall_clock_time': 932.200525522232, 'metric_for_logging': {'pred_time': 0.00011134910974023695}, 'val_loss': 0.2485398716095868, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340d04c0>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 11, 'learning_rate': 0.04290307222977751, 'n_estimators': 8192}, 'config/early_stopping_rounds': 11, 'config/learning_rate': 0.04290307222977751, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.399165868759155}\n",
      "[flaml.tune.tune: 09-25 12:47:56] {197} INFO - result: {'pred_time': 0.00011134910974023695, 'wall_clock_time': 932.200525522232, 'metric_for_logging': {'pred_time': 0.00011134910974023695}, 'val_loss': 0.2485398716095868, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340d04c0>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 11, 'learning_rate': 0.04290307222977751, 'n_estimators': 8192}, 'config/early_stopping_rounds': 11, 'config/learning_rate': 0.04290307222977751, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.4009575843811035}\n",
      "[flaml.automl.logger: 09-25 12:47:56] {2391} INFO -  at 932.2s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:47:56] {2218} INFO - iteration 254, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:47:56] {805} INFO - trial 1 config: {'n_estimators': 48, 'max_features': 0.04777517295882704, 'max_leaves': 73, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:47:57] {197} INFO - result: {'pred_time': 8.154551287291602e-05, 'wall_clock_time': 933.6336982250214, 'metric_for_logging': {'pred_time': 8.154551287291602e-05}, 'val_loss': 0.21959752538838, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668105b20>, 'training_iteration': 0, 'config': {'n_estimators': 48, 'max_features': 0.04777517295882704, 'max_leaves': 73, 'criterion': 'gini'}, 'config/n_estimators': 48, 'config/max_features': 0.04777517295882704, 'config/max_leaves': 73, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.4260179996490479}\n",
      "[flaml.tune.tune: 09-25 12:47:57] {197} INFO - result: {'pred_time': 8.154551287291602e-05, 'wall_clock_time': 933.6336982250214, 'metric_for_logging': {'pred_time': 8.154551287291602e-05}, 'val_loss': 0.21959752538838, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668105b20>, 'training_iteration': 1, 'config': {'n_estimators': 48, 'max_features': 0.04777517295882704, 'max_leaves': 73, 'criterion': 'gini'}, 'config/n_estimators': 48, 'config/max_features': 0.04777517295882704, 'config/max_leaves': 73, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.4271790981292725}\n",
      "[flaml.automl.logger: 09-25 12:47:57] {2391} INFO -  at 933.6s,\testimator extra_tree's best error=0.2003,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:47:57] {2218} INFO - iteration 255, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:47:57] {805} INFO - trial 1 config: {'n_estimators': 77, 'max_depth': 9, 'min_child_weight': 0.015159357865631107, 'learning_rate': 0.14698110676756723, 'subsample': 0.801611099960444, 'colsample_bylevel': 0.14936609303589107, 'colsample_bytree': 0.579449345471817, 'reg_alpha': 0.0061962448817717, 'reg_lambda': 1.9741587508935008}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:48:04] {197} INFO - result: {'pred_time': 4.812080210862709e-05, 'wall_clock_time': 940.3373286724091, 'metric_for_logging': {'pred_time': 4.812080210862709e-05}, 'val_loss': 0.1960596624764541, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680a5220>, 'training_iteration': 0, 'config': {'n_estimators': 77, 'max_depth': 9, 'min_child_weight': 0.015159357865631107, 'learning_rate': 0.14698110676756723, 'subsample': 0.801611099960444, 'colsample_bylevel': 0.14936609303589107, 'colsample_bytree': 0.579449345471817, 'reg_alpha': 0.0061962448817717, 'reg_lambda': 1.9741587508935008}, 'config/n_estimators': 77, 'config/max_depth': 9, 'config/min_child_weight': 0.015159357865631107, 'config/learning_rate': 0.14698110676756723, 'config/subsample': 0.801611099960444, 'config/colsample_bylevel': 0.14936609303589107, 'config/colsample_bytree': 0.579449345471817, 'config/reg_alpha': 0.0061962448817717, 'config/reg_lambda': 1.9741587508935008, 'experiment_tag': 'exp', 'time_total_s': 6.697675466537476}\n",
      "[flaml.tune.tune: 09-25 12:48:04] {197} INFO - result: {'pred_time': 4.812080210862709e-05, 'wall_clock_time': 940.3373286724091, 'metric_for_logging': {'pred_time': 4.812080210862709e-05}, 'val_loss': 0.1960596624764541, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680a5220>, 'training_iteration': 1, 'config': {'n_estimators': 77, 'max_depth': 9, 'min_child_weight': 0.015159357865631107, 'learning_rate': 0.14698110676756723, 'subsample': 0.801611099960444, 'colsample_bylevel': 0.14936609303589107, 'colsample_bytree': 0.579449345471817, 'reg_alpha': 0.0061962448817717, 'reg_lambda': 1.9741587508935008}, 'config/n_estimators': 77, 'config/max_depth': 9, 'config/min_child_weight': 0.015159357865631107, 'config/learning_rate': 0.14698110676756723, 'config/subsample': 0.801611099960444, 'config/colsample_bylevel': 0.14936609303589107, 'config/colsample_bytree': 0.579449345471817, 'config/reg_alpha': 0.0061962448817717, 'config/reg_lambda': 1.9741587508935008, 'experiment_tag': 'exp', 'time_total_s': 6.6991212368011475}\n",
      "[flaml.automl.logger: 09-25 12:48:04] {2391} INFO -  at 940.3s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:48:04] {2218} INFO - iteration 256, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:48:04] {805} INFO - trial 1 config: {'n_estimators': 216, 'num_leaves': 20, 'min_child_samples': 6, 'learning_rate': 0.22027487611145957, 'log_max_bin': 9, 'colsample_bytree': 0.7409037850665453, 'reg_alpha': 0.0009765625, 'reg_lambda': 11.649459793139602}\n",
      "[flaml.tune.tune: 09-25 12:48:05] {197} INFO - result: {'pred_time': 1.5951678412074243e-05, 'wall_clock_time': 941.9435946941376, 'metric_for_logging': {'pred_time': 1.5951678412074243e-05}, 'val_loss': 0.2058781679846148, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680a5f40>, 'training_iteration': 0, 'config': {'n_estimators': 216, 'num_leaves': 20, 'min_child_samples': 6, 'learning_rate': 0.22027487611145957, 'log_max_bin': 9, 'colsample_bytree': 0.7409037850665453, 'reg_alpha': 0.0009765625, 'reg_lambda': 11.649459793139602}, 'config/n_estimators': 216, 'config/num_leaves': 20, 'config/min_child_samples': 6, 'config/learning_rate': 0.22027487611145957, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7409037850665453, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 11.649459793139602, 'experiment_tag': 'exp', 'time_total_s': 1.598759651184082}\n",
      "[flaml.tune.tune: 09-25 12:48:05] {197} INFO - result: {'pred_time': 1.5951678412074243e-05, 'wall_clock_time': 941.9435946941376, 'metric_for_logging': {'pred_time': 1.5951678412074243e-05}, 'val_loss': 0.2058781679846148, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680a5f40>, 'training_iteration': 1, 'config': {'n_estimators': 216, 'num_leaves': 20, 'min_child_samples': 6, 'learning_rate': 0.22027487611145957, 'log_max_bin': 9, 'colsample_bytree': 0.7409037850665453, 'reg_alpha': 0.0009765625, 'reg_lambda': 11.649459793139602}, 'config/n_estimators': 216, 'config/num_leaves': 20, 'config/min_child_samples': 6, 'config/learning_rate': 0.22027487611145957, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.7409037850665453, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 11.649459793139602, 'experiment_tag': 'exp', 'time_total_s': 1.6006646156311035}\n",
      "[flaml.automl.logger: 09-25 12:48:05] {2391} INFO -  at 941.9s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:48:05] {2218} INFO - iteration 257, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:48:05] {805} INFO - trial 1 config: {'n_estimators': 216, 'max_depth': 10, 'min_child_weight': 0.06579229901257695, 'learning_rate': 0.1105951983066625, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.26735884807331084, 'colsample_bytree': 0.5755451734871456, 'reg_alpha': 0.036619209129239036, 'reg_lambda': 4.742391450688205}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:48:29] {197} INFO - result: {'pred_time': 5.0735797656187386e-05, 'wall_clock_time': 965.8701374530792, 'metric_for_logging': {'pred_time': 5.0735797656187386e-05}, 'val_loss': 0.20116354677823942, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680a2430>, 'training_iteration': 0, 'config': {'n_estimators': 216, 'max_depth': 10, 'min_child_weight': 0.06579229901257695, 'learning_rate': 0.1105951983066625, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.26735884807331084, 'colsample_bytree': 0.5755451734871456, 'reg_alpha': 0.036619209129239036, 'reg_lambda': 4.742391450688205}, 'config/n_estimators': 216, 'config/max_depth': 10, 'config/min_child_weight': 0.06579229901257695, 'config/learning_rate': 0.1105951983066625, 'config/subsample': 0.8413048297641477, 'config/colsample_bylevel': 0.26735884807331084, 'config/colsample_bytree': 0.5755451734871456, 'config/reg_alpha': 0.036619209129239036, 'config/reg_lambda': 4.742391450688205, 'experiment_tag': 'exp', 'time_total_s': 23.919657468795776}\n",
      "[flaml.tune.tune: 09-25 12:48:29] {197} INFO - result: {'pred_time': 5.0735797656187386e-05, 'wall_clock_time': 965.8701374530792, 'metric_for_logging': {'pred_time': 5.0735797656187386e-05}, 'val_loss': 0.20116354677823942, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680a2430>, 'training_iteration': 1, 'config': {'n_estimators': 216, 'max_depth': 10, 'min_child_weight': 0.06579229901257695, 'learning_rate': 0.1105951983066625, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.26735884807331084, 'colsample_bytree': 0.5755451734871456, 'reg_alpha': 0.036619209129239036, 'reg_lambda': 4.742391450688205}, 'config/n_estimators': 216, 'config/max_depth': 10, 'config/min_child_weight': 0.06579229901257695, 'config/learning_rate': 0.1105951983066625, 'config/subsample': 0.8413048297641477, 'config/colsample_bylevel': 0.26735884807331084, 'config/colsample_bytree': 0.5755451734871456, 'config/reg_alpha': 0.036619209129239036, 'config/reg_lambda': 4.742391450688205, 'experiment_tag': 'exp', 'time_total_s': 23.92096495628357}\n",
      "[flaml.automl.logger: 09-25 12:48:29] {2391} INFO -  at 965.9s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:48:29] {2218} INFO - iteration 258, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:48:29] {805} INFO - trial 1 config: {'n_estimators': 55, 'max_features': 0.032427221756276076, 'max_leaves': 129, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:48:31] {197} INFO - result: {'pred_time': 8.450372168256144e-05, 'wall_clock_time': 967.6184389591217, 'metric_for_logging': {'pred_time': 8.450372168256144e-05}, 'val_loss': 0.20112090957293355, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680a2d30>, 'training_iteration': 0, 'config': {'n_estimators': 55, 'max_features': 0.032427221756276076, 'max_leaves': 129, 'criterion': 'gini'}, 'config/n_estimators': 55, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 129, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.7403056621551514}\n",
      "[flaml.tune.tune: 09-25 12:48:31] {197} INFO - result: {'pred_time': 8.450372168256144e-05, 'wall_clock_time': 967.6184389591217, 'metric_for_logging': {'pred_time': 8.450372168256144e-05}, 'val_loss': 0.20112090957293355, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680a2d30>, 'training_iteration': 1, 'config': {'n_estimators': 55, 'max_features': 0.032427221756276076, 'max_leaves': 129, 'criterion': 'gini'}, 'config/n_estimators': 55, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 129, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.7414722442626953}\n",
      "[flaml.automl.logger: 09-25 12:48:31] {2391} INFO -  at 967.6s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:48:31] {2218} INFO - iteration 259, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:48:31] {805} INFO - trial 1 config: {'n_estimators': 63, 'max_depth': 9, 'min_child_weight': 0.004852459400586349, 'learning_rate': 0.06391164572774671, 'subsample': 0.8968046658840862, 'colsample_bylevel': 0.01, 'colsample_bytree': 0.607842041296469, 'reg_alpha': 0.0021157642401283937, 'reg_lambda': 0.7675254990354506}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:48:35] {197} INFO - result: {'pred_time': 4.446270705811014e-05, 'wall_clock_time': 971.1664671897888, 'metric_for_logging': {'pred_time': 4.446270705811014e-05}, 'val_loss': 0.23033301869508765, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680a2610>, 'training_iteration': 0, 'config': {'n_estimators': 63, 'max_depth': 9, 'min_child_weight': 0.004852459400586349, 'learning_rate': 0.06391164572774671, 'subsample': 0.8968046658840862, 'colsample_bylevel': 0.01, 'colsample_bytree': 0.607842041296469, 'reg_alpha': 0.0021157642401283937, 'reg_lambda': 0.7675254990354506}, 'config/n_estimators': 63, 'config/max_depth': 9, 'config/min_child_weight': 0.004852459400586349, 'config/learning_rate': 0.06391164572774671, 'config/subsample': 0.8968046658840862, 'config/colsample_bylevel': 0.01, 'config/colsample_bytree': 0.607842041296469, 'config/reg_alpha': 0.0021157642401283937, 'config/reg_lambda': 0.7675254990354506, 'experiment_tag': 'exp', 'time_total_s': 3.541609764099121}\n",
      "[flaml.tune.tune: 09-25 12:48:35] {197} INFO - result: {'pred_time': 4.446270705811014e-05, 'wall_clock_time': 971.1664671897888, 'metric_for_logging': {'pred_time': 4.446270705811014e-05}, 'val_loss': 0.23033301869508765, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680a2610>, 'training_iteration': 1, 'config': {'n_estimators': 63, 'max_depth': 9, 'min_child_weight': 0.004852459400586349, 'learning_rate': 0.06391164572774671, 'subsample': 0.8968046658840862, 'colsample_bylevel': 0.01, 'colsample_bytree': 0.607842041296469, 'reg_alpha': 0.0021157642401283937, 'reg_lambda': 0.7675254990354506}, 'config/n_estimators': 63, 'config/max_depth': 9, 'config/min_child_weight': 0.004852459400586349, 'config/learning_rate': 0.06391164572774671, 'config/subsample': 0.8968046658840862, 'config/colsample_bylevel': 0.01, 'config/colsample_bytree': 0.607842041296469, 'config/reg_alpha': 0.0021157642401283937, 'config/reg_lambda': 0.7675254990354506, 'experiment_tag': 'exp', 'time_total_s': 3.5430359840393066}\n",
      "[flaml.automl.logger: 09-25 12:48:35] {2391} INFO -  at 971.2s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:48:35] {2218} INFO - iteration 260, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:48:35] {805} INFO - trial 1 config: {'n_estimators': 105, 'max_features': 0.06235385345049134, 'max_leaves': 174, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:48:38] {197} INFO - result: {'pred_time': 0.00015923220966807938, 'wall_clock_time': 974.6362996101379, 'metric_for_logging': {'pred_time': 0.00015923220966807938}, 'val_loss': 0.19502094067311457, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668105520>, 'training_iteration': 0, 'config': {'n_estimators': 105, 'max_features': 0.06235385345049134, 'max_leaves': 174, 'criterion': 'entropy'}, 'config/n_estimators': 105, 'config/max_features': 0.06235385345049134, 'config/max_leaves': 174, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.4634909629821777}\n",
      "[flaml.tune.tune: 09-25 12:48:38] {197} INFO - result: {'pred_time': 0.00015923220966807938, 'wall_clock_time': 974.6362996101379, 'metric_for_logging': {'pred_time': 0.00015923220966807938}, 'val_loss': 0.19502094067311457, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668105520>, 'training_iteration': 1, 'config': {'n_estimators': 105, 'max_features': 0.06235385345049134, 'max_leaves': 174, 'criterion': 'entropy'}, 'config/n_estimators': 105, 'config/max_features': 0.06235385345049134, 'config/max_leaves': 174, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.469374656677246}\n",
      "[flaml.automl.logger: 09-25 12:48:38] {2391} INFO -  at 974.6s,\testimator extra_tree's best error=0.1950,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:48:38] {2218} INFO - iteration 261, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:48:38] {805} INFO - trial 1 config: {'n_estimators': 66, 'max_features': 0.07833494720505348, 'max_leaves': 81, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:48:40] {197} INFO - result: {'pred_time': 0.00010862500458610196, 'wall_clock_time': 976.8457939624786, 'metric_for_logging': {'pred_time': 0.00010862500458610196}, 'val_loss': 0.20878819945536584, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680b5d60>, 'training_iteration': 0, 'config': {'n_estimators': 66, 'max_features': 0.07833494720505348, 'max_leaves': 81, 'criterion': 'entropy'}, 'config/n_estimators': 66, 'config/max_features': 0.07833494720505348, 'config/max_leaves': 81, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.1938581466674805}\n",
      "[flaml.tune.tune: 09-25 12:48:40] {197} INFO - result: {'pred_time': 0.00010862500458610196, 'wall_clock_time': 976.8457939624786, 'metric_for_logging': {'pred_time': 0.00010862500458610196}, 'val_loss': 0.20878819945536584, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680b5d60>, 'training_iteration': 1, 'config': {'n_estimators': 66, 'max_features': 0.07833494720505348, 'max_leaves': 81, 'criterion': 'entropy'}, 'config/n_estimators': 66, 'config/max_features': 0.07833494720505348, 'config/max_leaves': 81, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.195460796356201}\n",
      "[flaml.automl.logger: 09-25 12:48:40] {2391} INFO -  at 976.8s,\testimator extra_tree's best error=0.1950,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:48:40] {2218} INFO - iteration 262, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:48:40] {805} INFO - trial 1 config: {'n_estimators': 168, 'max_features': 0.04963305879236657, 'max_leaves': 374, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:48:46] {197} INFO - result: {'pred_time': 0.00024406794142140895, 'wall_clock_time': 982.7189240455627, 'metric_for_logging': {'pred_time': 0.00024406794142140895}, 'val_loss': 0.20406357805158404, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a2970>, 'training_iteration': 0, 'config': {'n_estimators': 168, 'max_features': 0.04963305879236657, 'max_leaves': 374, 'criterion': 'gini'}, 'config/n_estimators': 168, 'config/max_features': 0.04963305879236657, 'config/max_leaves': 374, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 5.866711139678955}\n",
      "[flaml.tune.tune: 09-25 12:48:46] {197} INFO - result: {'pred_time': 0.00024406794142140895, 'wall_clock_time': 982.7189240455627, 'metric_for_logging': {'pred_time': 0.00024406794142140895}, 'val_loss': 0.20406357805158404, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a2970>, 'training_iteration': 1, 'config': {'n_estimators': 168, 'max_features': 0.04963305879236657, 'max_leaves': 374, 'criterion': 'gini'}, 'config/n_estimators': 168, 'config/max_features': 0.04963305879236657, 'config/max_leaves': 374, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 5.868133306503296}\n",
      "[flaml.automl.logger: 09-25 12:48:46] {2391} INFO -  at 982.7s,\testimator extra_tree's best error=0.1950,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:48:46] {2218} INFO - iteration 263, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:48:46] {805} INFO - trial 1 config: {'n_estimators': 71, 'max_features': 0.05163463315027458, 'max_leaves': 75, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:48:48] {197} INFO - result: {'pred_time': 0.00011224873579388833, 'wall_clock_time': 984.8026587963104, 'metric_for_logging': {'pred_time': 0.00011224873579388833}, 'val_loss': 0.22247891993019428, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668105370>, 'training_iteration': 0, 'config': {'n_estimators': 71, 'max_features': 0.05163463315027458, 'max_leaves': 75, 'criterion': 'gini'}, 'config/n_estimators': 71, 'config/max_features': 0.05163463315027458, 'config/max_leaves': 75, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.0775866508483887}\n",
      "[flaml.tune.tune: 09-25 12:48:48] {197} INFO - result: {'pred_time': 0.00011224873579388833, 'wall_clock_time': 984.8026587963104, 'metric_for_logging': {'pred_time': 0.00011224873579388833}, 'val_loss': 0.22247891993019428, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668105370>, 'training_iteration': 1, 'config': {'n_estimators': 71, 'max_features': 0.05163463315027458, 'max_leaves': 75, 'criterion': 'gini'}, 'config/n_estimators': 71, 'config/max_features': 0.05163463315027458, 'config/max_leaves': 75, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.079101800918579}\n",
      "[flaml.automl.logger: 09-25 12:48:48] {2391} INFO -  at 984.8s,\testimator extra_tree's best error=0.1950,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:48:48] {2218} INFO - iteration 264, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:48:48] {805} INFO - trial 1 config: {'n_estimators': 89, 'max_features': 0.048517471408544795, 'max_leaves': 123, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:48:51] {197} INFO - result: {'pred_time': 0.00013060221216374833, 'wall_clock_time': 987.848938703537, 'metric_for_logging': {'pred_time': 0.00013060221216374833}, 'val_loss': 0.19179511941880759, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6681059d0>, 'training_iteration': 0, 'config': {'n_estimators': 89, 'max_features': 0.048517471408544795, 'max_leaves': 123, 'criterion': 'entropy'}, 'config/n_estimators': 89, 'config/max_features': 0.048517471408544795, 'config/max_leaves': 123, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.039332628250122}\n",
      "[flaml.tune.tune: 09-25 12:48:51] {197} INFO - result: {'pred_time': 0.00013060221216374833, 'wall_clock_time': 987.848938703537, 'metric_for_logging': {'pred_time': 0.00013060221216374833}, 'val_loss': 0.19179511941880759, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6681059d0>, 'training_iteration': 1, 'config': {'n_estimators': 89, 'max_features': 0.048517471408544795, 'max_leaves': 123, 'criterion': 'entropy'}, 'config/n_estimators': 89, 'config/max_features': 0.048517471408544795, 'config/max_leaves': 123, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.04081392288208}\n",
      "[flaml.automl.logger: 09-25 12:48:51] {2391} INFO -  at 987.8s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:48:51] {2218} INFO - iteration 265, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:48:51] {805} INFO - trial 1 config: {'n_estimators': 155, 'max_features': 0.07529835699248452, 'max_leaves': 406, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:48:58] {197} INFO - result: {'pred_time': 0.00023078009833786927, 'wall_clock_time': 994.069552898407, 'metric_for_logging': {'pred_time': 0.00023078009833786927}, 'val_loss': 0.20252661264655264, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a4a90>, 'training_iteration': 0, 'config': {'n_estimators': 155, 'max_features': 0.07529835699248452, 'max_leaves': 406, 'criterion': 'entropy'}, 'config/n_estimators': 155, 'config/max_features': 0.07529835699248452, 'config/max_leaves': 406, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 6.213042974472046}\n",
      "[flaml.tune.tune: 09-25 12:48:58] {197} INFO - result: {'pred_time': 0.00023078009833786927, 'wall_clock_time': 994.069552898407, 'metric_for_logging': {'pred_time': 0.00023078009833786927}, 'val_loss': 0.20252661264655264, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a4a90>, 'training_iteration': 1, 'config': {'n_estimators': 155, 'max_features': 0.07529835699248452, 'max_leaves': 406, 'criterion': 'entropy'}, 'config/n_estimators': 155, 'config/max_features': 0.07529835699248452, 'config/max_leaves': 406, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 6.214645862579346}\n",
      "[flaml.automl.logger: 09-25 12:48:58] {2391} INFO -  at 994.1s,\testimator extra_tree's best error=0.1950,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:48:58] {2218} INFO - iteration 266, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:48:58] {805} INFO - trial 1 config: {'n_estimators': 76, 'max_features': 0.08783474168533527, 'max_leaves': 126, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:49:01] {197} INFO - result: {'pred_time': 0.00012577422942506943, 'wall_clock_time': 997.1634657382965, 'metric_for_logging': {'pred_time': 0.00012577422942506943}, 'val_loss': 0.22329730405067733, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe66807bb20>, 'training_iteration': 0, 'config': {'n_estimators': 76, 'max_features': 0.08783474168533527, 'max_leaves': 126, 'criterion': 'gini'}, 'config/n_estimators': 76, 'config/max_features': 0.08783474168533527, 'config/max_leaves': 126, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.0859904289245605}\n",
      "[flaml.tune.tune: 09-25 12:49:01] {197} INFO - result: {'pred_time': 0.00012577422942506943, 'wall_clock_time': 997.1634657382965, 'metric_for_logging': {'pred_time': 0.00012577422942506943}, 'val_loss': 0.22329730405067733, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe66807bb20>, 'training_iteration': 1, 'config': {'n_estimators': 76, 'max_features': 0.08783474168533527, 'max_leaves': 126, 'criterion': 'gini'}, 'config/n_estimators': 76, 'config/max_features': 0.08783474168533527, 'config/max_leaves': 126, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.0876030921936035}\n",
      "[flaml.automl.logger: 09-25 12:49:01] {2391} INFO -  at 997.2s,\testimator extra_tree's best error=0.1950,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:49:01] {2218} INFO - iteration 267, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:49:01] {805} INFO - trial 1 config: {'n_estimators': 146, 'max_features': 0.04426497950041201, 'max_leaves': 241, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:49:05] {197} INFO - result: {'pred_time': 0.00023539785668757587, 'wall_clock_time': 1001.8286957740784, 'metric_for_logging': {'pred_time': 0.00023539785668757587}, 'val_loss': 0.1923100992816135, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a2bb0>, 'training_iteration': 0, 'config': {'n_estimators': 146, 'max_features': 0.04426497950041201, 'max_leaves': 241, 'criterion': 'entropy'}, 'config/n_estimators': 146, 'config/max_features': 0.04426497950041201, 'config/max_leaves': 241, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 4.657726049423218}\n",
      "[flaml.tune.tune: 09-25 12:49:05] {197} INFO - result: {'pred_time': 0.00023539785668757587, 'wall_clock_time': 1001.8286957740784, 'metric_for_logging': {'pred_time': 0.00023539785668757587}, 'val_loss': 0.1923100992816135, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a2bb0>, 'training_iteration': 1, 'config': {'n_estimators': 146, 'max_features': 0.04426497950041201, 'max_leaves': 241, 'criterion': 'entropy'}, 'config/n_estimators': 146, 'config/max_features': 0.04426497950041201, 'config/max_leaves': 241, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 4.659912109375}\n",
      "[flaml.automl.logger: 09-25 12:49:05] {2391} INFO -  at 1001.8s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:49:05] {2218} INFO - iteration 268, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:49:05] {805} INFO - trial 1 config: {'n_estimators': 71, 'max_features': 0.060771018765202967, 'max_leaves': 337, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:49:08] {197} INFO - result: {'pred_time': 0.00011561761014778455, 'wall_clock_time': 1004.8431119918823, 'metric_for_logging': {'pred_time': 0.00011561761014778455}, 'val_loss': 0.20416252805683088, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a0310>, 'training_iteration': 0, 'config': {'n_estimators': 71, 'max_features': 0.060771018765202967, 'max_leaves': 337, 'criterion': 'gini'}, 'config/n_estimators': 71, 'config/max_features': 0.060771018765202967, 'config/max_leaves': 337, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.006448984146118}\n",
      "[flaml.tune.tune: 09-25 12:49:08] {197} INFO - result: {'pred_time': 0.00011561761014778455, 'wall_clock_time': 1004.8431119918823, 'metric_for_logging': {'pred_time': 0.00011561761014778455}, 'val_loss': 0.20416252805683088, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a0310>, 'training_iteration': 1, 'config': {'n_estimators': 71, 'max_features': 0.060771018765202967, 'max_leaves': 337, 'criterion': 'gini'}, 'config/n_estimators': 71, 'config/max_features': 0.060771018765202967, 'config/max_leaves': 337, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.008042097091675}\n",
      "[flaml.automl.logger: 09-25 12:49:08] {2391} INFO -  at 1004.8s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:49:08] {2218} INFO - iteration 269, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:49:08] {805} INFO - trial 1 config: {'n_estimators': 301, 'max_features': 0.032427221756276076, 'max_leaves': 172, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:49:16] {197} INFO - result: {'pred_time': 0.00039273745699935377, 'wall_clock_time': 1012.3220958709717, 'metric_for_logging': {'pred_time': 0.00039273745699935377}, 'val_loss': 0.19449165749765449, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a4490>, 'training_iteration': 0, 'config': {'n_estimators': 301, 'max_features': 0.032427221756276076, 'max_leaves': 172, 'criterion': 'entropy'}, 'config/n_estimators': 301, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 172, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 7.472481966018677}\n",
      "[flaml.tune.tune: 09-25 12:49:16] {197} INFO - result: {'pred_time': 0.00039273745699935377, 'wall_clock_time': 1012.3220958709717, 'metric_for_logging': {'pred_time': 0.00039273745699935377}, 'val_loss': 0.19449165749765449, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a4490>, 'training_iteration': 1, 'config': {'n_estimators': 301, 'max_features': 0.032427221756276076, 'max_leaves': 172, 'criterion': 'entropy'}, 'config/n_estimators': 301, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 172, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 7.47385311126709}\n",
      "[flaml.automl.logger: 09-25 12:49:16] {2391} INFO -  at 1012.3s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:49:16] {2218} INFO - iteration 270, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:49:16] {805} INFO - trial 1 config: {'n_estimators': 373, 'max_features': 0.04808765965857635, 'max_leaves': 205, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:49:26] {197} INFO - result: {'pred_time': 0.00048366289071070473, 'wall_clock_time': 1022.7927560806274, 'metric_for_logging': {'pred_time': 0.00048366289071070473}, 'val_loss': 0.19462340901621267, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a28e0>, 'training_iteration': 0, 'config': {'n_estimators': 373, 'max_features': 0.04808765965857635, 'max_leaves': 205, 'criterion': 'entropy'}, 'config/n_estimators': 373, 'config/max_features': 0.04808765965857635, 'config/max_leaves': 205, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 10.463977098464966}\n",
      "[flaml.tune.tune: 09-25 12:49:26] {197} INFO - result: {'pred_time': 0.00048366289071070473, 'wall_clock_time': 1022.7927560806274, 'metric_for_logging': {'pred_time': 0.00048366289071070473}, 'val_loss': 0.19462340901621267, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680a28e0>, 'training_iteration': 1, 'config': {'n_estimators': 373, 'max_features': 0.04808765965857635, 'max_leaves': 205, 'criterion': 'entropy'}, 'config/n_estimators': 373, 'config/max_features': 0.04808765965857635, 'config/max_leaves': 205, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 10.465273380279541}\n",
      "[flaml.automl.logger: 09-25 12:49:26] {2391} INFO -  at 1022.8s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:49:26] {2218} INFO - iteration 271, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:49:26] {805} INFO - trial 1 config: {'n_estimators': 48, 'max_features': 0.032427221756276076, 'max_leaves': 83, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:49:28] {197} INFO - result: {'pred_time': 7.960547297869346e-05, 'wall_clock_time': 1024.4096026420593, 'metric_for_logging': {'pred_time': 7.960547297869346e-05}, 'val_loss': 0.20833798277576387, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe66807d5b0>, 'training_iteration': 0, 'config': {'n_estimators': 48, 'max_features': 0.032427221756276076, 'max_leaves': 83, 'criterion': 'gini'}, 'config/n_estimators': 48, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 83, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.6087603569030762}\n",
      "[flaml.tune.tune: 09-25 12:49:28] {197} INFO - result: {'pred_time': 7.960547297869346e-05, 'wall_clock_time': 1024.4096026420593, 'metric_for_logging': {'pred_time': 7.960547297869346e-05}, 'val_loss': 0.20833798277576387, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe66807d5b0>, 'training_iteration': 1, 'config': {'n_estimators': 48, 'max_features': 0.032427221756276076, 'max_leaves': 83, 'criterion': 'gini'}, 'config/n_estimators': 48, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 83, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.6100037097930908}\n",
      "[flaml.automl.logger: 09-25 12:49:28] {2391} INFO -  at 1024.4s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:49:28] {2218} INFO - iteration 272, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:49:28] {805} INFO - trial 1 config: {'n_estimators': 57, 'max_features': 0.04074617945817295, 'max_leaves': 284, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:49:30] {197} INFO - result: {'pred_time': 9.49125903861852e-05, 'wall_clock_time': 1026.5340683460236, 'metric_for_logging': {'pred_time': 9.49125903861852e-05}, 'val_loss': 0.21954377540959252, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5242ece20>, 'training_iteration': 0, 'config': {'n_estimators': 57, 'max_features': 0.04074617945817295, 'max_leaves': 284, 'criterion': 'gini'}, 'config/n_estimators': 57, 'config/max_features': 0.04074617945817295, 'config/max_leaves': 284, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.118929386138916}\n",
      "[flaml.tune.tune: 09-25 12:49:30] {197} INFO - result: {'pred_time': 9.49125903861852e-05, 'wall_clock_time': 1026.5340683460236, 'metric_for_logging': {'pred_time': 9.49125903861852e-05}, 'val_loss': 0.21954377540959252, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5242ece20>, 'training_iteration': 1, 'config': {'n_estimators': 57, 'max_features': 0.04074617945817295, 'max_leaves': 284, 'criterion': 'gini'}, 'config/n_estimators': 57, 'config/max_features': 0.04074617945817295, 'config/max_leaves': 284, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.120112180709839}\n",
      "[flaml.automl.logger: 09-25 12:49:30] {2391} INFO -  at 1026.5s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:49:30] {2218} INFO - iteration 273, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:49:30] {805} INFO - trial 1 config: {'n_estimators': 185, 'max_leaves': 35, 'min_child_weight': 0.1853559952382296, 'learning_rate': 0.06197791739406124, 'subsample': 0.770888792964588, 'colsample_bylevel': 0.4867136232959035, 'colsample_bytree': 0.6135955921416617, 'reg_alpha': 0.006535953249353212, 'reg_lambda': 0.5184213276703741}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:49:45] {197} INFO - result: {'pred_time': 4.9031562632560366e-05, 'wall_clock_time': 1041.3477437496185, 'metric_for_logging': {'pred_time': 4.9031562632560366e-05}, 'val_loss': 0.185639984927841, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5242ec1c0>, 'training_iteration': 0, 'config': {'n_estimators': 185, 'max_leaves': 35, 'min_child_weight': 0.1853559952382296, 'learning_rate': 0.06197791739406124, 'subsample': 0.770888792964588, 'colsample_bylevel': 0.4867136232959035, 'colsample_bytree': 0.6135955921416617, 'reg_alpha': 0.006535953249353212, 'reg_lambda': 0.5184213276703741}, 'config/n_estimators': 185, 'config/max_leaves': 35, 'config/min_child_weight': 0.1853559952382296, 'config/learning_rate': 0.06197791739406124, 'config/subsample': 0.770888792964588, 'config/colsample_bylevel': 0.4867136232959035, 'config/colsample_bytree': 0.6135955921416617, 'config/reg_alpha': 0.006535953249353212, 'config/reg_lambda': 0.5184213276703741, 'experiment_tag': 'exp', 'time_total_s': 14.807488441467285}\n",
      "[flaml.tune.tune: 09-25 12:49:45] {197} INFO - result: {'pred_time': 4.9031562632560366e-05, 'wall_clock_time': 1041.3477437496185, 'metric_for_logging': {'pred_time': 4.9031562632560366e-05}, 'val_loss': 0.185639984927841, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5242ec1c0>, 'training_iteration': 1, 'config': {'n_estimators': 185, 'max_leaves': 35, 'min_child_weight': 0.1853559952382296, 'learning_rate': 0.06197791739406124, 'subsample': 0.770888792964588, 'colsample_bylevel': 0.4867136232959035, 'colsample_bytree': 0.6135955921416617, 'reg_alpha': 0.006535953249353212, 'reg_lambda': 0.5184213276703741}, 'config/n_estimators': 185, 'config/max_leaves': 35, 'config/min_child_weight': 0.1853559952382296, 'config/learning_rate': 0.06197791739406124, 'config/subsample': 0.770888792964588, 'config/colsample_bylevel': 0.4867136232959035, 'config/colsample_bytree': 0.6135955921416617, 'config/reg_alpha': 0.006535953249353212, 'config/reg_lambda': 0.5184213276703741, 'experiment_tag': 'exp', 'time_total_s': 14.808868408203125}\n",
      "[flaml.automl.logger: 09-25 12:49:45] {2391} INFO -  at 1041.3s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:49:45] {2218} INFO - iteration 274, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:49:45] {805} INFO - trial 1 config: {'early_stopping_rounds': 15, 'learning_rate': 0.04056414230242968, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:49:51] {197} INFO - result: {'pred_time': 8.051347403902221e-05, 'wall_clock_time': 1047.0495619773865, 'metric_for_logging': {'pred_time': 8.051347403902221e-05}, 'val_loss': 0.24382287373291867, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5242ec220>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 15, 'learning_rate': 0.04056414230242968, 'n_estimators': 8192}, 'config/early_stopping_rounds': 15, 'config/learning_rate': 0.04056414230242968, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.695779085159302}\n",
      "[flaml.tune.tune: 09-25 12:49:51] {197} INFO - result: {'pred_time': 8.051347403902221e-05, 'wall_clock_time': 1047.0495619773865, 'metric_for_logging': {'pred_time': 8.051347403902221e-05}, 'val_loss': 0.24382287373291867, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5242ec220>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 15, 'learning_rate': 0.04056414230242968, 'n_estimators': 8192}, 'config/early_stopping_rounds': 15, 'config/learning_rate': 0.04056414230242968, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.697175741195679}\n",
      "[flaml.automl.logger: 09-25 12:49:51] {2391} INFO -  at 1047.0s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:49:51] {2218} INFO - iteration 275, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:49:51] {805} INFO - trial 1 config: {'early_stopping_rounds': 14, 'learning_rate': 0.04792481151607564, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:49:56] {197} INFO - result: {'pred_time': 7.970976952653998e-05, 'wall_clock_time': 1052.0576570034027, 'metric_for_logging': {'pred_time': 7.970976952653998e-05}, 'val_loss': 0.2397969198006679, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680ca1c0>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 14, 'learning_rate': 0.04792481151607564, 'n_estimators': 8192}, 'config/early_stopping_rounds': 14, 'config/learning_rate': 0.04792481151607564, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.998771667480469}\n",
      "[flaml.tune.tune: 09-25 12:49:56] {197} INFO - result: {'pred_time': 7.970976952653998e-05, 'wall_clock_time': 1052.0576570034027, 'metric_for_logging': {'pred_time': 7.970976952653998e-05}, 'val_loss': 0.2397969198006679, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680ca1c0>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 14, 'learning_rate': 0.04792481151607564, 'n_estimators': 8192}, 'config/early_stopping_rounds': 14, 'config/learning_rate': 0.04792481151607564, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.000119209289551}\n",
      "[flaml.automl.logger: 09-25 12:49:56] {2391} INFO -  at 1052.1s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:49:56] {2218} INFO - iteration 276, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:49:56] {805} INFO - trial 1 config: {'early_stopping_rounds': 12, 'learning_rate': 0.036313681203656877, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:50:02] {197} INFO - result: {'pred_time': 0.0001356639832170591, 'wall_clock_time': 1058.342687368393, 'metric_for_logging': {'pred_time': 0.0001356639832170591}, 'val_loss': 0.24392367658859415, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe534070820>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.036313681203656877, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.036313681203656877, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.2773120403289795}\n",
      "[flaml.tune.tune: 09-25 12:50:02] {197} INFO - result: {'pred_time': 0.0001356639832170591, 'wall_clock_time': 1058.342687368393, 'metric_for_logging': {'pred_time': 0.0001356639832170591}, 'val_loss': 0.24392367658859415, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe534070820>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.036313681203656877, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.036313681203656877, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.279102087020874}\n",
      "[flaml.automl.logger: 09-25 12:50:02] {2391} INFO -  at 1058.3s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:50:02] {2218} INFO - iteration 277, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:50:02] {805} INFO - trial 1 config: {'n_estimators': 103, 'max_features': 0.038381363399609625, 'max_leaves': 192, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:50:05] {197} INFO - result: {'pred_time': 0.00014580663004852237, 'wall_clock_time': 1061.541137456894, 'metric_for_logging': {'pred_time': 0.00014580663004852237}, 'val_loss': 0.19097615087120337, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680dd100>, 'training_iteration': 0, 'config': {'n_estimators': 103, 'max_features': 0.038381363399609625, 'max_leaves': 192, 'criterion': 'entropy'}, 'config/n_estimators': 103, 'config/max_features': 0.038381363399609625, 'config/max_leaves': 192, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.191743850708008}\n",
      "[flaml.tune.tune: 09-25 12:50:05] {197} INFO - result: {'pred_time': 0.00014580663004852237, 'wall_clock_time': 1061.541137456894, 'metric_for_logging': {'pred_time': 0.00014580663004852237}, 'val_loss': 0.19097615087120337, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680dd100>, 'training_iteration': 1, 'config': {'n_estimators': 103, 'max_features': 0.038381363399609625, 'max_leaves': 192, 'criterion': 'entropy'}, 'config/n_estimators': 103, 'config/max_features': 0.038381363399609625, 'config/max_leaves': 192, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.193204402923584}\n",
      "[flaml.automl.logger: 09-25 12:50:05] {2391} INFO -  at 1061.5s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:50:05] {2218} INFO - iteration 278, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:50:05] {805} INFO - trial 1 config: {'n_estimators': 75, 'max_features': 0.04575231615103124, 'max_leaves': 124, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:50:07] {197} INFO - result: {'pred_time': 0.00011730851938683497, 'wall_clock_time': 1063.7931649684906, 'metric_for_logging': {'pred_time': 0.00011730851938683497}, 'val_loss': 0.20600669866037177, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe53407ee50>, 'training_iteration': 0, 'config': {'n_estimators': 75, 'max_features': 0.04575231615103124, 'max_leaves': 124, 'criterion': 'entropy'}, 'config/n_estimators': 75, 'config/max_features': 0.04575231615103124, 'config/max_leaves': 124, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.2448782920837402}\n",
      "[flaml.tune.tune: 09-25 12:50:07] {197} INFO - result: {'pred_time': 0.00011730851938683497, 'wall_clock_time': 1063.7931649684906, 'metric_for_logging': {'pred_time': 0.00011730851938683497}, 'val_loss': 0.20600669866037177, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe53407ee50>, 'training_iteration': 1, 'config': {'n_estimators': 75, 'max_features': 0.04575231615103124, 'max_leaves': 124, 'criterion': 'entropy'}, 'config/n_estimators': 75, 'config/max_features': 0.04575231615103124, 'config/max_leaves': 124, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.245941162109375}\n",
      "[flaml.automl.logger: 09-25 12:50:07] {2391} INFO -  at 1063.8s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:50:07] {2218} INFO - iteration 279, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:50:07] {805} INFO - trial 1 config: {'n_estimators': 226, 'max_leaves': 125, 'min_child_weight': 1.1309760521402732, 'learning_rate': 0.027929112809163263, 'subsample': 0.8820870936896645, 'colsample_bylevel': 0.340774196359384, 'colsample_bytree': 0.4965728001291857, 'reg_alpha': 0.0028655578294995757, 'reg_lambda': 19.44240753221536}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:50:25] {197} INFO - result: {'pred_time': 5.216358291930596e-05, 'wall_clock_time': 1081.1860115528107, 'metric_for_logging': {'pred_time': 5.216358291930596e-05}, 'val_loss': 0.20918766621540233, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680bc490>, 'training_iteration': 0, 'config': {'n_estimators': 226, 'max_leaves': 125, 'min_child_weight': 1.1309760521402732, 'learning_rate': 0.027929112809163263, 'subsample': 0.8820870936896645, 'colsample_bylevel': 0.340774196359384, 'colsample_bytree': 0.4965728001291857, 'reg_alpha': 0.0028655578294995757, 'reg_lambda': 19.44240753221536}, 'config/n_estimators': 226, 'config/max_leaves': 125, 'config/min_child_weight': 1.1309760521402732, 'config/learning_rate': 0.027929112809163263, 'config/subsample': 0.8820870936896645, 'config/colsample_bylevel': 0.340774196359384, 'config/colsample_bytree': 0.4965728001291857, 'config/reg_alpha': 0.0028655578294995757, 'config/reg_lambda': 19.44240753221536, 'experiment_tag': 'exp', 'time_total_s': 17.385910272598267}\n",
      "[flaml.tune.tune: 09-25 12:50:25] {197} INFO - result: {'pred_time': 5.216358291930596e-05, 'wall_clock_time': 1081.1860115528107, 'metric_for_logging': {'pred_time': 5.216358291930596e-05}, 'val_loss': 0.20918766621540233, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6680bc490>, 'training_iteration': 1, 'config': {'n_estimators': 226, 'max_leaves': 125, 'min_child_weight': 1.1309760521402732, 'learning_rate': 0.027929112809163263, 'subsample': 0.8820870936896645, 'colsample_bylevel': 0.340774196359384, 'colsample_bytree': 0.4965728001291857, 'reg_alpha': 0.0028655578294995757, 'reg_lambda': 19.44240753221536}, 'config/n_estimators': 226, 'config/max_leaves': 125, 'config/min_child_weight': 1.1309760521402732, 'config/learning_rate': 0.027929112809163263, 'config/subsample': 0.8820870936896645, 'config/colsample_bylevel': 0.340774196359384, 'config/colsample_bytree': 0.4965728001291857, 'config/reg_alpha': 0.0028655578294995757, 'config/reg_lambda': 19.44240753221536, 'experiment_tag': 'exp', 'time_total_s': 17.3877272605896}\n",
      "[flaml.automl.logger: 09-25 12:50:25] {2391} INFO -  at 1081.2s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:50:25] {2218} INFO - iteration 280, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:50:25] {805} INFO - trial 1 config: {'n_estimators': 94, 'max_depth': 9, 'min_child_weight': 0.047358692144957054, 'learning_rate': 0.33802048907715804, 'subsample': 0.7064175340368017, 'colsample_bylevel': 0.3464436797393451, 'colsample_bytree': 0.5510566496471649, 'reg_alpha': 0.018146374679511603, 'reg_lambda': 5.077750222796673}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:50:36] {197} INFO - result: {'pred_time': 4.7256023438860115e-05, 'wall_clock_time': 1092.9910464286804, 'metric_for_logging': {'pred_time': 4.7256023438860115e-05}, 'val_loss': 0.20198371015462468, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680bc430>, 'training_iteration': 0, 'config': {'n_estimators': 94, 'max_depth': 9, 'min_child_weight': 0.047358692144957054, 'learning_rate': 0.33802048907715804, 'subsample': 0.7064175340368017, 'colsample_bylevel': 0.3464436797393451, 'colsample_bytree': 0.5510566496471649, 'reg_alpha': 0.018146374679511603, 'reg_lambda': 5.077750222796673}, 'config/n_estimators': 94, 'config/max_depth': 9, 'config/min_child_weight': 0.047358692144957054, 'config/learning_rate': 0.33802048907715804, 'config/subsample': 0.7064175340368017, 'config/colsample_bylevel': 0.3464436797393451, 'config/colsample_bytree': 0.5510566496471649, 'config/reg_alpha': 0.018146374679511603, 'config/reg_lambda': 5.077750222796673, 'experiment_tag': 'exp', 'time_total_s': 11.798073291778564}\n",
      "[flaml.tune.tune: 09-25 12:50:36] {197} INFO - result: {'pred_time': 4.7256023438860115e-05, 'wall_clock_time': 1092.9910464286804, 'metric_for_logging': {'pred_time': 4.7256023438860115e-05}, 'val_loss': 0.20198371015462468, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe6680bc430>, 'training_iteration': 1, 'config': {'n_estimators': 94, 'max_depth': 9, 'min_child_weight': 0.047358692144957054, 'learning_rate': 0.33802048907715804, 'subsample': 0.7064175340368017, 'colsample_bylevel': 0.3464436797393451, 'colsample_bytree': 0.5510566496471649, 'reg_alpha': 0.018146374679511603, 'reg_lambda': 5.077750222796673}, 'config/n_estimators': 94, 'config/max_depth': 9, 'config/min_child_weight': 0.047358692144957054, 'config/learning_rate': 0.33802048907715804, 'config/subsample': 0.7064175340368017, 'config/colsample_bylevel': 0.3464436797393451, 'config/colsample_bytree': 0.5510566496471649, 'config/reg_alpha': 0.018146374679511603, 'config/reg_lambda': 5.077750222796673, 'experiment_tag': 'exp', 'time_total_s': 11.799984693527222}\n",
      "[flaml.automl.logger: 09-25 12:50:36] {2391} INFO -  at 1093.0s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:50:36] {2218} INFO - iteration 281, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:50:36] {805} INFO - trial 1 config: {'n_estimators': 282, 'max_features': 0.04282599385141143, 'max_leaves': 468, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:50:46] {197} INFO - result: {'pred_time': 0.00039404949691950223, 'wall_clock_time': 1102.0836136341095, 'metric_for_logging': {'pred_time': 0.00039404949691950223}, 'val_loss': 0.20305512524403083, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680bc0a0>, 'training_iteration': 0, 'config': {'n_estimators': 282, 'max_features': 0.04282599385141143, 'max_leaves': 468, 'criterion': 'gini'}, 'config/n_estimators': 282, 'config/max_features': 0.04282599385141143, 'config/max_leaves': 468, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 9.083459377288818}\n",
      "[flaml.tune.tune: 09-25 12:50:46] {197} INFO - result: {'pred_time': 0.00039404949691950223, 'wall_clock_time': 1102.0836136341095, 'metric_for_logging': {'pred_time': 0.00039404949691950223}, 'val_loss': 0.20305512524403083, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6680bc0a0>, 'training_iteration': 1, 'config': {'n_estimators': 282, 'max_features': 0.04282599385141143, 'max_leaves': 468, 'criterion': 'gini'}, 'config/n_estimators': 282, 'config/max_features': 0.04282599385141143, 'config/max_leaves': 468, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 9.084580183029175}\n",
      "[flaml.automl.logger: 09-25 12:50:46] {2391} INFO -  at 1102.1s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:50:46] {2218} INFO - iteration 282, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:50:46] {805} INFO - trial 1 config: {'n_estimators': 44, 'max_features': 0.04196873042245033, 'max_leaves': 60, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:50:47] {197} INFO - result: {'pred_time': 7.41336887691298e-05, 'wall_clock_time': 1103.5520367622375, 'metric_for_logging': {'pred_time': 7.41336887691298e-05}, 'val_loss': 0.21417738376134174, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe53407e340>, 'training_iteration': 0, 'config': {'n_estimators': 44, 'max_features': 0.04196873042245033, 'max_leaves': 60, 'criterion': 'entropy'}, 'config/n_estimators': 44, 'config/max_features': 0.04196873042245033, 'config/max_leaves': 60, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.4624712467193604}\n",
      "[flaml.tune.tune: 09-25 12:50:47] {197} INFO - result: {'pred_time': 7.41336887691298e-05, 'wall_clock_time': 1103.5520367622375, 'metric_for_logging': {'pred_time': 7.41336887691298e-05}, 'val_loss': 0.21417738376134174, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe53407e340>, 'training_iteration': 1, 'config': {'n_estimators': 44, 'max_features': 0.04196873042245033, 'max_leaves': 60, 'criterion': 'entropy'}, 'config/n_estimators': 44, 'config/max_features': 0.04196873042245033, 'config/max_leaves': 60, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.4635522365570068}\n",
      "[flaml.automl.logger: 09-25 12:50:47] {2391} INFO -  at 1103.6s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:50:47] {2218} INFO - iteration 283, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:50:47] {805} INFO - trial 1 config: {'early_stopping_rounds': 12, 'learning_rate': 0.047970970828920274, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:50:52] {197} INFO - result: {'pred_time': 0.00013891881251940056, 'wall_clock_time': 1108.314903974533, 'metric_for_logging': {'pred_time': 0.00013891881251940056}, 'val_loss': 0.23984881692902685, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680be280>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.047970970828920274, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.047970970828920274, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.753763198852539}\n",
      "[flaml.tune.tune: 09-25 12:50:52] {197} INFO - result: {'pred_time': 0.00013891881251940056, 'wall_clock_time': 1108.314903974533, 'metric_for_logging': {'pred_time': 0.00013891881251940056}, 'val_loss': 0.23984881692902685, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680be280>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.047970970828920274, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.047970970828920274, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.754977464675903}\n",
      "[flaml.automl.logger: 09-25 12:50:52] {2391} INFO -  at 1108.3s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:50:52] {2218} INFO - iteration 284, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:50:52] {805} INFO - trial 1 config: {'n_estimators': 110, 'max_features': 0.032427221756276076, 'max_leaves': 263, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:50:55] {197} INFO - result: {'pred_time': 0.0001577248474784599, 'wall_clock_time': 1111.7053554058075, 'metric_for_logging': {'pred_time': 0.0001577248474784599}, 'val_loss': 0.1939785651179954, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524163e80>, 'training_iteration': 0, 'config': {'n_estimators': 110, 'max_features': 0.032427221756276076, 'max_leaves': 263, 'criterion': 'gini'}, 'config/n_estimators': 110, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 263, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.3841145038604736}\n",
      "[flaml.tune.tune: 09-25 12:50:55] {197} INFO - result: {'pred_time': 0.0001577248474784599, 'wall_clock_time': 1111.7053554058075, 'metric_for_logging': {'pred_time': 0.0001577248474784599}, 'val_loss': 0.1939785651179954, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524163e80>, 'training_iteration': 1, 'config': {'n_estimators': 110, 'max_features': 0.032427221756276076, 'max_leaves': 263, 'criterion': 'gini'}, 'config/n_estimators': 110, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 263, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.386160373687744}\n",
      "[flaml.automl.logger: 09-25 12:50:55] {2391} INFO -  at 1111.7s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:50:55] {2218} INFO - iteration 285, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:50:55] {805} INFO - trial 1 config: {'n_estimators': 228, 'max_features': 0.042436785427716575, 'max_leaves': 505, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:51:03] {197} INFO - result: {'pred_time': 0.00032360304064264474, 'wall_clock_time': 1119.343339920044, 'metric_for_logging': {'pred_time': 0.00032360304064264474}, 'val_loss': 0.20617926050834598, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe53407ed90>, 'training_iteration': 0, 'config': {'n_estimators': 228, 'max_features': 0.042436785427716575, 'max_leaves': 505, 'criterion': 'gini'}, 'config/n_estimators': 228, 'config/max_features': 0.042436785427716575, 'config/max_leaves': 505, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 7.629224538803101}\n",
      "[flaml.tune.tune: 09-25 12:51:03] {197} INFO - result: {'pred_time': 0.00032360304064264474, 'wall_clock_time': 1119.343339920044, 'metric_for_logging': {'pred_time': 0.00032360304064264474}, 'val_loss': 0.20617926050834598, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe53407ed90>, 'training_iteration': 1, 'config': {'n_estimators': 228, 'max_features': 0.042436785427716575, 'max_leaves': 505, 'criterion': 'gini'}, 'config/n_estimators': 228, 'config/max_features': 0.042436785427716575, 'config/max_leaves': 505, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 7.630542039871216}\n",
      "[flaml.automl.logger: 09-25 12:51:03] {2391} INFO -  at 1119.3s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:51:03] {2218} INFO - iteration 286, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:51:03] {805} INFO - trial 1 config: {'n_estimators': 23, 'max_depth': 9, 'min_child_weight': 0.007836049290851804, 'learning_rate': 0.30880362131814654, 'subsample': 0.7501066407084306, 'colsample_bylevel': 0.040240235276758914, 'colsample_bytree': 0.4591799847797127, 'reg_alpha': 0.023700854383386517, 'reg_lambda': 4.37717915665135}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:51:05] {197} INFO - result: {'pred_time': 4.5179021505769146e-05, 'wall_clock_time': 1121.3445336818695, 'metric_for_logging': {'pred_time': 4.5179021505769146e-05}, 'val_loss': 0.24056743284629345, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524349d60>, 'training_iteration': 0, 'config': {'n_estimators': 23, 'max_depth': 9, 'min_child_weight': 0.007836049290851804, 'learning_rate': 0.30880362131814654, 'subsample': 0.7501066407084306, 'colsample_bylevel': 0.040240235276758914, 'colsample_bytree': 0.4591799847797127, 'reg_alpha': 0.023700854383386517, 'reg_lambda': 4.37717915665135}, 'config/n_estimators': 23, 'config/max_depth': 9, 'config/min_child_weight': 0.007836049290851804, 'config/learning_rate': 0.30880362131814654, 'config/subsample': 0.7501066407084306, 'config/colsample_bylevel': 0.040240235276758914, 'config/colsample_bytree': 0.4591799847797127, 'config/reg_alpha': 0.023700854383386517, 'config/reg_lambda': 4.37717915665135, 'experiment_tag': 'exp', 'time_total_s': 1.996018886566162}\n",
      "[flaml.tune.tune: 09-25 12:51:05] {197} INFO - result: {'pred_time': 4.5179021505769146e-05, 'wall_clock_time': 1121.3445336818695, 'metric_for_logging': {'pred_time': 4.5179021505769146e-05}, 'val_loss': 0.24056743284629345, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524349d60>, 'training_iteration': 1, 'config': {'n_estimators': 23, 'max_depth': 9, 'min_child_weight': 0.007836049290851804, 'learning_rate': 0.30880362131814654, 'subsample': 0.7501066407084306, 'colsample_bylevel': 0.040240235276758914, 'colsample_bytree': 0.4591799847797127, 'reg_alpha': 0.023700854383386517, 'reg_lambda': 4.37717915665135}, 'config/n_estimators': 23, 'config/max_depth': 9, 'config/min_child_weight': 0.007836049290851804, 'config/learning_rate': 0.30880362131814654, 'config/subsample': 0.7501066407084306, 'config/colsample_bylevel': 0.040240235276758914, 'config/colsample_bytree': 0.4591799847797127, 'config/reg_alpha': 0.023700854383386517, 'config/reg_lambda': 4.37717915665135, 'experiment_tag': 'exp', 'time_total_s': 1.9971816539764404}\n",
      "[flaml.automl.logger: 09-25 12:51:05] {2391} INFO -  at 1121.3s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:51:05] {2218} INFO - iteration 287, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:51:05] {805} INFO - trial 1 config: {'n_estimators': 262, 'max_depth': 9, 'min_child_weight': 0.02932678475702787, 'learning_rate': 0.06995852462611485, 'subsample': 0.8531155592124574, 'colsample_bylevel': 0.25849195079502324, 'colsample_bytree': 0.6997187061639213, 'reg_alpha': 0.0016199184220883813, 'reg_lambda': 0.8903685762569797}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:51:34] {197} INFO - result: {'pred_time': 5.194230913004268e-05, 'wall_clock_time': 1150.2475039958954, 'metric_for_logging': {'pred_time': 5.194230913004268e-05}, 'val_loss': 0.20220842454725513, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524166160>, 'training_iteration': 0, 'config': {'n_estimators': 262, 'max_depth': 9, 'min_child_weight': 0.02932678475702787, 'learning_rate': 0.06995852462611485, 'subsample': 0.8531155592124574, 'colsample_bylevel': 0.25849195079502324, 'colsample_bytree': 0.6997187061639213, 'reg_alpha': 0.0016199184220883813, 'reg_lambda': 0.8903685762569797}, 'config/n_estimators': 262, 'config/max_depth': 9, 'config/min_child_weight': 0.02932678475702787, 'config/learning_rate': 0.06995852462611485, 'config/subsample': 0.8531155592124574, 'config/colsample_bylevel': 0.25849195079502324, 'config/colsample_bytree': 0.6997187061639213, 'config/reg_alpha': 0.0016199184220883813, 'config/reg_lambda': 0.8903685762569797, 'experiment_tag': 'exp', 'time_total_s': 28.89541268348694}\n",
      "[flaml.tune.tune: 09-25 12:51:34] {197} INFO - result: {'pred_time': 5.194230913004268e-05, 'wall_clock_time': 1150.2475039958954, 'metric_for_logging': {'pred_time': 5.194230913004268e-05}, 'val_loss': 0.20220842454725513, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524166160>, 'training_iteration': 1, 'config': {'n_estimators': 262, 'max_depth': 9, 'min_child_weight': 0.02932678475702787, 'learning_rate': 0.06995852462611485, 'subsample': 0.8531155592124574, 'colsample_bylevel': 0.25849195079502324, 'colsample_bytree': 0.6997187061639213, 'reg_alpha': 0.0016199184220883813, 'reg_lambda': 0.8903685762569797}, 'config/n_estimators': 262, 'config/max_depth': 9, 'config/min_child_weight': 0.02932678475702787, 'config/learning_rate': 0.06995852462611485, 'config/subsample': 0.8531155592124574, 'config/colsample_bylevel': 0.25849195079502324, 'config/colsample_bytree': 0.6997187061639213, 'config/reg_alpha': 0.0016199184220883813, 'config/reg_lambda': 0.8903685762569797, 'experiment_tag': 'exp', 'time_total_s': 28.89773464202881}\n",
      "[flaml.automl.logger: 09-25 12:51:34] {2391} INFO -  at 1150.2s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:51:34] {2218} INFO - iteration 288, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:51:34] {805} INFO - trial 1 config: {'n_estimators': 94, 'max_features': 0.04617193292148298, 'max_leaves': 115, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:51:36] {197} INFO - result: {'pred_time': 0.00014155242611017127, 'wall_clock_time': 1152.8682055473328, 'metric_for_logging': {'pred_time': 0.00014155242611017127}, 'val_loss': 0.2020022559752695, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5241668b0>, 'training_iteration': 0, 'config': {'n_estimators': 94, 'max_features': 0.04617193292148298, 'max_leaves': 115, 'criterion': 'entropy'}, 'config/n_estimators': 94, 'config/max_features': 0.04617193292148298, 'config/max_leaves': 115, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.6119494438171387}\n",
      "[flaml.tune.tune: 09-25 12:51:36] {197} INFO - result: {'pred_time': 0.00014155242611017127, 'wall_clock_time': 1152.8682055473328, 'metric_for_logging': {'pred_time': 0.00014155242611017127}, 'val_loss': 0.2020022559752695, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5241668b0>, 'training_iteration': 1, 'config': {'n_estimators': 94, 'max_features': 0.04617193292148298, 'max_leaves': 115, 'criterion': 'entropy'}, 'config/n_estimators': 94, 'config/max_features': 0.04617193292148298, 'config/max_leaves': 115, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.613229751586914}\n",
      "[flaml.automl.logger: 09-25 12:51:36] {2391} INFO -  at 1152.9s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:51:36] {2218} INFO - iteration 289, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:51:36] {805} INFO - trial 1 config: {'n_estimators': 48, 'max_features': 0.032427221756276076, 'max_leaves': 56, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:51:38] {197} INFO - result: {'pred_time': 7.776438564817333e-05, 'wall_clock_time': 1154.4328248500824, 'metric_for_logging': {'pred_time': 7.776438564817333e-05}, 'val_loss': 0.2139463662139824, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5340648e0>, 'training_iteration': 0, 'config': {'n_estimators': 48, 'max_features': 0.032427221756276076, 'max_leaves': 56, 'criterion': 'gini'}, 'config/n_estimators': 48, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 56, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.5580048561096191}\n",
      "[flaml.tune.tune: 09-25 12:51:38] {197} INFO - result: {'pred_time': 7.776438564817333e-05, 'wall_clock_time': 1154.4328248500824, 'metric_for_logging': {'pred_time': 7.776438564817333e-05}, 'val_loss': 0.2139463662139824, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5340648e0>, 'training_iteration': 1, 'config': {'n_estimators': 48, 'max_features': 0.032427221756276076, 'max_leaves': 56, 'criterion': 'gini'}, 'config/n_estimators': 48, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 56, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.559251308441162}\n",
      "[flaml.automl.logger: 09-25 12:51:38] {2391} INFO -  at 1154.4s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:51:38] {2218} INFO - iteration 290, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:51:38] {805} INFO - trial 1 config: {'n_estimators': 101, 'max_features': 0.04028336900062868, 'max_leaves': 281, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:51:41] {197} INFO - result: {'pred_time': 0.00014740727854929795, 'wall_clock_time': 1157.6611704826355, 'metric_for_logging': {'pred_time': 0.00014740727854929795}, 'val_loss': 0.19815443975863764, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe52414f820>, 'training_iteration': 0, 'config': {'n_estimators': 101, 'max_features': 0.04028336900062868, 'max_leaves': 281, 'criterion': 'entropy'}, 'config/n_estimators': 101, 'config/max_features': 0.04028336900062868, 'config/max_leaves': 281, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.2218377590179443}\n",
      "[flaml.tune.tune: 09-25 12:51:41] {197} INFO - result: {'pred_time': 0.00014740727854929795, 'wall_clock_time': 1157.6611704826355, 'metric_for_logging': {'pred_time': 0.00014740727854929795}, 'val_loss': 0.19815443975863764, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe52414f820>, 'training_iteration': 1, 'config': {'n_estimators': 101, 'max_features': 0.04028336900062868, 'max_leaves': 281, 'criterion': 'entropy'}, 'config/n_estimators': 101, 'config/max_features': 0.04028336900062868, 'config/max_leaves': 281, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 3.22326397895813}\n",
      "[flaml.automl.logger: 09-25 12:51:41] {2391} INFO -  at 1157.7s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:51:41] {2218} INFO - iteration 291, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:51:41] {805} INFO - trial 1 config: {'n_estimators': 212, 'max_features': 0.04221174709674877, 'max_leaves': 110, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:51:47] {197} INFO - result: {'pred_time': 0.0002898294533194678, 'wall_clock_time': 1163.1073424816132, 'metric_for_logging': {'pred_time': 0.0002898294533194678}, 'val_loss': 0.20245600519213713, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668105370>, 'training_iteration': 0, 'config': {'n_estimators': 212, 'max_features': 0.04221174709674877, 'max_leaves': 110, 'criterion': 'entropy'}, 'config/n_estimators': 212, 'config/max_features': 0.04221174709674877, 'config/max_leaves': 110, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 5.439428091049194}\n",
      "[flaml.tune.tune: 09-25 12:51:47] {197} INFO - result: {'pred_time': 0.0002898294533194678, 'wall_clock_time': 1163.1073424816132, 'metric_for_logging': {'pred_time': 0.0002898294533194678}, 'val_loss': 0.20245600519213713, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe668105370>, 'training_iteration': 1, 'config': {'n_estimators': 212, 'max_features': 0.04221174709674877, 'max_leaves': 110, 'criterion': 'entropy'}, 'config/n_estimators': 212, 'config/max_features': 0.04221174709674877, 'config/max_leaves': 110, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 5.440859317779541}\n",
      "[flaml.automl.logger: 09-25 12:51:47] {2391} INFO -  at 1163.1s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:51:47] {2218} INFO - iteration 292, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:51:47] {805} INFO - trial 1 config: {'n_estimators': 86, 'max_leaves': 148, 'min_child_weight': 0.06486061533356074, 'learning_rate': 0.08390703872340605, 'subsample': 0.7726156233460315, 'colsample_bylevel': 0.3686000791800466, 'colsample_bytree': 0.7546876060615879, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.09556486588913746}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:51:58] {197} INFO - result: {'pred_time': 5.2068779110993023e-05, 'wall_clock_time': 1174.0323214530945, 'metric_for_logging': {'pred_time': 5.2068779110993023e-05}, 'val_loss': 0.19163171359573164, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe66807db80>, 'training_iteration': 0, 'config': {'n_estimators': 86, 'max_leaves': 148, 'min_child_weight': 0.06486061533356074, 'learning_rate': 0.08390703872340605, 'subsample': 0.7726156233460315, 'colsample_bylevel': 0.3686000791800466, 'colsample_bytree': 0.7546876060615879, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.09556486588913746}, 'config/n_estimators': 86, 'config/max_leaves': 148, 'config/min_child_weight': 0.06486061533356074, 'config/learning_rate': 0.08390703872340605, 'config/subsample': 0.7726156233460315, 'config/colsample_bylevel': 0.3686000791800466, 'config/colsample_bytree': 0.7546876060615879, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.09556486588913746, 'experiment_tag': 'exp', 'time_total_s': 10.918837785720825}\n",
      "[flaml.tune.tune: 09-25 12:51:58] {197} INFO - result: {'pred_time': 5.2068779110993023e-05, 'wall_clock_time': 1174.0323214530945, 'metric_for_logging': {'pred_time': 5.2068779110993023e-05}, 'val_loss': 0.19163171359573164, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe66807db80>, 'training_iteration': 1, 'config': {'n_estimators': 86, 'max_leaves': 148, 'min_child_weight': 0.06486061533356074, 'learning_rate': 0.08390703872340605, 'subsample': 0.7726156233460315, 'colsample_bylevel': 0.3686000791800466, 'colsample_bytree': 0.7546876060615879, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.09556486588913746}, 'config/n_estimators': 86, 'config/max_leaves': 148, 'config/min_child_weight': 0.06486061533356074, 'config/learning_rate': 0.08390703872340605, 'config/subsample': 0.7726156233460315, 'config/colsample_bylevel': 0.3686000791800466, 'config/colsample_bytree': 0.7546876060615879, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.09556486588913746, 'experiment_tag': 'exp', 'time_total_s': 10.920347213745117}\n",
      "[flaml.automl.logger: 09-25 12:51:58] {2391} INFO -  at 1174.0s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:51:58] {2218} INFO - iteration 293, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:51:58] {805} INFO - trial 1 config: {'n_estimators': 100, 'max_features': 0.04641808370738608, 'max_leaves': 528, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:52:01] {197} INFO - result: {'pred_time': 0.00015816792838394385, 'wall_clock_time': 1177.7416672706604, 'metric_for_logging': {'pred_time': 0.00015816792838394385}, 'val_loss': 0.21724017582338426, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe66807d070>, 'training_iteration': 0, 'config': {'n_estimators': 100, 'max_features': 0.04641808370738608, 'max_leaves': 528, 'criterion': 'gini'}, 'config/n_estimators': 100, 'config/max_features': 0.04641808370738608, 'config/max_leaves': 528, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.702359199523926}\n",
      "[flaml.tune.tune: 09-25 12:52:01] {197} INFO - result: {'pred_time': 0.00015816792838394385, 'wall_clock_time': 1177.7416672706604, 'metric_for_logging': {'pred_time': 0.00015816792838394385}, 'val_loss': 0.21724017582338426, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe66807d070>, 'training_iteration': 1, 'config': {'n_estimators': 100, 'max_features': 0.04641808370738608, 'max_leaves': 528, 'criterion': 'gini'}, 'config/n_estimators': 100, 'config/max_features': 0.04641808370738608, 'config/max_leaves': 528, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 3.703409194946289}\n",
      "[flaml.automl.logger: 09-25 12:52:01] {2391} INFO -  at 1177.7s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:52:01] {2218} INFO - iteration 294, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:52:01] {805} INFO - trial 1 config: {'n_estimators': 565, 'max_leaves': 142, 'min_child_weight': 0.39472434545783913, 'learning_rate': 0.10656290384758234, 'subsample': 0.764420047619262, 'colsample_bylevel': 0.4547084579267674, 'colsample_bytree': 0.516113577375858, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.1082257767660613}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:52:56] {197} INFO - result: {'pred_time': 6.53718885170463e-05, 'wall_clock_time': 1232.6292831897736, 'metric_for_logging': {'pred_time': 6.53718885170463e-05}, 'val_loss': 0.20171983914487662, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe524166220>, 'training_iteration': 0, 'config': {'n_estimators': 565, 'max_leaves': 142, 'min_child_weight': 0.39472434545783913, 'learning_rate': 0.10656290384758234, 'subsample': 0.764420047619262, 'colsample_bylevel': 0.4547084579267674, 'colsample_bytree': 0.516113577375858, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.1082257767660613}, 'config/n_estimators': 565, 'config/max_leaves': 142, 'config/min_child_weight': 0.39472434545783913, 'config/learning_rate': 0.10656290384758234, 'config/subsample': 0.764420047619262, 'config/colsample_bylevel': 0.4547084579267674, 'config/colsample_bytree': 0.516113577375858, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.1082257767660613, 'experiment_tag': 'exp', 'time_total_s': 54.881317377090454}\n",
      "[flaml.tune.tune: 09-25 12:52:56] {197} INFO - result: {'pred_time': 6.53718885170463e-05, 'wall_clock_time': 1232.6292831897736, 'metric_for_logging': {'pred_time': 6.53718885170463e-05}, 'val_loss': 0.20171983914487662, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe524166220>, 'training_iteration': 1, 'config': {'n_estimators': 565, 'max_leaves': 142, 'min_child_weight': 0.39472434545783913, 'learning_rate': 0.10656290384758234, 'subsample': 0.764420047619262, 'colsample_bylevel': 0.4547084579267674, 'colsample_bytree': 0.516113577375858, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.1082257767660613}, 'config/n_estimators': 565, 'config/max_leaves': 142, 'config/min_child_weight': 0.39472434545783913, 'config/learning_rate': 0.10656290384758234, 'config/subsample': 0.764420047619262, 'config/colsample_bylevel': 0.4547084579267674, 'config/colsample_bytree': 0.516113577375858, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.1082257767660613, 'experiment_tag': 'exp', 'time_total_s': 54.882492542266846}\n",
      "[flaml.automl.logger: 09-25 12:52:56] {2391} INFO -  at 1232.6s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:52:56] {2218} INFO - iteration 295, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:52:56] {805} INFO - trial 1 config: {'n_estimators': 236, 'max_features': 0.0716424206584515, 'max_leaves': 247, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:53:04] {197} INFO - result: {'pred_time': 0.00033969035507318545, 'wall_clock_time': 1241.0006098747253, 'metric_for_logging': {'pred_time': 0.00033969035507318545}, 'val_loss': 0.19407592634729068, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5241660a0>, 'training_iteration': 0, 'config': {'n_estimators': 236, 'max_features': 0.0716424206584515, 'max_leaves': 247, 'criterion': 'entropy'}, 'config/n_estimators': 236, 'config/max_features': 0.0716424206584515, 'config/max_leaves': 247, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 8.363350629806519}\n",
      "[flaml.tune.tune: 09-25 12:53:04] {197} INFO - result: {'pred_time': 0.00033969035507318545, 'wall_clock_time': 1241.0006098747253, 'metric_for_logging': {'pred_time': 0.00033969035507318545}, 'val_loss': 0.19407592634729068, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5241660a0>, 'training_iteration': 1, 'config': {'n_estimators': 236, 'max_features': 0.0716424206584515, 'max_leaves': 247, 'criterion': 'entropy'}, 'config/n_estimators': 236, 'config/max_features': 0.0716424206584515, 'config/max_leaves': 247, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 8.365605115890503}\n",
      "[flaml.automl.logger: 09-25 12:53:04] {2391} INFO -  at 1241.0s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:53:04] {2218} INFO - iteration 296, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:53:04] {805} INFO - trial 1 config: {'early_stopping_rounds': 14, 'learning_rate': 0.03627873893456672, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:53:11] {197} INFO - result: {'pred_time': 0.00011015681751678076, 'wall_clock_time': 1247.376399755478, 'metric_for_logging': {'pred_time': 0.00011015681751678076}, 'val_loss': 0.2365966834669983, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe668105190>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 14, 'learning_rate': 0.03627873893456672, 'n_estimators': 8192}, 'config/early_stopping_rounds': 14, 'config/learning_rate': 0.03627873893456672, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.36614465713501}\n",
      "[flaml.tune.tune: 09-25 12:53:11] {197} INFO - result: {'pred_time': 0.00011015681751678076, 'wall_clock_time': 1247.376399755478, 'metric_for_logging': {'pred_time': 0.00011015681751678076}, 'val_loss': 0.2365966834669983, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe668105190>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 14, 'learning_rate': 0.03627873893456672, 'n_estimators': 8192}, 'config/early_stopping_rounds': 14, 'config/learning_rate': 0.03627873893456672, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 6.367404222488403}\n",
      "[flaml.automl.logger: 09-25 12:53:11] {2391} INFO -  at 1247.4s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:53:11] {2218} INFO - iteration 297, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:53:11] {805} INFO - trial 1 config: {'n_estimators': 90, 'max_features': 0.032427221756276076, 'max_leaves': 235, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:53:13] {197} INFO - result: {'pred_time': 0.00013961059762169806, 'wall_clock_time': 1249.9185655117035, 'metric_for_logging': {'pred_time': 0.00013961059762169806}, 'val_loss': 0.19484391986266048, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340bcac0>, 'training_iteration': 0, 'config': {'n_estimators': 90, 'max_features': 0.032427221756276076, 'max_leaves': 235, 'criterion': 'gini'}, 'config/n_estimators': 90, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 235, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.535318374633789}\n",
      "[flaml.tune.tune: 09-25 12:53:13] {197} INFO - result: {'pred_time': 0.00013961059762169806, 'wall_clock_time': 1249.9185655117035, 'metric_for_logging': {'pred_time': 0.00013961059762169806}, 'val_loss': 0.19484391986266048, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340bcac0>, 'training_iteration': 1, 'config': {'n_estimators': 90, 'max_features': 0.032427221756276076, 'max_leaves': 235, 'criterion': 'gini'}, 'config/n_estimators': 90, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 235, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.5372707843780518}\n",
      "[flaml.automl.logger: 09-25 12:53:13] {2391} INFO -  at 1249.9s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:53:13] {2218} INFO - iteration 298, current learner lrl1\n",
      "[flaml.tune.tune: 09-25 12:53:13] {805} INFO - trial 1 config: {'C': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:53:39] {197} INFO - result: {'pred_time': 1.4163329672863017e-05, 'wall_clock_time': 1275.355307817459, 'metric_for_logging': {'pred_time': 1.4163329672863017e-05}, 'val_loss': 0.2161315348909052, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe524290940>, 'training_iteration': 0, 'config': {'C': 1.0}, 'config/C': 1.0, 'experiment_tag': 'exp', 'time_total_s': 25.428134441375732}\n",
      "[flaml.tune.tune: 09-25 12:53:39] {197} INFO - result: {'pred_time': 1.4163329672863017e-05, 'wall_clock_time': 1275.355307817459, 'metric_for_logging': {'pred_time': 1.4163329672863017e-05}, 'val_loss': 0.2161315348909052, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe524290940>, 'training_iteration': 1, 'config': {'C': 1.0}, 'config/C': 1.0, 'experiment_tag': 'exp', 'time_total_s': 25.43045449256897}\n",
      "[flaml.automl.logger: 09-25 12:53:39] {2391} INFO -  at 1275.4s,\testimator lrl1's best error=0.2161,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:53:39] {2218} INFO - iteration 299, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:53:39] {805} INFO - trial 1 config: {'n_estimators': 58, 'max_depth': 10, 'min_child_weight': 0.022150901434543593, 'learning_rate': 0.11480275271990871, 'subsample': 0.858073665513704, 'colsample_bylevel': 0.017339607509702933, 'colsample_bytree': 0.5914839564255421, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.190669313011294}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:53:42] {197} INFO - result: {'pred_time': 4.385590770807935e-05, 'wall_clock_time': 1278.889548778534, 'metric_for_logging': {'pred_time': 4.385590770807935e-05}, 'val_loss': 0.22606866611739176, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524290fa0>, 'training_iteration': 0, 'config': {'n_estimators': 58, 'max_depth': 10, 'min_child_weight': 0.022150901434543593, 'learning_rate': 0.11480275271990871, 'subsample': 0.858073665513704, 'colsample_bylevel': 0.017339607509702933, 'colsample_bytree': 0.5914839564255421, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.190669313011294}, 'config/n_estimators': 58, 'config/max_depth': 10, 'config/min_child_weight': 0.022150901434543593, 'config/learning_rate': 0.11480275271990871, 'config/subsample': 0.858073665513704, 'config/colsample_bylevel': 0.017339607509702933, 'config/colsample_bytree': 0.5914839564255421, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.190669313011294, 'experiment_tag': 'exp', 'time_total_s': 3.5191650390625}\n",
      "[flaml.tune.tune: 09-25 12:53:42] {197} INFO - result: {'pred_time': 4.385590770807935e-05, 'wall_clock_time': 1278.889548778534, 'metric_for_logging': {'pred_time': 4.385590770807935e-05}, 'val_loss': 0.22606866611739176, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524290fa0>, 'training_iteration': 1, 'config': {'n_estimators': 58, 'max_depth': 10, 'min_child_weight': 0.022150901434543593, 'learning_rate': 0.11480275271990871, 'subsample': 0.858073665513704, 'colsample_bylevel': 0.017339607509702933, 'colsample_bytree': 0.5914839564255421, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.190669313011294}, 'config/n_estimators': 58, 'config/max_depth': 10, 'config/min_child_weight': 0.022150901434543593, 'config/learning_rate': 0.11480275271990871, 'config/subsample': 0.858073665513704, 'config/colsample_bylevel': 0.017339607509702933, 'config/colsample_bytree': 0.5914839564255421, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.190669313011294, 'experiment_tag': 'exp', 'time_total_s': 3.5204946994781494}\n",
      "[flaml.automl.logger: 09-25 12:53:42] {2391} INFO -  at 1278.9s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:53:42] {2218} INFO - iteration 300, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:53:42] {805} INFO - trial 1 config: {'n_estimators': 259, 'max_features': 0.03648985592303652, 'max_leaves': 396, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:53:50] {197} INFO - result: {'pred_time': 0.0003596211066636136, 'wall_clock_time': 1286.2990500926971, 'metric_for_logging': {'pred_time': 0.0003596211066636136}, 'val_loss': 0.19816663913365562, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe524290790>, 'training_iteration': 0, 'config': {'n_estimators': 259, 'max_features': 0.03648985592303652, 'max_leaves': 396, 'criterion': 'gini'}, 'config/n_estimators': 259, 'config/max_features': 0.03648985592303652, 'config/max_leaves': 396, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 7.403516530990601}\n",
      "[flaml.tune.tune: 09-25 12:53:50] {197} INFO - result: {'pred_time': 0.0003596211066636136, 'wall_clock_time': 1286.2990500926971, 'metric_for_logging': {'pred_time': 0.0003596211066636136}, 'val_loss': 0.19816663913365562, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe524290790>, 'training_iteration': 1, 'config': {'n_estimators': 259, 'max_features': 0.03648985592303652, 'max_leaves': 396, 'criterion': 'gini'}, 'config/n_estimators': 259, 'config/max_features': 0.03648985592303652, 'config/max_leaves': 396, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 7.405040979385376}\n",
      "[flaml.automl.logger: 09-25 12:53:50] {2391} INFO -  at 1286.3s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:53:50] {2218} INFO - iteration 301, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:53:50] {805} INFO - trial 1 config: {'early_stopping_rounds': 14, 'learning_rate': 0.04599015617453359, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:53:53] {197} INFO - result: {'pred_time': 0.00010746693691596662, 'wall_clock_time': 1289.7489306926727, 'metric_for_logging': {'pred_time': 0.00010746693691596662}, 'val_loss': 0.2520627376886747, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680e08e0>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 14, 'learning_rate': 0.04599015617453359, 'n_estimators': 8192}, 'config/early_stopping_rounds': 14, 'config/learning_rate': 0.04599015617453359, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 3.441046953201294}\n",
      "[flaml.tune.tune: 09-25 12:53:53] {197} INFO - result: {'pred_time': 0.00010746693691596662, 'wall_clock_time': 1289.7489306926727, 'metric_for_logging': {'pred_time': 0.00010746693691596662}, 'val_loss': 0.2520627376886747, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe6680e08e0>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 14, 'learning_rate': 0.04599015617453359, 'n_estimators': 8192}, 'config/early_stopping_rounds': 14, 'config/learning_rate': 0.04599015617453359, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 3.4424171447753906}\n",
      "[flaml.automl.logger: 09-25 12:53:53] {2391} INFO -  at 1289.7s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:53:53] {2218} INFO - iteration 302, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:53:53] {805} INFO - trial 1 config: {'n_estimators': 37, 'num_leaves': 251, 'min_child_samples': 8, 'learning_rate': 0.19016888402986543, 'log_max_bin': 9, 'colsample_bytree': 0.8090781061355357, 'reg_alpha': 0.0016487485010271022, 'reg_lambda': 0.14940597830281235}\n",
      "[flaml.tune.tune: 09-25 12:53:54] {197} INFO - result: {'pred_time': 1.1647589745074988e-05, 'wall_clock_time': 1290.945315361023, 'metric_for_logging': {'pred_time': 1.1647589745074988e-05}, 'val_loss': 0.2090964912554118, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340bc940>, 'training_iteration': 0, 'config': {'n_estimators': 37, 'num_leaves': 251, 'min_child_samples': 8, 'learning_rate': 0.19016888402986543, 'log_max_bin': 9, 'colsample_bytree': 0.8090781061355357, 'reg_alpha': 0.0016487485010271022, 'reg_lambda': 0.14940597830281235}, 'config/n_estimators': 37, 'config/num_leaves': 251, 'config/min_child_samples': 8, 'config/learning_rate': 0.19016888402986543, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8090781061355357, 'config/reg_alpha': 0.0016487485010271022, 'config/reg_lambda': 0.14940597830281235, 'experiment_tag': 'exp', 'time_total_s': 1.1901681423187256}\n",
      "[flaml.tune.tune: 09-25 12:53:54] {197} INFO - result: {'pred_time': 1.1647589745074988e-05, 'wall_clock_time': 1290.945315361023, 'metric_for_logging': {'pred_time': 1.1647589745074988e-05}, 'val_loss': 0.2090964912554118, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340bc940>, 'training_iteration': 1, 'config': {'n_estimators': 37, 'num_leaves': 251, 'min_child_samples': 8, 'learning_rate': 0.19016888402986543, 'log_max_bin': 9, 'colsample_bytree': 0.8090781061355357, 'reg_alpha': 0.0016487485010271022, 'reg_lambda': 0.14940597830281235}, 'config/n_estimators': 37, 'config/num_leaves': 251, 'config/min_child_samples': 8, 'config/learning_rate': 0.19016888402986543, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8090781061355357, 'config/reg_alpha': 0.0016487485010271022, 'config/reg_lambda': 0.14940597830281235, 'experiment_tag': 'exp', 'time_total_s': 1.1914699077606201}\n",
      "[flaml.automl.logger: 09-25 12:53:54] {2391} INFO -  at 1290.9s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:53:54] {2218} INFO - iteration 303, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:53:54] {805} INFO - trial 1 config: {'n_estimators': 34, 'max_leaves': 130, 'min_child_weight': 0.18584058346908996, 'learning_rate': 0.021991228329707402, 'subsample': 0.8902826694164341, 'colsample_bylevel': 0.25466581761266327, 'colsample_bytree': 0.7351468288149156, 'reg_alpha': 0.002839187489003967, 'reg_lambda': 1.6765636635884984}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:53:58] {197} INFO - result: {'pred_time': 4.6829793411475905e-05, 'wall_clock_time': 1294.836136341095, 'metric_for_logging': {'pred_time': 4.6829793411475905e-05}, 'val_loss': 0.2434599488197689, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5340bcc40>, 'training_iteration': 0, 'config': {'n_estimators': 34, 'max_leaves': 130, 'min_child_weight': 0.18584058346908996, 'learning_rate': 0.021991228329707402, 'subsample': 0.8902826694164341, 'colsample_bylevel': 0.25466581761266327, 'colsample_bytree': 0.7351468288149156, 'reg_alpha': 0.002839187489003967, 'reg_lambda': 1.6765636635884984}, 'config/n_estimators': 34, 'config/max_leaves': 130, 'config/min_child_weight': 0.18584058346908996, 'config/learning_rate': 0.021991228329707402, 'config/subsample': 0.8902826694164341, 'config/colsample_bylevel': 0.25466581761266327, 'config/colsample_bytree': 0.7351468288149156, 'config/reg_alpha': 0.002839187489003967, 'config/reg_lambda': 1.6765636635884984, 'experiment_tag': 'exp', 'time_total_s': 3.8848395347595215}\n",
      "[flaml.tune.tune: 09-25 12:53:58] {197} INFO - result: {'pred_time': 4.6829793411475905e-05, 'wall_clock_time': 1294.836136341095, 'metric_for_logging': {'pred_time': 4.6829793411475905e-05}, 'val_loss': 0.2434599488197689, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5340bcc40>, 'training_iteration': 1, 'config': {'n_estimators': 34, 'max_leaves': 130, 'min_child_weight': 0.18584058346908996, 'learning_rate': 0.021991228329707402, 'subsample': 0.8902826694164341, 'colsample_bylevel': 0.25466581761266327, 'colsample_bytree': 0.7351468288149156, 'reg_alpha': 0.002839187489003967, 'reg_lambda': 1.6765636635884984}, 'config/n_estimators': 34, 'config/max_leaves': 130, 'config/min_child_weight': 0.18584058346908996, 'config/learning_rate': 0.021991228329707402, 'config/subsample': 0.8902826694164341, 'config/colsample_bylevel': 0.25466581761266327, 'config/colsample_bytree': 0.7351468288149156, 'config/reg_alpha': 0.002839187489003967, 'config/reg_lambda': 1.6765636635884984, 'experiment_tag': 'exp', 'time_total_s': 3.8870081901550293}\n",
      "[flaml.automl.logger: 09-25 12:53:58] {2391} INFO -  at 1294.8s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:53:58] {2218} INFO - iteration 304, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:53:58] {805} INFO - trial 1 config: {'n_estimators': 68, 'num_leaves': 114, 'min_child_samples': 9, 'learning_rate': 0.1614211089048535, 'log_max_bin': 9, 'colsample_bytree': 0.5476061907122303, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.711834188094637}\n",
      "[flaml.tune.tune: 09-25 12:54:00] {197} INFO - result: {'pred_time': 1.2569961537654248e-05, 'wall_clock_time': 1296.1991293430328, 'metric_for_logging': {'pred_time': 1.2569961537654248e-05}, 'val_loss': 0.2046546200219363, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340bc5e0>, 'training_iteration': 0, 'config': {'n_estimators': 68, 'num_leaves': 114, 'min_child_samples': 9, 'learning_rate': 0.1614211089048535, 'log_max_bin': 9, 'colsample_bytree': 0.5476061907122303, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.711834188094637}, 'config/n_estimators': 68, 'config/num_leaves': 114, 'config/min_child_samples': 9, 'config/learning_rate': 0.1614211089048535, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.5476061907122303, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.711834188094637, 'experiment_tag': 'exp', 'time_total_s': 1.3546357154846191}\n",
      "[flaml.tune.tune: 09-25 12:54:00] {197} INFO - result: {'pred_time': 1.2569961537654248e-05, 'wall_clock_time': 1296.1991293430328, 'metric_for_logging': {'pred_time': 1.2569961537654248e-05}, 'val_loss': 0.2046546200219363, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340bc5e0>, 'training_iteration': 1, 'config': {'n_estimators': 68, 'num_leaves': 114, 'min_child_samples': 9, 'learning_rate': 0.1614211089048535, 'log_max_bin': 9, 'colsample_bytree': 0.5476061907122303, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.711834188094637}, 'config/n_estimators': 68, 'config/num_leaves': 114, 'config/min_child_samples': 9, 'config/learning_rate': 0.1614211089048535, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.5476061907122303, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.711834188094637, 'experiment_tag': 'exp', 'time_total_s': 1.356053113937378}\n",
      "[flaml.automl.logger: 09-25 12:54:00] {2391} INFO -  at 1296.2s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:54:00] {2218} INFO - iteration 305, current learner lrl1\n",
      "[flaml.tune.tune: 09-25 12:54:00] {805} INFO - trial 1 config: {'C': 0.24999999999999997}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:54:24] {197} INFO - result: {'pred_time': 1.2046167129948791e-05, 'wall_clock_time': 1320.8948457241058, 'metric_for_logging': {'pred_time': 1.2046167129948791e-05}, 'val_loss': 0.25334639939212655, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe6681b3eb0>, 'training_iteration': 0, 'config': {'C': 0.24999999999999997}, 'config/C': 0.24999999999999997, 'experiment_tag': 'exp', 'time_total_s': 24.688985109329224}\n",
      "[flaml.tune.tune: 09-25 12:54:24] {197} INFO - result: {'pred_time': 1.2046167129948791e-05, 'wall_clock_time': 1320.8948457241058, 'metric_for_logging': {'pred_time': 1.2046167129948791e-05}, 'val_loss': 0.25334639939212655, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe6681b3eb0>, 'training_iteration': 1, 'config': {'C': 0.24999999999999997}, 'config/C': 0.24999999999999997, 'experiment_tag': 'exp', 'time_total_s': 24.693825244903564}\n",
      "[flaml.automl.logger: 09-25 12:54:24] {2391} INFO -  at 1320.9s,\testimator lrl1's best error=0.2161,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:54:24] {2218} INFO - iteration 306, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:54:24] {805} INFO - trial 1 config: {'n_estimators': 52, 'max_features': 0.04637942239083641, 'max_leaves': 93, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:54:26] {197} INFO - result: {'pred_time': 8.212695028160438e-05, 'wall_clock_time': 1322.6708190441132, 'metric_for_logging': {'pred_time': 8.212695028160438e-05}, 'val_loss': 0.2024367320844082, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6681b3fa0>, 'training_iteration': 0, 'config': {'n_estimators': 52, 'max_features': 0.04637942239083641, 'max_leaves': 93, 'criterion': 'gini'}, 'config/n_estimators': 52, 'config/max_features': 0.04637942239083641, 'config/max_leaves': 93, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.765667200088501}\n",
      "[flaml.tune.tune: 09-25 12:54:26] {197} INFO - result: {'pred_time': 8.212695028160438e-05, 'wall_clock_time': 1322.6708190441132, 'metric_for_logging': {'pred_time': 8.212695028160438e-05}, 'val_loss': 0.2024367320844082, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6681b3fa0>, 'training_iteration': 1, 'config': {'n_estimators': 52, 'max_features': 0.04637942239083641, 'max_leaves': 93, 'criterion': 'gini'}, 'config/n_estimators': 52, 'config/max_features': 0.04637942239083641, 'config/max_leaves': 93, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.7671561241149902}\n",
      "[flaml.automl.logger: 09-25 12:54:26] {2391} INFO -  at 1322.7s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:54:26] {2218} INFO - iteration 307, current learner lrl1\n",
      "[flaml.tune.tune: 09-25 12:54:26] {805} INFO - trial 1 config: {'C': 3.9999999999999987}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:54:52] {197} INFO - result: {'pred_time': 1.2843289386518526e-05, 'wall_clock_time': 1348.2781043052673, 'metric_for_logging': {'pred_time': 1.2843289386518526e-05}, 'val_loss': 0.21588412308052485, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe53408c940>, 'training_iteration': 0, 'config': {'C': 3.9999999999999987}, 'config/C': 3.9999999999999987, 'experiment_tag': 'exp', 'time_total_s': 25.600868701934814}\n",
      "[flaml.tune.tune: 09-25 12:54:52] {197} INFO - result: {'pred_time': 1.2843289386518526e-05, 'wall_clock_time': 1348.2781043052673, 'metric_for_logging': {'pred_time': 1.2843289386518526e-05}, 'val_loss': 0.21588412308052485, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe53408c940>, 'training_iteration': 1, 'config': {'C': 3.9999999999999987}, 'config/C': 3.9999999999999987, 'experiment_tag': 'exp', 'time_total_s': 25.602723121643066}\n",
      "[flaml.automl.logger: 09-25 12:54:52] {2391} INFO -  at 1348.3s,\testimator lrl1's best error=0.2159,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:54:52] {2218} INFO - iteration 308, current learner lrl1\n",
      "[flaml.tune.tune: 09-25 12:54:52] {805} INFO - trial 1 config: {'C': 1.9999999999999998}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:55:17] {197} INFO - result: {'pred_time': 1.207465938833083e-05, 'wall_clock_time': 1373.9027743339539, 'metric_for_logging': {'pred_time': 1.207465938833083e-05}, 'val_loss': 0.21379983085380383, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe6680c7160>, 'training_iteration': 0, 'config': {'C': 1.9999999999999998}, 'config/C': 1.9999999999999998, 'experiment_tag': 'exp', 'time_total_s': 25.616576433181763}\n",
      "[flaml.tune.tune: 09-25 12:55:17] {197} INFO - result: {'pred_time': 1.207465938833083e-05, 'wall_clock_time': 1373.9027743339539, 'metric_for_logging': {'pred_time': 1.207465938833083e-05}, 'val_loss': 0.21379983085380383, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe6680c7160>, 'training_iteration': 1, 'config': {'C': 1.9999999999999998}, 'config/C': 1.9999999999999998, 'experiment_tag': 'exp', 'time_total_s': 25.618149757385254}\n",
      "[flaml.automl.logger: 09-25 12:55:17] {2391} INFO -  at 1373.9s,\testimator lrl1's best error=0.2138,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:55:17] {2218} INFO - iteration 309, current learner lrl1\n",
      "[flaml.tune.tune: 09-25 12:55:17] {805} INFO - trial 1 config: {'C': 1.1843299396935874}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:55:43] {197} INFO - result: {'pred_time': 1.4974166209538086e-05, 'wall_clock_time': 1399.1431677341461, 'metric_for_logging': {'pred_time': 1.4974166209538086e-05}, 'val_loss': 0.2147101258795412, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe6680c73a0>, 'training_iteration': 0, 'config': {'C': 1.1843299396935874}, 'config/C': 1.1843299396935874, 'experiment_tag': 'exp', 'time_total_s': 25.232261657714844}\n",
      "[flaml.tune.tune: 09-25 12:55:43] {197} INFO - result: {'pred_time': 1.4974166209538086e-05, 'wall_clock_time': 1399.1431677341461, 'metric_for_logging': {'pred_time': 1.4974166209538086e-05}, 'val_loss': 0.2147101258795412, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe6680c73a0>, 'training_iteration': 1, 'config': {'C': 1.1843299396935874}, 'config/C': 1.1843299396935874, 'experiment_tag': 'exp', 'time_total_s': 25.233872413635254}\n",
      "[flaml.automl.logger: 09-25 12:55:43] {2391} INFO -  at 1399.1s,\testimator lrl1's best error=0.2138,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:55:43] {2218} INFO - iteration 310, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:55:43] {805} INFO - trial 1 config: {'n_estimators': 103, 'max_depth': 7, 'min_child_weight': 0.010374572410849912, 'learning_rate': 0.18817881309280315, 'subsample': 0.745148534407184, 'colsample_bylevel': 0.2813925785620792, 'colsample_bytree': 0.5674147345180919, 'reg_alpha': 0.041470327673655244, 'reg_lambda': 0.750828561542177}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:55:53] {197} INFO - result: {'pred_time': 4.8291911482018926e-05, 'wall_clock_time': 1409.0806148052216, 'metric_for_logging': {'pred_time': 4.8291911482018926e-05}, 'val_loss': 0.19831596675674631, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe66804bb80>, 'training_iteration': 0, 'config': {'n_estimators': 103, 'max_depth': 7, 'min_child_weight': 0.010374572410849912, 'learning_rate': 0.18817881309280315, 'subsample': 0.745148534407184, 'colsample_bylevel': 0.2813925785620792, 'colsample_bytree': 0.5674147345180919, 'reg_alpha': 0.041470327673655244, 'reg_lambda': 0.750828561542177}, 'config/n_estimators': 103, 'config/max_depth': 7, 'config/min_child_weight': 0.010374572410849912, 'config/learning_rate': 0.18817881309280315, 'config/subsample': 0.745148534407184, 'config/colsample_bylevel': 0.2813925785620792, 'config/colsample_bytree': 0.5674147345180919, 'config/reg_alpha': 0.041470327673655244, 'config/reg_lambda': 0.750828561542177, 'experiment_tag': 'exp', 'time_total_s': 9.925298690795898}\n",
      "[flaml.tune.tune: 09-25 12:55:53] {197} INFO - result: {'pred_time': 4.8291911482018926e-05, 'wall_clock_time': 1409.0806148052216, 'metric_for_logging': {'pred_time': 4.8291911482018926e-05}, 'val_loss': 0.19831596675674631, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe66804bb80>, 'training_iteration': 1, 'config': {'n_estimators': 103, 'max_depth': 7, 'min_child_weight': 0.010374572410849912, 'learning_rate': 0.18817881309280315, 'subsample': 0.745148534407184, 'colsample_bylevel': 0.2813925785620792, 'colsample_bytree': 0.5674147345180919, 'reg_alpha': 0.041470327673655244, 'reg_lambda': 0.750828561542177}, 'config/n_estimators': 103, 'config/max_depth': 7, 'config/min_child_weight': 0.010374572410849912, 'config/learning_rate': 0.18817881309280315, 'config/subsample': 0.745148534407184, 'config/colsample_bylevel': 0.2813925785620792, 'config/colsample_bytree': 0.5674147345180919, 'config/reg_alpha': 0.041470327673655244, 'config/reg_lambda': 0.750828561542177, 'experiment_tag': 'exp', 'time_total_s': 9.926966190338135}\n",
      "[flaml.automl.logger: 09-25 12:55:53] {2391} INFO -  at 1409.1s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:55:53] {2218} INFO - iteration 311, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:55:53] {805} INFO - trial 1 config: {'n_estimators': 95, 'max_features': 0.032427221756276076, 'max_leaves': 171, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:55:55] {197} INFO - result: {'pred_time': 0.00013664675442611536, 'wall_clock_time': 1411.9556503295898, 'metric_for_logging': {'pred_time': 0.00013664675442611536}, 'val_loss': 0.19169327325249358, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe66804b190>, 'training_iteration': 0, 'config': {'n_estimators': 95, 'max_features': 0.032427221756276076, 'max_leaves': 171, 'criterion': 'entropy'}, 'config/n_estimators': 95, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 171, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.867340564727783}\n",
      "[flaml.tune.tune: 09-25 12:55:55] {197} INFO - result: {'pred_time': 0.00013664675442611536, 'wall_clock_time': 1411.9556503295898, 'metric_for_logging': {'pred_time': 0.00013664675442611536}, 'val_loss': 0.19169327325249358, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe66804b190>, 'training_iteration': 1, 'config': {'n_estimators': 95, 'max_features': 0.032427221756276076, 'max_leaves': 171, 'criterion': 'entropy'}, 'config/n_estimators': 95, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 171, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.868751287460327}\n",
      "[flaml.automl.logger: 09-25 12:55:55] {2391} INFO -  at 1412.0s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:55:55] {2218} INFO - iteration 312, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:55:55] {805} INFO - trial 1 config: {'n_estimators': 82, 'max_features': 0.05369679766082354, 'max_leaves': 147, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:55:58] {197} INFO - result: {'pred_time': 0.00013085559419402765, 'wall_clock_time': 1414.5897336006165, 'metric_for_logging': {'pred_time': 0.00013085559419402765}, 'val_loss': 0.19716587478956293, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe524317880>, 'training_iteration': 0, 'config': {'n_estimators': 82, 'max_features': 0.05369679766082354, 'max_leaves': 147, 'criterion': 'entropy'}, 'config/n_estimators': 82, 'config/max_features': 0.05369679766082354, 'config/max_leaves': 147, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.627941608428955}\n",
      "[flaml.tune.tune: 09-25 12:55:58] {197} INFO - result: {'pred_time': 0.00013085559419402765, 'wall_clock_time': 1414.5897336006165, 'metric_for_logging': {'pred_time': 0.00013085559419402765}, 'val_loss': 0.19716587478956293, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe524317880>, 'training_iteration': 1, 'config': {'n_estimators': 82, 'max_features': 0.05369679766082354, 'max_leaves': 147, 'criterion': 'entropy'}, 'config/n_estimators': 82, 'config/max_features': 0.05369679766082354, 'config/max_leaves': 147, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.629425525665283}\n",
      "[flaml.automl.logger: 09-25 12:55:58] {2391} INFO -  at 1414.6s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:55:58] {2218} INFO - iteration 313, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:55:58] {805} INFO - trial 1 config: {'n_estimators': 93, 'max_leaves': 377, 'min_child_weight': 0.038581823962540694, 'learning_rate': 0.0422483696170599, 'subsample': 0.7786134771134025, 'colsample_bylevel': 0.3797042768892083, 'colsample_bytree': 0.7198939225509953, 'reg_alpha': 0.007264415841269545, 'reg_lambda': 2.719456729889843}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:56:09] {197} INFO - result: {'pred_time': 5.001948145355572e-05, 'wall_clock_time': 1425.8441936969757, 'metric_for_logging': {'pred_time': 5.001948145355572e-05}, 'val_loss': 0.19565184923130954, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6681b3fa0>, 'training_iteration': 0, 'config': {'n_estimators': 93, 'max_leaves': 377, 'min_child_weight': 0.038581823962540694, 'learning_rate': 0.0422483696170599, 'subsample': 0.7786134771134025, 'colsample_bylevel': 0.3797042768892083, 'colsample_bytree': 0.7198939225509953, 'reg_alpha': 0.007264415841269545, 'reg_lambda': 2.719456729889843}, 'config/n_estimators': 93, 'config/max_leaves': 377, 'config/min_child_weight': 0.038581823962540694, 'config/learning_rate': 0.0422483696170599, 'config/subsample': 0.7786134771134025, 'config/colsample_bylevel': 0.3797042768892083, 'config/colsample_bytree': 0.7198939225509953, 'config/reg_alpha': 0.007264415841269545, 'config/reg_lambda': 2.719456729889843, 'experiment_tag': 'exp', 'time_total_s': 11.246970415115356}\n",
      "[flaml.tune.tune: 09-25 12:56:09] {197} INFO - result: {'pred_time': 5.001948145355572e-05, 'wall_clock_time': 1425.8441936969757, 'metric_for_logging': {'pred_time': 5.001948145355572e-05}, 'val_loss': 0.19565184923130954, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6681b3fa0>, 'training_iteration': 1, 'config': {'n_estimators': 93, 'max_leaves': 377, 'min_child_weight': 0.038581823962540694, 'learning_rate': 0.0422483696170599, 'subsample': 0.7786134771134025, 'colsample_bylevel': 0.3797042768892083, 'colsample_bytree': 0.7198939225509953, 'reg_alpha': 0.007264415841269545, 'reg_lambda': 2.719456729889843}, 'config/n_estimators': 93, 'config/max_leaves': 377, 'config/min_child_weight': 0.038581823962540694, 'config/learning_rate': 0.0422483696170599, 'config/subsample': 0.7786134771134025, 'config/colsample_bylevel': 0.3797042768892083, 'config/colsample_bytree': 0.7198939225509953, 'config/reg_alpha': 0.007264415841269545, 'config/reg_lambda': 2.719456729889843, 'experiment_tag': 'exp', 'time_total_s': 11.248460531234741}\n",
      "[flaml.automl.logger: 09-25 12:56:09] {2391} INFO -  at 1425.8s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:56:09] {2218} INFO - iteration 314, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:56:09] {805} INFO - trial 1 config: {'n_estimators': 36, 'max_features': 0.04507906172954978, 'max_leaves': 171, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:56:11] {197} INFO - result: {'pred_time': 6.316118620797572e-05, 'wall_clock_time': 1427.2032871246338, 'metric_for_logging': {'pred_time': 6.316118620797572e-05}, 'val_loss': 0.21515816502698062, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680e4280>, 'training_iteration': 0, 'config': {'n_estimators': 36, 'max_features': 0.04507906172954978, 'max_leaves': 171, 'criterion': 'gini'}, 'config/n_estimators': 36, 'config/max_features': 0.04507906172954978, 'config/max_leaves': 171, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.3527827262878418}\n",
      "[flaml.tune.tune: 09-25 12:56:11] {197} INFO - result: {'pred_time': 6.316118620797572e-05, 'wall_clock_time': 1427.2032871246338, 'metric_for_logging': {'pred_time': 6.316118620797572e-05}, 'val_loss': 0.21515816502698062, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680e4280>, 'training_iteration': 1, 'config': {'n_estimators': 36, 'max_features': 0.04507906172954978, 'max_leaves': 171, 'criterion': 'gini'}, 'config/n_estimators': 36, 'config/max_features': 0.04507906172954978, 'config/max_leaves': 171, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.3541462421417236}\n",
      "[flaml.automl.logger: 09-25 12:56:11] {2391} INFO -  at 1427.2s,\testimator rf's best error=0.1889,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:56:11] {2218} INFO - iteration 315, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:56:11] {805} INFO - trial 1 config: {'n_estimators': 125, 'max_depth': 9, 'min_child_weight': 0.06330193384242062, 'learning_rate': 0.0847990303666923, 'subsample': 0.8563468351322605, 'colsample_bylevel': 0.13545315162555974, 'colsample_bytree': 0.4503919425056159, 'reg_alpha': 0.018181834787284544, 'reg_lambda': 28.158399551053552}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:56:20] {197} INFO - result: {'pred_time': 4.8015825277953906e-05, 'wall_clock_time': 1436.39462184906, 'metric_for_logging': {'pred_time': 4.8015825277953906e-05}, 'val_loss': 0.21846070208139173, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe52414a640>, 'training_iteration': 0, 'config': {'n_estimators': 125, 'max_depth': 9, 'min_child_weight': 0.06330193384242062, 'learning_rate': 0.0847990303666923, 'subsample': 0.8563468351322605, 'colsample_bylevel': 0.13545315162555974, 'colsample_bytree': 0.4503919425056159, 'reg_alpha': 0.018181834787284544, 'reg_lambda': 28.158399551053552}, 'config/n_estimators': 125, 'config/max_depth': 9, 'config/min_child_weight': 0.06330193384242062, 'config/learning_rate': 0.0847990303666923, 'config/subsample': 0.8563468351322605, 'config/colsample_bylevel': 0.13545315162555974, 'config/colsample_bytree': 0.4503919425056159, 'config/reg_alpha': 0.018181834787284544, 'config/reg_lambda': 28.158399551053552, 'experiment_tag': 'exp', 'time_total_s': 9.183965682983398}\n",
      "[flaml.tune.tune: 09-25 12:56:20] {197} INFO - result: {'pred_time': 4.8015825277953906e-05, 'wall_clock_time': 1436.39462184906, 'metric_for_logging': {'pred_time': 4.8015825277953906e-05}, 'val_loss': 0.21846070208139173, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe52414a640>, 'training_iteration': 1, 'config': {'n_estimators': 125, 'max_depth': 9, 'min_child_weight': 0.06330193384242062, 'learning_rate': 0.0847990303666923, 'subsample': 0.8563468351322605, 'colsample_bylevel': 0.13545315162555974, 'colsample_bytree': 0.4503919425056159, 'reg_alpha': 0.018181834787284544, 'reg_lambda': 28.158399551053552}, 'config/n_estimators': 125, 'config/max_depth': 9, 'config/min_child_weight': 0.06330193384242062, 'config/learning_rate': 0.0847990303666923, 'config/subsample': 0.8563468351322605, 'config/colsample_bylevel': 0.13545315162555974, 'config/colsample_bytree': 0.4503919425056159, 'config/reg_alpha': 0.018181834787284544, 'config/reg_lambda': 28.158399551053552, 'experiment_tag': 'exp', 'time_total_s': 9.185412406921387}\n",
      "[flaml.automl.logger: 09-25 12:56:20] {2391} INFO -  at 1436.4s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:56:20] {2218} INFO - iteration 316, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:56:20] {805} INFO - trial 1 config: {'early_stopping_rounds': 12, 'learning_rate': 0.03784127891489518, 'n_estimators': 8192}\n",
      "[flaml.tune.tune: 09-25 12:56:26] {197} INFO - result: {'pred_time': 8.16697971739576e-05, 'wall_clock_time': 1442.370859861374, 'metric_for_logging': {'pred_time': 8.16697971739576e-05}, 'val_loss': 0.24750101993355367, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340bcd90>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.03784127891489518, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.03784127891489518, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.969739198684692}\n",
      "[flaml.tune.tune: 09-25 12:56:26] {197} INFO - result: {'pred_time': 8.16697971739576e-05, 'wall_clock_time': 1442.370859861374, 'metric_for_logging': {'pred_time': 8.16697971739576e-05}, 'val_loss': 0.24750101993355367, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe5340bcd90>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.03784127891489518, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.03784127891489518, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 5.971606731414795}\n",
      "[flaml.automl.logger: 09-25 12:56:26] {2391} INFO -  at 1442.4s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:56:26] {2218} INFO - iteration 317, current learner lrl1\n",
      "[flaml.tune.tune: 09-25 12:56:26] {805} INFO - trial 1 config: {'C': 3.377437203888376}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:56:52] {197} INFO - result: {'pred_time': 1.2290488328705053e-05, 'wall_clock_time': 1468.1501371860504, 'metric_for_logging': {'pred_time': 1.2290488328705053e-05}, 'val_loss': 0.2157121110269536, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe534095430>, 'training_iteration': 0, 'config': {'C': 3.377437203888376}, 'config/C': 3.377437203888376, 'experiment_tag': 'exp', 'time_total_s': 25.7725670337677}\n",
      "[flaml.tune.tune: 09-25 12:56:52] {197} INFO - result: {'pred_time': 1.2290488328705053e-05, 'wall_clock_time': 1468.1501371860504, 'metric_for_logging': {'pred_time': 1.2290488328705053e-05}, 'val_loss': 0.2157121110269536, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe534095430>, 'training_iteration': 1, 'config': {'C': 3.377437203888376}, 'config/C': 3.377437203888376, 'experiment_tag': 'exp', 'time_total_s': 25.77395725250244}\n",
      "[flaml.automl.logger: 09-25 12:56:52] {2391} INFO -  at 1468.2s,\testimator lrl1's best error=0.2138,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:56:52] {2218} INFO - iteration 318, current learner lrl1\n",
      "[flaml.tune.tune: 09-25 12:56:52] {805} INFO - trial 1 config: {'C': 3.1748021039363983}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:57:18] {197} INFO - result: {'pred_time': 1.221689216432612e-05, 'wall_clock_time': 1494.2873122692108, 'metric_for_logging': {'pred_time': 1.221689216432612e-05}, 'val_loss': 0.21532567049808432, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe534095430>, 'training_iteration': 0, 'config': {'C': 3.1748021039363983}, 'config/C': 3.1748021039363983, 'experiment_tag': 'exp', 'time_total_s': 26.129444122314453}\n",
      "[flaml.tune.tune: 09-25 12:57:18] {197} INFO - result: {'pred_time': 1.221689216432612e-05, 'wall_clock_time': 1494.2873122692108, 'metric_for_logging': {'pred_time': 1.221689216432612e-05}, 'val_loss': 0.21532567049808432, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe534095430>, 'training_iteration': 1, 'config': {'C': 3.1748021039363983}, 'config/C': 3.1748021039363983, 'experiment_tag': 'exp', 'time_total_s': 26.1312415599823}\n",
      "[flaml.automl.logger: 09-25 12:57:18] {2391} INFO -  at 1494.3s,\testimator lrl1's best error=0.2138,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:57:18] {2218} INFO - iteration 319, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:57:18] {805} INFO - trial 1 config: {'n_estimators': 136, 'max_features': 0.032427221756276076, 'max_leaves': 93, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:57:22] {197} INFO - result: {'pred_time': 0.00018784141850510937, 'wall_clock_time': 1498.4669346809387, 'metric_for_logging': {'pred_time': 0.00018784141850510937}, 'val_loss': 0.18872863464317738, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe534080640>, 'training_iteration': 0, 'config': {'n_estimators': 136, 'max_features': 0.032427221756276076, 'max_leaves': 93, 'criterion': 'entropy'}, 'config/n_estimators': 136, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 93, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 4.1734819412231445}\n",
      "[flaml.tune.tune: 09-25 12:57:22] {197} INFO - result: {'pred_time': 0.00018784141850510937, 'wall_clock_time': 1498.4669346809387, 'metric_for_logging': {'pred_time': 0.00018784141850510937}, 'val_loss': 0.18872863464317738, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe534080640>, 'training_iteration': 1, 'config': {'n_estimators': 136, 'max_features': 0.032427221756276076, 'max_leaves': 93, 'criterion': 'entropy'}, 'config/n_estimators': 136, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 93, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 4.174969434738159}\n",
      "[flaml.automl.logger: 09-25 12:57:22] {2391} INFO -  at 1498.5s,\testimator rf's best error=0.1887,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:57:22] {2218} INFO - iteration 320, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:57:22] {805} INFO - trial 1 config: {'n_estimators': 119, 'num_leaves': 43, 'min_child_samples': 5, 'learning_rate': 0.2595040243133507, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0022016336816518957, 'reg_lambda': 0.30471804323750823}\n",
      "[flaml.tune.tune: 09-25 12:57:24] {197} INFO - result: {'pred_time': 1.4055005832209116e-05, 'wall_clock_time': 1500.1418771743774, 'metric_for_logging': {'pred_time': 1.4055005832209116e-05}, 'val_loss': 0.21317528172850508, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680b9070>, 'training_iteration': 0, 'config': {'n_estimators': 119, 'num_leaves': 43, 'min_child_samples': 5, 'learning_rate': 0.2595040243133507, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0022016336816518957, 'reg_lambda': 0.30471804323750823}, 'config/n_estimators': 119, 'config/num_leaves': 43, 'config/min_child_samples': 5, 'config/learning_rate': 0.2595040243133507, 'config/log_max_bin': 9, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0022016336816518957, 'config/reg_lambda': 0.30471804323750823, 'experiment_tag': 'exp', 'time_total_s': 1.6684081554412842}\n",
      "[flaml.tune.tune: 09-25 12:57:24] {197} INFO - result: {'pred_time': 1.4055005832209116e-05, 'wall_clock_time': 1500.1418771743774, 'metric_for_logging': {'pred_time': 1.4055005832209116e-05}, 'val_loss': 0.21317528172850508, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe6680b9070>, 'training_iteration': 1, 'config': {'n_estimators': 119, 'num_leaves': 43, 'min_child_samples': 5, 'learning_rate': 0.2595040243133507, 'log_max_bin': 9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0022016336816518957, 'reg_lambda': 0.30471804323750823}, 'config/n_estimators': 119, 'config/num_leaves': 43, 'config/min_child_samples': 5, 'config/learning_rate': 0.2595040243133507, 'config/log_max_bin': 9, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0022016336816518957, 'config/reg_lambda': 0.30471804323750823, 'experiment_tag': 'exp', 'time_total_s': 1.6701476573944092}\n",
      "[flaml.automl.logger: 09-25 12:57:24] {2391} INFO -  at 1500.1s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:57:24] {2218} INFO - iteration 321, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:57:24] {805} INFO - trial 1 config: {'n_estimators': 318, 'max_features': 0.03495323586325951, 'max_leaves': 80, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:57:32] {197} INFO - result: {'pred_time': 0.00039966093982199066, 'wall_clock_time': 1508.8605771064758, 'metric_for_logging': {'pred_time': 0.00039966093982199066}, 'val_loss': 0.189840119787646, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680e0670>, 'training_iteration': 0, 'config': {'n_estimators': 318, 'max_features': 0.03495323586325951, 'max_leaves': 80, 'criterion': 'entropy'}, 'config/n_estimators': 318, 'config/max_features': 0.03495323586325951, 'config/max_leaves': 80, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 8.711770296096802}\n",
      "[flaml.tune.tune: 09-25 12:57:32] {197} INFO - result: {'pred_time': 0.00039966093982199066, 'wall_clock_time': 1508.8605771064758, 'metric_for_logging': {'pred_time': 0.00039966093982199066}, 'val_loss': 0.189840119787646, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680e0670>, 'training_iteration': 1, 'config': {'n_estimators': 318, 'max_features': 0.03495323586325951, 'max_leaves': 80, 'criterion': 'entropy'}, 'config/n_estimators': 318, 'config/max_features': 0.03495323586325951, 'config/max_leaves': 80, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 8.71288275718689}\n",
      "[flaml.automl.logger: 09-25 12:57:32] {2391} INFO -  at 1508.9s,\testimator rf's best error=0.1887,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:57:32] {2218} INFO - iteration 322, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:57:32] {805} INFO - trial 1 config: {'n_estimators': 208, 'max_leaves': 49, 'min_child_weight': 1.901304685350308, 'learning_rate': 0.05546839253750881, 'subsample': 0.8760892399222936, 'colsample_bylevel': 0.3296699986502223, 'colsample_bytree': 0.5313664836397782, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6832287669652973}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:57:54] {197} INFO - result: {'pred_time': 5.150344819489182e-05, 'wall_clock_time': 1530.4318866729736, 'metric_for_logging': {'pred_time': 5.150344819489182e-05}, 'val_loss': 0.20605800703251975, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe524290fa0>, 'training_iteration': 0, 'config': {'n_estimators': 208, 'max_leaves': 49, 'min_child_weight': 1.901304685350308, 'learning_rate': 0.05546839253750881, 'subsample': 0.8760892399222936, 'colsample_bylevel': 0.3296699986502223, 'colsample_bytree': 0.5313664836397782, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6832287669652973}, 'config/n_estimators': 208, 'config/max_leaves': 49, 'config/min_child_weight': 1.901304685350308, 'config/learning_rate': 0.05546839253750881, 'config/subsample': 0.8760892399222936, 'config/colsample_bylevel': 0.3296699986502223, 'config/colsample_bytree': 0.5313664836397782, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.6832287669652973, 'experiment_tag': 'exp', 'time_total_s': 21.565494775772095}\n",
      "[flaml.tune.tune: 09-25 12:57:54] {197} INFO - result: {'pred_time': 5.150344819489182e-05, 'wall_clock_time': 1530.4318866729736, 'metric_for_logging': {'pred_time': 5.150344819489182e-05}, 'val_loss': 0.20605800703251975, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe524290fa0>, 'training_iteration': 1, 'config': {'n_estimators': 208, 'max_leaves': 49, 'min_child_weight': 1.901304685350308, 'learning_rate': 0.05546839253750881, 'subsample': 0.8760892399222936, 'colsample_bylevel': 0.3296699986502223, 'colsample_bytree': 0.5313664836397782, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6832287669652973}, 'config/n_estimators': 208, 'config/max_leaves': 49, 'config/min_child_weight': 1.901304685350308, 'config/learning_rate': 0.05546839253750881, 'config/subsample': 0.8760892399222936, 'config/colsample_bylevel': 0.3296699986502223, 'config/colsample_bytree': 0.5313664836397782, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.6832287669652973, 'experiment_tag': 'exp', 'time_total_s': 21.566941499710083}\n",
      "[flaml.automl.logger: 09-25 12:57:54] {2391} INFO -  at 1530.4s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:57:54] {2218} INFO - iteration 323, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:57:54] {805} INFO - trial 1 config: {'n_estimators': 47, 'max_depth': 9, 'min_child_weight': 0.0036303177004092008, 'learning_rate': 0.2547605279588726, 'subsample': 0.7468753647886275, 'colsample_bylevel': 0.1632790344462224, 'colsample_bytree': 0.7085067484380181, 'reg_alpha': 0.002111637856358282, 'reg_lambda': 0.13840640220561004}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:57:59] {197} INFO - result: {'pred_time': 4.5862051049421054e-05, 'wall_clock_time': 1535.3427338600159, 'metric_for_logging': {'pred_time': 4.5862051049421054e-05}, 'val_loss': 0.2093657779564826, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524290d30>, 'training_iteration': 0, 'config': {'n_estimators': 47, 'max_depth': 9, 'min_child_weight': 0.0036303177004092008, 'learning_rate': 0.2547605279588726, 'subsample': 0.7468753647886275, 'colsample_bylevel': 0.1632790344462224, 'colsample_bytree': 0.7085067484380181, 'reg_alpha': 0.002111637856358282, 'reg_lambda': 0.13840640220561004}, 'config/n_estimators': 47, 'config/max_depth': 9, 'config/min_child_weight': 0.0036303177004092008, 'config/learning_rate': 0.2547605279588726, 'config/subsample': 0.7468753647886275, 'config/colsample_bylevel': 0.1632790344462224, 'config/colsample_bytree': 0.7085067484380181, 'config/reg_alpha': 0.002111637856358282, 'config/reg_lambda': 0.13840640220561004, 'experiment_tag': 'exp', 'time_total_s': 4.904147386550903}\n",
      "[flaml.tune.tune: 09-25 12:57:59] {197} INFO - result: {'pred_time': 4.5862051049421054e-05, 'wall_clock_time': 1535.3427338600159, 'metric_for_logging': {'pred_time': 4.5862051049421054e-05}, 'val_loss': 0.2093657779564826, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524290d30>, 'training_iteration': 1, 'config': {'n_estimators': 47, 'max_depth': 9, 'min_child_weight': 0.0036303177004092008, 'learning_rate': 0.2547605279588726, 'subsample': 0.7468753647886275, 'colsample_bylevel': 0.1632790344462224, 'colsample_bytree': 0.7085067484380181, 'reg_alpha': 0.002111637856358282, 'reg_lambda': 0.13840640220561004}, 'config/n_estimators': 47, 'config/max_depth': 9, 'config/min_child_weight': 0.0036303177004092008, 'config/learning_rate': 0.2547605279588726, 'config/subsample': 0.7468753647886275, 'config/colsample_bylevel': 0.1632790344462224, 'config/colsample_bytree': 0.7085067484380181, 'config/reg_alpha': 0.002111637856358282, 'config/reg_lambda': 0.13840640220561004, 'experiment_tag': 'exp', 'time_total_s': 4.905777454376221}\n",
      "[flaml.automl.logger: 09-25 12:57:59] {2391} INFO -  at 1535.3s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:57:59] {2218} INFO - iteration 324, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:57:59] {805} INFO - trial 1 config: {'n_estimators': 58, 'max_features': 0.032427221756276076, 'max_leaves': 108, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:58:01] {197} INFO - result: {'pred_time': 9.132862067049038e-05, 'wall_clock_time': 1537.2942185401917, 'metric_for_logging': {'pred_time': 9.132862067049038e-05}, 'val_loss': 0.19979425134972364, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524290460>, 'training_iteration': 0, 'config': {'n_estimators': 58, 'max_features': 0.032427221756276076, 'max_leaves': 108, 'criterion': 'gini'}, 'config/n_estimators': 58, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 108, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.9442448616027832}\n",
      "[flaml.tune.tune: 09-25 12:58:01] {197} INFO - result: {'pred_time': 9.132862067049038e-05, 'wall_clock_time': 1537.2942185401917, 'metric_for_logging': {'pred_time': 9.132862067049038e-05}, 'val_loss': 0.19979425134972364, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524290460>, 'training_iteration': 1, 'config': {'n_estimators': 58, 'max_features': 0.032427221756276076, 'max_leaves': 108, 'criterion': 'gini'}, 'config/n_estimators': 58, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 108, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.9460179805755615}\n",
      "[flaml.automl.logger: 09-25 12:58:01] {2391} INFO -  at 1537.3s,\testimator rf's best error=0.1887,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:58:01] {2218} INFO - iteration 325, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:58:01] {805} INFO - trial 1 config: {'n_estimators': 75, 'max_features': 0.03341240339134118, 'max_leaves': 51, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:58:03] {197} INFO - result: {'pred_time': 0.00011195454196655859, 'wall_clock_time': 1539.5389511585236, 'metric_for_logging': {'pred_time': 0.00011195454196655859}, 'val_loss': 0.20304689131525713, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680b9160>, 'training_iteration': 0, 'config': {'n_estimators': 75, 'max_features': 0.03341240339134118, 'max_leaves': 51, 'criterion': 'entropy'}, 'config/n_estimators': 75, 'config/max_features': 0.03341240339134118, 'config/max_leaves': 51, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.237037181854248}\n",
      "[flaml.tune.tune: 09-25 12:58:03] {197} INFO - result: {'pred_time': 0.00011195454196655859, 'wall_clock_time': 1539.5389511585236, 'metric_for_logging': {'pred_time': 0.00011195454196655859}, 'val_loss': 0.20304689131525713, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe6680b9160>, 'training_iteration': 1, 'config': {'n_estimators': 75, 'max_features': 0.03341240339134118, 'max_leaves': 51, 'criterion': 'entropy'}, 'config/n_estimators': 75, 'config/max_features': 0.03341240339134118, 'config/max_leaves': 51, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.2382566928863525}\n",
      "[flaml.automl.logger: 09-25 12:58:03] {2391} INFO -  at 1539.5s,\testimator rf's best error=0.1887,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:58:03] {2218} INFO - iteration 326, current learner lrl1\n",
      "[flaml.tune.tune: 09-25 12:58:03] {805} INFO - trial 1 config: {'C': 1.2599210498948732}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:58:28] {197} INFO - result: {'pred_time': 1.2682154815942328e-05, 'wall_clock_time': 1564.9740815162659, 'metric_for_logging': {'pred_time': 1.2682154815942328e-05}, 'val_loss': 0.21423902999989952, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe524283fa0>, 'training_iteration': 0, 'config': {'C': 1.2599210498948732}, 'config/C': 1.2599210498948732, 'experiment_tag': 'exp', 'time_total_s': 25.42868995666504}\n",
      "[flaml.tune.tune: 09-25 12:58:28] {197} INFO - result: {'pred_time': 1.2682154815942328e-05, 'wall_clock_time': 1564.9740815162659, 'metric_for_logging': {'pred_time': 1.2682154815942328e-05}, 'val_loss': 0.21423902999989952, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe524283fa0>, 'training_iteration': 1, 'config': {'C': 1.2599210498948732}, 'config/C': 1.2599210498948732, 'experiment_tag': 'exp', 'time_total_s': 25.430397033691406}\n",
      "[flaml.automl.logger: 09-25 12:58:28] {2391} INFO -  at 1565.0s,\testimator lrl1's best error=0.2138,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:58:28] {2218} INFO - iteration 327, current learner catboost\n",
      "[flaml.tune.tune: 09-25 12:58:28] {805} INFO - trial 1 config: {'early_stopping_rounds': 12, 'learning_rate': 0.03687782199546864, 'n_estimators': 8192}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:58:33] {197} INFO - result: {'pred_time': 0.00013863174268033616, 'wall_clock_time': 1569.528094291687, 'metric_for_logging': {'pred_time': 0.00013863174268033616}, 'val_loss': 0.2469063415277808, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe53409b160>, 'training_iteration': 0, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.03687782199546864, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.03687782199546864, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.540306806564331}\n",
      "[flaml.tune.tune: 09-25 12:58:33] {197} INFO - result: {'pred_time': 0.00013863174268033616, 'wall_clock_time': 1569.528094291687, 'metric_for_logging': {'pred_time': 0.00013863174268033616}, 'val_loss': 0.2469063415277808, 'trained_estimator': <flaml.automl.model.CatBoostEstimator object at 0x7fe53409b160>, 'training_iteration': 1, 'config': {'early_stopping_rounds': 12, 'learning_rate': 0.03687782199546864, 'n_estimators': 8192}, 'config/early_stopping_rounds': 12, 'config/learning_rate': 0.03687782199546864, 'config/n_estimators': 8192, 'experiment_tag': 'exp', 'time_total_s': 4.541568756103516}\n",
      "[flaml.automl.logger: 09-25 12:58:33] {2391} INFO -  at 1569.5s,\testimator catboost's best error=0.2335,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:58:33] {2218} INFO - iteration 328, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:58:33] {805} INFO - trial 1 config: {'n_estimators': 70, 'max_features': 0.04089856929884572, 'max_leaves': 189, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:58:35] {197} INFO - result: {'pred_time': 0.00011122125490111684, 'wall_clock_time': 1571.6341588497162, 'metric_for_logging': {'pred_time': 0.00011122125490111684}, 'val_loss': 0.19823526386494902, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe534062c40>, 'training_iteration': 0, 'config': {'n_estimators': 70, 'max_features': 0.04089856929884572, 'max_leaves': 189, 'criterion': 'entropy'}, 'config/n_estimators': 70, 'config/max_features': 0.04089856929884572, 'config/max_leaves': 189, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.09971284866333}\n",
      "[flaml.tune.tune: 09-25 12:58:35] {197} INFO - result: {'pred_time': 0.00011122125490111684, 'wall_clock_time': 1571.6341588497162, 'metric_for_logging': {'pred_time': 0.00011122125490111684}, 'val_loss': 0.19823526386494902, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe534062c40>, 'training_iteration': 1, 'config': {'n_estimators': 70, 'max_features': 0.04089856929884572, 'max_leaves': 189, 'criterion': 'entropy'}, 'config/n_estimators': 70, 'config/max_features': 0.04089856929884572, 'config/max_leaves': 189, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.1012051105499268}\n",
      "[flaml.automl.logger: 09-25 12:58:35] {2391} INFO -  at 1571.6s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:58:35] {2218} INFO - iteration 329, current learner rf\n",
      "[flaml.tune.tune: 09-25 12:58:35] {805} INFO - trial 1 config: {'n_estimators': 247, 'max_features': 0.032427221756276076, 'max_leaves': 170, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:58:42] {197} INFO - result: {'pred_time': 0.00032695307167025995, 'wall_clock_time': 1578.4846622943878, 'metric_for_logging': {'pred_time': 0.00032695307167025995}, 'val_loss': 0.1888317622200681, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe534076070>, 'training_iteration': 0, 'config': {'n_estimators': 247, 'max_features': 0.032427221756276076, 'max_leaves': 170, 'criterion': 'gini'}, 'config/n_estimators': 247, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 170, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 6.843057870864868}\n",
      "[flaml.tune.tune: 09-25 12:58:42] {197} INFO - result: {'pred_time': 0.00032695307167025995, 'wall_clock_time': 1578.4846622943878, 'metric_for_logging': {'pred_time': 0.00032695307167025995}, 'val_loss': 0.1888317622200681, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe534076070>, 'training_iteration': 1, 'config': {'n_estimators': 247, 'max_features': 0.032427221756276076, 'max_leaves': 170, 'criterion': 'gini'}, 'config/n_estimators': 247, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 170, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 6.844667196273804}\n",
      "[flaml.automl.logger: 09-25 12:58:42] {2391} INFO -  at 1578.5s,\testimator rf's best error=0.1887,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:58:42] {2218} INFO - iteration 330, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:58:42] {805} INFO - trial 1 config: {'n_estimators': 63, 'num_leaves': 22, 'min_child_samples': 10, 'learning_rate': 0.09589244531430785, 'log_max_bin': 10, 'colsample_bytree': 0.7720282213070145, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5888026026452496}\n",
      "[flaml.tune.tune: 09-25 12:58:43] {197} INFO - result: {'pred_time': 1.1880369135156164e-05, 'wall_clock_time': 1579.293072938919, 'metric_for_logging': {'pred_time': 1.1880369135156164e-05}, 'val_loss': 0.2161822501777524, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe534062220>, 'training_iteration': 0, 'config': {'n_estimators': 63, 'num_leaves': 22, 'min_child_samples': 10, 'learning_rate': 0.09589244531430785, 'log_max_bin': 10, 'colsample_bytree': 0.7720282213070145, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5888026026452496}, 'config/n_estimators': 63, 'config/num_leaves': 22, 'config/min_child_samples': 10, 'config/learning_rate': 0.09589244531430785, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7720282213070145, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5888026026452496, 'experiment_tag': 'exp', 'time_total_s': 0.8002631664276123}\n",
      "[flaml.tune.tune: 09-25 12:58:43] {197} INFO - result: {'pred_time': 1.1880369135156164e-05, 'wall_clock_time': 1579.293072938919, 'metric_for_logging': {'pred_time': 1.1880369135156164e-05}, 'val_loss': 0.2161822501777524, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe534062220>, 'training_iteration': 1, 'config': {'n_estimators': 63, 'num_leaves': 22, 'min_child_samples': 10, 'learning_rate': 0.09589244531430785, 'log_max_bin': 10, 'colsample_bytree': 0.7720282213070145, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.5888026026452496}, 'config/n_estimators': 63, 'config/num_leaves': 22, 'config/min_child_samples': 10, 'config/learning_rate': 0.09589244531430785, 'config/log_max_bin': 10, 'config/colsample_bytree': 0.7720282213070145, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.5888026026452496, 'experiment_tag': 'exp', 'time_total_s': 0.8014953136444092}\n",
      "[flaml.automl.logger: 09-25 12:58:43] {2391} INFO -  at 1579.3s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:58:43] {2218} INFO - iteration 331, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:58:43] {805} INFO - trial 1 config: {'n_estimators': 181, 'max_leaves': 141, 'min_child_weight': 0.04214906908091815, 'learning_rate': 0.013430423254764004, 'subsample': 0.8600914058285769, 'colsample_bylevel': 0.2155729958428665, 'colsample_bytree': 0.5464348585114062, 'reg_alpha': 0.0013276370830253815, 'reg_lambda': 0.832212921663087}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:59:00] {197} INFO - result: {'pred_time': 6.018215843465902e-05, 'wall_clock_time': 1596.3857941627502, 'metric_for_logging': {'pred_time': 6.018215843465902e-05}, 'val_loss': 0.18917492483834314, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5340d6f70>, 'training_iteration': 0, 'config': {'n_estimators': 181, 'max_leaves': 141, 'min_child_weight': 0.04214906908091815, 'learning_rate': 0.013430423254764004, 'subsample': 0.8600914058285769, 'colsample_bylevel': 0.2155729958428665, 'colsample_bytree': 0.5464348585114062, 'reg_alpha': 0.0013276370830253815, 'reg_lambda': 0.832212921663087}, 'config/n_estimators': 181, 'config/max_leaves': 141, 'config/min_child_weight': 0.04214906908091815, 'config/learning_rate': 0.013430423254764004, 'config/subsample': 0.8600914058285769, 'config/colsample_bylevel': 0.2155729958428665, 'config/colsample_bytree': 0.5464348585114062, 'config/reg_alpha': 0.0013276370830253815, 'config/reg_lambda': 0.832212921663087, 'experiment_tag': 'exp', 'time_total_s': 17.084566354751587}\n",
      "[flaml.tune.tune: 09-25 12:59:00] {197} INFO - result: {'pred_time': 6.018215843465902e-05, 'wall_clock_time': 1596.3857941627502, 'metric_for_logging': {'pred_time': 6.018215843465902e-05}, 'val_loss': 0.18917492483834314, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5340d6f70>, 'training_iteration': 1, 'config': {'n_estimators': 181, 'max_leaves': 141, 'min_child_weight': 0.04214906908091815, 'learning_rate': 0.013430423254764004, 'subsample': 0.8600914058285769, 'colsample_bylevel': 0.2155729958428665, 'colsample_bytree': 0.5464348585114062, 'reg_alpha': 0.0013276370830253815, 'reg_lambda': 0.832212921663087}, 'config/n_estimators': 181, 'config/max_leaves': 141, 'config/min_child_weight': 0.04214906908091815, 'config/learning_rate': 0.013430423254764004, 'config/subsample': 0.8600914058285769, 'config/colsample_bylevel': 0.2155729958428665, 'config/colsample_bytree': 0.5464348585114062, 'config/reg_alpha': 0.0013276370830253815, 'config/reg_lambda': 0.832212921663087, 'experiment_tag': 'exp', 'time_total_s': 17.085689067840576}\n",
      "[flaml.automl.logger: 09-25 12:59:00] {2391} INFO -  at 1596.4s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:59:00] {2218} INFO - iteration 332, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 12:59:00] {805} INFO - trial 1 config: {'n_estimators': 107, 'max_leaves': 131, 'min_child_weight': 1.740389628262261, 'learning_rate': 0.1744881084933475, 'subsample': 0.7946113112071191, 'colsample_bylevel': 0.4938012796965641, 'colsample_bytree': 0.7048255476793673, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.232615019561441}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 12:59:11] {197} INFO - result: {'pred_time': 4.703979159370789e-05, 'wall_clock_time': 1607.9517385959625, 'metric_for_logging': {'pred_time': 4.703979159370789e-05}, 'val_loss': 0.20891750070910492, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5340d6fa0>, 'training_iteration': 0, 'config': {'n_estimators': 107, 'max_leaves': 131, 'min_child_weight': 1.740389628262261, 'learning_rate': 0.1744881084933475, 'subsample': 0.7946113112071191, 'colsample_bylevel': 0.4938012796965641, 'colsample_bytree': 0.7048255476793673, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.232615019561441}, 'config/n_estimators': 107, 'config/max_leaves': 131, 'config/min_child_weight': 1.740389628262261, 'config/learning_rate': 0.1744881084933475, 'config/subsample': 0.7946113112071191, 'config/colsample_bylevel': 0.4938012796965641, 'config/colsample_bytree': 0.7048255476793673, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.232615019561441, 'experiment_tag': 'exp', 'time_total_s': 11.559337615966797}\n",
      "[flaml.tune.tune: 09-25 12:59:11] {197} INFO - result: {'pred_time': 4.703979159370789e-05, 'wall_clock_time': 1607.9517385959625, 'metric_for_logging': {'pred_time': 4.703979159370789e-05}, 'val_loss': 0.20891750070910492, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5340d6fa0>, 'training_iteration': 1, 'config': {'n_estimators': 107, 'max_leaves': 131, 'min_child_weight': 1.740389628262261, 'learning_rate': 0.1744881084933475, 'subsample': 0.7946113112071191, 'colsample_bylevel': 0.4938012796965641, 'colsample_bytree': 0.7048255476793673, 'reg_alpha': 0.0009765625, 'reg_lambda': 2.232615019561441}, 'config/n_estimators': 107, 'config/max_leaves': 131, 'config/min_child_weight': 1.740389628262261, 'config/learning_rate': 0.1744881084933475, 'config/subsample': 0.7946113112071191, 'config/colsample_bylevel': 0.4938012796965641, 'config/colsample_bytree': 0.7048255476793673, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 2.232615019561441, 'experiment_tag': 'exp', 'time_total_s': 11.560641765594482}\n",
      "[flaml.automl.logger: 09-25 12:59:11] {2391} INFO -  at 1608.0s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:59:11] {2218} INFO - iteration 333, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:59:11] {805} INFO - trial 1 config: {'n_estimators': 129, 'num_leaves': 228, 'min_child_samples': 5, 'learning_rate': 0.43683761773549146, 'log_max_bin': 8, 'colsample_bytree': 0.7779536698950663, 'reg_alpha': 0.004463941456177412, 'reg_lambda': 2.9559973567948745}\n",
      "[flaml.tune.tune: 09-25 12:59:14] {197} INFO - result: {'pred_time': 1.6144237246160468e-05, 'wall_clock_time': 1610.0887441635132, 'metric_for_logging': {'pred_time': 1.6144237246160468e-05}, 'val_loss': 0.20289286230065845, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340d6820>, 'training_iteration': 0, 'config': {'n_estimators': 129, 'num_leaves': 228, 'min_child_samples': 5, 'learning_rate': 0.43683761773549146, 'log_max_bin': 8, 'colsample_bytree': 0.7779536698950663, 'reg_alpha': 0.004463941456177412, 'reg_lambda': 2.9559973567948745}, 'config/n_estimators': 129, 'config/num_leaves': 228, 'config/min_child_samples': 5, 'config/learning_rate': 0.43683761773549146, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7779536698950663, 'config/reg_alpha': 0.004463941456177412, 'config/reg_lambda': 2.9559973567948745, 'experiment_tag': 'exp', 'time_total_s': 2.1296260356903076}\n",
      "[flaml.tune.tune: 09-25 12:59:14] {197} INFO - result: {'pred_time': 1.6144237246160468e-05, 'wall_clock_time': 1610.0887441635132, 'metric_for_logging': {'pred_time': 1.6144237246160468e-05}, 'val_loss': 0.20289286230065845, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe5340d6820>, 'training_iteration': 1, 'config': {'n_estimators': 129, 'num_leaves': 228, 'min_child_samples': 5, 'learning_rate': 0.43683761773549146, 'log_max_bin': 8, 'colsample_bytree': 0.7779536698950663, 'reg_alpha': 0.004463941456177412, 'reg_lambda': 2.9559973567948745}, 'config/n_estimators': 129, 'config/num_leaves': 228, 'config/min_child_samples': 5, 'config/learning_rate': 0.43683761773549146, 'config/log_max_bin': 8, 'config/colsample_bytree': 0.7779536698950663, 'config/reg_alpha': 0.004463941456177412, 'config/reg_lambda': 2.9559973567948745, 'experiment_tag': 'exp', 'time_total_s': 2.131092071533203}\n",
      "[flaml.automl.logger: 09-25 12:59:14] {2391} INFO -  at 1610.1s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:59:14] {2218} INFO - iteration 334, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:59:14] {805} INFO - trial 1 config: {'n_estimators': 307, 'max_features': 0.04790848295583766, 'max_leaves': 307, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:59:23] {197} INFO - result: {'pred_time': 0.0004240472131610801, 'wall_clock_time': 1619.7569375038147, 'metric_for_logging': {'pred_time': 0.0004240472131610801}, 'val_loss': 0.197146177431035, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe534062a60>, 'training_iteration': 0, 'config': {'n_estimators': 307, 'max_features': 0.04790848295583766, 'max_leaves': 307, 'criterion': 'gini'}, 'config/n_estimators': 307, 'config/max_features': 0.04790848295583766, 'config/max_leaves': 307, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 9.66173243522644}\n",
      "[flaml.tune.tune: 09-25 12:59:23] {197} INFO - result: {'pred_time': 0.0004240472131610801, 'wall_clock_time': 1619.7569375038147, 'metric_for_logging': {'pred_time': 0.0004240472131610801}, 'val_loss': 0.197146177431035, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe534062a60>, 'training_iteration': 1, 'config': {'n_estimators': 307, 'max_features': 0.04790848295583766, 'max_leaves': 307, 'criterion': 'gini'}, 'config/n_estimators': 307, 'config/max_features': 0.04790848295583766, 'config/max_leaves': 307, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 9.66311526298523}\n",
      "[flaml.automl.logger: 09-25 12:59:23] {2391} INFO -  at 1619.8s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:59:23] {2218} INFO - iteration 335, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:59:23] {805} INFO - trial 1 config: {'n_estimators': 70, 'max_features': 0.04217619717515389, 'max_leaves': 190, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 12:59:25] {197} INFO - result: {'pred_time': 0.00011247007128429596, 'wall_clock_time': 1621.8940086364746, 'metric_for_logging': {'pred_time': 0.00011247007128429596}, 'val_loss': 0.20705716095521193, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52413aa30>, 'training_iteration': 0, 'config': {'n_estimators': 70, 'max_features': 0.04217619717515389, 'max_leaves': 190, 'criterion': 'entropy'}, 'config/n_estimators': 70, 'config/max_features': 0.04217619717515389, 'config/max_leaves': 190, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.130697011947632}\n",
      "[flaml.tune.tune: 09-25 12:59:25] {197} INFO - result: {'pred_time': 0.00011247007128429596, 'wall_clock_time': 1621.8940086364746, 'metric_for_logging': {'pred_time': 0.00011247007128429596}, 'val_loss': 0.20705716095521193, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe52413aa30>, 'training_iteration': 1, 'config': {'n_estimators': 70, 'max_features': 0.04217619717515389, 'max_leaves': 190, 'criterion': 'entropy'}, 'config/n_estimators': 70, 'config/max_features': 0.04217619717515389, 'config/max_leaves': 190, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.1320717334747314}\n",
      "[flaml.automl.logger: 09-25 12:59:25] {2391} INFO -  at 1621.9s,\testimator extra_tree's best error=0.1923,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:59:25] {2218} INFO - iteration 336, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 12:59:25] {805} INFO - trial 1 config: {'n_estimators': 307, 'max_features': 0.046457209075411295, 'max_leaves': 306, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 12:59:35] {197} INFO - result: {'pred_time': 0.0004220909607369743, 'wall_clock_time': 1631.3817050457, 'metric_for_logging': {'pred_time': 0.0004220909607369743}, 'val_loss': 0.19108639547170284, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340cdb80>, 'training_iteration': 0, 'config': {'n_estimators': 307, 'max_features': 0.046457209075411295, 'max_leaves': 306, 'criterion': 'gini'}, 'config/n_estimators': 307, 'config/max_features': 0.046457209075411295, 'config/max_leaves': 306, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 9.47922658920288}\n",
      "[flaml.tune.tune: 09-25 12:59:35] {197} INFO - result: {'pred_time': 0.0004220909607369743, 'wall_clock_time': 1631.3817050457, 'metric_for_logging': {'pred_time': 0.0004220909607369743}, 'val_loss': 0.19108639547170284, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340cdb80>, 'training_iteration': 1, 'config': {'n_estimators': 307, 'max_features': 0.046457209075411295, 'max_leaves': 306, 'criterion': 'gini'}, 'config/n_estimators': 307, 'config/max_features': 0.046457209075411295, 'config/max_leaves': 306, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 9.480722427368164}\n",
      "[flaml.automl.logger: 09-25 12:59:35] {2391} INFO -  at 1631.4s,\testimator extra_tree's best error=0.1911,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:59:35] {2218} INFO - iteration 337, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 12:59:35] {805} INFO - trial 1 config: {'n_estimators': 324, 'num_leaves': 81, 'min_child_samples': 7, 'learning_rate': 0.23345510935701777, 'log_max_bin': 9, 'colsample_bytree': 0.6976890065573333, 'reg_alpha': 0.0027642982098096502, 'reg_lambda': 15.37838002015033}\n",
      "[flaml.tune.tune: 09-25 12:59:39] {197} INFO - result: {'pred_time': 2.353316357496549e-05, 'wall_clock_time': 1635.0895228385925, 'metric_for_logging': {'pred_time': 2.353316357496549e-05}, 'val_loss': 0.19771087256094752, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe53409e880>, 'training_iteration': 0, 'config': {'n_estimators': 324, 'num_leaves': 81, 'min_child_samples': 7, 'learning_rate': 0.23345510935701777, 'log_max_bin': 9, 'colsample_bytree': 0.6976890065573333, 'reg_alpha': 0.0027642982098096502, 'reg_lambda': 15.37838002015033}, 'config/n_estimators': 324, 'config/num_leaves': 81, 'config/min_child_samples': 7, 'config/learning_rate': 0.23345510935701777, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.6976890065573333, 'config/reg_alpha': 0.0027642982098096502, 'config/reg_lambda': 15.37838002015033, 'experiment_tag': 'exp', 'time_total_s': 3.701117992401123}\n",
      "[flaml.tune.tune: 09-25 12:59:39] {197} INFO - result: {'pred_time': 2.353316357496549e-05, 'wall_clock_time': 1635.0895228385925, 'metric_for_logging': {'pred_time': 2.353316357496549e-05}, 'val_loss': 0.19771087256094752, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe53409e880>, 'training_iteration': 1, 'config': {'n_estimators': 324, 'num_leaves': 81, 'min_child_samples': 7, 'learning_rate': 0.23345510935701777, 'log_max_bin': 9, 'colsample_bytree': 0.6976890065573333, 'reg_alpha': 0.0027642982098096502, 'reg_lambda': 15.37838002015033}, 'config/n_estimators': 324, 'config/num_leaves': 81, 'config/min_child_samples': 7, 'config/learning_rate': 0.23345510935701777, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.6976890065573333, 'config/reg_alpha': 0.0027642982098096502, 'config/reg_lambda': 15.37838002015033, 'experiment_tag': 'exp', 'time_total_s': 3.7033841609954834}\n",
      "[flaml.automl.logger: 09-25 12:59:39] {2391} INFO -  at 1635.1s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 12:59:39] {2218} INFO - iteration 338, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 12:59:39] {805} INFO - trial 1 config: {'n_estimators': 313, 'max_depth': 9, 'min_child_weight': 0.022093141897106962, 'learning_rate': 0.3235487994580797, 'subsample': 0.7386797890618579, 'colsample_bylevel': 0.24938741319294316, 'colsample_bytree': 0.4699327197522882, 'reg_alpha': 0.0021312507242971725, 'reg_lambda': 1.6050411536353433}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 13:00:07] {197} INFO - result: {'pred_time': 5.076327480143089e-05, 'wall_clock_time': 1663.6817944049835, 'metric_for_logging': {'pred_time': 5.076327480143089e-05}, 'val_loss': 0.21329328405790174, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524283310>, 'training_iteration': 0, 'config': {'n_estimators': 313, 'max_depth': 9, 'min_child_weight': 0.022093141897106962, 'learning_rate': 0.3235487994580797, 'subsample': 0.7386797890618579, 'colsample_bylevel': 0.24938741319294316, 'colsample_bytree': 0.4699327197522882, 'reg_alpha': 0.0021312507242971725, 'reg_lambda': 1.6050411536353433}, 'config/n_estimators': 313, 'config/max_depth': 9, 'config/min_child_weight': 0.022093141897106962, 'config/learning_rate': 0.3235487994580797, 'config/subsample': 0.7386797890618579, 'config/colsample_bylevel': 0.24938741319294316, 'config/colsample_bytree': 0.4699327197522882, 'config/reg_alpha': 0.0021312507242971725, 'config/reg_lambda': 1.6050411536353433, 'experiment_tag': 'exp', 'time_total_s': 28.583415269851685}\n",
      "[flaml.tune.tune: 09-25 13:00:07] {197} INFO - result: {'pred_time': 5.076327480143089e-05, 'wall_clock_time': 1663.6817944049835, 'metric_for_logging': {'pred_time': 5.076327480143089e-05}, 'val_loss': 0.21329328405790174, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe524283310>, 'training_iteration': 1, 'config': {'n_estimators': 313, 'max_depth': 9, 'min_child_weight': 0.022093141897106962, 'learning_rate': 0.3235487994580797, 'subsample': 0.7386797890618579, 'colsample_bylevel': 0.24938741319294316, 'colsample_bytree': 0.4699327197522882, 'reg_alpha': 0.0021312507242971725, 'reg_lambda': 1.6050411536353433}, 'config/n_estimators': 313, 'config/max_depth': 9, 'config/min_child_weight': 0.022093141897106962, 'config/learning_rate': 0.3235487994580797, 'config/subsample': 0.7386797890618579, 'config/colsample_bylevel': 0.24938741319294316, 'config/colsample_bytree': 0.4699327197522882, 'config/reg_alpha': 0.0021312507242971725, 'config/reg_lambda': 1.6050411536353433, 'experiment_tag': 'exp', 'time_total_s': 28.584644556045532}\n",
      "[flaml.automl.logger: 09-25 13:00:07] {2391} INFO -  at 1663.7s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 13:00:07] {2218} INFO - iteration 339, current learner rf\n",
      "[flaml.tune.tune: 09-25 13:00:07] {805} INFO - trial 1 config: {'n_estimators': 203, 'max_features': 0.032427221756276076, 'max_leaves': 182, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 09-25 13:00:13] {197} INFO - result: {'pred_time': 0.000269406174006772, 'wall_clock_time': 1669.6206631660461, 'metric_for_logging': {'pred_time': 0.000269406174006772}, 'val_loss': 0.19082187076939708, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524283f40>, 'training_iteration': 0, 'config': {'n_estimators': 203, 'max_features': 0.032427221756276076, 'max_leaves': 182, 'criterion': 'gini'}, 'config/n_estimators': 203, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 182, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 5.93240761756897}\n",
      "[flaml.tune.tune: 09-25 13:00:13] {197} INFO - result: {'pred_time': 0.000269406174006772, 'wall_clock_time': 1669.6206631660461, 'metric_for_logging': {'pred_time': 0.000269406174006772}, 'val_loss': 0.19082187076939708, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe524283f40>, 'training_iteration': 1, 'config': {'n_estimators': 203, 'max_features': 0.032427221756276076, 'max_leaves': 182, 'criterion': 'gini'}, 'config/n_estimators': 203, 'config/max_features': 0.032427221756276076, 'config/max_leaves': 182, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 5.933892488479614}\n",
      "[flaml.automl.logger: 09-25 13:00:13] {2391} INFO -  at 1669.6s,\testimator rf's best error=0.1887,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 13:00:13] {2218} INFO - iteration 340, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 13:00:13] {805} INFO - trial 1 config: {'n_estimators': 78, 'max_leaves': 71, 'min_child_weight': 0.28385895176700504, 'learning_rate': 0.14332189487662236, 'subsample': 0.6643008028748328, 'colsample_bylevel': 0.32873216969000446, 'colsample_bytree': 0.7272135446493013, 'reg_alpha': 0.0014425976504579719, 'reg_lambda': 0.5626338533649355}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 13:00:24] {197} INFO - result: {'pred_time': 4.67843047046296e-05, 'wall_clock_time': 1680.318011522293, 'metric_for_logging': {'pred_time': 4.67843047046296e-05}, 'val_loss': 0.19545754669442825, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe53409d460>, 'training_iteration': 0, 'config': {'n_estimators': 78, 'max_leaves': 71, 'min_child_weight': 0.28385895176700504, 'learning_rate': 0.14332189487662236, 'subsample': 0.6643008028748328, 'colsample_bylevel': 0.32873216969000446, 'colsample_bytree': 0.7272135446493013, 'reg_alpha': 0.0014425976504579719, 'reg_lambda': 0.5626338533649355}, 'config/n_estimators': 78, 'config/max_leaves': 71, 'config/min_child_weight': 0.28385895176700504, 'config/learning_rate': 0.14332189487662236, 'config/subsample': 0.6643008028748328, 'config/colsample_bylevel': 0.32873216969000446, 'config/colsample_bytree': 0.7272135446493013, 'config/reg_alpha': 0.0014425976504579719, 'config/reg_lambda': 0.5626338533649355, 'experiment_tag': 'exp', 'time_total_s': 10.688110828399658}\n",
      "[flaml.tune.tune: 09-25 13:00:24] {197} INFO - result: {'pred_time': 4.67843047046296e-05, 'wall_clock_time': 1680.318011522293, 'metric_for_logging': {'pred_time': 4.67843047046296e-05}, 'val_loss': 0.19545754669442825, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe53409d460>, 'training_iteration': 1, 'config': {'n_estimators': 78, 'max_leaves': 71, 'min_child_weight': 0.28385895176700504, 'learning_rate': 0.14332189487662236, 'subsample': 0.6643008028748328, 'colsample_bylevel': 0.32873216969000446, 'colsample_bytree': 0.7272135446493013, 'reg_alpha': 0.0014425976504579719, 'reg_lambda': 0.5626338533649355}, 'config/n_estimators': 78, 'config/max_leaves': 71, 'config/min_child_weight': 0.28385895176700504, 'config/learning_rate': 0.14332189487662236, 'config/subsample': 0.6643008028748328, 'config/colsample_bylevel': 0.32873216969000446, 'config/colsample_bytree': 0.7272135446493013, 'config/reg_alpha': 0.0014425976504579719, 'config/reg_lambda': 0.5626338533649355, 'experiment_tag': 'exp', 'time_total_s': 10.689167737960815}\n",
      "[flaml.automl.logger: 09-25 13:00:24] {2391} INFO -  at 1680.3s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 13:00:24] {2218} INFO - iteration 341, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 13:00:24] {805} INFO - trial 1 config: {'n_estimators': 19, 'max_depth': 9, 'min_child_weight': 0.010401695330095368, 'learning_rate': 0.06677028560391253, 'subsample': 0.86454241085903, 'colsample_bylevel': 0.049344772878839024, 'colsample_bytree': 0.6889659711913458, 'reg_alpha': 0.018014516169862223, 'reg_lambda': 2.4281637669552447}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 13:00:26] {197} INFO - result: {'pred_time': 5.227791218406616e-05, 'wall_clock_time': 1682.1631343364716, 'metric_for_logging': {'pred_time': 5.227791218406616e-05}, 'val_loss': 0.24771476441266546, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe53409d7f0>, 'training_iteration': 0, 'config': {'n_estimators': 19, 'max_depth': 9, 'min_child_weight': 0.010401695330095368, 'learning_rate': 0.06677028560391253, 'subsample': 0.86454241085903, 'colsample_bylevel': 0.049344772878839024, 'colsample_bytree': 0.6889659711913458, 'reg_alpha': 0.018014516169862223, 'reg_lambda': 2.4281637669552447}, 'config/n_estimators': 19, 'config/max_depth': 9, 'config/min_child_weight': 0.010401695330095368, 'config/learning_rate': 0.06677028560391253, 'config/subsample': 0.86454241085903, 'config/colsample_bylevel': 0.049344772878839024, 'config/colsample_bytree': 0.6889659711913458, 'config/reg_alpha': 0.018014516169862223, 'config/reg_lambda': 2.4281637669552447, 'experiment_tag': 'exp', 'time_total_s': 1.840000867843628}\n",
      "[flaml.tune.tune: 09-25 13:00:26] {197} INFO - result: {'pred_time': 5.227791218406616e-05, 'wall_clock_time': 1682.1631343364716, 'metric_for_logging': {'pred_time': 5.227791218406616e-05}, 'val_loss': 0.24771476441266546, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe53409d7f0>, 'training_iteration': 1, 'config': {'n_estimators': 19, 'max_depth': 9, 'min_child_weight': 0.010401695330095368, 'learning_rate': 0.06677028560391253, 'subsample': 0.86454241085903, 'colsample_bylevel': 0.049344772878839024, 'colsample_bytree': 0.6889659711913458, 'reg_alpha': 0.018014516169862223, 'reg_lambda': 2.4281637669552447}, 'config/n_estimators': 19, 'config/max_depth': 9, 'config/min_child_weight': 0.010401695330095368, 'config/learning_rate': 0.06677028560391253, 'config/subsample': 0.86454241085903, 'config/colsample_bylevel': 0.049344772878839024, 'config/colsample_bytree': 0.6889659711913458, 'config/reg_alpha': 0.018014516169862223, 'config/reg_lambda': 2.4281637669552447, 'experiment_tag': 'exp', 'time_total_s': 1.8411064147949219}\n",
      "[flaml.automl.logger: 09-25 13:00:26] {2391} INFO -  at 1682.2s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 13:00:26] {2218} INFO - iteration 342, current learner lgbm\n",
      "[flaml.tune.tune: 09-25 13:00:26] {805} INFO - trial 1 config: {'n_estimators': 25, 'num_leaves': 60, 'min_child_samples': 7, 'learning_rate': 0.17943247198703435, 'log_max_bin': 9, 'colsample_bytree': 0.8522928846447476, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.11317830192859848}\n",
      "[flaml.tune.tune: 09-25 13:00:26] {197} INFO - result: {'pred_time': 1.1730726402717473e-05, 'wall_clock_time': 1682.9531736373901, 'metric_for_logging': {'pred_time': 1.1730726402717473e-05}, 'val_loss': 0.2117340281695604, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe53409df40>, 'training_iteration': 0, 'config': {'n_estimators': 25, 'num_leaves': 60, 'min_child_samples': 7, 'learning_rate': 0.17943247198703435, 'log_max_bin': 9, 'colsample_bytree': 0.8522928846447476, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.11317830192859848}, 'config/n_estimators': 25, 'config/num_leaves': 60, 'config/min_child_samples': 7, 'config/learning_rate': 0.17943247198703435, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8522928846447476, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.11317830192859848, 'experiment_tag': 'exp', 'time_total_s': 0.7836117744445801}\n",
      "[flaml.tune.tune: 09-25 13:00:26] {197} INFO - result: {'pred_time': 1.1730726402717473e-05, 'wall_clock_time': 1682.9531736373901, 'metric_for_logging': {'pred_time': 1.1730726402717473e-05}, 'val_loss': 0.2117340281695604, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x7fe53409df40>, 'training_iteration': 1, 'config': {'n_estimators': 25, 'num_leaves': 60, 'min_child_samples': 7, 'learning_rate': 0.17943247198703435, 'log_max_bin': 9, 'colsample_bytree': 0.8522928846447476, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.11317830192859848}, 'config/n_estimators': 25, 'config/num_leaves': 60, 'config/min_child_samples': 7, 'config/learning_rate': 0.17943247198703435, 'config/log_max_bin': 9, 'config/colsample_bytree': 0.8522928846447476, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.11317830192859848, 'experiment_tag': 'exp', 'time_total_s': 0.7854032516479492}\n",
      "[flaml.automl.logger: 09-25 13:00:26] {2391} INFO -  at 1683.0s,\testimator lgbm's best error=0.1972,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 13:00:26] {2218} INFO - iteration 343, current learner rf\n",
      "[flaml.tune.tune: 09-25 13:00:26] {805} INFO - trial 1 config: {'n_estimators': 91, 'max_features': 0.03368979836608144, 'max_leaves': 48, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 13:00:29] {197} INFO - result: {'pred_time': 0.00013570238238852465, 'wall_clock_time': 1685.621209859848, 'metric_for_logging': {'pred_time': 0.00013570238238852465}, 'val_loss': 0.2090675123283819, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5340d7e80>, 'training_iteration': 0, 'config': {'n_estimators': 91, 'max_features': 0.03368979836608144, 'max_leaves': 48, 'criterion': 'entropy'}, 'config/n_estimators': 91, 'config/max_features': 0.03368979836608144, 'config/max_leaves': 48, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.660888195037842}\n",
      "[flaml.tune.tune: 09-25 13:00:29] {197} INFO - result: {'pred_time': 0.00013570238238852465, 'wall_clock_time': 1685.621209859848, 'metric_for_logging': {'pred_time': 0.00013570238238852465}, 'val_loss': 0.2090675123283819, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7fe5340d7e80>, 'training_iteration': 1, 'config': {'n_estimators': 91, 'max_features': 0.03368979836608144, 'max_leaves': 48, 'criterion': 'entropy'}, 'config/n_estimators': 91, 'config/max_features': 0.03368979836608144, 'config/max_leaves': 48, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.6624035835266113}\n",
      "[flaml.automl.logger: 09-25 13:00:29] {2391} INFO -  at 1685.6s,\testimator rf's best error=0.1887,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 13:00:29] {2218} INFO - iteration 344, current learner lrl1\n",
      "[flaml.tune.tune: 09-25 13:00:29] {805} INFO - trial 1 config: {'C': 1.3167462135285348}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 13:00:54] {197} INFO - result: {'pred_time': 1.4239064132888643e-05, 'wall_clock_time': 1710.905544757843, 'metric_for_logging': {'pred_time': 1.4239064132888643e-05}, 'val_loss': 0.21406239447843642, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe5340d7b50>, 'training_iteration': 0, 'config': {'C': 1.3167462135285348}, 'config/C': 1.3167462135285348, 'experiment_tag': 'exp', 'time_total_s': 25.277384042739868}\n",
      "[flaml.tune.tune: 09-25 13:00:54] {197} INFO - result: {'pred_time': 1.4239064132888643e-05, 'wall_clock_time': 1710.905544757843, 'metric_for_logging': {'pred_time': 1.4239064132888643e-05}, 'val_loss': 0.21406239447843642, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe5340d7b50>, 'training_iteration': 1, 'config': {'C': 1.3167462135285348}, 'config/C': 1.3167462135285348, 'experiment_tag': 'exp', 'time_total_s': 25.282491445541382}\n",
      "[flaml.automl.logger: 09-25 13:00:54] {2391} INFO -  at 1710.9s,\testimator lrl1's best error=0.2138,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 13:00:54] {2218} INFO - iteration 345, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 13:00:54] {805} INFO - trial 1 config: {'n_estimators': 51, 'max_depth': 10, 'min_child_weight': 0.0021594657670910198, 'learning_rate': 0.1282754952719043, 'subsample': 0.7528732185559984, 'colsample_bylevel': 0.1743832321553841, 'colsample_bytree': 0.6737130649274254, 'reg_alpha': 0.04609238986294034, 'reg_lambda': 3.9385836880106964}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 13:01:00] {197} INFO - result: {'pred_time': 5.179470706135011e-05, 'wall_clock_time': 1716.6566967964172, 'metric_for_logging': {'pred_time': 5.179470706135011e-05}, 'val_loss': 0.20341537477969257, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340d3400>, 'training_iteration': 0, 'config': {'n_estimators': 51, 'max_depth': 10, 'min_child_weight': 0.0021594657670910198, 'learning_rate': 0.1282754952719043, 'subsample': 0.7528732185559984, 'colsample_bylevel': 0.1743832321553841, 'colsample_bytree': 0.6737130649274254, 'reg_alpha': 0.04609238986294034, 'reg_lambda': 3.9385836880106964}, 'config/n_estimators': 51, 'config/max_depth': 10, 'config/min_child_weight': 0.0021594657670910198, 'config/learning_rate': 0.1282754952719043, 'config/subsample': 0.7528732185559984, 'config/colsample_bylevel': 0.1743832321553841, 'config/colsample_bytree': 0.6737130649274254, 'config/reg_alpha': 0.04609238986294034, 'config/reg_lambda': 3.9385836880106964, 'experiment_tag': 'exp', 'time_total_s': 5.740375995635986}\n",
      "[flaml.tune.tune: 09-25 13:01:00] {197} INFO - result: {'pred_time': 5.179470706135011e-05, 'wall_clock_time': 1716.6566967964172, 'metric_for_logging': {'pred_time': 5.179470706135011e-05}, 'val_loss': 0.20341537477969257, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340d3400>, 'training_iteration': 1, 'config': {'n_estimators': 51, 'max_depth': 10, 'min_child_weight': 0.0021594657670910198, 'learning_rate': 0.1282754952719043, 'subsample': 0.7528732185559984, 'colsample_bylevel': 0.1743832321553841, 'colsample_bytree': 0.6737130649274254, 'reg_alpha': 0.04609238986294034, 'reg_lambda': 3.9385836880106964}, 'config/n_estimators': 51, 'config/max_depth': 10, 'config/min_child_weight': 0.0021594657670910198, 'config/learning_rate': 0.1282754952719043, 'config/subsample': 0.7528732185559984, 'config/colsample_bylevel': 0.1743832321553841, 'config/colsample_bytree': 0.6737130649274254, 'config/reg_alpha': 0.04609238986294034, 'config/reg_lambda': 3.9385836880106964, 'experiment_tag': 'exp', 'time_total_s': 5.742180347442627}\n",
      "[flaml.automl.logger: 09-25 13:01:00] {2391} INFO -  at 1716.7s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 13:01:00] {2218} INFO - iteration 346, current learner xgboost\n",
      "[flaml.tune.tune: 09-25 13:01:00] {805} INFO - trial 1 config: {'n_estimators': 248, 'max_leaves': 262, 'min_child_weight': 0.2584234254819303, 'learning_rate': 0.016350950090397425, 'subsample': 0.9904019141608633, 'colsample_bylevel': 0.3806421058494262, 'colsample_bytree': 0.5240468615414722, 'reg_alpha': 0.0009765625, 'reg_lambda': 3.30234495714387}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 13:01:28] {197} INFO - result: {'pred_time': 6.303527403123319e-05, 'wall_clock_time': 1744.5861542224884, 'metric_for_logging': {'pred_time': 6.303527403123319e-05}, 'val_loss': 0.19034548907112622, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5340d3d60>, 'training_iteration': 0, 'config': {'n_estimators': 248, 'max_leaves': 262, 'min_child_weight': 0.2584234254819303, 'learning_rate': 0.016350950090397425, 'subsample': 0.9904019141608633, 'colsample_bylevel': 0.3806421058494262, 'colsample_bytree': 0.5240468615414722, 'reg_alpha': 0.0009765625, 'reg_lambda': 3.30234495714387}, 'config/n_estimators': 248, 'config/max_leaves': 262, 'config/min_child_weight': 0.2584234254819303, 'config/learning_rate': 0.016350950090397425, 'config/subsample': 0.9904019141608633, 'config/colsample_bylevel': 0.3806421058494262, 'config/colsample_bytree': 0.5240468615414722, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 3.30234495714387, 'experiment_tag': 'exp', 'time_total_s': 27.92002034187317}\n",
      "[flaml.tune.tune: 09-25 13:01:28] {197} INFO - result: {'pred_time': 6.303527403123319e-05, 'wall_clock_time': 1744.5861542224884, 'metric_for_logging': {'pred_time': 6.303527403123319e-05}, 'val_loss': 0.19034548907112622, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe5340d3d60>, 'training_iteration': 1, 'config': {'n_estimators': 248, 'max_leaves': 262, 'min_child_weight': 0.2584234254819303, 'learning_rate': 0.016350950090397425, 'subsample': 0.9904019141608633, 'colsample_bylevel': 0.3806421058494262, 'colsample_bytree': 0.5240468615414722, 'reg_alpha': 0.0009765625, 'reg_lambda': 3.30234495714387}, 'config/n_estimators': 248, 'config/max_leaves': 262, 'config/min_child_weight': 0.2584234254819303, 'config/learning_rate': 0.016350950090397425, 'config/subsample': 0.9904019141608633, 'config/colsample_bylevel': 0.3806421058494262, 'config/colsample_bytree': 0.5240468615414722, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 3.30234495714387, 'experiment_tag': 'exp', 'time_total_s': 27.92186975479126}\n",
      "[flaml.automl.logger: 09-25 13:01:28] {2391} INFO -  at 1744.6s,\testimator xgboost's best error=0.1843,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 13:01:28] {2218} INFO - iteration 347, current learner xgb_limitdepth\n",
      "[flaml.tune.tune: 09-25 13:01:28] {805} INFO - trial 1 config: {'n_estimators': 115, 'max_depth': 8, 'min_child_weight': 0.10641804764881257, 'learning_rate': 0.16841444034830183, 'subsample': 0.8503489813648896, 'colsample_bylevel': 0.12434895391639805, 'colsample_bytree': 0.48518562601620857, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.9895188429264633}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 13:01:36] {197} INFO - result: {'pred_time': 4.6936101527469e-05, 'wall_clock_time': 1752.529539346695, 'metric_for_logging': {'pred_time': 4.6936101527469e-05}, 'val_loss': 0.19730689056026382, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340d3250>, 'training_iteration': 0, 'config': {'n_estimators': 115, 'max_depth': 8, 'min_child_weight': 0.10641804764881257, 'learning_rate': 0.16841444034830183, 'subsample': 0.8503489813648896, 'colsample_bylevel': 0.12434895391639805, 'colsample_bytree': 0.48518562601620857, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.9895188429264633}, 'config/n_estimators': 115, 'config/max_depth': 8, 'config/min_child_weight': 0.10641804764881257, 'config/learning_rate': 0.16841444034830183, 'config/subsample': 0.8503489813648896, 'config/colsample_bylevel': 0.12434895391639805, 'config/colsample_bytree': 0.48518562601620857, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.9895188429264633, 'experiment_tag': 'exp', 'time_total_s': 7.936480283737183}\n",
      "[flaml.tune.tune: 09-25 13:01:36] {197} INFO - result: {'pred_time': 4.6936101527469e-05, 'wall_clock_time': 1752.529539346695, 'metric_for_logging': {'pred_time': 4.6936101527469e-05}, 'val_loss': 0.19730689056026382, 'trained_estimator': <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340d3250>, 'training_iteration': 1, 'config': {'n_estimators': 115, 'max_depth': 8, 'min_child_weight': 0.10641804764881257, 'learning_rate': 0.16841444034830183, 'subsample': 0.8503489813648896, 'colsample_bylevel': 0.12434895391639805, 'colsample_bytree': 0.48518562601620857, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.9895188429264633}, 'config/n_estimators': 115, 'config/max_depth': 8, 'config/min_child_weight': 0.10641804764881257, 'config/learning_rate': 0.16841444034830183, 'config/subsample': 0.8503489813648896, 'config/colsample_bylevel': 0.12434895391639805, 'config/colsample_bytree': 0.48518562601620857, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 0.9895188429264633, 'experiment_tag': 'exp', 'time_total_s': 7.937524795532227}\n",
      "[flaml.automl.logger: 09-25 13:01:36] {2391} INFO -  at 1752.5s,\testimator xgb_limitdepth's best error=0.1961,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 13:01:36] {2218} INFO - iteration 348, current learner lrl1\n",
      "[flaml.tune.tune: 09-25 13:01:36] {805} INFO - trial 1 config: {'C': 3.037791154364551}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 13:02:02] {197} INFO - result: {'pred_time': 1.3996768080225415e-05, 'wall_clock_time': 1778.6427128314972, 'metric_for_logging': {'pred_time': 1.3996768080225415e-05}, 'val_loss': 0.21505473874289463, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe5340d3b50>, 'training_iteration': 0, 'config': {'C': 3.037791154364551}, 'config/C': 3.037791154364551, 'experiment_tag': 'exp', 'time_total_s': 26.10639715194702}\n",
      "[flaml.tune.tune: 09-25 13:02:02] {197} INFO - result: {'pred_time': 1.3996768080225415e-05, 'wall_clock_time': 1778.6427128314972, 'metric_for_logging': {'pred_time': 1.3996768080225415e-05}, 'val_loss': 0.21505473874289463, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7fe5340d3b50>, 'training_iteration': 1, 'config': {'C': 3.037791154364551}, 'config/C': 3.037791154364551, 'experiment_tag': 'exp', 'time_total_s': 26.10824418067932}\n",
      "[flaml.automl.logger: 09-25 13:02:02] {2391} INFO -  at 1778.6s,\testimator lrl1's best error=0.2138,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 13:02:02] {2218} INFO - iteration 349, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 13:02:02] {805} INFO - trial 1 config: {'n_estimators': 455, 'max_features': 0.0645416003203881, 'max_leaves': 374, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 09-25 13:02:04] {197} INFO - result: {'pred_time': 6.640528884026332e-05, 'wall_clock_time': 1780.4518666267395, 'metric_for_logging': {'pred_time': 6.640528884026332e-05}, 'val_loss': 0.2143001480895034, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe534076ac0>, 'training_iteration': 0, 'config': {'n_estimators': 455, 'max_features': 0.0645416003203881, 'max_leaves': 374, 'criterion': 'gini'}, 'config/n_estimators': 455, 'config/max_features': 0.0645416003203881, 'config/max_leaves': 374, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.7984724044799805}\n",
      "[flaml.tune.tune: 09-25 13:02:04] {197} INFO - result: {'pred_time': 6.640528884026332e-05, 'wall_clock_time': 1780.4518666267395, 'metric_for_logging': {'pred_time': 6.640528884026332e-05}, 'val_loss': 0.2143001480895034, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe534076ac0>, 'training_iteration': 1, 'config': {'n_estimators': 455, 'max_features': 0.0645416003203881, 'max_leaves': 374, 'criterion': 'gini'}, 'config/n_estimators': 455, 'config/max_features': 0.0645416003203881, 'config/max_leaves': 374, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.800311803817749}\n",
      "[flaml.automl.logger: 09-25 13:02:04] {2391} INFO -  at 1780.5s,\testimator extra_tree's best error=0.1911,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 13:02:04] {2218} INFO - iteration 350, current learner extra_tree\n",
      "[flaml.tune.tune: 09-25 13:02:04] {805} INFO - trial 1 config: {'n_estimators': 207, 'max_features': 0.03344001797852384, 'max_leaves': 250, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 09-25 13:02:10] {197} INFO - result: {'pred_time': 0.0002987944783905838, 'wall_clock_time': 1786.3147172927856, 'metric_for_logging': {'pred_time': 0.0002987944783905838}, 'val_loss': 0.18647259010827225, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6681b3fa0>, 'training_iteration': 0, 'config': {'n_estimators': 207, 'max_features': 0.03344001797852384, 'max_leaves': 250, 'criterion': 'entropy'}, 'config/n_estimators': 207, 'config/max_features': 0.03344001797852384, 'config/max_leaves': 250, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 5.854884147644043}\n",
      "[flaml.tune.tune: 09-25 13:02:10] {197} INFO - result: {'pred_time': 0.0002987944783905838, 'wall_clock_time': 1786.3147172927856, 'metric_for_logging': {'pred_time': 0.0002987944783905838}, 'val_loss': 0.18647259010827225, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7fe6681b3fa0>, 'training_iteration': 1, 'config': {'n_estimators': 207, 'max_features': 0.03344001797852384, 'max_leaves': 250, 'criterion': 'entropy'}, 'config/n_estimators': 207, 'config/max_features': 0.03344001797852384, 'config/max_leaves': 250, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 5.85638689994812}\n",
      "[flaml.automl.logger: 09-25 13:02:10] {2391} INFO -  at 1786.3s,\testimator extra_tree's best error=0.1865,\tbest estimator xgboost's best error=0.1843\n",
      "[flaml.automl.logger: 09-25 13:02:10] {2525} INFO - [('xgboost', {'n_jobs': -1, 'n_estimators': 139, 'max_leaves': 136, 'min_child_weight': 0.27084276373818733, 'learning_rate': 0.0484091845623208, 'subsample': 0.827351358517848, 'colsample_bylevel': 0.35468713776971533, 'colsample_bytree': 0.6256302030953867, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3630887969527579, 'max_depth': 0, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'use_label_encoder': False, 'verbosity': 0}), ('extra_tree', {'n_jobs': -1, 'n_estimators': 207, 'max_features': 0.03344001797852384, 'criterion': 'entropy', 'max_leaf_nodes': 250, 'random_state': 12032022, 'verbose': 0}), ('rf', {'n_jobs': -1, 'n_estimators': 136, 'max_features': 0.032427221756276076, 'criterion': 'entropy', 'max_leaf_nodes': 93, 'random_state': 12032022, 'verbose': 0}), ('xgb_limitdepth', {'n_jobs': -1, 'n_estimators': 77, 'max_depth': 9, 'min_child_weight': 0.015159357865631107, 'learning_rate': 0.14698110676756723, 'subsample': 0.801611099960444, 'colsample_bylevel': 0.14936609303589107, 'colsample_bytree': 0.579449345471817, 'reg_alpha': 0.0061962448817717, 'reg_lambda': 1.9741587508935008, 'use_label_encoder': False, 'verbosity': 0}), ('lgbm', {'n_jobs': -1, 'n_estimators': 90, 'num_leaves': 70, 'min_child_samples': 7, 'learning_rate': 0.20466906793634726, 'colsample_bytree': 0.7749909456010404, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3192797038889443, 'max_bin': 511, 'verbose': -1}), ('lrl1', {'n_jobs': -1, 'C': 1.9999999999999998, 'tol': 0.0001, 'solver': 'saga', 'penalty': 'l1'}), ('catboost', {'early_stopping_rounds': 13, 'learning_rate': 0.04171721859304757, 'n_estimators': 126, 'thread_count': -1, 'verbose': False, 'random_seed': 10242048})]\n",
      "[flaml.automl.logger: 09-25 13:02:10] {2568} INFO - Building ensemble with tuned estimators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 09-25 13:03:36] {2574} INFO - ensemble: StackingClassifier(estimators=[('xgboost',\n",
      "                                <flaml.automl.model.XGBoostSklearnEstimator object at 0x7fe6d5b622e0>),\n",
      "                               ('extra_tree',\n",
      "                                <flaml.automl.model.ExtraTreesEstimator object at 0x7fe5340bcfa0>),\n",
      "                               ('rf',\n",
      "                                <flaml.automl.model.RandomForestEstimator object at 0x7fe5340bc370>),\n",
      "                               ('xgb_limitdepth',\n",
      "                                <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x7fe5340bc700>),\n",
      "                               ('lgbm',\n",
      "                                <flaml.automl.model.LGBMEstimator object at 0x7fe5340bc3d0>),\n",
      "                               ('lrl1',\n",
      "                                <flaml.automl.model.LRL1Classifier object at 0x7fe5340bc7f0>),\n",
      "                               ('catboost',\n",
      "                                <flaml.automl.model.CatBoostEstimator object at 0x7fe5340bc490>)],\n",
      "                   n_jobs=1, passthrough=True)\n",
      "[flaml.automl.logger: 09-25 13:03:36] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 09-25 13:03:36] {1931} INFO - Time taken to find the best model: 251.22577333450317\n",
      "CPU times: user 1h 34min 29s, sys: 7min 46s, total: 1h 42min 15s\n",
      "Wall time: 31min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, task=\"classification\", time_budget=time_sec, verbose=9999, ensemble=True)\n",
    "# uses all cores by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18ea52c1-8ff3-4a48-be91-6015bbbb457c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888641425389755"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = automl.predict(X_test)\n",
    "accuracy_score(y_test,y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60425775-59ef-4b5c-a914-bf63d711070f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StackingClassifier' object has no attribute 'estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StackingClassifier' object has no attribute 'estimator'"
     ]
    }
   ],
   "source": [
    "print(automl.model.estimators, automl.model.final_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50ccceaa-35a5-4018-8dc3-5fdffb920b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost\n",
      "{'n_estimators': 139, 'max_leaves': 136, 'min_child_weight': 0.27084276373818733, 'learning_rate': 0.0484091845623208, 'subsample': 0.827351358517848, 'colsample_bylevel': 0.35468713776971533, 'colsample_bytree': 0.6256302030953867, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.3630887969527579}\n"
     ]
    }
   ],
   "source": [
    "print(automl.best_estimator)\n",
    "print(automl.best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d049b93e-4618-4b57-8592-d7380aaef4cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f313239-e3be-4ad0-a540-65f6b1a9277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5f32e29-d868-405c-81c1-2906c6e95386",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e007af2efdb64e50979f0d5c9058e4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9312357382777845\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=9, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9312357382777845\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=9, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9312357382777845\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=9, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=3 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=4 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=5 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=6 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=7 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.9312357382777845\tKNeighborsClassifier(input_matrix, KNeighborsClassifier__n_neighbors=9, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Negative values in data passed to MultinomialNB (input X).\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only dual=False, got dual=True.\n",
      "_pre_test decorator: _mate_operator: num_test=0 'str' object has no attribute 'arity'.\n",
      "\n",
      "30.01 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "CPU times: user 3h 15s, sys: 22min 46s, total: 3h 23min 2s\n",
      "Wall time: 30min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(config_dict=&#x27;TPOT light&#x27;, max_time_mins=30, random_state=23372,\n",
       "               verbosity=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TPOTClassifier</label><div class=\"sk-toggleable__content\"><pre>TPOTClassifier(config_dict=&#x27;TPOT light&#x27;, max_time_mins=30, random_state=23372,\n",
       "               verbosity=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TPOTClassifier(config_dict='TPOT light', max_time_mins=30, random_state=23372,\n",
       "               verbosity=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline_optimizer = TPOTClassifier(verbosity=3, max_time_mins=time_min, random_state=dagstuhl_seed,  config_dict='TPOT light')\n",
    "pipeline_optimizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36478590-b837-41d7-b80b-f7891f38f8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9991648106904232\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_optimizer.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "865bb1a3-cf12-47d2-b3c8-b5b544a32fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimizer.export('tpot_exported_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5146373-b00e-498e-b8a4-a8a11c7cee84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;kneighborsclassifier&#x27;,\n",
       "                 KNeighborsClassifier(n_neighbors=9, p=1, weights=&#x27;distance&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;kneighborsclassifier&#x27;,\n",
       "                 KNeighborsClassifier(n_neighbors=9, p=1, weights=&#x27;distance&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=9, p=1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('kneighborsclassifier',\n",
       "                 KNeighborsClassifier(n_neighbors=9, p=1, weights='distance'))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_optimizer.fitted_pipeline_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
