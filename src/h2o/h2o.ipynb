{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bdd4295-8dfa-4e4c-91ad-fb756d4e85ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "Random State for reproduceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b65a39-45a2-48d6-a8cc-6ec1186d2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "dagstuhl_seed=23372"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28eda4-8c34-4744-b674-a074ff9c300a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f85df1-4143-4d09-956c-3d56839b21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989eb01e-d24c-4a9b-a4f4-cc8ae3ab5e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label    0    1    2    3    4    5    6    7    8  ...  1014  1015  \\\n",
       "4306  inactive  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4307  inactive  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4308  inactive  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4309  inactive  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4310  inactive  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "      1016  1017  1018  1019  1020  1021  1022  1023  \n",
       "4306   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "4307   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4308   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "4309   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4310   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/preprocessed.csv')\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "df_train = pd.read_csv('../../data/preprocessed-train.csv')\n",
    "df_train = df_train.loc[:, ~df_train.columns.str.contains('^Unnamed')]\n",
    "\n",
    "df_test = pd.read_csv('../../data/preprocessed-test.csv')\n",
    "df_test = df_test.loc[:, ~df_test.columns.str.contains('^Unnamed')]\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86aeca34-8fa2-416f-a782-49039c18c3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3592, 1024)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_train['label']\n",
    "X = df_train.loc[:, df_train.columns != \"label\"]\n",
    "X.to_numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0c61ae-4bc3-4537-8c72-fb6091ea6b25",
   "metadata": {},
   "source": [
    "# AutoML Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8079b20e-8d35-4176-a6c8-d609f14a0dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_min = 60\n",
    "time_sec = time_min * 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ecc4d0-9bb4-4b05-8372-9b9860baae0e",
   "metadata": {},
   "source": [
    "## H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa99b35-a678-450c-84b2-762db595bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"17.0.8.1\" 2023-08-24; OpenJDK Runtime Environment (build 17.0.8.1+1-Ubuntu-0ubuntu122.04); OpenJDK 64-Bit Server VM (build 17.0.8.1+1-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n",
      "  Starting server from /opt/conda/lib/python3.9/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpl0j89hyt\n",
      "  JVM stdout: /tmp/tmpl0j89hyt/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpl0j89hyt/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.42.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>30 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_unknownUser_kl88sr</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.887 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.13 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.42.0.3\n",
       "H2O_cluster_version_age:    30 days\n",
       "H2O_cluster_name:           H2O_from_python_unknownUser_kl88sr\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.887 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.13 final\n",
       "--------------------------  ----------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init(nthreads=-1, log_level=\"TRACE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1de82fc0-4d67-4e75-aec9-03daef6ccdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "hf = h2o.H2OFrame(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc6dbe0-510e-4a0f-a4c7-3fcc5bf667df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "07:03:53.262: Project: AutoML_2_20230922_70353\n",
      "07:03:53.262: 5-fold cross-validation will be used.\n",
      "07:03:53.262: Setting stopping tolerance adaptively based on the training frame: 0.016685216106649997\n",
      "07:03:53.262: Build control seed: 23372\n",
      "07:03:53.263: training frame: Frame key: AutoML_2_20230922_70353_training_Key_Frame__upload_bb830e471e8c01632129daebf3ef48ed.hex    cols: 1025    rows: 3592  chunks: 4    size: 403868  checksum: -87072914012808\n",
      "07:03:53.263: validation frame: NULL\n",
      "07:03:53.263: leaderboard frame: NULL\n",
      "07:03:53.263: blending frame: NULL\n",
      "07:03:53.263: response column: label\n",
      "07:03:53.263: fold column: null\n",
      "07:03:53.263: weights column: null\n",
      "07:03:53.264: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
      "07:03:53.265: Defined work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_1, GLM, ModelBuild, group=1, weight=10}, Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{best_of_family_1, StackedEnsemble, ModelBuild, group=1, weight=5}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_1, DRF, ModelBuild, group=2, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{best_of_family_2, StackedEnsemble, ModelBuild, group=2, weight=5}, Work{all_2, StackedEnsemble, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{XRT, DRF, ModelBuild, group=3, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{def_1, DeepLearning, ModelBuild, group=3, weight=10}, Work{best_of_family_3, StackedEnsemble, ModelBuild, group=3, weight=5}, Work{all_3, StackedEnsemble, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{grid_1, DeepLearning, HyperparamSearch, group=4, weight=30}, Work{best_of_family_4, StackedEnsemble, ModelBuild, group=4, weight=5}, Work{all_4, StackedEnsemble, ModelBuild, group=4, weight=10}, Work{grid_2, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{grid_3, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{best_of_family_5, StackedEnsemble, ModelBuild, group=5, weight=5}, Work{all_5, StackedEnsemble, ModelBuild, group=5, weight=10}, Work{lr_search, XGBoost, Selection, group=6, weight=30}, Work{lr_annealing, GBM, Selection, group=6, weight=10}, Work{monotonic, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{best_of_family_gbm, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{all_gbm, StackedEnsemble, ModelBuild, group=7, weight=10}, Work{best_of_family_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{all_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}, Work{best_of_family, StackedEnsemble, ModelBuild, group=10, weight=10}, Work{best_N, StackedEnsemble, ModelBuild, group=10, weight=10}]\n",
      "07:03:53.265: Actual work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_1, GLM, ModelBuild, group=1, weight=10}, Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{best_of_family_1, StackedEnsemble, ModelBuild, group=1, weight=5}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_1, DRF, ModelBuild, group=2, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{best_of_family_2, StackedEnsemble, ModelBuild, group=2, weight=5}, Work{all_2, StackedEnsemble, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{XRT, DRF, ModelBuild, group=3, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{def_1, DeepLearning, ModelBuild, group=3, weight=10}, Work{best_of_family_3, StackedEnsemble, ModelBuild, group=3, weight=5}, Work{all_3, StackedEnsemble, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{grid_1, DeepLearning, HyperparamSearch, group=4, weight=30}, Work{best_of_family_4, StackedEnsemble, ModelBuild, group=4, weight=5}, Work{all_4, StackedEnsemble, ModelBuild, group=4, weight=10}, Work{grid_2, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{grid_3, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{best_of_family_5, StackedEnsemble, ModelBuild, group=5, weight=5}, Work{all_5, StackedEnsemble, ModelBuild, group=5, weight=10}, Work{lr_search, XGBoost, Selection, group=6, weight=30}, Work{lr_annealing, GBM, Selection, group=6, weight=10}, Work{monotonic, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{best_of_family_gbm, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{all_gbm, StackedEnsemble, ModelBuild, group=7, weight=10}, Work{best_of_family_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{all_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}, Work{best_of_family, StackedEnsemble, ModelBuild, group=10, weight=10}, Work{best_N, StackedEnsemble, ModelBuild, group=10, weight=10}]\n",
      "07:03:53.265: AutoML job created: 2023.09.22 07:03:53.261\n",
      "07:03:53.265: AutoML build started: 2023.09.22 07:03:53.265\n",
      "07:03:53.270: Time assigned for XGBoost_1_AutoML_2_20230922_70353: 1028.5700625s\n",
      "07:03:53.271: AutoML: starting XGBoost_1_AutoML_2_20230922_70353 model training\n",
      "07:03:53.275: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:03:53.275: XGBoost_1_AutoML_2_20230922_70353 [XGBoost def_2] started\n",
      "\n",
      "██\n",
      "07:04:03.108: XGBoost_1_AutoML_2_20230922_70353 [XGBoost def_2] complete\n",
      "07:04:03.108: Adding model XGBoost_1_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=7s, total=10s\n",
      "07:04:03.110: New leader: XGBoost_1_AutoML_2_20230922_70353, auc: 0.7302163172961492\n",
      "07:04:03.113: Time assigned for GLM_1_AutoML_2_20230922_70353: 1436.060875s\n",
      "07:04:03.113: AutoML: starting GLM_1_AutoML_2_20230922_70353 model training\n",
      "07:04:03.117: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:04:03.117: GLM_1_AutoML_2_20230922_70353 [GLM def_1] started\n",
      "\n",
      "\n",
      "07:04:08.475: GLM_1_AutoML_2_20230922_70353 [GLM def_1] complete\n",
      "07:04:08.475: Adding model GLM_1_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=5s\n",
      "07:04:08.477: New leader: GLM_1_AutoML_2_20230922_70353, auc: 0.776140456182473\n",
      "07:04:08.480: Time assigned for GBM_1_AutoML_2_20230922_70353: 2389.85675s\n",
      "07:04:08.481: AutoML: starting GBM_1_AutoML_2_20230922_70353 model training\n",
      "07:04:08.484: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:04:08.484: GBM_1_AutoML_2_20230922_70353 [GBM def_5] started\n",
      "\n",
      "██\n",
      "07:04:29.247: GBM_1_AutoML_2_20230922_70353 [GBM def_5] complete\n",
      "07:04:29.247: Adding model GBM_1_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=8s, total=21s\n",
      "07:04:29.253: Time assigned for StackedEnsemble_BestOfFamily_1_AutoML_2_20230922_70353: 3564.012s\n",
      "07:04:29.253: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_2_20230922_70353 model training\n",
      "07:04:29.256: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:04:29.256: StackedEnsemble_BestOfFamily_1_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_1 (built with AUTO metalearner, using top model from each algorithm type)] started\n",
      "07:04:29.562: StackedEnsemble_BestOfFamily_1_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_1 (built with AUTO metalearner, using top model from each algorithm type)] complete\n",
      "07:04:29.563: Adding model StackedEnsemble_BestOfFamily_1_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=0s, total=0s\n",
      "07:04:29.566: New leader: StackedEnsemble_BestOfFamily_1_AutoML_2_20230922_70353, auc: 0.7842921784098255\n",
      "07:04:29.569: Time assigned for XGBoost_2_AutoML_2_20230922_70353: 548.2609375s\n",
      "07:04:29.569: AutoML: starting XGBoost_2_AutoML_2_20230922_70353 model training\n",
      "07:04:29.574: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:04:29.574: XGBoost_2_AutoML_2_20230922_70353 [XGBoost def_1] started\n",
      "\n",
      "█\n",
      "07:04:33.653: XGBoost_2_AutoML_2_20230922_70353 [XGBoost def_1] complete\n",
      "07:04:33.654: Adding model XGBoost_2_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=4s\n",
      "07:04:33.660: Time assigned for DRF_1_AutoML_2_20230922_70353: 647.2009375s\n",
      "07:04:33.660: AutoML: starting DRF_1_AutoML_2_20230922_70353 model training\n",
      "07:04:33.663: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:04:33.663: DRF_1_AutoML_2_20230922_70353 [DRF def_1] started\n",
      "\n",
      "██\n",
      "07:04:46.914: DRF_1_AutoML_2_20230922_70353 [DRF def_1] complete\n",
      "07:04:46.914: Adding model DRF_1_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=13s\n",
      "07:04:46.924: Time assigned for GBM_2_AutoML_2_20230922_70353: 788.0758125s\n",
      "07:04:46.924: AutoML: starting GBM_2_AutoML_2_20230922_70353 model training\n",
      "07:04:46.927: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:04:46.928: GBM_2_AutoML_2_20230922_70353 [GBM def_2] started\n",
      "\n",
      "█\n",
      "07:05:05.309: GBM_2_AutoML_2_20230922_70353 [GBM def_2] complete\n",
      "07:05:05.309: Adding model GBM_2_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=5s, total=18s\n",
      "07:05:05.317: Time assigned for GBM_3_AutoML_2_20230922_70353: 1007.9851875s\n",
      "07:05:05.317: AutoML: starting GBM_3_AutoML_2_20230922_70353 model training\n",
      "07:05:05.322: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:05:05.322: GBM_3_AutoML_2_20230922_70353 [GBM def_3] started\n",
      "\n",
      "█\n",
      "07:05:28.61: GBM_3_AutoML_2_20230922_70353 [GBM def_3] complete\n",
      "07:05:28.61: Adding model GBM_3_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=7s, total=23s\n",
      "07:05:28.67: New leader: GBM_3_AutoML_2_20230922_70353, auc: 0.7913196047649829\n",
      "07:05:28.72: Time assigned for GBM_4_AutoML_2_20230922_70353: 1402.077625s\n",
      "07:05:28.72: AutoML: starting GBM_4_AutoML_2_20230922_70353 model training\n",
      "07:05:28.76: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:05:28.76: GBM_4_AutoML_2_20230922_70353 [GBM def_4] started\n",
      "\n",
      "█\n",
      "07:05:49.217: GBM_4_AutoML_2_20230922_70353 [GBM def_4] complete\n",
      "07:05:49.217: Adding model GBM_4_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=7s, total=21s\n",
      "07:05:49.226: Time assigned for StackedEnsemble_BestOfFamily_2_AutoML_2_20230922_70353: 1161.346375s\n",
      "07:05:49.227: AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_2_20230922_70353 model training\n",
      "07:05:49.229: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:05:49.229: StackedEnsemble_BestOfFamily_2_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_2 (built with AUTO metalearner, using top model from each algorithm type)] started\n",
      "07:05:49.723: StackedEnsemble_BestOfFamily_2_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_2 (built with AUTO metalearner, using top model from each algorithm type)] complete\n",
      "07:05:49.723: Adding model StackedEnsemble_BestOfFamily_2_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=0s, total=0s\n",
      "07:05:49.728: New leader: StackedEnsemble_BestOfFamily_2_AutoML_2_20230922_70353, auc: 0.8040712438821682\n",
      "07:05:49.734: Time assigned for StackedEnsemble_AllModels_1_AutoML_2_20230922_70353: 3483.531s\n",
      "07:05:49.735: AutoML: starting StackedEnsemble_AllModels_1_AutoML_2_20230922_70353 model training\n",
      "07:05:49.741: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:05:49.741: StackedEnsemble_AllModels_1_AutoML_2_20230922_70353 [StackedEnsemble all_2 (built with AUTO metalearner, using all AutoML models)] started\n",
      "07:05:50.314: StackedEnsemble_AllModels_1_AutoML_2_20230922_70353 [StackedEnsemble all_2 (built with AUTO metalearner, using all AutoML models)] complete\n",
      "07:05:50.315: Adding model StackedEnsemble_AllModels_1_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=1s\n",
      "07:05:50.329: Time assigned for XGBoost_3_AutoML_2_20230922_70353: 633.261125s\n",
      "07:05:50.329: AutoML: starting XGBoost_3_AutoML_2_20230922_70353 model training\n",
      "07:05:50.332: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:05:50.332: XGBoost_3_AutoML_2_20230922_70353 [XGBoost def_3] started\n",
      "\n",
      "██\n",
      "07:05:57.68: XGBoost_3_AutoML_2_20230922_70353 [XGBoost def_3] complete\n",
      "07:05:57.69: Adding model XGBoost_3_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=7s\n",
      "07:05:57.80: Time assigned for XRT_1_AutoML_2_20230922_70353: 772.4858125s\n",
      "07:05:57.80: AutoML: starting XRT_1_AutoML_2_20230922_70353 model training\n",
      "07:05:57.83: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:05:57.83: XRT_1_AutoML_2_20230922_70353 [DRF XRT (Extremely Randomized Trees)] started\n",
      "\n",
      "█\n",
      "07:06:05.401: XRT_1_AutoML_2_20230922_70353 [DRF XRT (Extremely Randomized Trees)] complete\n",
      "07:06:05.401: Adding model XRT_1_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=8s\n",
      "07:06:05.412: Time assigned for GBM_5_AutoML_2_20230922_70353: 990.8151875s\n",
      "07:06:05.413: AutoML: starting GBM_5_AutoML_2_20230922_70353 model training\n",
      "07:06:05.416: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:06:05.416: GBM_5_AutoML_2_20230922_70353 [GBM def_1] started\n",
      "\n",
      "██\n",
      "07:06:18.193: GBM_5_AutoML_2_20230922_70353 [GBM def_1] complete\n",
      "07:06:18.194: Adding model GBM_5_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=13s\n",
      "07:06:18.207: Time assigned for DeepLearning_1_AutoML_2_20230922_70353: 1382.02325s\n",
      "07:06:18.207: AutoML: starting DeepLearning_1_AutoML_2_20230922_70353 model training\n",
      "07:06:18.210: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:06:18.210: DeepLearning_1_AutoML_2_20230922_70353 [DeepLearning def_1] started\n",
      "\n",
      "█\n",
      "07:06:35.575: DeepLearning_1_AutoML_2_20230922_70353 [DeepLearning def_1] complete\n",
      "07:06:35.575: Adding model DeepLearning_1_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=17s\n",
      "07:06:35.585: Time assigned for StackedEnsemble_BestOfFamily_3_AutoML_2_20230922_70353: 1145.893375s\n",
      "07:06:35.585: AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_2_20230922_70353 model training\n",
      "07:06:35.588: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:06:35.594: StackedEnsemble_BestOfFamily_3_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_3 (built with AUTO metalearner, using top model from each algorithm type)] started\n",
      "07:06:36.191: StackedEnsemble_BestOfFamily_3_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_3 (built with AUTO metalearner, using top model from each algorithm type)] complete\n",
      "07:06:36.191: Adding model StackedEnsemble_BestOfFamily_3_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=1s\n",
      "07:06:36.204: Time assigned for StackedEnsemble_AllModels_2_AutoML_2_20230922_70353: 3437.061s\n",
      "07:06:36.205: AutoML: starting StackedEnsemble_AllModels_2_AutoML_2_20230922_70353 model training\n",
      "07:06:36.207: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:06:36.208: StackedEnsemble_AllModels_2_AutoML_2_20230922_70353 [StackedEnsemble all_3 (built with AUTO metalearner, using all AutoML models)] started\n",
      "07:06:36.918: StackedEnsemble_AllModels_2_AutoML_2_20230922_70353 [StackedEnsemble all_3 (built with AUTO metalearner, using all AutoML models)] complete\n",
      "07:06:36.918: Adding model StackedEnsemble_AllModels_2_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=1s\n",
      "07:06:36.933: Time assigned for XGBoost_grid_1_AutoML_2_20230922_70353: 1586.000375s\n",
      "07:06:36.933: AutoML: starting XGBoost_grid_1_AutoML_2_20230922_70353 hyperparameter search\n",
      "07:06:36.954: XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search] started\n",
      "\n",
      "██\n",
      "07:06:41.955: Built: 1 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:06:41.956: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_1 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=5s\n",
      "07:06:45.990: Built: 2 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:06:45.990: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_2 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=4s\n",
      "\n",
      "█\n",
      "07:06:50.0: Built: 3 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:06:50.0: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_3 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=4s\n",
      "07:06:57.36: Built: 4 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:06:57.36: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_4 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=8s\n",
      "07:07:02.51: Built: 5 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:07:02.51: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_5 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=4s\n",
      "\n",
      "\n",
      "07:07:07.71: Built: 6 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:07:07.71: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_6 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=5s\n",
      "07:07:11.103: Built: 7 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:07:11.103: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_7 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=5s\n",
      "07:07:16.124: Built: 8 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:07:16.125: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_8 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=4s\n",
      "07:07:21.162: Built: 9 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:07:21.163: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_9 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=6s\n",
      "\n",
      "█\n",
      "07:07:28.254: Built: 10 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:07:28.254: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_10 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=7s\n",
      "07:07:33.315: Built: 11 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:07:33.315: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_11 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=5s\n",
      "07:07:40.364: Built: 12 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:07:40.364: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_12 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=6s\n",
      "\n",
      "█\n",
      "07:07:47.388: Built: 13 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:07:47.388: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_13 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=7s\n",
      "07:07:54.414: Built: 14 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:07:54.414: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_14 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=7s\n",
      "\n",
      "█\n",
      "07:08:02.485: Built: 15 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:08:02.485: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_15 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=8s\n",
      "07:08:08.505: Built: 16 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:08:08.505: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_16 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=6s\n",
      "\n",
      "█\n",
      "07:08:18.548: Built: 17 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:08:18.549: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_17 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=7s, total=10s\n",
      "07:08:29.675: Built: 18 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:08:29.675: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_18 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=7s, total=11s\n",
      "\n",
      "█\n",
      "07:08:36.751: Built: 19 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:08:36.753: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_19 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=7s\n",
      "\n",
      "\n",
      "07:08:55.795: Built: 20 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:08:55.795: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_20 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=14s, total=19s\n",
      "07:09:06.855: Built: 21 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:09:06.855: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_21 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=6s, total=11s\n",
      "\n",
      "█\n",
      "07:09:18.897: Built: 22 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:09:18.899: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_22 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=7s, total=12s\n",
      "\n",
      "█\n",
      "07:09:28.952: Built: 23 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:09:28.953: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_23 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=10s\n",
      "07:09:36.13: Built: 24 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:09:36.14: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_24 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=7s\n",
      "07:09:44.60: Built: 25 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:09:44.60: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_25 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=8s\n",
      "\n",
      "█\n",
      "07:09:55.111: Built: 26 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:09:55.113: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_26 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=5s, total=11s\n",
      "\n",
      "\n",
      "07:10:04.162: Built: 27 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:10:04.162: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_27 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=9s\n",
      "07:10:09.240: Built: 28 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:10:09.241: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_28 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=5s\n",
      "07:10:16.276: Built: 29 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:10:16.278: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_29 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=6s\n",
      "\n",
      "█\n",
      "07:10:24.320: Built: 30 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:10:24.320: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_30 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=8s\n",
      "\n",
      "█\n",
      "07:10:37.429: Built: 31 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:10:37.430: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_31 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=7s, total=13s\n",
      "07:10:49.569: Built: 32 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:10:49.570: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_32 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=8s, total=12s\n",
      "\n",
      "\n",
      "07:11:07.632: Built: 33 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:11:07.632: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_33 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=7s, total=18s\n",
      "\n",
      "█\n",
      "07:11:13.666: Built: 34 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:11:13.667: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_34 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=6s\n",
      "07:11:22.707: Built: 35 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:11:22.708: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_35 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=9s\n",
      "\n",
      "█\n",
      "07:11:31.830: Built: 36 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:11:31.830: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_36 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=5s, total=9s\n",
      "07:11:42.122: Built: 37 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:11:42.124: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_37 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=10s\n",
      "\n",
      "█\n",
      "07:12:12.200: Built: 38 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:12:12.201: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_38 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=18s, total=30s\n",
      "\n",
      "█\n",
      "07:12:26.245: Built: 39 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:12:26.246: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_39 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=8s, total=14s\n",
      "07:12:33.389: Built: 40 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:12:33.390: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_40 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=7s\n",
      "\n",
      "\n",
      "07:12:50.484: Built: 41 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:12:50.485: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_41 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=8s, total=17s\n",
      "\n",
      "█\n",
      "07:13:02.588: Built: 42 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:13:02.589: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_42 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=6s, total=12s\n",
      "07:13:08.679: Built: 43 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:13:08.679: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_43 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=6s\n",
      "\n",
      "\n",
      "07:13:15.754: Built: 44 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:13:15.755: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_44 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=6s\n",
      "07:13:23.843: Built: 45 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:13:23.844: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_45 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=8s\n",
      "07:13:32.930: Built: 46 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:13:32.930: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_46 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=6s, total=10s\n",
      "\n",
      "█\n",
      "07:13:40.29: Built: 47 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:13:40.30: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_47 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=7s\n",
      "\n",
      "\n",
      "07:14:00.226: Built: 48 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:14:00.227: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_48 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=13s, total=20s\n",
      "07:14:06.452: Built: 49 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:14:06.452: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_49 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=7s\n",
      "\n",
      "█\n",
      "07:14:15.519: Built: 50 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:14:15.520: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_50 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=8s\n",
      "07:14:20.612: Built: 51 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:14:20.613: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_51 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=5s\n",
      "07:14:23.680: Built: 52 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:14:23.680: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_52 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=3s\n",
      "\n",
      "█\n",
      "07:14:28.746: Built: 53 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:14:28.747: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_53 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=5s\n",
      "07:14:32.796: Built: 54 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:14:32.796: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_54 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=4s\n",
      "07:14:37.830: Built: 55 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:14:37.831: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_55 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=5s\n",
      "07:14:41.873: Built: 56 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:14:41.873: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_56 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=4s\n",
      "\n",
      "\n",
      "07:14:44.926: Built: 57 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:14:44.926: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_57 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=4s\n",
      "07:14:50.965: Built: 58 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:14:50.965: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_58 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=6s\n",
      "07:14:57.46: Built: 59 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:14:57.46: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_59 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=6s\n",
      "\n",
      "█\n",
      "07:15:04.112: Built: 60 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:15:04.112: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_60 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=7s\n",
      "07:15:10.163: Built: 61 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:15:10.164: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_61 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=6s\n",
      "\n",
      "\n",
      "07:15:21.242: Built: 62 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:15:21.243: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_62 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=6s, total=11s\n",
      "07:15:35.403: Built: 63 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:15:35.404: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_63 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=9s, total=14s\n",
      "\n",
      "\n",
      "07:15:47.40: XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search] complete\n",
      "07:15:47.40: Built: 64 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "07:15:47.41: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_64 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=5s, total=12s\n",
      "07:15:47.93: Time assigned for GBM_grid_1_AutoML_2_20230922_70353: 1649.24175s\n",
      "07:15:47.93: AutoML: starting GBM_grid_1_AutoML_2_20230922_70353 hyperparameter search\n",
      "07:15:47.97: GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search] started\n",
      "\n",
      "██████\n",
      "07:16:14.138: Built: 1 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:16:14.138: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_1 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=5s, total=27s\n",
      "07:16:31.277: Built: 2 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:16:31.277: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_2 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=17s\n",
      "\n",
      "█\n",
      "07:16:43.352: Built: 3 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:16:43.352: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_3 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=13s\n",
      "07:16:50.446: Built: 4 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:16:50.447: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_4 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=7s\n",
      "\n",
      "█\n",
      "07:17:14.605: Built: 5 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:17:14.606: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_5 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=5s, total=23s\n",
      "\n",
      "█\n",
      "07:17:31.723: Built: 6 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:17:31.724: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_6 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=17s\n",
      "\n",
      "\n",
      "07:17:55.910: Built: 7 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:17:55.911: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_7 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=6s, total=24s\n",
      "07:18:16.67: Built: 8 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:18:16.67: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_8 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=20s\n",
      "\n",
      "██\n",
      "07:18:56.301: Built: 9 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:18:56.302: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_9 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=10s, total=40s\n",
      "\n",
      "█\n",
      "07:19:27.488: Built: 10 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:19:27.489: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_10 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=5s, total=31s\n",
      "\n",
      "█\n",
      "07:20:11.738: Built: 11 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:20:11.738: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_11 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=10s, total=45s\n",
      "07:20:34.954: Built: 12 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:20:34.954: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_12 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=5s, total=22s\n",
      "\n",
      "█\n",
      "07:20:46.61: Built: 13 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:20:46.61: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_13 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=11s\n",
      "07:20:53.147: Built: 14 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:20:53.147: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_14 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=7s\n",
      "\n",
      "\n",
      "07:21:21.17: GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search] complete\n",
      "07:21:21.17: Built: 15 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "07:21:21.18: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_15 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=8s, total=28s\n",
      "07:21:21.59: Time assigned for DeepLearning_grid_1_AutoML_2_20230922_70353: 1701.471375s\n",
      "07:21:21.59: AutoML: starting DeepLearning_grid_1_AutoML_2_20230922_70353 hyperparameter search\n",
      "07:21:21.63: DeepLearning_grid_1_AutoML_2_20230922_70353 [DeepLearning Grid Search] started\n",
      "\n",
      "██████████\n",
      "07:39:20.745: Built: 1 models for HyperparamSearch : DeepLearning_grid_1_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "07:39:20.745: Adding model DeepLearning_grid_1_AutoML_2_20230922_70353_model_1 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=225s, total=1079s\n",
      "\n",
      "\n",
      "07:45:24.288: Built: 2 models for HyperparamSearch : DeepLearning_grid_1_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "07:45:24.288: Adding model DeepLearning_grid_1_AutoML_2_20230922_70353_model_2 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=42s, total=363s\n",
      "\n",
      "\n",
      "07:48:01.596: Built: 3 models for HyperparamSearch : DeepLearning_grid_1_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "07:48:01.596: Adding model DeepLearning_grid_1_AutoML_2_20230922_70353_model_3 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=19s, total=158s\n",
      "\n",
      "\n",
      "07:48:59.739: Built: 4 models for HyperparamSearch : DeepLearning_grid_1_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "07:48:59.739: Adding model DeepLearning_grid_1_AutoML_2_20230922_70353_model_4 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=57s\n",
      "\n",
      "\n",
      "07:49:28.878: Built: 5 models for HyperparamSearch : DeepLearning_grid_1_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "07:49:28.878: Adding model DeepLearning_grid_1_AutoML_2_20230922_70353_model_5 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=29s\n",
      "\n",
      "\n",
      "07:50:13.894: DeepLearning_grid_1_AutoML_2_20230922_70353 [DeepLearning Grid Search] complete\n",
      "07:50:13.894: Built: 6 models for HyperparamSearch : DeepLearning_grid_1_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "07:50:13.894: Adding model DeepLearning_grid_1_AutoML_2_20230922_70353_model_6 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=9s, total=46s\n",
      "07:50:13.947: Time assigned for StackedEnsemble_BestOfFamily_4_AutoML_2_20230922_70353: 273.106s\n",
      "07:50:13.947: AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_2_20230922_70353 model training\n",
      "07:50:13.952: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:50:13.954: StackedEnsemble_BestOfFamily_4_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_4 (built with AUTO metalearner, using top model from each algorithm type)] started\n",
      "07:50:14.464: StackedEnsemble_BestOfFamily_4_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_4 (built with AUTO metalearner, using top model from each algorithm type)] complete\n",
      "07:50:14.464: Adding model StackedEnsemble_BestOfFamily_4_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=1s\n",
      "07:50:14.503: New leader: StackedEnsemble_BestOfFamily_4_AutoML_2_20230922_70353, auc: 0.8113826299750669\n",
      "07:50:14.511: Time assigned for StackedEnsemble_AllModels_3_AutoML_2_20230922_70353: 818.754s\n",
      "07:50:14.511: AutoML: starting StackedEnsemble_AllModels_3_AutoML_2_20230922_70353 model training\n",
      "07:50:14.519: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "07:50:14.522: StackedEnsemble_AllModels_3_AutoML_2_20230922_70353 [StackedEnsemble all_4 (built with AUTO metalearner, using all AutoML models)] started\n",
      "\n",
      "\n",
      "07:50:17.17: StackedEnsemble_AllModels_3_AutoML_2_20230922_70353 [StackedEnsemble all_4 (built with AUTO metalearner, using all AutoML models)] complete\n",
      "07:50:17.17: Adding model StackedEnsemble_AllModels_3_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=2s\n",
      "07:50:17.69: Time assigned for DeepLearning_grid_2_AutoML_2_20230922_70353: 326.4788125s\n",
      "07:50:17.69: AutoML: starting DeepLearning_grid_2_AutoML_2_20230922_70353 hyperparameter search\n",
      "07:50:17.71: DeepLearning_grid_2_AutoML_2_20230922_70353 [DeepLearning Grid Search] started\n",
      "\n",
      "\n",
      "07:53:26.216: Built: 1 models for HyperparamSearch : DeepLearning_grid_2_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "07:53:26.217: Adding model DeepLearning_grid_2_AutoML_2_20230922_70353_model_1 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=24s, total=189s\n",
      "\n",
      "\n",
      "07:54:49.364: Built: 2 models for HyperparamSearch : DeepLearning_grid_2_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "07:54:49.364: Adding model DeepLearning_grid_2_AutoML_2_20230922_70353_model_2 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=12s, total=83s\n",
      "\n",
      "\n",
      "07:55:41.616: Built: 3 models for HyperparamSearch : DeepLearning_grid_2_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "07:55:41.616: Adding model DeepLearning_grid_2_AutoML_2_20230922_70353_model_3 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=11s, total=52s\n",
      "\n",
      "\n",
      "07:55:59.397: DeepLearning_grid_2_AutoML_2_20230922_70353 [DeepLearning Grid Search] complete\n",
      "07:55:59.397: Built: 4 models for HyperparamSearch : DeepLearning_grid_2_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "07:55:59.397: Adding model DeepLearning_grid_2_AutoML_2_20230922_70353_model_4 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=18s\n",
      "07:55:59.440: Time assigned for DeepLearning_grid_3_AutoML_2_20230922_70353: 315.884s\n",
      "07:55:59.440: AutoML: starting DeepLearning_grid_3_AutoML_2_20230922_70353 hyperparameter search\n",
      "07:55:59.443: DeepLearning_grid_3_AutoML_2_20230922_70353 [DeepLearning Grid Search] started\n",
      "\n",
      "\n",
      "07:59:02.626: Built: 1 models for HyperparamSearch : DeepLearning_grid_3_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "07:59:02.626: Adding model DeepLearning_grid_3_AutoML_2_20230922_70353_model_1 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=23s, total=183s\n",
      "\n",
      "\n",
      "08:00:20.764: Built: 2 models for HyperparamSearch : DeepLearning_grid_3_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "08:00:20.765: Adding model DeepLearning_grid_3_AutoML_2_20230922_70353_model_2 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=5s, total=77s\n",
      "\n",
      "\n",
      "08:00:59.931: Built: 3 models for HyperparamSearch : DeepLearning_grid_3_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "08:00:59.932: Adding model DeepLearning_grid_3_AutoML_2_20230922_70353_model_3 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=5s, total=39s\n",
      "\n",
      "\n",
      "08:01:12.96: Built: 4 models for HyperparamSearch : DeepLearning_grid_3_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "08:01:12.96: Adding model DeepLearning_grid_3_AutoML_2_20230922_70353_model_4 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=12s\n",
      "\n",
      "\n",
      "08:01:32.942: DeepLearning_grid_3_AutoML_2_20230922_70353 [DeepLearning Grid Search] complete\n",
      "08:01:32.942: Built: 5 models for HyperparamSearch : DeepLearning_grid_3_AutoML_2_20230922_70353 [DeepLearning Grid Search]\n",
      "08:01:32.942: Adding model DeepLearning_grid_3_AutoML_2_20230922_70353_model_5 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=21s\n",
      "08:01:32.982: Time assigned for StackedEnsemble_BestOfFamily_5_AutoML_2_20230922_70353: 46.761s\n",
      "08:01:32.983: AutoML: starting StackedEnsemble_BestOfFamily_5_AutoML_2_20230922_70353 model training\n",
      "08:01:32.985: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "08:01:32.986: StackedEnsemble_BestOfFamily_5_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_5 (built with AUTO metalearner, using top model from each algorithm type)] started\n",
      "08:01:33.385: StackedEnsemble_BestOfFamily_5_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_5 (built with AUTO metalearner, using top model from each algorithm type)] complete\n",
      "08:01:33.385: Adding model StackedEnsemble_BestOfFamily_5_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=0s, total=0s\n",
      "\n",
      "\n",
      "08:01:33.430: Time assigned for StackedEnsemble_AllModels_4_AutoML_2_20230922_70353: 139.835s\n",
      "08:01:33.430: AutoML: starting StackedEnsemble_AllModels_4_AutoML_2_20230922_70353 model training\n",
      "08:01:33.437: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "08:01:33.439: StackedEnsemble_AllModels_4_AutoML_2_20230922_70353 [StackedEnsemble all_5 (built with AUTO metalearner, using all AutoML models)] started\n",
      "\n",
      "\n",
      "08:01:35.728: StackedEnsemble_AllModels_4_AutoML_2_20230922_70353 [StackedEnsemble all_5 (built with AUTO metalearner, using all AutoML models)] complete\n",
      "08:01:35.728: Adding model StackedEnsemble_AllModels_4_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=2s\n",
      "08:01:35.769: Time assigned for XGBoost_lr_search_selection_AutoML_2_20230922_70353: 24.264s\n",
      "08:01:35.783: XGBoost_lr_search_selection_AutoML_2_20230922_70353 [XGBoost lr_search] started\n",
      "08:01:35.784: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_2_20230922_70353_model_60\n",
      "08:01:35.784: AutoML: starting XGBoost_lr_search_selection_AutoML_2_20230922_70353_select model training\n",
      "\n",
      "\n",
      "08:02:00.291: XGBoost_lr_search_selection_AutoML_2_20230922_70353 [XGBoost lr_search] complete\n",
      "08:02:00.292: Time assigned for GBM_lr_annealing_selection_AutoML_2_20230922_70353: 8.06950048828125s\n",
      "08:02:00.293: GBM_lr_annealing_selection_AutoML_2_20230922_70353 [GBM lr_annealing] started\n",
      "08:02:00.294: Retraining best GBM with learning rate annealing: GBM_3_AutoML_2_20230922_70353\n",
      "08:02:00.294: AutoML: starting GBM_lr_annealing_selection_AutoML_2_20230922_70353_select_model model training\n",
      "08:02:00.297: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "\n",
      "\n",
      "08:02:09.539: GBM_lr_annealing_selection_AutoML_2_20230922_70353 [GBM lr_annealing] complete\n",
      "08:02:09.542: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
      "\n",
      "\n",
      "08:02:09.547: Time assigned for StackedEnsemble_BestOfFamily_6_AutoML_2_20230922_70353: 103.718s\n",
      "08:02:09.547: AutoML: starting StackedEnsemble_BestOfFamily_6_AutoML_2_20230922_70353 model training\n",
      "08:02:09.550: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "08:02:09.552: StackedEnsemble_BestOfFamily_6_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_gbm (built with gbm metalearner, using top model from each algorithm type)] started\n",
      "\n",
      "\n",
      "08:02:13.946: StackedEnsemble_BestOfFamily_6_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_gbm (built with gbm metalearner, using top model from each algorithm type)] complete\n",
      "08:02:13.946: Adding model StackedEnsemble_BestOfFamily_6_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=4s\n",
      "08:02:13.990: Time assigned for StackedEnsemble_AllModels_5_AutoML_2_20230922_70353: 99.275s\n",
      "08:02:13.990: AutoML: starting StackedEnsemble_AllModels_5_AutoML_2_20230922_70353 model training\n",
      "08:02:13.995: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "08:02:13.996: StackedEnsemble_AllModels_5_AutoML_2_20230922_70353 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)] started\n",
      "\n",
      "\n",
      "08:02:34.999: StackedEnsemble_AllModels_5_AutoML_2_20230922_70353 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)] complete\n",
      "08:02:35.0: Adding model StackedEnsemble_AllModels_5_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=21s, total=21s\n",
      "08:02:35.173: Time assigned for StackedEnsemble_BestOfFamily_7_AutoML_2_20230922_70353: 39.046s\n",
      "08:02:35.173: AutoML: starting StackedEnsemble_BestOfFamily_7_AutoML_2_20230922_70353 model training\n",
      "08:02:35.187: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "08:02:35.190: StackedEnsemble_BestOfFamily_7_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_xglm (built with AUTO metalearner, using top model from each algorithm type)] started\n",
      "\n",
      "\n",
      "08:02:39.289: StackedEnsemble_BestOfFamily_7_AutoML_2_20230922_70353 [StackedEnsemble best_of_family_xglm (built with AUTO metalearner, using top model from each algorithm type)] complete\n",
      "08:02:39.289: Adding model StackedEnsemble_BestOfFamily_7_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=4s, total=4s\n",
      "08:02:39.364: Time assigned for StackedEnsemble_AllModels_6_AutoML_2_20230922_70353: 73.901s\n",
      "08:02:39.364: AutoML: starting StackedEnsemble_AllModels_6_AutoML_2_20230922_70353 model training\n",
      "08:02:39.371: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "08:02:39.373: StackedEnsemble_AllModels_6_AutoML_2_20230922_70353 [StackedEnsemble all_xglm (built with AUTO metalearner, using all AutoML models)] started\n",
      "\n",
      "\n",
      "08:02:59.595: StackedEnsemble_AllModels_6_AutoML_2_20230922_70353 [StackedEnsemble all_xglm (built with AUTO metalearner, using all AutoML models)] complete\n",
      "08:02:59.595: Adding model StackedEnsemble_AllModels_6_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=20s, total=20s\n",
      "08:02:59.665: Time assigned for GBM_grid_1_AutoML_2_20230922_70353: 20.1s\n",
      "08:02:59.665: AutoML: starting GBM_grid_1_AutoML_2_20230922_70353 hyperparameter search\n",
      "08:02:59.668: GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search] started\n",
      "08:02:59.668: Built: 15 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "\n",
      "\n",
      "08:03:13.674: Built: 16 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "08:03:13.675: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_31 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=2s, total=13s\n",
      "\n",
      "\n",
      "08:03:17.785: Built: 17 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "08:03:17.785: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_32 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=5s\n",
      "\n",
      "█| (done) 100%\n",
      "\n",
      "08:03:19.857: Built: 18 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "08:03:19.857: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_33 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=2s\n",
      "08:03:20.516: GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search] complete\n",
      "08:03:20.516: Built: 19 models for HyperparamSearch : GBM_grid_1_AutoML_2_20230922_70353 [GBM Grid Search]\n",
      "08:03:20.516: Adding model GBM_grid_1_AutoML_2_20230922_70353_model_34 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=0s, total=1s\n",
      "08:03:20.561: Time assigned for XGBoost_grid_1_AutoML_2_20230922_70353: 12.264s\n",
      "08:03:20.561: AutoML: starting XGBoost_grid_1_AutoML_2_20230922_70353 hyperparameter search\n",
      "08:03:20.563: XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search] started\n",
      "08:03:20.563: Built: 64 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "08:03:28.575: Built: 65 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "08:03:28.576: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_129 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=8s\n",
      "08:03:32.717: Built: 66 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "08:03:32.718: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_130 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=1s, total=4s\n",
      "08:03:33.445: XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search] complete\n",
      "08:03:33.445: Built: 67 models for HyperparamSearch : XGBoost_grid_1_AutoML_2_20230922_70353 [XGBoost Grid Search]\n",
      "08:03:33.445: Adding model XGBoost_grid_1_AutoML_2_20230922_70353_model_131 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=0s, total=1s\n",
      "08:03:33.493: Time assigned for StackedEnsemble_BestOfFamily_8_AutoML_2_20230922_70353: 9.886s\n",
      "08:03:33.493: AutoML: starting StackedEnsemble_BestOfFamily_8_AutoML_2_20230922_70353 model training\n",
      "08:03:33.495: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "08:03:33.497: StackedEnsemble_BestOfFamily_8_AutoML_2_20230922_70353 [StackedEnsemble best_of_family (built with AUTO metalearner, using top model from each algorithm type)] started\n",
      "08:03:33.946: StackedEnsemble_BestOfFamily_8_AutoML_2_20230922_70353 [StackedEnsemble best_of_family (built with AUTO metalearner, using top model from each algorithm type)] complete\n",
      "08:03:33.946: Adding model StackedEnsemble_BestOfFamily_8_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=0s, total=0s\n",
      "08:03:34.29: Time assigned for StackedEnsemble_Best1000_1_AutoML_2_20230922_70353: 19.236s\n",
      "08:03:34.29: AutoML: starting StackedEnsemble_Best1000_1_AutoML_2_20230922_70353 model training\n",
      "08:03:34.40: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "08:03:34.43: StackedEnsemble_Best1000_1_AutoML_2_20230922_70353 [StackedEnsemble best_N (built with AUTO metalearner, using best 1000 non-SE models)] started\n",
      "08:03:37.77: StackedEnsemble_Best1000_1_AutoML_2_20230922_70353 [StackedEnsemble best_N (built with AUTO metalearner, using best 1000 non-SE models)] complete\n",
      "08:03:37.77: Adding model StackedEnsemble_Best1000_1_AutoML_2_20230922_70353 to leaderboard Leaderboard_AutoML_2_20230922_70353@@label. Training time: model=3s, total=3s\n",
      "08:03:37.120: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [best_of_family_5 (5g, 5w), all_5 (5g, 10w)]}, {XGBoost : [lr_search (6g, 30w)]}, {GBM : [lr_annealing (6g, 10w)]}, {StackedEnsemble : [best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
      "08:03:37.121: AutoML build stopped: 2023.09.22 08:03:37.120\n",
      "08:03:37.121: AutoML build done: built 113 models\n",
      "08:03:37.121: AutoML duration: 59 min 43.855 sec\n",
      "08:03:37.161: Verifying training frame immutability. . .\n",
      "08:03:37.161: Training frame was not mutated (as expected).\n",
      "\n",
      "CPU times: user 58.3 s, sys: 4.09 s, total: 1min 2s\n",
      "Wall time: 59min 45s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_BestOfFamily_4_AutoML_2_20230922_70353\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary for Stacked Ensemble: </caption>\n",
       "    <thead><tr><th>key</th>\n",
       "<th>value</th></tr></thead>\n",
       "    <tbody><tr><td>Stacking strategy</td>\n",
       "<td>cross_validation</td></tr>\n",
       "<tr><td>Number of base models (used / total)</td>\n",
       "<td>4/6</td></tr>\n",
       "<tr><td># GBM base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># XGBoost base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># DRF base models (used / total)</td>\n",
       "<td>1/2</td></tr>\n",
       "<tr><td># GLM base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># DeepLearning base models (used / total)</td>\n",
       "<td>0/1</td></tr>\n",
       "<tr><td>Metalearner algorithm</td>\n",
       "<td>GLM</td></tr>\n",
       "<tr><td>Metalearner fold assignment scheme</td>\n",
       "<td>Random</td></tr>\n",
       "<tr><td>Metalearner nfolds</td>\n",
       "<td>5</td></tr>\n",
       "<tr><td>Metalearner fold_column</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Custom metalearner hyperparameters</td>\n",
       "<td>None</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.02033521607375839\n",
       "RMSE: 0.14260159912763387\n",
       "LogLoss: 0.09212201285098282\n",
       "AUC: 0.9930989703573737\n",
       "AUCPR: 0.999429197868189\n",
       "Gini: 0.9861979407147474\n",
       "Null degrees of freedom: 3591\n",
       "Residual degrees of freedom: 3587\n",
       "Null deviance: 1866.1161989374114\n",
       "Residual deviance: 661.8045403214605\n",
       "AIC: 671.8045403214605</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7055301188642314</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>active</th>\n",
       "<th>inactive</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>active</td>\n",
       "<td>227.0</td>\n",
       "<td>33.0</td>\n",
       "<td>0.1269</td>\n",
       "<td> (33.0/260.0)</td></tr>\n",
       "<tr><td>inactive</td>\n",
       "<td>19.0</td>\n",
       "<td>3313.0</td>\n",
       "<td>0.0057</td>\n",
       "<td> (19.0/3332.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>246.0</td>\n",
       "<td>3346.0</td>\n",
       "<td>0.0145</td>\n",
       "<td> (52.0/3592.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.7055301</td>\n",
       "<td>0.9922132</td>\n",
       "<td>244.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.6126413</td>\n",
       "<td>0.9953344</td>\n",
       "<td>272.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7575052</td>\n",
       "<td>0.9915561</td>\n",
       "<td>227.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7088460</td>\n",
       "<td>0.9855234</td>\n",
       "<td>243.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9951977</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.4841672</td>\n",
       "<td>1.0</td>\n",
       "<td>295.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9951977</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7088460</td>\n",
       "<td>0.8901410</td>\n",
       "<td>243.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.8531195</td>\n",
       "<td>0.9582833</td>\n",
       "<td>189.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.8563201</td>\n",
       "<td>0.9619563</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9951977</td>\n",
       "<td>260.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9951977</td>\n",
       "<td>3323.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0180568</td>\n",
       "<td>260.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.4841672</td>\n",
       "<td>3332.0</td>\n",
       "<td>295.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9951977</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9951977</td>\n",
       "<td>0.9972989</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0180568</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.4841672</td>\n",
       "<td>1.0</td>\n",
       "<td>295.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 92.76 %, avg score: 91.32 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100223</td>\n",
       "<td>0.9935938</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943384</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943384</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0108043</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.0108043</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200445</td>\n",
       "<td>0.9924984</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929710</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9936547</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0216086</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.0216086</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300668</td>\n",
       "<td>0.9917438</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9920818</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9931304</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0324130</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.0324130</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400891</td>\n",
       "<td>0.9912308</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9914679</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9927148</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0432173</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.0432173</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0501114</td>\n",
       "<td>0.9908675</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9911039</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9923926</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0540216</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.0540216</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1002227</td>\n",
       "<td>0.9885900</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9897305</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9910615</td>\n",
       "<td>0.0540216</td>\n",
       "<td>0.1080432</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.1080432</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500557</td>\n",
       "<td>0.9863185</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9875012</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9898792</td>\n",
       "<td>0.0537215</td>\n",
       "<td>0.1617647</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.1617647</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2001670</td>\n",
       "<td>0.9838456</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9851102</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9886853</td>\n",
       "<td>0.0540216</td>\n",
       "<td>0.2157863</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.2157863</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3001114</td>\n",
       "<td>0.9784183</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9813304</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9862359</td>\n",
       "<td>0.1077431</td>\n",
       "<td>0.3235294</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.3235294</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4003341</td>\n",
       "<td>0.9725315</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9755046</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9835494</td>\n",
       "<td>0.1080432</td>\n",
       "<td>0.4315726</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.4315726</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9654404</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9692349</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9806960</td>\n",
       "<td>0.1074430</td>\n",
       "<td>0.5390156</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.5390156</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5999443</td>\n",
       "<td>0.9569497</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9614215</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9774851</td>\n",
       "<td>0.1077431</td>\n",
       "<td>0.6467587</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.6467587</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6998886</td>\n",
       "<td>0.9431375</td>\n",
       "<td>1.0750283</td>\n",
       "<td>1.0776024</td>\n",
       "<td>0.9972145</td>\n",
       "<td>0.9506143</td>\n",
       "<td>0.9996022</td>\n",
       "<td>0.9736479</td>\n",
       "<td>0.1074430</td>\n",
       "<td>0.7542017</td>\n",
       "<td>7.5028340</td>\n",
       "<td>7.7602401</td>\n",
       "<td>0.7503555</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7998330</td>\n",
       "<td>0.9191475</td>\n",
       "<td>1.0720255</td>\n",
       "<td>1.0769055</td>\n",
       "<td>0.9944290</td>\n",
       "<td>0.9324459</td>\n",
       "<td>0.9989558</td>\n",
       "<td>0.9684995</td>\n",
       "<td>0.1071429</td>\n",
       "<td>0.8613445</td>\n",
       "<td>7.2025468</td>\n",
       "<td>7.6905527</td>\n",
       "<td>0.8498061</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8997773</td>\n",
       "<td>0.8332572</td>\n",
       "<td>1.0419967</td>\n",
       "<td>1.0730280</td>\n",
       "<td>0.9665738</td>\n",
       "<td>0.8892171</td>\n",
       "<td>0.9953589</td>\n",
       "<td>0.9596931</td>\n",
       "<td>0.1041417</td>\n",
       "<td>0.9654862</td>\n",
       "<td>4.1996743</td>\n",
       "<td>7.3027974</td>\n",
       "<td>0.9077939</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0180568</td>\n",
       "<td>0.3443711</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3194444</td>\n",
       "<td>0.4960612</td>\n",
       "<td>0.9276169</td>\n",
       "<td>0.9132266</td>\n",
       "<td>0.0345138</td>\n",
       "<td>1.0</td>\n",
       "<td>-65.5628918</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.05569191193203718\n",
       "RMSE: 0.2359913386801244\n",
       "LogLoss: 0.20666350865548658\n",
       "AUC: 0.8113826299750669\n",
       "AUCPR: 0.9766826232142947\n",
       "Gini: 0.6227652599501339\n",
       "Null degrees of freedom: 3591\n",
       "Residual degrees of freedom: 3586\n",
       "Null deviance: 1867.9636839921757\n",
       "Residual deviance: 1484.6706461810159\n",
       "AIC: 1496.6706461810159</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.38656134317824375</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>active</th>\n",
       "<th>inactive</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>active</td>\n",
       "<td>29.0</td>\n",
       "<td>231.0</td>\n",
       "<td>0.8885</td>\n",
       "<td> (231.0/260.0)</td></tr>\n",
       "<tr><td>inactive</td>\n",
       "<td>8.0</td>\n",
       "<td>3324.0</td>\n",
       "<td>0.0024</td>\n",
       "<td> (8.0/3332.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>37.0</td>\n",
       "<td>3555.0</td>\n",
       "<td>0.0665</td>\n",
       "<td> (239.0/3592.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3865613</td>\n",
       "<td>0.9652969</td>\n",
       "<td>367.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1866422</td>\n",
       "<td>0.9854490</td>\n",
       "<td>386.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7674222</td>\n",
       "<td>0.9529879</td>\n",
       "<td>271.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3865613</td>\n",
       "<td>0.9334633</td>\n",
       "<td>367.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9865040</td>\n",
       "<td>0.9926199</td>\n",
       "<td>21.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1866422</td>\n",
       "<td>1.0</td>\n",
       "<td>386.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9958083</td>\n",
       "<td>0.9961538</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7674222</td>\n",
       "<td>0.3493378</td>\n",
       "<td>271.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9353747</td>\n",
       "<td>0.7301921</td>\n",
       "<td>126.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9383634</td>\n",
       "<td>0.7342437</td>\n",
       "<td>122.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9958083</td>\n",
       "<td>259.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9958083</td>\n",
       "<td>3329.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0541731</td>\n",
       "<td>260.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.1866422</td>\n",
       "<td>3332.0</td>\n",
       "<td>386.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9958083</td>\n",
       "<td>0.9961538</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9958083</td>\n",
       "<td>0.9990996</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0541731</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.1866422</td>\n",
       "<td>1.0</td>\n",
       "<td>386.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 92.76 %, avg score: 92.76 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100223</td>\n",
       "<td>0.9936211</td>\n",
       "<td>1.0181406</td>\n",
       "<td>1.0181406</td>\n",
       "<td>0.9444444</td>\n",
       "<td>0.9945416</td>\n",
       "<td>0.9444444</td>\n",
       "<td>0.9945416</td>\n",
       "<td>0.0102041</td>\n",
       "<td>0.0102041</td>\n",
       "<td>1.8140590</td>\n",
       "<td>1.8140590</td>\n",
       "<td>0.0025118</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200445</td>\n",
       "<td>0.9930174</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0480859</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933501</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.9939458</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0210084</td>\n",
       "<td>7.8031212</td>\n",
       "<td>4.8085901</td>\n",
       "<td>0.0133161</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300668</td>\n",
       "<td>0.9921900</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0580677</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925823</td>\n",
       "<td>0.9814815</td>\n",
       "<td>0.9934913</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0318127</td>\n",
       "<td>7.8031212</td>\n",
       "<td>5.8067672</td>\n",
       "<td>0.0241204</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400891</td>\n",
       "<td>0.9916229</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0630586</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9919287</td>\n",
       "<td>0.9861111</td>\n",
       "<td>0.9931006</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0426170</td>\n",
       "<td>7.8031212</td>\n",
       "<td>6.3058557</td>\n",
       "<td>0.0349247</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0501114</td>\n",
       "<td>0.9911650</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0660531</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9913826</td>\n",
       "<td>0.9888889</td>\n",
       "<td>0.9927570</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0534214</td>\n",
       "<td>7.8031212</td>\n",
       "<td>6.6053088</td>\n",
       "<td>0.0457291</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1002227</td>\n",
       "<td>0.9886568</td>\n",
       "<td>1.0660531</td>\n",
       "<td>1.0660531</td>\n",
       "<td>0.9888889</td>\n",
       "<td>0.9898459</td>\n",
       "<td>0.9888889</td>\n",
       "<td>0.9913015</td>\n",
       "<td>0.0534214</td>\n",
       "<td>0.1068427</td>\n",
       "<td>6.6053088</td>\n",
       "<td>6.6053088</td>\n",
       "<td>0.0914581</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500557</td>\n",
       "<td>0.9863155</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0700310</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9875616</td>\n",
       "<td>0.9925788</td>\n",
       "<td>0.9900595</td>\n",
       "<td>0.0537215</td>\n",
       "<td>0.1605642</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.0030981</td>\n",
       "<td>0.1451796</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2001670</td>\n",
       "<td>0.9839551</td>\n",
       "<td>1.0600640</td>\n",
       "<td>1.0675358</td>\n",
       "<td>0.9833333</td>\n",
       "<td>0.9851520</td>\n",
       "<td>0.9902643</td>\n",
       "<td>0.9888309</td>\n",
       "<td>0.0531212</td>\n",
       "<td>0.2136855</td>\n",
       "<td>6.0064026</td>\n",
       "<td>6.7535776</td>\n",
       "<td>0.1867624</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3001114</td>\n",
       "<td>0.9784692</td>\n",
       "<td>1.0600140</td>\n",
       "<td>1.0650308</td>\n",
       "<td>0.9832869</td>\n",
       "<td>0.9812813</td>\n",
       "<td>0.9879406</td>\n",
       "<td>0.9863167</td>\n",
       "<td>0.1059424</td>\n",
       "<td>0.3196279</td>\n",
       "<td>6.0013978</td>\n",
       "<td>6.5030836</td>\n",
       "<td>0.2696279</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000557</td>\n",
       "<td>0.9720606</td>\n",
       "<td>1.0570111</td>\n",
       "<td>1.0630273</td>\n",
       "<td>0.9805014</td>\n",
       "<td>0.9753696</td>\n",
       "<td>0.9860821</td>\n",
       "<td>0.9835818</td>\n",
       "<td>0.1056423</td>\n",
       "<td>0.4252701</td>\n",
       "<td>5.7011105</td>\n",
       "<td>6.3027299</td>\n",
       "<td>0.3483470</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9641275</td>\n",
       "<td>1.0419967</td>\n",
       "<td>1.0588235</td>\n",
       "<td>0.9665738</td>\n",
       "<td>0.9682236</td>\n",
       "<td>0.9821826</td>\n",
       "<td>0.9805119</td>\n",
       "<td>0.1041417</td>\n",
       "<td>0.5294118</td>\n",
       "<td>4.1996743</td>\n",
       "<td>5.8823529</td>\n",
       "<td>0.4063348</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5999443</td>\n",
       "<td>0.9526820</td>\n",
       "<td>1.0269824</td>\n",
       "<td>1.0535191</td>\n",
       "<td>0.9526462</td>\n",
       "<td>0.9588656</td>\n",
       "<td>0.9772622</td>\n",
       "<td>0.9769058</td>\n",
       "<td>0.1026411</td>\n",
       "<td>0.6320528</td>\n",
       "<td>2.6982381</td>\n",
       "<td>5.3519134</td>\n",
       "<td>0.4435913</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6998886</td>\n",
       "<td>0.9345947</td>\n",
       "<td>1.0119680</td>\n",
       "<td>1.0475856</td>\n",
       "<td>0.9387187</td>\n",
       "<td>0.9444770</td>\n",
       "<td>0.9717582</td>\n",
       "<td>0.9722750</td>\n",
       "<td>0.1011405</td>\n",
       "<td>0.7331933</td>\n",
       "<td>1.1968018</td>\n",
       "<td>4.7585621</td>\n",
       "<td>0.4601164</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7998330</td>\n",
       "<td>0.9063049</td>\n",
       "<td>0.9789364</td>\n",
       "<td>1.0390075</td>\n",
       "<td>0.9080780</td>\n",
       "<td>0.9218358</td>\n",
       "<td>0.9638009</td>\n",
       "<td>0.9659723</td>\n",
       "<td>0.0978391</td>\n",
       "<td>0.8310324</td>\n",
       "<td>-2.1063579</td>\n",
       "<td>3.9007458</td>\n",
       "<td>0.4310324</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8997773</td>\n",
       "<td>0.8421846</td>\n",
       "<td>0.9729307</td>\n",
       "<td>1.0316679</td>\n",
       "<td>0.9025070</td>\n",
       "<td>0.8790015</td>\n",
       "<td>0.9569926</td>\n",
       "<td>0.9563118</td>\n",
       "<td>0.0972389</td>\n",
       "<td>0.9282713</td>\n",
       "<td>-2.7069324</td>\n",
       "<td>3.1667865</td>\n",
       "<td>0.3936559</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0539272</td>\n",
       "<td>0.7156929</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6638889</td>\n",
       "<td>0.6701975</td>\n",
       "<td>0.9276169</td>\n",
       "<td>0.9276367</td>\n",
       "<td>0.0717287</td>\n",
       "<td>1.0</td>\n",
       "<td>-28.4307056</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9355313</td>\n",
       "<td>0.0061236</td>\n",
       "<td>0.9413534</td>\n",
       "<td>0.9381720</td>\n",
       "<td>0.9297521</td>\n",
       "<td>0.9401947</td>\n",
       "<td>0.9281843</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.8111371</td>\n",
       "<td>0.0268557</td>\n",
       "<td>0.8402706</td>\n",
       "<td>0.7795588</td>\n",
       "<td>0.8379031</td>\n",
       "<td>0.8026359</td>\n",
       "<td>0.7953171</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0644687</td>\n",
       "<td>0.0061236</td>\n",
       "<td>0.0586466</td>\n",
       "<td>0.0618280</td>\n",
       "<td>0.0702479</td>\n",
       "<td>0.0598053</td>\n",
       "<td>0.0718157</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>46.4</td>\n",
       "<td>5.7271285</td>\n",
       "<td>39.0</td>\n",
       "<td>46.0</td>\n",
       "<td>51.0</td>\n",
       "<td>43.0</td>\n",
       "<td>53.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9496538</td>\n",
       "<td>0.0061576</td>\n",
       "<td>0.9519408</td>\n",
       "<td>0.9533665</td>\n",
       "<td>0.9430756</td>\n",
       "<td>0.9566216</td>\n",
       "<td>0.9432644</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9662547</td>\n",
       "<td>0.0033347</td>\n",
       "<td>0.9694118</td>\n",
       "<td>0.9677871</td>\n",
       "<td>0.9631236</td>\n",
       "<td>0.9687273</td>\n",
       "<td>0.9622238</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9834667</td>\n",
       "<td>0.0025111</td>\n",
       "<td>0.9875360</td>\n",
       "<td>0.9826508</td>\n",
       "<td>0.9840425</td>\n",
       "<td>0.9811432</td>\n",
       "<td>0.981961</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>1.0241274</td>\n",
       "<td>0.0738450</td>\n",
       "<td>1.0760518</td>\n",
       "<td>0.9353448</td>\n",
       "<td>1.0884558</td>\n",
       "<td>1.0683507</td>\n",
       "<td>0.9524337</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.2063001</td>\n",
       "<td>0.0163242</td>\n",
       "<td>0.1903819</td>\n",
       "<td>0.2035891</td>\n",
       "<td>0.2127795</td>\n",
       "<td>0.1938091</td>\n",
       "<td>0.2309410</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.8294707</td>\n",
       "<td>0.0280379</td>\n",
       "<td>0.8297872</td>\n",
       "<td>0.8541667</td>\n",
       "<td>0.8474576</td>\n",
       "<td>0.7826087</td>\n",
       "<td>0.8333333</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.4170863</td>\n",
       "<td>0.0129510</td>\n",
       "<td>0.4148936</td>\n",
       "<td>0.4306753</td>\n",
       "<td>0.4244784</td>\n",
       "<td>0.3965049</td>\n",
       "<td>0.4188791</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0555951</td>\n",
       "<td>0.0050946</td>\n",
       "<td>0.0511862</td>\n",
       "<td>0.0535680</td>\n",
       "<td>0.0589764</td>\n",
       "<td>0.0514580</td>\n",
       "<td>0.0627870</td></tr>\n",
       "<tr><td>null_deviance</td>\n",
       "<td>373.59274</td>\n",
       "<td>37.565002</td>\n",
       "<td>339.70676</td>\n",
       "<td>357.06476</td>\n",
       "<td>410.56888</td>\n",
       "<td>343.1259</td>\n",
       "<td>417.49738</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9774191</td>\n",
       "<td>0.0073888</td>\n",
       "<td>0.9841775</td>\n",
       "<td>0.9722998</td>\n",
       "<td>0.981759</td>\n",
       "<td>0.9818388</td>\n",
       "<td>0.9670207</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9389097</td>\n",
       "<td>0.0081154</td>\n",
       "<td>0.9406393</td>\n",
       "<td>0.9439891</td>\n",
       "<td>0.9301676</td>\n",
       "<td>0.9487180</td>\n",
       "<td>0.9310345</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.1686626</td>\n",
       "<td>0.0459697</td>\n",
       "<td>0.2206913</td>\n",
       "<td>0.1124338</td>\n",
       "<td>0.2100972</td>\n",
       "<td>0.1407136</td>\n",
       "<td>0.1593770</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9952981</td>\n",
       "<td>0.0042156</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928161</td>\n",
       "<td>0.9985008</td>\n",
       "<td>0.9895988</td>\n",
       "<td>0.9955753</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>296.93414</td>\n",
       "<td>32.997795</td>\n",
       "<td>253.20789</td>\n",
       "<td>302.94055</td>\n",
       "<td>308.9558</td>\n",
       "<td>278.6975</td>\n",
       "<td>340.86887</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.2355917</td>\n",
       "<td>0.0107031</td>\n",
       "<td>0.2262436</td>\n",
       "<td>0.2314476</td>\n",
       "<td>0.2428506</td>\n",
       "<td>0.2268436</td>\n",
       "<td>0.2505733</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.1705293</td>\n",
       "<td>0.0280379</td>\n",
       "<td>0.1702128</td>\n",
       "<td>0.1458333</td>\n",
       "<td>0.1525424</td>\n",
       "<td>0.2173913</td>\n",
       "<td>0.1666667</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 8 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_BestOfFamily_4_AutoML_2_20230922_70353\n",
       "\n",
       "\n",
       "Model Summary for Stacked Ensemble: \n",
       "key                                        value\n",
       "-----------------------------------------  ----------------\n",
       "Stacking strategy                          cross_validation\n",
       "Number of base models (used / total)       4/6\n",
       "# GBM base models (used / total)           1/1\n",
       "# XGBoost base models (used / total)       1/1\n",
       "# DRF base models (used / total)           1/2\n",
       "# GLM base models (used / total)           1/1\n",
       "# DeepLearning base models (used / total)  0/1\n",
       "Metalearner algorithm                      GLM\n",
       "Metalearner fold assignment scheme         Random\n",
       "Metalearner nfolds                         5\n",
       "Metalearner fold_column\n",
       "Custom metalearner hyperparameters         None\n",
       "\n",
       "ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.02033521607375839\n",
       "RMSE: 0.14260159912763387\n",
       "LogLoss: 0.09212201285098282\n",
       "AUC: 0.9930989703573737\n",
       "AUCPR: 0.999429197868189\n",
       "Gini: 0.9861979407147474\n",
       "Null degrees of freedom: 3591\n",
       "Residual degrees of freedom: 3587\n",
       "Null deviance: 1866.1161989374114\n",
       "Residual deviance: 661.8045403214605\n",
       "AIC: 671.8045403214605\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7055301188642314\n",
       "          active    inactive    Error    Rate\n",
       "--------  --------  ----------  -------  -------------\n",
       "active    227       33          0.1269   (33.0/260.0)\n",
       "inactive  19        3313        0.0057   (19.0/3332.0)\n",
       "Total     246       3346        0.0145   (52.0/3592.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.70553      0.992213  244\n",
       "max f2                       0.612641     0.995334  272\n",
       "max f0point5                 0.757505     0.991556  227\n",
       "max accuracy                 0.708846     0.985523  243\n",
       "max precision                0.995198     1         0\n",
       "max recall                   0.484167     1         295\n",
       "max specificity              0.995198     1         0\n",
       "max absolute_mcc             0.708846     0.890141  243\n",
       "max min_per_class_accuracy   0.853119     0.958283  189\n",
       "max mean_per_class_accuracy  0.85632      0.961956  186\n",
       "max tns                      0.995198     260       0\n",
       "max fns                      0.995198     3323      0\n",
       "max fps                      0.0180568    260       399\n",
       "max tps                      0.484167     3332      295\n",
       "max tnr                      0.995198     1         0\n",
       "max fnr                      0.995198     0.997299  0\n",
       "max fpr                      0.0180568    1         399\n",
       "max tpr                      0.484167     1         295\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 92.76 %, avg score: 91.32 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100223                   0.993594           1.07803   1.07803            1                0.994338  1                           0.994338            0.0108043       0.0108043                  7.80312   7.80312            0.0108043\n",
       "2        0.0200445                   0.992498           1.07803   1.07803            1                0.992971  1                           0.993655            0.0108043       0.0216086                  7.80312   7.80312            0.0216086\n",
       "3        0.0300668                   0.991744           1.07803   1.07803            1                0.992082  1                           0.99313             0.0108043       0.032413                   7.80312   7.80312            0.032413\n",
       "4        0.0400891                   0.991231           1.07803   1.07803            1                0.991468  1                           0.992715            0.0108043       0.0432173                  7.80312   7.80312            0.0432173\n",
       "5        0.0501114                   0.990867           1.07803   1.07803            1                0.991104  1                           0.992393            0.0108043       0.0540216                  7.80312   7.80312            0.0540216\n",
       "6        0.100223                    0.98859            1.07803   1.07803            1                0.989731  1                           0.991062            0.0540216       0.108043                   7.80312   7.80312            0.108043\n",
       "7        0.150056                    0.986319           1.07803   1.07803            1                0.987501  1                           0.989879            0.0537215       0.161765                   7.80312   7.80312            0.161765\n",
       "8        0.200167                    0.983846           1.07803   1.07803            1                0.98511   1                           0.988685            0.0540216       0.215786                   7.80312   7.80312            0.215786\n",
       "9        0.300111                    0.978418           1.07803   1.07803            1                0.98133   1                           0.986236            0.107743        0.323529                   7.80312   7.80312            0.323529\n",
       "10       0.400334                    0.972532           1.07803   1.07803            1                0.975505  1                           0.983549            0.108043        0.431573                   7.80312   7.80312            0.431573\n",
       "11       0.5                         0.96544            1.07803   1.07803            1                0.969235  1                           0.980696            0.107443        0.539016                   7.80312   7.80312            0.539016\n",
       "12       0.599944                    0.95695            1.07803   1.07803            1                0.961421  1                           0.977485            0.107743        0.646759                   7.80312   7.80312            0.646759\n",
       "13       0.699889                    0.943137           1.07503   1.0776             0.997214         0.950614  0.999602                    0.973648            0.107443        0.754202                   7.50283   7.76024            0.750356\n",
       "14       0.799833                    0.919148           1.07203   1.07691            0.994429         0.932446  0.998956                    0.968499            0.107143        0.861345                   7.20255   7.69055            0.849806\n",
       "15       0.899777                    0.833257           1.042     1.07303            0.966574         0.889217  0.995359                    0.959693            0.104142        0.965486                   4.19967   7.3028             0.907794\n",
       "16       1                           0.0180568          0.344371  1                  0.319444         0.496061  0.927617                    0.913227            0.0345138       1                          -65.5629  0                  0\n",
       "\n",
       "ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.05569191193203718\n",
       "RMSE: 0.2359913386801244\n",
       "LogLoss: 0.20666350865548658\n",
       "AUC: 0.8113826299750669\n",
       "AUCPR: 0.9766826232142947\n",
       "Gini: 0.6227652599501339\n",
       "Null degrees of freedom: 3591\n",
       "Residual degrees of freedom: 3586\n",
       "Null deviance: 1867.9636839921757\n",
       "Residual deviance: 1484.6706461810159\n",
       "AIC: 1496.6706461810159\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.38656134317824375\n",
       "          active    inactive    Error    Rate\n",
       "--------  --------  ----------  -------  --------------\n",
       "active    29        231         0.8885   (231.0/260.0)\n",
       "inactive  8         3324        0.0024   (8.0/3332.0)\n",
       "Total     37        3555        0.0665   (239.0/3592.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.386561     0.965297  367\n",
       "max f2                       0.186642     0.985449  386\n",
       "max f0point5                 0.767422     0.952988  271\n",
       "max accuracy                 0.386561     0.933463  367\n",
       "max precision                0.986504     0.99262   21\n",
       "max recall                   0.186642     1         386\n",
       "max specificity              0.995808     0.996154  0\n",
       "max absolute_mcc             0.767422     0.349338  271\n",
       "max min_per_class_accuracy   0.935375     0.730192  126\n",
       "max mean_per_class_accuracy  0.938363     0.734244  122\n",
       "max tns                      0.995808     259       0\n",
       "max fns                      0.995808     3329      0\n",
       "max fps                      0.0541731    260       399\n",
       "max tps                      0.186642     3332      386\n",
       "max tnr                      0.995808     0.996154  0\n",
       "max fnr                      0.995808     0.9991    0\n",
       "max fpr                      0.0541731    1         399\n",
       "max tpr                      0.186642     1         386\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 92.76 %, avg score: 92.76 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100223                   0.993621           1.01814   1.01814            0.944444         0.994542  0.944444                    0.994542            0.0102041       0.0102041                  1.81406   1.81406            0.00251177\n",
       "2        0.0200445                   0.993017           1.07803   1.04809            1                0.99335   0.972222                    0.993946            0.0108043       0.0210084                  7.80312   4.80859            0.0133161\n",
       "3        0.0300668                   0.99219            1.07803   1.05807            1                0.992582  0.981481                    0.993491            0.0108043       0.0318127                  7.80312   5.80677            0.0241204\n",
       "4        0.0400891                   0.991623           1.07803   1.06306            1                0.991929  0.986111                    0.993101            0.0108043       0.042617                   7.80312   6.30586            0.0349247\n",
       "5        0.0501114                   0.991165           1.07803   1.06605            1                0.991383  0.988889                    0.992757            0.0108043       0.0534214                  7.80312   6.60531            0.0457291\n",
       "6        0.100223                    0.988657           1.06605   1.06605            0.988889         0.989846  0.988889                    0.991301            0.0534214       0.106843                   6.60531   6.60531            0.0914581\n",
       "7        0.150056                    0.986315           1.07803   1.07003            1                0.987562  0.992579                    0.990059            0.0537215       0.160564                   7.80312   7.0031             0.14518\n",
       "8        0.200167                    0.983955           1.06006   1.06754            0.983333         0.985152  0.990264                    0.988831            0.0531212       0.213685                   6.0064    6.75358            0.186762\n",
       "9        0.300111                    0.978469           1.06001   1.06503            0.983287         0.981281  0.987941                    0.986317            0.105942        0.319628                   6.0014    6.50308            0.269628\n",
       "10       0.400056                    0.972061           1.05701   1.06303            0.980501         0.97537   0.986082                    0.983582            0.105642        0.42527                    5.70111   6.30273            0.348347\n",
       "11       0.5                         0.964128           1.042     1.05882            0.966574         0.968224  0.982183                    0.980512            0.104142        0.529412                   4.19967   5.88235            0.406335\n",
       "12       0.599944                    0.952682           1.02698   1.05352            0.952646         0.958866  0.977262                    0.976906            0.102641        0.632053                   2.69824   5.35191            0.443591\n",
       "13       0.699889                    0.934595           1.01197   1.04759            0.938719         0.944477  0.971758                    0.972275            0.10114         0.733193                   1.1968    4.75856            0.460116\n",
       "14       0.799833                    0.906305           0.978936  1.03901            0.908078         0.921836  0.963801                    0.965972            0.0978391       0.831032                   -2.10636  3.90075            0.431032\n",
       "15       0.899777                    0.842185           0.972931  1.03167            0.902507         0.879001  0.956993                    0.956312            0.0972389       0.928271                   -2.70693  3.16679            0.393656\n",
       "16       1                           0.0539272          0.715693  1                  0.663889         0.670198  0.927617                    0.927637            0.0717287       1                          -28.4307  0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                      mean         sd            cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "--------------------  -----------  ------------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy              0.9355313    0.006123639   0.9413534     0.93817204    0.92975205    0.9401947     0.9281843\n",
       "auc                   0.8111371    0.02685569    0.8402706     0.7795588     0.8379031     0.80263585    0.7953171\n",
       "err                   0.064468704  0.006123639   0.058646616   0.061827958   0.07024793    0.059805285   0.07181572\n",
       "err_count             46.4         5.7271285     39.0          46.0          51.0          43.0          53.0\n",
       "f0point5              0.9496538    0.0061575654  0.95194083    0.95336646    0.9430756     0.95662165    0.94326437\n",
       "f1                    0.9662547    0.0033346883  0.9694118     0.9677871     0.9631236     0.9687273     0.9622238\n",
       "f2                    0.9834667    0.0025110755  0.98753595    0.98265076    0.9840425     0.9811432     0.981961\n",
       "lift_top_group        1.0241274    0.07384498    1.0760518     0.9353448     1.0884558     1.0683507     0.95243365\n",
       "logloss               0.20630011   0.016324209   0.19038187    0.20358907    0.21277949    0.19380912    0.23094097\n",
       "max_per_class_error   0.8294707    0.028037867   0.82978725    0.8541667     0.84745765    0.7826087     0.8333333\n",
       "---                   ---          ---           ---           ---           ---           ---           ---\n",
       "mean_per_class_error  0.41708627   0.012951046   0.41489363    0.4306753     0.42447844    0.39650494    0.41887906\n",
       "mse                   0.055595107  0.0050945925  0.051186163   0.05356799    0.0589764     0.051458016   0.06278697\n",
       "null_deviance         373.59274    37.565002     339.70676     357.06476     410.56888     343.1259      417.49738\n",
       "pr_auc                0.97741914   0.0073888176  0.98417753    0.9722998     0.981759      0.98183876    0.9670207\n",
       "precision             0.93890965   0.008115364   0.94063926    0.9439891     0.9301676     0.94871795    0.9310345\n",
       "r2                    0.16866256   0.045969706   0.22069128    0.11243379    0.21009718    0.1407136     0.15937698\n",
       "recall                0.99529815   0.0042155627  1.0           0.9928161     0.99850076    0.9895988     0.99557525\n",
       "residual_deviance     296.93414    32.997795     253.20789     302.94055     308.9558      278.6975      340.86887\n",
       "rmse                  0.23559172   0.01070314    0.22624359    0.2314476     0.24285057    0.2268436     0.25057328\n",
       "specificity           0.17052929   0.028037867   0.17021276    0.14583333    0.15254237    0.2173913     0.16666667\n",
       "[22 rows x 8 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "aml = H2OAutoML(max_runtime_secs=time_sec, seed=dagstuhl_seed, verbosity=\"debug\")\n",
    "aml.train(y = 'label' , training_frame = hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e54b1cd-883a-409e-bfe3-fadc9579e9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "hf_test = h2o.H2OFrame(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7f3be7c-c4e8-4733-adf1-3c0eb96878fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9443671766342142"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = aml.predict(hf_test)\n",
    "accuracy_score(df_test[\"label\"], y_pred.as_data_frame()['predict']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1f62001-653d-412d-9343-57f2b8e7f2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                              </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th><th>algo           </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_4_AutoML_2_20230922_70353</td><td style=\"text-align: right;\">0.811383</td><td style=\"text-align: right;\"> 0.206664</td><td style=\"text-align: right;\">0.976683</td><td style=\"text-align: right;\">              0.445431</td><td style=\"text-align: right;\">0.235991</td><td style=\"text-align: right;\">0.0556919</td><td style=\"text-align: right;\">               503</td><td style=\"text-align: right;\">                 0.04129 </td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_5_AutoML_2_20230922_70353</td><td style=\"text-align: right;\">0.810375</td><td style=\"text-align: right;\"> 0.207058</td><td style=\"text-align: right;\">0.977054</td><td style=\"text-align: right;\">              0.449427</td><td style=\"text-align: right;\">0.236346</td><td style=\"text-align: right;\">0.0558594</td><td style=\"text-align: right;\">               394</td><td style=\"text-align: right;\">                 0.04812 </td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_8_AutoML_2_20230922_70353</td><td style=\"text-align: right;\">0.807147</td><td style=\"text-align: right;\"> 0.209462</td><td style=\"text-align: right;\">0.97838 </td><td style=\"text-align: right;\">              0.45652 </td><td style=\"text-align: right;\">0.238308</td><td style=\"text-align: right;\">0.0567908</td><td style=\"text-align: right;\">               443</td><td style=\"text-align: right;\">                 0.050921</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_Best1000_1_AutoML_2_20230922_70353    </td><td style=\"text-align: right;\">0.806971</td><td style=\"text-align: right;\"> 0.208146</td><td style=\"text-align: right;\">0.978514</td><td style=\"text-align: right;\">              0.441735</td><td style=\"text-align: right;\">0.237038</td><td style=\"text-align: right;\">0.056187 </td><td style=\"text-align: right;\">              3022</td><td style=\"text-align: right;\">                 0.220452</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_6_AutoML_2_20230922_70353   </td><td style=\"text-align: right;\">0.806611</td><td style=\"text-align: right;\"> 0.209065</td><td style=\"text-align: right;\">0.978407</td><td style=\"text-align: right;\">              0.443808</td><td style=\"text-align: right;\">0.237722</td><td style=\"text-align: right;\">0.0565117</td><td style=\"text-align: right;\">             20205</td><td style=\"text-align: right;\">                 0.225715</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_7_AutoML_2_20230922_70353</td><td style=\"text-align: right;\">0.806409</td><td style=\"text-align: right;\"> 0.208378</td><td style=\"text-align: right;\">0.976002</td><td style=\"text-align: right;\">              0.456369</td><td style=\"text-align: right;\">0.236861</td><td style=\"text-align: right;\">0.056103 </td><td style=\"text-align: right;\">              4082</td><td style=\"text-align: right;\">                 0.042157</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_3_AutoML_2_20230922_70353   </td><td style=\"text-align: right;\">0.805646</td><td style=\"text-align: right;\"> 0.208237</td><td style=\"text-align: right;\">0.977067</td><td style=\"text-align: right;\">              0.447204</td><td style=\"text-align: right;\">0.236675</td><td style=\"text-align: right;\">0.0560149</td><td style=\"text-align: right;\">              2486</td><td style=\"text-align: right;\">                 0.106873</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_4_AutoML_2_20230922_70353   </td><td style=\"text-align: right;\">0.805497</td><td style=\"text-align: right;\"> 0.208456</td><td style=\"text-align: right;\">0.978005</td><td style=\"text-align: right;\">              0.441435</td><td style=\"text-align: right;\">0.236875</td><td style=\"text-align: right;\">0.0561095</td><td style=\"text-align: right;\">              2282</td><td style=\"text-align: right;\">                 0.16563 </td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_2_AutoML_2_20230922_70353</td><td style=\"text-align: right;\">0.804071</td><td style=\"text-align: right;\"> 0.20998 </td><td style=\"text-align: right;\">0.977521</td><td style=\"text-align: right;\">              0.447354</td><td style=\"text-align: right;\">0.238091</td><td style=\"text-align: right;\">0.0566873</td><td style=\"text-align: right;\">               488</td><td style=\"text-align: right;\">                 0.030631</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_2_20230922_70353   </td><td style=\"text-align: right;\">0.803543</td><td style=\"text-align: right;\"> 0.210387</td><td style=\"text-align: right;\">0.977933</td><td style=\"text-align: right;\">              0.447354</td><td style=\"text-align: right;\">0.238497</td><td style=\"text-align: right;\">0.0568807</td><td style=\"text-align: right;\">               566</td><td style=\"text-align: right;\">                 0.043384</td><td>StackedEnsemble</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[128 rows x 10 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                     auc    logloss     aucpr    mean_per_class_error      rmse        mse    training_time_ms    predict_time_per_row_ms  algo\n",
       "------------------------------------------------------  --------  ---------  --------  ----------------------  --------  ---------  ------------------  -------------------------  ---------------\n",
       "StackedEnsemble_BestOfFamily_4_AutoML_2_20230922_70353  0.811383   0.206664  0.976683                0.445431  0.235991  0.0556919                 503                   0.04129   StackedEnsemble\n",
       "StackedEnsemble_BestOfFamily_5_AutoML_2_20230922_70353  0.810375   0.207058  0.977054                0.449427  0.236346  0.0558594                 394                   0.04812   StackedEnsemble\n",
       "StackedEnsemble_BestOfFamily_8_AutoML_2_20230922_70353  0.807147   0.209462  0.97838                 0.45652   0.238308  0.0567908                 443                   0.050921  StackedEnsemble\n",
       "StackedEnsemble_Best1000_1_AutoML_2_20230922_70353      0.806971   0.208146  0.978514                0.441735  0.237038  0.056187                 3022                   0.220452  StackedEnsemble\n",
       "StackedEnsemble_AllModels_6_AutoML_2_20230922_70353     0.806611   0.209065  0.978407                0.443808  0.237722  0.0565117               20205                   0.225715  StackedEnsemble\n",
       "StackedEnsemble_BestOfFamily_7_AutoML_2_20230922_70353  0.806409   0.208378  0.976002                0.456369  0.236861  0.056103                 4082                   0.042157  StackedEnsemble\n",
       "StackedEnsemble_AllModels_3_AutoML_2_20230922_70353     0.805646   0.208237  0.977067                0.447204  0.236675  0.0560149                2486                   0.106873  StackedEnsemble\n",
       "StackedEnsemble_AllModels_4_AutoML_2_20230922_70353     0.805497   0.208456  0.978005                0.441435  0.236875  0.0561095                2282                   0.16563   StackedEnsemble\n",
       "StackedEnsemble_BestOfFamily_2_AutoML_2_20230922_70353  0.804071   0.20998   0.977521                0.447354  0.238091  0.0566873                 488                   0.030631  StackedEnsemble\n",
       "StackedEnsemble_AllModels_1_AutoML_2_20230922_70353     0.803543   0.210387  0.977933                0.447354  0.238497  0.0568807                 566                   0.043384  StackedEnsemble\n",
       "[128 rows x 10 columns]\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = h2o.automl.get_leaderboard(aml, extra_columns = \"ALL\")\n",
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31764e9d-ed2a-492a-84dd-00b81f3a7e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_id', 'training_frame', 'response_column', 'validation_frame', 'blending_frame', 'base_models', 'metalearner_algorithm', 'metalearner_nfolds', 'metalearner_fold_assignment', 'metalearner_fold_column', 'metalearner_params', 'metalearner_transform', 'max_runtime_secs', 'weights_column', 'offset_column', 'seed', 'score_training_samples', 'keep_levelone_frame', 'export_checkpoints_dir', 'auc_type'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = aml.leader\n",
    "m.params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44a0c100-81bf-4dab-b86e-d5e8b8ddf2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>timestamp   </th><th>level  </th><th>stage     </th><th>message                                                                                                                                                                                             </th><th>name  </th><th>value  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>07:03:53.262</td><td>INFO   </td><td>Workflow  </td><td>Project: AutoML_2_20230922_70353                                                                                                                                                                    </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>07:03:53.262</td><td>INFO   </td><td>Validation</td><td>5-fold cross-validation will be used.                                                                                                                                                               </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>07:03:53.262</td><td>INFO   </td><td>Validation</td><td>Setting stopping tolerance adaptively based on the training frame: 0.016685216106649997                                                                                                             </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>07:03:53.262</td><td>INFO   </td><td>Validation</td><td>Build control seed: 23372                                                                                                                                                                           </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>07:03:53.263</td><td>INFO   </td><td>DataImport</td><td>training frame: Frame key: AutoML_2_20230922_70353_training_Key_Frame__upload_bb830e471e8c01632129daebf3ef48ed.hex    cols: 1025    rows: 3592  chunks: 4    size: 403868  checksum: -87072914012808</td><td>      </td><td>       </td></tr>\n",
       "<tr><td>07:03:53.263</td><td>INFO   </td><td>DataImport</td><td>validation frame: NULL                                                                                                                                                                              </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>07:03:53.263</td><td>INFO   </td><td>DataImport</td><td>leaderboard frame: NULL                                                                                                                                                                             </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>07:03:53.263</td><td>INFO   </td><td>DataImport</td><td>blending frame: NULL                                                                                                                                                                                </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>07:03:53.263</td><td>INFO   </td><td>DataImport</td><td>response column: label                                                                                                                                                                              </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>07:03:53.263</td><td>INFO   </td><td>DataImport</td><td>fold column: null                                                                                                                                                                                   </td><td>      </td><td>       </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[434 rows x 6 columns]</pre>"
      ],
      "text/plain": [
       "timestamp     level    stage       message                                                                                                                                                                                               name    value\n",
       "------------  -------  ----------  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------  -------\n",
       "07:03:53.262  INFO     Workflow    Project: AutoML_2_20230922_70353\n",
       "07:03:53.262  INFO     Validation  5-fold cross-validation will be used.\n",
       "07:03:53.262  INFO     Validation  Setting stopping tolerance adaptively based on the training frame: 0.016685216106649997\n",
       "07:03:53.262  INFO     Validation  Build control seed: 23372\n",
       "07:03:53.263  INFO     DataImport  training frame: Frame key: AutoML_2_20230922_70353_training_Key_Frame__upload_bb830e471e8c01632129daebf3ef48ed.hex    cols: 1025    rows: 3592  chunks: 4    size: 403868  checksum: -87072914012808\n",
       "07:03:53.263  INFO     DataImport  validation frame: NULL\n",
       "07:03:53.263  INFO     DataImport  leaderboard frame: NULL\n",
       "07:03:53.263  INFO     DataImport  blending frame: NULL\n",
       "07:03:53.263  INFO     DataImport  response column: label\n",
       "07:03:53.263  INFO     DataImport  fold column: null\n",
       "[434 rows x 6 columns]\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get AutoML event log\n",
    "log = aml.event_log\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "144b1c52-2d88-4884-9572-d96a44b29c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'creation_epoch': '1695366233',\n",
       " 'start_epoch': '1695366233',\n",
       " 'start_XGBoost_def_2': '1695366233',\n",
       " 'start_GLM_def_1': '1695366243',\n",
       " 'start_GBM_def_5': '1695366248',\n",
       " 'start_StackedEnsemble_best_of_family_1': '1695366269',\n",
       " 'start_XGBoost_def_1': '1695366270',\n",
       " 'start_DRF_def_1': '1695366274',\n",
       " 'start_GBM_def_2': '1695366287',\n",
       " 'start_GBM_def_3': '1695366305',\n",
       " 'start_GBM_def_4': '1695366328',\n",
       " 'start_StackedEnsemble_best_of_family_2': '1695366349',\n",
       " 'start_StackedEnsemble_all_2': '1695366350',\n",
       " 'start_XGBoost_def_3': '1695366350',\n",
       " 'start_DRF_XRT': '1695366357',\n",
       " 'start_GBM_def_1': '1695366365',\n",
       " 'start_DeepLearning_def_1': '1695366378',\n",
       " 'start_StackedEnsemble_best_of_family_3': '1695366396',\n",
       " 'start_StackedEnsemble_all_3': '1695366396',\n",
       " 'start_XGBoost_grid_1': '1695366397',\n",
       " 'start_GBM_grid_1': '1695366947',\n",
       " 'start_DeepLearning_grid_1': '1695367281',\n",
       " 'start_StackedEnsemble_best_of_family_4': '1695369014',\n",
       " 'start_StackedEnsemble_all_4': '1695369015',\n",
       " 'start_DeepLearning_grid_2': '1695369017',\n",
       " 'start_DeepLearning_grid_3': '1695369359',\n",
       " 'start_StackedEnsemble_best_of_family_5': '1695369693',\n",
       " 'start_StackedEnsemble_all_5': '1695369693',\n",
       " 'start_XGBoost_lr_search': '1695369696',\n",
       " 'start_GBM_lr_annealing': '1695369720',\n",
       " 'start_StackedEnsemble_best_of_family_gbm': '1695369730',\n",
       " 'start_StackedEnsemble_all_gbm': '1695369734',\n",
       " 'start_StackedEnsemble_best_of_family_xglm': '1695369755',\n",
       " 'start_StackedEnsemble_all_xglm': '1695369759',\n",
       " 'start_completion_GBM_grid_1': '1695369780',\n",
       " 'start_completion_XGBoost_grid_1': '1695369801',\n",
       " 'start_StackedEnsemble_best_of_family': '1695369813',\n",
       " 'start_StackedEnsemble_best_N': '1695369814',\n",
       " 'stop_epoch': '1695369817',\n",
       " 'duration_secs': '3584'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get training timing info\n",
    "info = aml.training_info\n",
    "info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
