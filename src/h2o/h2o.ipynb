{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bdd4295-8dfa-4e4c-91ad-fb756d4e85ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "Random State for reproduceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b65a39-45a2-48d6-a8cc-6ec1186d2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "dagstuhl_seed=23372"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28eda4-8c34-4744-b674-a074ff9c300a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f85df1-4143-4d09-956c-3d56839b21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989eb01e-d24c-4a9b-a4f4-cc8ae3ab5e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>inactive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label    0    1    2    3    4    5    6    7    8  ...  1014  1015  \\\n",
       "4306  inactive  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4307  inactive  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4308  inactive  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4309  inactive  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4310  inactive  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "      1016  1017  1018  1019  1020  1021  1022  1023  \n",
       "4306   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "4307   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4308   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "4309   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4310   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/preprocessed.csv')\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "df_train = pd.read_csv('../../data/preprocessed-train.csv')\n",
    "df_train = df_train.loc[:, ~df_train.columns.str.contains('^Unnamed')]\n",
    "\n",
    "df_test = pd.read_csv('../../data/preprocessed-test.csv')\n",
    "df_test = df_test.loc[:, ~df_test.columns.str.contains('^Unnamed')]\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86aeca34-8fa2-416f-a782-49039c18c3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3592, 1024)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_train['label']\n",
    "X = df_train.loc[:, df_train.columns != \"label\"]\n",
    "X.to_numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0c61ae-4bc3-4537-8c72-fb6091ea6b25",
   "metadata": {},
   "source": [
    "# AutoML Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8079b20e-8d35-4176-a6c8-d609f14a0dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_min = 30\n",
    "time_sec = time_min * 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ecc4d0-9bb4-4b05-8372-9b9860baae0e",
   "metadata": {},
   "source": [
    "## H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa99b35-a678-450c-84b2-762db595bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"17.0.8.1\" 2023-08-24; OpenJDK Runtime Environment (build 17.0.8.1+1-Ubuntu-0ubuntu122.04); OpenJDK 64-Bit Server VM (build 17.0.8.1+1-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n",
      "  Starting server from /opt/conda/lib/python3.9/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmphji_lbqg\n",
      "  JVM stdout: /tmp/tmphji_lbqg/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmphji_lbqg/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.42.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_unknownUser_hgafym</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.887 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.13 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.42.0.3\n",
       "H2O_cluster_version_age:    1 month\n",
       "H2O_cluster_name:           H2O_from_python_unknownUser_hgafym\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.887 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.13 final\n",
       "--------------------------  ----------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init(nthreads=-1, log_level=\"TRACE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1de82fc0-4d67-4e75-aec9-03daef6ccdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "hf = h2o.H2OFrame(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bc6dbe0-510e-4a0f-a4c7-3fcc5bf667df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "18:18:00.855: Project: AutoML_1_20230922_181800\n",
      "18:18:00.859: 5-fold cross-validation will be used.\n",
      "18:18:00.861: Setting stopping tolerance adaptively based on the training frame: 0.016685216106649997\n",
      "18:18:00.861: Build control seed: 23372\n",
      "18:18:00.865: training frame: Frame key: AutoML_1_20230922_181800_training_Key_Frame__upload_8bfa346ee01820b397e31d91bab24bb2.hex    cols: 1025    rows: 3592  chunks: 4    size: 403868  checksum: -87072914012808\n",
      "18:18:00.865: validation frame: NULL\n",
      "18:18:00.865: leaderboard frame: NULL\n",
      "18:18:00.866: blending frame: NULL\n",
      "18:18:00.866: response column: label\n",
      "18:18:00.867: fold column: null\n",
      "18:18:00.867: weights column: null\n",
      "18:18:00.895: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
      "18:18:00.923: Defined work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_1, GLM, ModelBuild, group=1, weight=10}, Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{best_of_family_1, StackedEnsemble, ModelBuild, group=1, weight=5}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_1, DRF, ModelBuild, group=2, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{best_of_family_2, StackedEnsemble, ModelBuild, group=2, weight=5}, Work{all_2, StackedEnsemble, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{XRT, DRF, ModelBuild, group=3, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{def_1, DeepLearning, ModelBuild, group=3, weight=10}, Work{best_of_family_3, StackedEnsemble, ModelBuild, group=3, weight=5}, Work{all_3, StackedEnsemble, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{grid_1, DeepLearning, HyperparamSearch, group=4, weight=30}, Work{best_of_family_4, StackedEnsemble, ModelBuild, group=4, weight=5}, Work{all_4, StackedEnsemble, ModelBuild, group=4, weight=10}, Work{grid_2, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{grid_3, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{best_of_family_5, StackedEnsemble, ModelBuild, group=5, weight=5}, Work{all_5, StackedEnsemble, ModelBuild, group=5, weight=10}, Work{lr_search, XGBoost, Selection, group=6, weight=30}, Work{lr_annealing, GBM, Selection, group=6, weight=10}, Work{monotonic, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{best_of_family_gbm, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{all_gbm, StackedEnsemble, ModelBuild, group=7, weight=10}, Work{best_of_family_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{all_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}, Work{best_of_family, StackedEnsemble, ModelBuild, group=10, weight=10}, Work{best_N, StackedEnsemble, ModelBuild, group=10, weight=10}]\n",
      "18:18:00.923: Actual work allocations: [Work{def_2, XGBoost, ModelBuild, group=1, weight=10}, Work{def_1, GLM, ModelBuild, group=1, weight=10}, Work{def_5, GBM, ModelBuild, group=1, weight=10}, Work{best_of_family_1, StackedEnsemble, ModelBuild, group=1, weight=5}, Work{def_1, XGBoost, ModelBuild, group=2, weight=10}, Work{def_1, DRF, ModelBuild, group=2, weight=10}, Work{def_2, GBM, ModelBuild, group=2, weight=10}, Work{def_3, GBM, ModelBuild, group=2, weight=10}, Work{def_4, GBM, ModelBuild, group=2, weight=10}, Work{best_of_family_2, StackedEnsemble, ModelBuild, group=2, weight=5}, Work{all_2, StackedEnsemble, ModelBuild, group=2, weight=10}, Work{def_3, XGBoost, ModelBuild, group=3, weight=10}, Work{XRT, DRF, ModelBuild, group=3, weight=10}, Work{def_1, GBM, ModelBuild, group=3, weight=10}, Work{def_1, DeepLearning, ModelBuild, group=3, weight=10}, Work{best_of_family_3, StackedEnsemble, ModelBuild, group=3, weight=5}, Work{all_3, StackedEnsemble, ModelBuild, group=3, weight=10}, Work{grid_1, XGBoost, HyperparamSearch, group=4, weight=90}, Work{grid_1, GBM, HyperparamSearch, group=4, weight=60}, Work{grid_1, DeepLearning, HyperparamSearch, group=4, weight=30}, Work{best_of_family_4, StackedEnsemble, ModelBuild, group=4, weight=5}, Work{all_4, StackedEnsemble, ModelBuild, group=4, weight=10}, Work{grid_2, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{grid_3, DeepLearning, HyperparamSearch, group=5, weight=30}, Work{best_of_family_5, StackedEnsemble, ModelBuild, group=5, weight=5}, Work{all_5, StackedEnsemble, ModelBuild, group=5, weight=10}, Work{lr_search, XGBoost, Selection, group=6, weight=30}, Work{lr_annealing, GBM, Selection, group=6, weight=10}, Work{monotonic, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{best_of_family_gbm, StackedEnsemble, ModelBuild, group=6, weight=10}, Work{all_gbm, StackedEnsemble, ModelBuild, group=7, weight=10}, Work{best_of_family_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{all_xglm, StackedEnsemble, ModelBuild, group=8, weight=10}, Work{resume_best_grids, virtual, Dynamic, group=10, weight=60}, Work{best_of_family, StackedEnsemble, ModelBuild, group=10, weight=10}, Work{best_N, StackedEnsemble, ModelBuild, group=10, weight=10}]\n",
      "18:18:00.925: AutoML job created: 2023.09.22 18:18:00.813\n",
      "18:18:00.926: AutoML build started: 2023.09.22 18:18:00.926\n",
      "18:18:00.962: Time assigned for XGBoost_1_AutoML_1_20230922_181800: 514.2754375s\n",
      "18:18:00.963: AutoML: starting XGBoost_1_AutoML_1_20230922_181800 model training\n",
      "18:18:00.976: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:18:00.977: XGBoost_1_AutoML_1_20230922_181800 [XGBoost def_2] started\n",
      "\n",
      "██\n",
      "18:18:12.656: XGBoost_1_AutoML_1_20230922_181800 [XGBoost def_2] complete\n",
      "18:18:12.656: Adding model XGBoost_1_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=7s, total=12s\n",
      "18:18:12.686: New leader: XGBoost_1_AutoML_1_20230922_181800, auc: 0.7302163172961492\n",
      "18:18:12.696: Time assigned for GLM_1_AutoML_1_20230922_181800: 715.292s\n",
      "18:18:12.697: AutoML: starting GLM_1_AutoML_1_20230922_181800 model training\n",
      "18:18:12.700: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:18:12.700: GLM_1_AutoML_1_20230922_181800 [GLM def_1] started\n",
      "\n",
      "█\n",
      "18:18:19.60: GLM_1_AutoML_1_20230922_181800 [GLM def_1] complete\n",
      "18:18:19.60: Adding model GLM_1_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=6s\n",
      "18:18:19.62: New leader: GLM_1_AutoML_1_20230922_181800, auc: 0.776140456182473\n",
      "18:18:19.73: Time assigned for GBM_1_AutoML_1_20230922_181800: 1187.902s\n",
      "18:18:19.73: AutoML: starting GBM_1_AutoML_1_20230922_181800 model training\n",
      "18:18:19.78: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:18:19.78: GBM_1_AutoML_1_20230922_181800 [GBM def_5] started\n",
      "\n",
      "██\n",
      "18:18:41.899: GBM_1_AutoML_1_20230922_181800 [GBM def_5] complete\n",
      "18:18:41.899: Adding model GBM_1_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=8s, total=23s\n",
      "18:18:41.914: Time assigned for StackedEnsemble_BestOfFamily_1_AutoML_1_20230922_181800: 1759.012s\n",
      "18:18:41.914: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_1_20230922_181800 model training\n",
      "18:18:41.916: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:18:41.917: StackedEnsemble_BestOfFamily_1_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_1 (built with AUTO metalearner, using top model from each algorithm type)] started\n",
      "18:18:42.616: StackedEnsemble_BestOfFamily_1_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_1 (built with AUTO metalearner, using top model from each algorithm type)] complete\n",
      "18:18:42.616: Adding model StackedEnsemble_BestOfFamily_1_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=1s\n",
      "18:18:42.619: New leader: StackedEnsemble_BestOfFamily_1_AutoML_1_20230922_181800, auc: 0.7842921784098255\n",
      "18:18:42.623: Time assigned for XGBoost_2_AutoML_1_20230922_181800: 270.50815625s\n",
      "18:18:42.623: AutoML: starting XGBoost_2_AutoML_1_20230922_181800 model training\n",
      "18:18:42.628: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:18:42.628: XGBoost_2_AutoML_1_20230922_181800 [XGBoost def_1] started\n",
      "\n",
      "\n",
      "18:18:46.564: XGBoost_2_AutoML_1_20230922_181800 [XGBoost def_1] complete\n",
      "18:18:46.564: Adding model XGBoost_2_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "18:18:46.572: Time assigned for DRF_1_AutoML_1_20230922_181800: 318.97346875s\n",
      "18:18:46.573: AutoML: starting DRF_1_AutoML_1_20230922_181800 model training\n",
      "18:18:46.575: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:18:46.576: DRF_1_AutoML_1_20230922_181800 [DRF def_1] started\n",
      "\n",
      "██\n",
      "18:19:01.8: DRF_1_AutoML_1_20230922_181800 [DRF def_1] complete\n",
      "18:19:01.8: Adding model DRF_1_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=4s, total=14s\n",
      "18:19:01.20: Time assigned for GBM_2_AutoML_1_20230922_181800: 386.64578125s\n",
      "18:19:01.20: AutoML: starting GBM_2_AutoML_1_20230922_181800 model training\n",
      "18:19:01.24: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:19:01.25: GBM_2_AutoML_1_20230922_181800 [GBM def_2] started\n",
      "\n",
      "█\n",
      "18:19:24.921: GBM_2_AutoML_1_20230922_181800 [GBM def_2] complete\n",
      "18:19:24.921: Adding model GBM_2_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=8s, total=24s\n",
      "18:19:24.929: Time assigned for GBM_3_AutoML_1_20230922_181800: 490.28515625s\n",
      "18:19:24.929: AutoML: starting GBM_3_AutoML_1_20230922_181800 model training\n",
      "18:19:24.932: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:19:24.932: GBM_3_AutoML_1_20230922_181800 [GBM def_3] started\n",
      "\n",
      "██\n",
      "18:19:50.455: GBM_3_AutoML_1_20230922_181800 [GBM def_3] complete\n",
      "18:19:50.456: Adding model GBM_3_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=8s, total=26s\n",
      "18:19:50.459: New leader: GBM_3_AutoML_1_20230922_181800, auc: 0.7913196047649829\n",
      "18:19:50.463: Time assigned for GBM_4_AutoML_1_20230922_181800: 676.1851875s\n",
      "18:19:50.463: AutoML: starting GBM_4_AutoML_1_20230922_181800 model training\n",
      "18:19:50.466: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:19:50.466: GBM_4_AutoML_1_20230922_181800 [GBM def_4] started\n",
      "\n",
      "\n",
      "18:20:11.676: GBM_4_AutoML_1_20230922_181800 [GBM def_4] complete\n",
      "18:20:11.676: Adding model GBM_4_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=7s, total=21s\n",
      "18:20:11.692: Time assigned for StackedEnsemble_BestOfFamily_2_AutoML_1_20230922_181800: 556.411375s\n",
      "18:20:11.692: AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_1_20230922_181800 model training\n",
      "18:20:11.696: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:20:11.696: StackedEnsemble_BestOfFamily_2_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_2 (built with AUTO metalearner, using top model from each algorithm type)] started\n",
      "18:20:12.273: StackedEnsemble_BestOfFamily_2_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_2 (built with AUTO metalearner, using top model from each algorithm type)] complete\n",
      "18:20:12.273: Adding model StackedEnsemble_BestOfFamily_2_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=1s\n",
      "18:20:12.278: New leader: StackedEnsemble_BestOfFamily_2_AutoML_1_20230922_181800, auc: 0.8040712438821682\n",
      "18:20:12.285: Time assigned for StackedEnsemble_AllModels_1_AutoML_1_20230922_181800: 1668.641s\n",
      "18:20:12.285: AutoML: starting StackedEnsemble_AllModels_1_AutoML_1_20230922_181800 model training\n",
      "18:20:12.288: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:20:12.288: StackedEnsemble_AllModels_1_AutoML_1_20230922_181800 [StackedEnsemble all_2 (built with AUTO metalearner, using all AutoML models)] started\n",
      "18:20:12.807: StackedEnsemble_AllModels_1_AutoML_1_20230922_181800 [StackedEnsemble all_2 (built with AUTO metalearner, using all AutoML models)] complete\n",
      "18:20:12.807: Adding model StackedEnsemble_AllModels_1_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=1s\n",
      "18:20:12.816: Time assigned for XGBoost_3_AutoML_1_20230922_181800: 303.29275s\n",
      "18:20:12.817: AutoML: starting XGBoost_3_AutoML_1_20230922_181800 model training\n",
      "18:20:12.820: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:20:12.820: XGBoost_3_AutoML_1_20230922_181800 [XGBoost def_3] started\n",
      "\n",
      "██\n",
      "18:20:21.260: XGBoost_3_AutoML_1_20230922_181800 [XGBoost def_3] complete\n",
      "18:20:21.260: Adding model XGBoost_3_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=3s, total=8s\n",
      "18:20:21.272: Time assigned for XRT_1_AutoML_1_20230922_181800: 368.812s\n",
      "18:20:21.272: AutoML: starting XRT_1_AutoML_1_20230922_181800 model training\n",
      "18:20:21.276: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:20:21.276: XRT_1_AutoML_1_20230922_181800 [DRF XRT (Extremely Randomized Trees)] started\n",
      "\n",
      "██\n",
      "18:20:31.256: XRT_1_AutoML_1_20230922_181800 [DRF XRT (Extremely Randomized Trees)] complete\n",
      "18:20:31.257: Adding model XRT_1_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=10s\n",
      "18:20:31.269: Time assigned for GBM_5_AutoML_1_20230922_181800: 471.33059375s\n",
      "18:20:31.269: AutoML: starting GBM_5_AutoML_1_20230922_181800 model training\n",
      "18:20:31.274: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:20:31.275: GBM_5_AutoML_1_20230922_181800 [GBM def_1] started\n",
      "\n",
      "█\n",
      "18:20:44.680: GBM_5_AutoML_1_20230922_181800 [GBM def_1] complete\n",
      "18:20:44.680: Adding model GBM_5_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=4s, total=13s\n",
      "18:20:44.692: Time assigned for DeepLearning_1_AutoML_1_20230922_181800: 654.493625s\n",
      "18:20:44.692: AutoML: starting DeepLearning_1_AutoML_1_20230922_181800 model training\n",
      "18:20:44.694: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:20:44.695: DeepLearning_1_AutoML_1_20230922_181800 [DeepLearning def_1] started\n",
      "\n",
      "█\n",
      "18:20:59.24: DeepLearning_1_AutoML_1_20230922_181800 [DeepLearning def_1] complete\n",
      "18:20:59.24: Adding model DeepLearning_1_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=14s\n",
      "18:20:59.35: Time assigned for StackedEnsemble_BestOfFamily_3_AutoML_1_20230922_181800: 540.630375s\n",
      "18:20:59.35: AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_1_20230922_181800 model training\n",
      "18:20:59.38: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:20:59.38: StackedEnsemble_BestOfFamily_3_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_3 (built with AUTO metalearner, using top model from each algorithm type)] started\n",
      "\n",
      "\n",
      "18:20:59.528: StackedEnsemble_BestOfFamily_3_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_3 (built with AUTO metalearner, using top model from each algorithm type)] complete\n",
      "18:20:59.528: Adding model StackedEnsemble_BestOfFamily_3_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=0s, total=0s\n",
      "18:20:59.541: Time assigned for StackedEnsemble_AllModels_2_AutoML_1_20230922_181800: 1621.386s\n",
      "18:20:59.541: AutoML: starting StackedEnsemble_AllModels_2_AutoML_1_20230922_181800 model training\n",
      "18:20:59.548: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:20:59.548: StackedEnsemble_AllModels_2_AutoML_1_20230922_181800 [StackedEnsemble all_3 (built with AUTO metalearner, using all AutoML models)] started\n",
      "18:21:00.212: StackedEnsemble_AllModels_2_AutoML_1_20230922_181800 [StackedEnsemble all_3 (built with AUTO metalearner, using all AutoML models)] complete\n",
      "18:21:00.213: Adding model StackedEnsemble_AllModels_2_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=1s\n",
      "18:21:00.224: Time assigned for XGBoost_grid_1_AutoML_1_20230922_181800: 748.01725s\n",
      "18:21:00.224: AutoML: starting XGBoost_grid_1_AutoML_1_20230922_181800 hyperparameter search\n",
      "18:21:00.243: XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search] started\n",
      "\n",
      "█\n",
      "18:21:04.244: Built: 1 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:04.244: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_1 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "\n",
      "█\n",
      "18:21:07.256: Built: 2 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:07.256: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_2 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "18:21:10.266: Built: 3 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:10.266: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_3 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "\n",
      "\n",
      "18:21:16.284: Built: 4 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:16.284: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_4 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=6s\n",
      "18:21:19.294: Built: 5 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:19.294: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_5 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "18:21:22.307: Built: 6 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:22.307: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_6 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "\n",
      "\n",
      "18:21:26.320: Built: 7 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:26.320: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_7 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "18:21:29.333: Built: 8 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:29.333: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_8 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "\n",
      "█\n",
      "18:21:32.347: Built: 9 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:32.347: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_9 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "18:21:37.372: Built: 10 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:37.372: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_10 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=5s\n",
      "\n",
      "\n",
      "18:21:41.411: Built: 11 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:41.411: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_11 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "18:21:45.431: Built: 12 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:45.431: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_12 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "\n",
      "\n",
      "18:21:50.447: Built: 13 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:50.447: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_13 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=6s\n",
      "\n",
      "\n",
      "18:21:57.459: Built: 14 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:21:57.460: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_14 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=3s, total=7s\n",
      "18:22:03.483: Built: 15 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:03.483: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_15 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=6s\n",
      "\n",
      "\n",
      "18:22:08.504: Built: 16 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:08.504: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_16 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "\n",
      "\n",
      "18:22:13.553: Built: 17 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:13.553: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_17 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=5s\n",
      "18:22:16.567: Built: 18 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:16.567: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_18 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "18:22:19.583: Built: 19 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:19.583: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_19 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "\n",
      "\n",
      "18:22:24.624: Built: 20 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:24.624: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_20 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=5s\n",
      "18:22:28.646: Built: 21 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:28.647: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_21 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "\n",
      "\n",
      "18:22:32.671: Built: 22 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:32.671: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_22 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "18:22:36.690: Built: 23 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:36.690: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_23 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "\n",
      "\n",
      "18:22:39.723: Built: 24 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:39.724: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_24 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=4s\n",
      "18:22:43.765: Built: 25 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:43.766: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_25 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "\n",
      "\n",
      "18:22:47.803: Built: 26 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:47.803: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_26 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "18:22:51.829: Built: 27 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:51.829: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_27 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "18:22:54.862: Built: 28 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:54.862: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_28 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "\n",
      "█\n",
      "18:22:56.891: Built: 29 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:56.892: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_29 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "18:22:59.912: Built: 30 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:22:59.912: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_30 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "\n",
      "\n",
      "18:23:03.941: Built: 31 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:23:03.942: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_31 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "18:23:06.964: Built: 32 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:23:06.964: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_32 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "\n",
      "\n",
      "18:23:18.17: Built: 33 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:23:18.17: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_33 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=3s, total=10s\n",
      "\n",
      "\n",
      "18:23:24.54: Built: 34 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:23:24.55: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_34 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=3s, total=6s\n",
      "18:23:28.119: Built: 35 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:23:28.119: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_35 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "\n",
      "\n",
      "18:23:30.147: Built: 36 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:23:30.148: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_36 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "18:23:33.206: Built: 37 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:23:33.206: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_37 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "\n",
      "\n",
      "18:23:38.228: Built: 38 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:23:38.228: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_38 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=5s\n",
      "18:23:43.272: Built: 39 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:23:43.272: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_39 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=5s\n",
      "\n",
      "\n",
      "18:23:47.308: Built: 40 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:23:47.309: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_40 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "18:23:51.352: Built: 41 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:23:51.352: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_41 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=5s\n",
      "\n",
      "\n",
      "18:23:56.370: Built: 42 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:23:56.371: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_42 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "18:23:59.409: Built: 43 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:23:59.409: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_43 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "\n",
      "\n",
      "18:24:02.431: Built: 44 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:02.432: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_44 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "18:24:06.479: Built: 45 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:06.479: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_45 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "\n",
      "\n",
      "18:24:10.502: Built: 46 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:10.503: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_46 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "18:24:13.537: Built: 47 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:13.538: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_47 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "18:24:17.568: Built: 48 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:17.568: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_48 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "\n",
      "█\n",
      "18:24:22.612: Built: 49 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:22.612: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_49 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=5s\n",
      "\n",
      "\n",
      "18:24:27.655: Built: 50 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:27.656: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_50 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=6s\n",
      "18:24:32.711: Built: 51 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:32.711: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_51 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "\n",
      "\n",
      "18:24:35.748: Built: 52 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:35.748: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_52 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "18:24:41.792: Built: 53 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:41.793: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_53 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=5s\n",
      "\n",
      "\n",
      "18:24:45.848: Built: 54 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:45.848: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_54 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "18:24:49.876: Built: 55 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:49.877: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_55 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "\n",
      "\n",
      "18:24:53.917: Built: 56 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:53.917: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_56 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "18:24:56.967: Built: 57 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:24:56.967: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_57 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "\n",
      "\n",
      "18:25:01.18: Built: 58 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:25:01.19: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_58 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "18:25:06.61: Built: 59 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:25:06.62: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_59 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=5s\n",
      "\n",
      "\n",
      "18:25:12.145: Built: 60 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:25:12.146: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_60 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=5s\n",
      "18:25:15.206: Built: 61 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:25:15.207: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_61 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=4s\n",
      "\n",
      "\n",
      "18:25:18.287: Built: 62 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:25:18.288: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_62 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "18:25:22.337: Built: 63 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:25:22.338: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_63 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=3s\n",
      "\n",
      "\n",
      "18:25:27.915: XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search] complete\n",
      "18:25:27.915: Built: 64 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:25:27.916: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_64 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=7s\n",
      "18:25:27.960: Time assigned for GBM_grid_1_AutoML_1_20230922_181800: 773.1240625s\n",
      "18:25:27.960: AutoML: starting GBM_grid_1_AutoML_1_20230922_181800 hyperparameter search\n",
      "18:25:27.963: GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search] started\n",
      "\n",
      "███████\n",
      "18:25:46.971: Built: 1 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:25:46.972: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_1 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=3s, total=18s\n",
      "\n",
      "█\n",
      "18:26:06.184: Built: 2 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:26:06.184: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_2 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=3s, total=19s\n",
      "\n",
      "\n",
      "18:26:17.372: Built: 3 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:26:17.372: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_3 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=11s\n",
      "18:26:22.469: Built: 4 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:26:22.469: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_4 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=5s\n",
      "\n",
      "\n",
      "18:26:40.493: Built: 5 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:26:40.494: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_5 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=7s, total=18s\n",
      "\n",
      "█\n",
      "18:26:50.571: Built: 6 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:26:50.571: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_6 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=10s\n",
      "\n",
      "\n",
      "18:27:02.667: Built: 7 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:27:02.667: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_7 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=12s\n",
      "\n",
      "\n",
      "18:27:09.723: Built: 8 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:27:09.723: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_8 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=8s\n",
      "\n",
      "\n",
      "18:27:26.778: Built: 9 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:27:26.778: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_9 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=3s, total=17s\n",
      "\n",
      "█\n",
      "18:27:37.835: Built: 10 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:27:37.835: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_10 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=11s\n",
      "\n",
      "\n",
      "18:28:12.936: Built: 11 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:28:12.937: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_11 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=13s, total=35s\n",
      "\n",
      "█\n",
      "18:28:35.59: Built: 12 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:28:35.60: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_12 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=4s, total=21s\n",
      "\n",
      "\n",
      "18:28:47.250: Built: 13 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:28:47.251: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_13 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=12s\n",
      "\n",
      "\n",
      "18:28:52.320: Built: 14 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:28:52.321: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_14 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=6s\n",
      "\n",
      "\n",
      "18:29:15.572: GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search] complete\n",
      "18:29:15.572: Built: 15 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:29:15.573: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_15 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=8s, total=23s\n",
      "18:29:15.605: Time assigned for DeepLearning_grid_1_AutoML_1_20230922_181800: 750.214s\n",
      "18:29:15.605: AutoML: starting DeepLearning_grid_1_AutoML_1_20230922_181800 hyperparameter search\n",
      "18:29:15.607: DeepLearning_grid_1_AutoML_1_20230922_181800 [DeepLearning Grid Search] started\n",
      "\n",
      "███████████████████\n",
      "18:36:43.842: Built: 1 models for HyperparamSearch : DeepLearning_grid_1_AutoML_1_20230922_181800 [DeepLearning Grid Search]\n",
      "18:36:43.842: Adding model DeepLearning_grid_1_AutoML_1_20230922_181800_model_1 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=68s, total=447s\n",
      "\n",
      "███\n",
      "18:39:52.161: Built: 2 models for HyperparamSearch : DeepLearning_grid_1_AutoML_1_20230922_181800 [DeepLearning Grid Search]\n",
      "18:39:52.161: Adding model DeepLearning_grid_1_AutoML_1_20230922_181800_model_2 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=27s, total=188s\n",
      "\n",
      "█\n",
      "18:41:07.421: Built: 3 models for HyperparamSearch : DeepLearning_grid_1_AutoML_1_20230922_181800 [DeepLearning Grid Search]\n",
      "18:41:07.422: Adding model DeepLearning_grid_1_AutoML_1_20230922_181800_model_3 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=9s, total=76s\n",
      "\n",
      "█\n",
      "18:41:31.540: Built: 4 models for HyperparamSearch : DeepLearning_grid_1_AutoML_1_20230922_181800 [DeepLearning Grid Search]\n",
      "18:41:31.540: Adding model DeepLearning_grid_1_AutoML_1_20230922_181800_model_4 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=3s, total=25s\n",
      "\n",
      "\n",
      "18:41:54.630: DeepLearning_grid_1_AutoML_1_20230922_181800 [DeepLearning Grid Search] complete\n",
      "18:41:54.630: Built: 5 models for HyperparamSearch : DeepLearning_grid_1_AutoML_1_20230922_181800 [DeepLearning Grid Search]\n",
      "18:41:54.630: Adding model DeepLearning_grid_1_AutoML_1_20230922_181800_model_5 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=5s, total=23s\n",
      "18:41:54.674: Time assigned for StackedEnsemble_BestOfFamily_4_AutoML_1_20230922_181800: 122.084s\n",
      "18:41:54.674: AutoML: starting StackedEnsemble_BestOfFamily_4_AutoML_1_20230922_181800 model training\n",
      "18:41:54.677: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:41:54.679: StackedEnsemble_BestOfFamily_4_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_4 (built with AUTO metalearner, using top model from each algorithm type)] started\n",
      "18:41:55.66: StackedEnsemble_BestOfFamily_4_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_4 (built with AUTO metalearner, using top model from each algorithm type)] complete\n",
      "18:41:55.66: Adding model StackedEnsemble_BestOfFamily_4_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=0s, total=0s\n",
      "18:41:55.105: New leader: StackedEnsemble_BestOfFamily_4_AutoML_1_20230922_181800, auc: 0.8114299565980237\n",
      "18:41:55.111: Time assigned for StackedEnsemble_AllModels_3_AutoML_1_20230922_181800: 365.815s\n",
      "18:41:55.111: AutoML: starting StackedEnsemble_AllModels_3_AutoML_1_20230922_181800 model training\n",
      "18:41:55.117: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:41:55.118: StackedEnsemble_AllModels_3_AutoML_1_20230922_181800 [StackedEnsemble all_4 (built with AUTO metalearner, using all AutoML models)] started\n",
      "\n",
      "\n",
      "18:41:56.986: StackedEnsemble_AllModels_3_AutoML_1_20230922_181800 [StackedEnsemble all_4 (built with AUTO metalearner, using all AutoML models)] complete\n",
      "18:41:56.986: Adding model StackedEnsemble_AllModels_3_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=2s\n",
      "18:41:57.41: Time assigned for DeepLearning_grid_2_AutoML_1_20230922_181800: 145.554s\n",
      "18:41:57.41: AutoML: starting DeepLearning_grid_2_AutoML_1_20230922_181800 hyperparameter search\n",
      "18:41:57.43: DeepLearning_grid_2_AutoML_1_20230922_181800 [DeepLearning Grid Search] started\n",
      "\n",
      "██\n",
      "18:43:25.78: Built: 1 models for HyperparamSearch : DeepLearning_grid_2_AutoML_1_20230922_181800 [DeepLearning Grid Search]\n",
      "18:43:25.79: Adding model DeepLearning_grid_2_AutoML_1_20230922_181800_model_1 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=13s, total=88s\n",
      "\n",
      "\n",
      "18:44:03.205: Built: 2 models for HyperparamSearch : DeepLearning_grid_2_AutoML_1_20230922_181800 [DeepLearning Grid Search]\n",
      "18:44:03.205: Adding model DeepLearning_grid_2_AutoML_1_20230922_181800_model_2 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=4s, total=38s\n",
      "\n",
      "█\n",
      "18:44:27.159: DeepLearning_grid_2_AutoML_1_20230922_181800 [DeepLearning Grid Search] complete\n",
      "18:44:27.159: Built: 3 models for HyperparamSearch : DeepLearning_grid_2_AutoML_1_20230922_181800 [DeepLearning Grid Search]\n",
      "18:44:27.159: Adding model DeepLearning_grid_2_AutoML_1_20230922_181800_model_3 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=5s, total=25s\n",
      "18:44:27.223: Time assigned for DeepLearning_grid_3_AutoML_1_20230922_181800: 142.468671875s\n",
      "18:44:27.223: AutoML: starting DeepLearning_grid_3_AutoML_1_20230922_181800 hyperparameter search\n",
      "18:44:27.226: DeepLearning_grid_3_AutoML_1_20230922_181800 [DeepLearning Grid Search] started\n",
      "\n",
      "█\n",
      "18:45:52.292: Built: 1 models for HyperparamSearch : DeepLearning_grid_3_AutoML_1_20230922_181800 [DeepLearning Grid Search]\n",
      "18:45:52.292: Adding model DeepLearning_grid_3_AutoML_1_20230922_181800_model_1 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=10s, total=84s\n",
      "\n",
      "█\n",
      "18:46:33.418: Built: 2 models for HyperparamSearch : DeepLearning_grid_3_AutoML_1_20230922_181800 [DeepLearning Grid Search]\n",
      "18:46:33.418: Adding model DeepLearning_grid_3_AutoML_1_20230922_181800_model_2 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=4s, total=42s\n",
      "\n",
      "\n",
      "18:46:59.789: DeepLearning_grid_3_AutoML_1_20230922_181800 [DeepLearning Grid Search] complete\n",
      "18:46:59.789: Built: 3 models for HyperparamSearch : DeepLearning_grid_3_AutoML_1_20230922_181800 [DeepLearning Grid Search]\n",
      "18:46:59.789: Adding model DeepLearning_grid_3_AutoML_1_20230922_181800_model_3 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=5s, total=26s\n",
      "18:46:59.828: Time assigned for StackedEnsemble_BestOfFamily_5_AutoML_1_20230922_181800: 20.366s\n",
      "18:46:59.828: AutoML: starting StackedEnsemble_BestOfFamily_5_AutoML_1_20230922_181800 model training\n",
      "18:46:59.831: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:46:59.832: StackedEnsemble_BestOfFamily_5_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_5 (built with AUTO metalearner, using top model from each algorithm type)] started\n",
      "\n",
      "\n",
      "18:47:00.395: StackedEnsemble_BestOfFamily_5_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_5 (built with AUTO metalearner, using top model from each algorithm type)] complete\n",
      "18:47:00.395: Adding model StackedEnsemble_BestOfFamily_5_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=1s, total=1s\n",
      "18:47:00.460: Time assigned for StackedEnsemble_AllModels_4_AutoML_1_20230922_181800: 60.466s\n",
      "18:47:00.460: AutoML: starting StackedEnsemble_AllModels_4_AutoML_1_20230922_181800 model training\n",
      "18:47:00.467: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:47:00.468: StackedEnsemble_AllModels_4_AutoML_1_20230922_181800 [StackedEnsemble all_5 (built with AUTO metalearner, using all AutoML models)] started\n",
      "\n",
      "\n",
      "18:47:02.756: StackedEnsemble_AllModels_4_AutoML_1_20230922_181800 [StackedEnsemble all_5 (built with AUTO metalearner, using all AutoML models)] complete\n",
      "18:47:02.756: Adding model StackedEnsemble_AllModels_4_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=2s\n",
      "18:47:02.794: Time assigned for XGBoost_lr_search_selection_AutoML_1_20230922_181800: 10.2585888671875s\n",
      "18:47:02.799: XGBoost_lr_search_selection_AutoML_1_20230922_181800 [XGBoost lr_search] started\n",
      "18:47:02.799: Applying learning rate search on best XGBoost: XGBoost_grid_1_AutoML_1_20230922_181800_model_60\n",
      "18:47:02.799: AutoML: starting XGBoost_lr_search_selection_AutoML_1_20230922_181800_select model training\n",
      "\n",
      "█\n",
      "18:47:13.317: XGBoost_lr_search_selection_AutoML_1_20230922_181800 [XGBoost lr_search] complete\n",
      "18:47:13.317: Time assigned for GBM_lr_annealing_selection_AutoML_1_20230922_181800: 3.40064306640625s\n",
      "18:47:13.319: GBM_lr_annealing_selection_AutoML_1_20230922_181800 [GBM lr_annealing] started\n",
      "18:47:13.319: Retraining best GBM with learning rate annealing: GBM_3_AutoML_1_20230922_181800\n",
      "18:47:13.320: AutoML: starting GBM_lr_annealing_selection_AutoML_1_20230922_181800_select_model model training\n",
      "18:47:13.323: _train param, Dropping bad and constant columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "\n",
      "\n",
      "18:47:18.478: GBM_lr_annealing_selection_AutoML_1_20230922_181800 [GBM lr_annealing] complete\n",
      "18:47:18.480: No base models, due to timeouts or the exclude_algos option. Skipping StackedEnsemble 'monotonic'.\n",
      "18:47:18.484: Time assigned for StackedEnsemble_BestOfFamily_6_AutoML_1_20230922_181800: 42.442s\n",
      "18:47:18.484: AutoML: starting StackedEnsemble_BestOfFamily_6_AutoML_1_20230922_181800 model training\n",
      "18:47:18.487: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:47:18.489: StackedEnsemble_BestOfFamily_6_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_gbm (built with gbm metalearner, using top model from each algorithm type)] started\n",
      "\n",
      "\n",
      "18:47:22.202: StackedEnsemble_BestOfFamily_6_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_gbm (built with gbm metalearner, using top model from each algorithm type)] complete\n",
      "18:47:22.202: Adding model StackedEnsemble_BestOfFamily_6_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=4s, total=4s\n",
      "18:47:22.259: Time assigned for StackedEnsemble_AllModels_5_AutoML_1_20230922_181800: 38.667s\n",
      "18:47:22.259: AutoML: starting StackedEnsemble_AllModels_5_AutoML_1_20230922_181800 model training\n",
      "18:47:22.265: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:47:22.267: StackedEnsemble_AllModels_5_AutoML_1_20230922_181800 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)] started\n",
      "\n",
      "\n",
      "18:47:40.54: StackedEnsemble_AllModels_5_AutoML_1_20230922_181800 [StackedEnsemble all_gbm (built with gbm metalearner, using all AutoML models)] complete\n",
      "18:47:40.54: Adding model StackedEnsemble_AllModels_5_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=18s, total=18s\n",
      "18:47:40.99: Time assigned for StackedEnsemble_BestOfFamily_7_AutoML_1_20230922_181800: 10.4135s\n",
      "18:47:40.99: AutoML: starting StackedEnsemble_BestOfFamily_7_AutoML_1_20230922_181800 model training\n",
      "18:47:40.103: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:47:40.105: StackedEnsemble_BestOfFamily_7_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_xglm (built with AUTO metalearner, using top model from each algorithm type)] started\n",
      "\n",
      "\n",
      "18:47:42.812: StackedEnsemble_BestOfFamily_7_AutoML_1_20230922_181800 [StackedEnsemble best_of_family_xglm (built with AUTO metalearner, using top model from each algorithm type)] complete\n",
      "18:47:42.813: Adding model StackedEnsemble_BestOfFamily_7_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=3s, total=3s\n",
      "18:47:42.861: Time assigned for StackedEnsemble_AllModels_6_AutoML_1_20230922_181800: 18.065s\n",
      "18:47:42.861: AutoML: starting StackedEnsemble_AllModels_6_AutoML_1_20230922_181800 model training\n",
      "18:47:42.867: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:47:42.868: StackedEnsemble_AllModels_6_AutoML_1_20230922_181800 [StackedEnsemble all_xglm (built with AUTO metalearner, using all AutoML models)] started\n",
      "\n",
      "█| (done) 100%\n",
      "\n",
      "18:47:56.436: StackedEnsemble_AllModels_6_AutoML_1_20230922_181800 [StackedEnsemble all_xglm (built with AUTO metalearner, using all AutoML models)] complete\n",
      "18:47:56.437: Adding model StackedEnsemble_AllModels_6_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=14s, total=14s\n",
      "18:47:56.500: Time assigned for GBM_grid_1_AutoML_1_20230922_181800: 1.65975s\n",
      "18:47:56.500: AutoML: starting GBM_grid_1_AutoML_1_20230922_181800 hyperparameter search\n",
      "18:47:56.504: GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search] started\n",
      "18:47:56.504: Built: 15 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:47:58.504: Built: 16 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:47:58.505: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_31 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=0s, total=1s\n",
      "18:47:58.792: GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search] complete\n",
      "18:47:58.792: Built: 17 models for HyperparamSearch : GBM_grid_1_AutoML_1_20230922_181800 [GBM Grid Search]\n",
      "18:47:58.792: Adding model GBM_grid_1_AutoML_1_20230922_181800_model_32 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=0s, total=1s\n",
      "18:47:58.834: Time assigned for XGBoost_grid_1_AutoML_1_20230922_181800: 0.784875s\n",
      "18:47:58.834: AutoML: starting XGBoost_grid_1_AutoML_1_20230922_181800 hyperparameter search\n",
      "18:47:58.836: XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search] started\n",
      "18:47:58.836: Built: 64 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:47:59.796: XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search] complete\n",
      "18:47:59.796: Built: 65 models for HyperparamSearch : XGBoost_grid_1_AutoML_1_20230922_181800 [XGBoost Grid Search]\n",
      "18:47:59.796: Adding model XGBoost_grid_1_AutoML_1_20230922_181800_model_129 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=0s, total=1s\n",
      "18:47:59.840: Time assigned for StackedEnsemble_Best1000_1_AutoML_1_20230922_181800: 1.086s\n",
      "18:47:59.840: AutoML: starting StackedEnsemble_Best1000_1_AutoML_1_20230922_181800 model training\n",
      "18:47:59.844: _train param, Dropping unused columns: [390, 153, 230, 671, 595, 793, 870, 354, 475, 311, 477, 797, 436, 513, 437, 93, 912, 638, 717, 16, 161, 243, 2, 365, 168, 201, 443, 203, 522, 127, 205, 689, 1023, 405, 768, 648, 529, 20, 21, 68, 173, 450, 572, 331, 530, 651, 377, 410, 454, 411, 774, 776, 930, 217, 415, 459, 858, 618, 817, 78, 185, 340, 780, 187, 1008, 100, 388, 465, 866, 82, 109, 903, 906]\n",
      "18:47:59.846: StackedEnsemble_Best1000_1_AutoML_1_20230922_181800 [StackedEnsemble best_N (built with AUTO metalearner, using best 1000 non-SE models)] started\n",
      "18:48:01.846: AutoML: out of time; skipping StackedEnsemble_Best1000_1_AutoML_1_20230922_181800 [StackedEnsemble best_N (built with AUTO metalearner, using best 1000 non-SE models)]\n",
      "18:48:02.140: StackedEnsemble_Best1000_1_AutoML_1_20230922_181800 [StackedEnsemble best_N (built with AUTO metalearner, using best 1000 non-SE models)] complete\n",
      "18:48:02.141: Adding model StackedEnsemble_Best1000_1_AutoML_1_20230922_181800 to leaderboard Leaderboard_AutoML_1_20230922_181800@@label. Training time: model=2s, total=2s\n",
      "18:48:02.181: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}, {StackedEnsemble : [best_of_family_4 (4g, 5w), all_4 (4g, 10w)]}, {DeepLearning : [grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {StackedEnsemble : [best_of_family_5 (5g, 5w), all_5 (5g, 10w)]}, {XGBoost : [lr_search (6g, 30w)]}, {GBM : [lr_annealing (6g, 10w)]}, {StackedEnsemble : [best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_N (10g, 10w)]}]\n",
      "18:48:02.181: AutoML build stopped: 2023.09.22 18:48:02.181\n",
      "18:48:02.181: AutoML build done: built 105 models\n",
      "18:48:02.181: AutoML duration: 30 min  1.255 sec\n",
      "18:48:02.206: Verifying training frame immutability. . .\n",
      "18:48:02.207: Training frame was not mutated (as expected).\n",
      "\n",
      "CPU times: user 29.2 s, sys: 1.66 s, total: 30.8 s\n",
      "Wall time: 30min 2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_BestOfFamily_4_AutoML_1_20230922_181800\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary for Stacked Ensemble: </caption>\n",
       "    <thead><tr><th>key</th>\n",
       "<th>value</th></tr></thead>\n",
       "    <tbody><tr><td>Stacking strategy</td>\n",
       "<td>cross_validation</td></tr>\n",
       "<tr><td>Number of base models (used / total)</td>\n",
       "<td>4/6</td></tr>\n",
       "<tr><td># GBM base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># XGBoost base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># DRF base models (used / total)</td>\n",
       "<td>1/2</td></tr>\n",
       "<tr><td># GLM base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># DeepLearning base models (used / total)</td>\n",
       "<td>0/1</td></tr>\n",
       "<tr><td>Metalearner algorithm</td>\n",
       "<td>GLM</td></tr>\n",
       "<tr><td>Metalearner fold assignment scheme</td>\n",
       "<td>Random</td></tr>\n",
       "<tr><td>Metalearner nfolds</td>\n",
       "<td>5</td></tr>\n",
       "<tr><td>Metalearner fold_column</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Custom metalearner hyperparameters</td>\n",
       "<td>None</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.02033863968715726\n",
       "RMSE: 0.14261360274236556\n",
       "LogLoss: 0.0921351403784241\n",
       "AUC: 0.9931070505125127\n",
       "AUCPR: 0.9994299647456739\n",
       "Gini: 0.9862141010250254\n",
       "Null degrees of freedom: 3591\n",
       "Residual degrees of freedom: 3587\n",
       "Null deviance: 1866.1161989374114\n",
       "Residual deviance: 661.8988484785988\n",
       "AIC: 671.8988484785988</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7055721307497054</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>active</th>\n",
       "<th>inactive</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>active</td>\n",
       "<td>227.0</td>\n",
       "<td>33.0</td>\n",
       "<td>0.1269</td>\n",
       "<td> (33.0/260.0)</td></tr>\n",
       "<tr><td>inactive</td>\n",
       "<td>19.0</td>\n",
       "<td>3313.0</td>\n",
       "<td>0.0057</td>\n",
       "<td> (19.0/3332.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>246.0</td>\n",
       "<td>3346.0</td>\n",
       "<td>0.0145</td>\n",
       "<td> (52.0/3592.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.7055721</td>\n",
       "<td>0.9922132</td>\n",
       "<td>244.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.6127356</td>\n",
       "<td>0.9953344</td>\n",
       "<td>272.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7575334</td>\n",
       "<td>0.9915561</td>\n",
       "<td>227.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7088787</td>\n",
       "<td>0.9855234</td>\n",
       "<td>243.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9951951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.4842365</td>\n",
       "<td>1.0</td>\n",
       "<td>295.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9951951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7088787</td>\n",
       "<td>0.8901410</td>\n",
       "<td>243.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.8531265</td>\n",
       "<td>0.9582833</td>\n",
       "<td>189.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.8563307</td>\n",
       "<td>0.9619563</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9951951</td>\n",
       "<td>260.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9951951</td>\n",
       "<td>3323.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0180867</td>\n",
       "<td>260.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.4842365</td>\n",
       "<td>3332.0</td>\n",
       "<td>295.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9951951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9951951</td>\n",
       "<td>0.9972989</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0180867</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.4842365</td>\n",
       "<td>1.0</td>\n",
       "<td>295.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 92.76 %, avg score: 91.32 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100223</td>\n",
       "<td>0.9935902</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943354</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943354</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0108043</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.0108043</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200445</td>\n",
       "<td>0.9924947</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929672</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9936513</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0216086</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.0216086</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300668</td>\n",
       "<td>0.9917397</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9920781</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9931269</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0324130</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.0324130</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400891</td>\n",
       "<td>0.9912263</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9914635</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9927111</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0432173</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.0432173</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0501114</td>\n",
       "<td>0.9908626</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9910993</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9923887</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0540216</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.0540216</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1002227</td>\n",
       "<td>0.9885841</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9897258</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9910573</td>\n",
       "<td>0.0540216</td>\n",
       "<td>0.1080432</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.1080432</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500557</td>\n",
       "<td>0.9863114</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9874960</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9898746</td>\n",
       "<td>0.0537215</td>\n",
       "<td>0.1617647</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.1617647</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2001670</td>\n",
       "<td>0.9838409</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9851045</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9886804</td>\n",
       "<td>0.0540216</td>\n",
       "<td>0.2157863</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.2157863</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3001114</td>\n",
       "<td>0.9784100</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9813243</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9862306</td>\n",
       "<td>0.1077431</td>\n",
       "<td>0.3235294</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.3235294</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4003341</td>\n",
       "<td>0.9725196</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9754980</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9835437</td>\n",
       "<td>0.1080432</td>\n",
       "<td>0.4315726</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.4315726</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9654334</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9692281</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9806902</td>\n",
       "<td>0.1074430</td>\n",
       "<td>0.5390156</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.5390156</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5999443</td>\n",
       "<td>0.9569453</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9614134</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9774789</td>\n",
       "<td>0.1077431</td>\n",
       "<td>0.6467587</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.8031212</td>\n",
       "<td>0.6467587</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6998886</td>\n",
       "<td>0.9431363</td>\n",
       "<td>1.0750283</td>\n",
       "<td>1.0776024</td>\n",
       "<td>0.9972145</td>\n",
       "<td>0.9506059</td>\n",
       "<td>0.9996022</td>\n",
       "<td>0.9736414</td>\n",
       "<td>0.1074430</td>\n",
       "<td>0.7542017</td>\n",
       "<td>7.5028340</td>\n",
       "<td>7.7602401</td>\n",
       "<td>0.7503555</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7998330</td>\n",
       "<td>0.9191346</td>\n",
       "<td>1.0720255</td>\n",
       "<td>1.0769055</td>\n",
       "<td>0.9944290</td>\n",
       "<td>0.9324370</td>\n",
       "<td>0.9989558</td>\n",
       "<td>0.9684926</td>\n",
       "<td>0.1071429</td>\n",
       "<td>0.8613445</td>\n",
       "<td>7.2025468</td>\n",
       "<td>7.6905527</td>\n",
       "<td>0.8498061</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8997773</td>\n",
       "<td>0.8332448</td>\n",
       "<td>1.0419967</td>\n",
       "<td>1.0730280</td>\n",
       "<td>0.9665738</td>\n",
       "<td>0.8892129</td>\n",
       "<td>0.9953589</td>\n",
       "<td>0.9596865</td>\n",
       "<td>0.1041417</td>\n",
       "<td>0.9654862</td>\n",
       "<td>4.1996743</td>\n",
       "<td>7.3027974</td>\n",
       "<td>0.9077939</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0180867</td>\n",
       "<td>0.3443711</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3194444</td>\n",
       "<td>0.4961241</td>\n",
       "<td>0.9276169</td>\n",
       "<td>0.9132270</td>\n",
       "<td>0.0345138</td>\n",
       "<td>1.0</td>\n",
       "<td>-65.5628918</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.05568601588670723\n",
       "RMSE: 0.23597884626954854\n",
       "LogLoss: 0.2066375209910182\n",
       "AUC: 0.8114299565980237\n",
       "AUCPR: 0.9766729132211267\n",
       "Gini: 0.6228599131960475\n",
       "Null degrees of freedom: 3591\n",
       "Residual degrees of freedom: 3586\n",
       "Null deviance: 1867.9636839921757\n",
       "Residual deviance: 1484.4839507994752\n",
       "AIC: 1496.4839507994752</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.38680527590647507</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>active</th>\n",
       "<th>inactive</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>active</td>\n",
       "<td>29.0</td>\n",
       "<td>231.0</td>\n",
       "<td>0.8885</td>\n",
       "<td> (231.0/260.0)</td></tr>\n",
       "<tr><td>inactive</td>\n",
       "<td>8.0</td>\n",
       "<td>3324.0</td>\n",
       "<td>0.0024</td>\n",
       "<td> (8.0/3332.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>37.0</td>\n",
       "<td>3555.0</td>\n",
       "<td>0.0665</td>\n",
       "<td> (239.0/3592.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3868053</td>\n",
       "<td>0.9652969</td>\n",
       "<td>367.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1868277</td>\n",
       "<td>0.9854490</td>\n",
       "<td>387.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7849400</td>\n",
       "<td>0.9531063</td>\n",
       "<td>258.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3868053</td>\n",
       "<td>0.9334633</td>\n",
       "<td>367.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9864655</td>\n",
       "<td>0.9926063</td>\n",
       "<td>22.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1868277</td>\n",
       "<td>1.0</td>\n",
       "<td>387.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9958068</td>\n",
       "<td>0.9961538</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7849400</td>\n",
       "<td>0.3512198</td>\n",
       "<td>258.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9353613</td>\n",
       "<td>0.7304922</td>\n",
       "<td>127.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9382342</td>\n",
       "<td>0.7343938</td>\n",
       "<td>123.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9958068</td>\n",
       "<td>259.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9958068</td>\n",
       "<td>3329.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0542393</td>\n",
       "<td>260.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.1868277</td>\n",
       "<td>3332.0</td>\n",
       "<td>387.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9958068</td>\n",
       "<td>0.9961538</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9958068</td>\n",
       "<td>0.9990996</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0542393</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.1868277</td>\n",
       "<td>1.0</td>\n",
       "<td>387.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 92.76 %, avg score: 92.77 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100223</td>\n",
       "<td>0.9936086</td>\n",
       "<td>1.0181406</td>\n",
       "<td>1.0181406</td>\n",
       "<td>0.9444444</td>\n",
       "<td>0.9945264</td>\n",
       "<td>0.9444444</td>\n",
       "<td>0.9945264</td>\n",
       "<td>0.0102041</td>\n",
       "<td>0.0102041</td>\n",
       "<td>1.8140590</td>\n",
       "<td>1.8140590</td>\n",
       "<td>0.0025118</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200445</td>\n",
       "<td>0.9930123</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0480859</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933306</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.9939285</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0210084</td>\n",
       "<td>7.8031212</td>\n",
       "<td>4.8085901</td>\n",
       "<td>0.0133161</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300668</td>\n",
       "<td>0.9921847</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0580677</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925702</td>\n",
       "<td>0.9814815</td>\n",
       "<td>0.9934757</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0318127</td>\n",
       "<td>7.8031212</td>\n",
       "<td>5.8067672</td>\n",
       "<td>0.0241204</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400891</td>\n",
       "<td>0.9916170</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0630586</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9919277</td>\n",
       "<td>0.9861111</td>\n",
       "<td>0.9930887</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0426170</td>\n",
       "<td>7.8031212</td>\n",
       "<td>6.3058557</td>\n",
       "<td>0.0349247</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0501114</td>\n",
       "<td>0.9911002</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0660531</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9913555</td>\n",
       "<td>0.9888889</td>\n",
       "<td>0.9927421</td>\n",
       "<td>0.0108043</td>\n",
       "<td>0.0534214</td>\n",
       "<td>7.8031212</td>\n",
       "<td>6.6053088</td>\n",
       "<td>0.0457291</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1002227</td>\n",
       "<td>0.9886469</td>\n",
       "<td>1.0660531</td>\n",
       "<td>1.0660531</td>\n",
       "<td>0.9888889</td>\n",
       "<td>0.9898266</td>\n",
       "<td>0.9888889</td>\n",
       "<td>0.9912844</td>\n",
       "<td>0.0534214</td>\n",
       "<td>0.1068427</td>\n",
       "<td>6.6053088</td>\n",
       "<td>6.6053088</td>\n",
       "<td>0.0914581</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500557</td>\n",
       "<td>0.9863084</td>\n",
       "<td>1.0780312</td>\n",
       "<td>1.0700310</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9875430</td>\n",
       "<td>0.9925788</td>\n",
       "<td>0.9900419</td>\n",
       "<td>0.0537215</td>\n",
       "<td>0.1605642</td>\n",
       "<td>7.8031212</td>\n",
       "<td>7.0030981</td>\n",
       "<td>0.1451796</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2001670</td>\n",
       "<td>0.9839281</td>\n",
       "<td>1.0600640</td>\n",
       "<td>1.0675358</td>\n",
       "<td>0.9833333</td>\n",
       "<td>0.9851419</td>\n",
       "<td>0.9902643</td>\n",
       "<td>0.9888152</td>\n",
       "<td>0.0531212</td>\n",
       "<td>0.2136855</td>\n",
       "<td>6.0064026</td>\n",
       "<td>6.7535776</td>\n",
       "<td>0.1867624</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3001114</td>\n",
       "<td>0.9784353</td>\n",
       "<td>1.0600140</td>\n",
       "<td>1.0650308</td>\n",
       "<td>0.9832869</td>\n",
       "<td>0.9812675</td>\n",
       "<td>0.9879406</td>\n",
       "<td>0.9863016</td>\n",
       "<td>0.1059424</td>\n",
       "<td>0.3196279</td>\n",
       "<td>6.0013978</td>\n",
       "<td>6.5030836</td>\n",
       "<td>0.2696279</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000557</td>\n",
       "<td>0.9720265</td>\n",
       "<td>1.0570111</td>\n",
       "<td>1.0630273</td>\n",
       "<td>0.9805014</td>\n",
       "<td>0.9753553</td>\n",
       "<td>0.9860821</td>\n",
       "<td>0.9835669</td>\n",
       "<td>0.1056423</td>\n",
       "<td>0.4252701</td>\n",
       "<td>5.7011105</td>\n",
       "<td>6.3027299</td>\n",
       "<td>0.3483470</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9639125</td>\n",
       "<td>1.0419967</td>\n",
       "<td>1.0588235</td>\n",
       "<td>0.9665738</td>\n",
       "<td>0.9682395</td>\n",
       "<td>0.9821826</td>\n",
       "<td>0.9805032</td>\n",
       "<td>0.1041417</td>\n",
       "<td>0.5294118</td>\n",
       "<td>4.1996743</td>\n",
       "<td>5.8823529</td>\n",
       "<td>0.4063348</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5999443</td>\n",
       "<td>0.9526935</td>\n",
       "<td>1.0269824</td>\n",
       "<td>1.0535191</td>\n",
       "<td>0.9526462</td>\n",
       "<td>0.9588166</td>\n",
       "<td>0.9772622</td>\n",
       "<td>0.9768904</td>\n",
       "<td>0.1026411</td>\n",
       "<td>0.6320528</td>\n",
       "<td>2.6982381</td>\n",
       "<td>5.3519134</td>\n",
       "<td>0.4435913</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6998886</td>\n",
       "<td>0.9345436</td>\n",
       "<td>1.0089651</td>\n",
       "<td>1.0471568</td>\n",
       "<td>0.9359331</td>\n",
       "<td>0.9444936</td>\n",
       "<td>0.9713604</td>\n",
       "<td>0.9722641</td>\n",
       "<td>0.1008403</td>\n",
       "<td>0.7328932</td>\n",
       "<td>0.8965146</td>\n",
       "<td>4.7156810</td>\n",
       "<td>0.4559701</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7998330</td>\n",
       "<td>0.9062936</td>\n",
       "<td>0.9849422</td>\n",
       "<td>1.0393827</td>\n",
       "<td>0.9136490</td>\n",
       "<td>0.9218404</td>\n",
       "<td>0.9641490</td>\n",
       "<td>0.9659634</td>\n",
       "<td>0.0984394</td>\n",
       "<td>0.8313325</td>\n",
       "<td>-1.5057834</td>\n",
       "<td>3.9382687</td>\n",
       "<td>0.4351787</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8997773</td>\n",
       "<td>0.8417531</td>\n",
       "<td>0.9699278</td>\n",
       "<td>1.0316679</td>\n",
       "<td>0.8997214</td>\n",
       "<td>0.8790649</td>\n",
       "<td>0.9569926</td>\n",
       "<td>0.9563110</td>\n",
       "<td>0.0969388</td>\n",
       "<td>0.9282713</td>\n",
       "<td>-3.0072196</td>\n",
       "<td>3.1667865</td>\n",
       "<td>0.3936559</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0539960</td>\n",
       "<td>0.7156929</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6638889</td>\n",
       "<td>0.6703879</td>\n",
       "<td>0.9276169</td>\n",
       "<td>0.9276550</td>\n",
       "<td>0.0717287</td>\n",
       "<td>1.0</td>\n",
       "<td>-28.4307056</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9358094</td>\n",
       "<td>0.0064132</td>\n",
       "<td>0.9413534</td>\n",
       "<td>0.9381720</td>\n",
       "<td>0.9297521</td>\n",
       "<td>0.9415855</td>\n",
       "<td>0.9281843</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.8111817</td>\n",
       "<td>0.0269480</td>\n",
       "<td>0.8406321</td>\n",
       "<td>0.7796037</td>\n",
       "<td>0.8378777</td>\n",
       "<td>0.8024905</td>\n",
       "<td>0.7953048</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0641905</td>\n",
       "<td>0.0064132</td>\n",
       "<td>0.0586466</td>\n",
       "<td>0.0618280</td>\n",
       "<td>0.0702479</td>\n",
       "<td>0.0584145</td>\n",
       "<td>0.0718157</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>46.2</td>\n",
       "<td>5.890671</td>\n",
       "<td>39.0</td>\n",
       "<td>46.0</td>\n",
       "<td>51.0</td>\n",
       "<td>42.0</td>\n",
       "<td>53.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9498739</td>\n",
       "<td>0.0064801</td>\n",
       "<td>0.9519408</td>\n",
       "<td>0.9533665</td>\n",
       "<td>0.9430756</td>\n",
       "<td>0.9577222</td>\n",
       "<td>0.9432644</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9663957</td>\n",
       "<td>0.0034772</td>\n",
       "<td>0.9694118</td>\n",
       "<td>0.9677871</td>\n",
       "<td>0.9631236</td>\n",
       "<td>0.9694323</td>\n",
       "<td>0.9622238</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9835245</td>\n",
       "<td>0.0024467</td>\n",
       "<td>0.9875360</td>\n",
       "<td>0.9826508</td>\n",
       "<td>0.9840425</td>\n",
       "<td>0.9814324</td>\n",
       "<td>0.981961</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>1.0241274</td>\n",
       "<td>0.0738450</td>\n",
       "<td>1.0760518</td>\n",
       "<td>0.9353448</td>\n",
       "<td>1.0884558</td>\n",
       "<td>1.0683507</td>\n",
       "<td>0.9524337</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.2062719</td>\n",
       "<td>0.0163552</td>\n",
       "<td>0.1902299</td>\n",
       "<td>0.2035905</td>\n",
       "<td>0.2127781</td>\n",
       "<td>0.1938268</td>\n",
       "<td>0.2309341</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.8251229</td>\n",
       "<td>0.0372828</td>\n",
       "<td>0.8297872</td>\n",
       "<td>0.8541667</td>\n",
       "<td>0.8474576</td>\n",
       "<td>0.7608696</td>\n",
       "<td>0.8333333</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.4149123</td>\n",
       "<td>0.0174130</td>\n",
       "<td>0.4148936</td>\n",
       "<td>0.4306753</td>\n",
       "<td>0.4244784</td>\n",
       "<td>0.3856354</td>\n",
       "<td>0.4188791</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0555887</td>\n",
       "<td>0.0051007</td>\n",
       "<td>0.0511506</td>\n",
       "<td>0.0535681</td>\n",
       "<td>0.0589758</td>\n",
       "<td>0.0514633</td>\n",
       "<td>0.0627856</td></tr>\n",
       "<tr><td>null_deviance</td>\n",
       "<td>373.59274</td>\n",
       "<td>37.565002</td>\n",
       "<td>339.70676</td>\n",
       "<td>357.06476</td>\n",
       "<td>410.56888</td>\n",
       "<td>343.1259</td>\n",
       "<td>417.49738</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9774215</td>\n",
       "<td>0.0073942</td>\n",
       "<td>0.9842110</td>\n",
       "<td>0.9723029</td>\n",
       "<td>0.9817545</td>\n",
       "<td>0.9818222</td>\n",
       "<td>0.9670169</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9391804</td>\n",
       "<td>0.0085360</td>\n",
       "<td>0.9406393</td>\n",
       "<td>0.9439891</td>\n",
       "<td>0.9301676</td>\n",
       "<td>0.9500713</td>\n",
       "<td>0.9310345</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.1687580</td>\n",
       "<td>0.0461382</td>\n",
       "<td>0.2212330</td>\n",
       "<td>0.1124315</td>\n",
       "<td>0.2101048</td>\n",
       "<td>0.1406262</td>\n",
       "<td>0.1593946</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9952981</td>\n",
       "<td>0.0042156</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928161</td>\n",
       "<td>0.9985008</td>\n",
       "<td>0.9895988</td>\n",
       "<td>0.9955753</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>296.8968</td>\n",
       "<td>33.057842</td>\n",
       "<td>253.0058</td>\n",
       "<td>302.94263</td>\n",
       "<td>308.95377</td>\n",
       "<td>278.723</td>\n",
       "<td>340.85876</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.2355776</td>\n",
       "<td>0.0107169</td>\n",
       "<td>0.2261649</td>\n",
       "<td>0.2314479</td>\n",
       "<td>0.2428494</td>\n",
       "<td>0.2268551</td>\n",
       "<td>0.2505707</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.1748771</td>\n",
       "<td>0.0372828</td>\n",
       "<td>0.1702128</td>\n",
       "<td>0.1458333</td>\n",
       "<td>0.1525424</td>\n",
       "<td>0.2391304</td>\n",
       "<td>0.1666667</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 8 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_BestOfFamily_4_AutoML_1_20230922_181800\n",
       "\n",
       "\n",
       "Model Summary for Stacked Ensemble: \n",
       "key                                        value\n",
       "-----------------------------------------  ----------------\n",
       "Stacking strategy                          cross_validation\n",
       "Number of base models (used / total)       4/6\n",
       "# GBM base models (used / total)           1/1\n",
       "# XGBoost base models (used / total)       1/1\n",
       "# DRF base models (used / total)           1/2\n",
       "# GLM base models (used / total)           1/1\n",
       "# DeepLearning base models (used / total)  0/1\n",
       "Metalearner algorithm                      GLM\n",
       "Metalearner fold assignment scheme         Random\n",
       "Metalearner nfolds                         5\n",
       "Metalearner fold_column\n",
       "Custom metalearner hyperparameters         None\n",
       "\n",
       "ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.02033863968715726\n",
       "RMSE: 0.14261360274236556\n",
       "LogLoss: 0.0921351403784241\n",
       "AUC: 0.9931070505125127\n",
       "AUCPR: 0.9994299647456739\n",
       "Gini: 0.9862141010250254\n",
       "Null degrees of freedom: 3591\n",
       "Residual degrees of freedom: 3587\n",
       "Null deviance: 1866.1161989374114\n",
       "Residual deviance: 661.8988484785988\n",
       "AIC: 671.8988484785988\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7055721307497054\n",
       "          active    inactive    Error    Rate\n",
       "--------  --------  ----------  -------  -------------\n",
       "active    227       33          0.1269   (33.0/260.0)\n",
       "inactive  19        3313        0.0057   (19.0/3332.0)\n",
       "Total     246       3346        0.0145   (52.0/3592.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.705572     0.992213  244\n",
       "max f2                       0.612736     0.995334  272\n",
       "max f0point5                 0.757533     0.991556  227\n",
       "max accuracy                 0.708879     0.985523  243\n",
       "max precision                0.995195     1         0\n",
       "max recall                   0.484236     1         295\n",
       "max specificity              0.995195     1         0\n",
       "max absolute_mcc             0.708879     0.890141  243\n",
       "max min_per_class_accuracy   0.853126     0.958283  189\n",
       "max mean_per_class_accuracy  0.856331     0.961956  186\n",
       "max tns                      0.995195     260       0\n",
       "max fns                      0.995195     3323      0\n",
       "max fps                      0.0180867    260       399\n",
       "max tps                      0.484236     3332      295\n",
       "max tnr                      0.995195     1         0\n",
       "max fnr                      0.995195     0.997299  0\n",
       "max fpr                      0.0180867    1         399\n",
       "max tpr                      0.484236     1         295\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 92.76 %, avg score: 91.32 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100223                   0.99359            1.07803   1.07803            1                0.994335  1                           0.994335            0.0108043       0.0108043                  7.80312   7.80312            0.0108043\n",
       "2        0.0200445                   0.992495           1.07803   1.07803            1                0.992967  1                           0.993651            0.0108043       0.0216086                  7.80312   7.80312            0.0216086\n",
       "3        0.0300668                   0.99174            1.07803   1.07803            1                0.992078  1                           0.993127            0.0108043       0.032413                   7.80312   7.80312            0.032413\n",
       "4        0.0400891                   0.991226           1.07803   1.07803            1                0.991464  1                           0.992711            0.0108043       0.0432173                  7.80312   7.80312            0.0432173\n",
       "5        0.0501114                   0.990863           1.07803   1.07803            1                0.991099  1                           0.992389            0.0108043       0.0540216                  7.80312   7.80312            0.0540216\n",
       "6        0.100223                    0.988584           1.07803   1.07803            1                0.989726  1                           0.991057            0.0540216       0.108043                   7.80312   7.80312            0.108043\n",
       "7        0.150056                    0.986311           1.07803   1.07803            1                0.987496  1                           0.989875            0.0537215       0.161765                   7.80312   7.80312            0.161765\n",
       "8        0.200167                    0.983841           1.07803   1.07803            1                0.985104  1                           0.98868             0.0540216       0.215786                   7.80312   7.80312            0.215786\n",
       "9        0.300111                    0.97841            1.07803   1.07803            1                0.981324  1                           0.986231            0.107743        0.323529                   7.80312   7.80312            0.323529\n",
       "10       0.400334                    0.97252            1.07803   1.07803            1                0.975498  1                           0.983544            0.108043        0.431573                   7.80312   7.80312            0.431573\n",
       "11       0.5                         0.965433           1.07803   1.07803            1                0.969228  1                           0.98069             0.107443        0.539016                   7.80312   7.80312            0.539016\n",
       "12       0.599944                    0.956945           1.07803   1.07803            1                0.961413  1                           0.977479            0.107743        0.646759                   7.80312   7.80312            0.646759\n",
       "13       0.699889                    0.943136           1.07503   1.0776             0.997214         0.950606  0.999602                    0.973641            0.107443        0.754202                   7.50283   7.76024            0.750356\n",
       "14       0.799833                    0.919135           1.07203   1.07691            0.994429         0.932437  0.998956                    0.968493            0.107143        0.861345                   7.20255   7.69055            0.849806\n",
       "15       0.899777                    0.833245           1.042     1.07303            0.966574         0.889213  0.995359                    0.959687            0.104142        0.965486                   4.19967   7.3028             0.907794\n",
       "16       1                           0.0180867          0.344371  1                  0.319444         0.496124  0.927617                    0.913227            0.0345138       1                          -65.5629  0                  0\n",
       "\n",
       "ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.05568601588670723\n",
       "RMSE: 0.23597884626954854\n",
       "LogLoss: 0.2066375209910182\n",
       "AUC: 0.8114299565980237\n",
       "AUCPR: 0.9766729132211267\n",
       "Gini: 0.6228599131960475\n",
       "Null degrees of freedom: 3591\n",
       "Residual degrees of freedom: 3586\n",
       "Null deviance: 1867.9636839921757\n",
       "Residual deviance: 1484.4839507994752\n",
       "AIC: 1496.4839507994752\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.38680527590647507\n",
       "          active    inactive    Error    Rate\n",
       "--------  --------  ----------  -------  --------------\n",
       "active    29        231         0.8885   (231.0/260.0)\n",
       "inactive  8         3324        0.0024   (8.0/3332.0)\n",
       "Total     37        3555        0.0665   (239.0/3592.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.386805     0.965297  367\n",
       "max f2                       0.186828     0.985449  387\n",
       "max f0point5                 0.78494      0.953106  258\n",
       "max accuracy                 0.386805     0.933463  367\n",
       "max precision                0.986465     0.992606  22\n",
       "max recall                   0.186828     1         387\n",
       "max specificity              0.995807     0.996154  0\n",
       "max absolute_mcc             0.78494      0.35122   258\n",
       "max min_per_class_accuracy   0.935361     0.730492  127\n",
       "max mean_per_class_accuracy  0.938234     0.734394  123\n",
       "max tns                      0.995807     259       0\n",
       "max fns                      0.995807     3329      0\n",
       "max fps                      0.0542393    260       399\n",
       "max tps                      0.186828     3332      387\n",
       "max tnr                      0.995807     0.996154  0\n",
       "max fnr                      0.995807     0.9991    0\n",
       "max fpr                      0.0542393    1         399\n",
       "max tpr                      0.186828     1         387\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 92.76 %, avg score: 92.77 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100223                   0.993609           1.01814   1.01814            0.944444         0.994526  0.944444                    0.994526            0.0102041       0.0102041                  1.81406   1.81406            0.00251177\n",
       "2        0.0200445                   0.993012           1.07803   1.04809            1                0.993331  0.972222                    0.993929            0.0108043       0.0210084                  7.80312   4.80859            0.0133161\n",
       "3        0.0300668                   0.992185           1.07803   1.05807            1                0.99257   0.981481                    0.993476            0.0108043       0.0318127                  7.80312   5.80677            0.0241204\n",
       "4        0.0400891                   0.991617           1.07803   1.06306            1                0.991928  0.986111                    0.993089            0.0108043       0.042617                   7.80312   6.30586            0.0349247\n",
       "5        0.0501114                   0.9911             1.07803   1.06605            1                0.991356  0.988889                    0.992742            0.0108043       0.0534214                  7.80312   6.60531            0.0457291\n",
       "6        0.100223                    0.988647           1.06605   1.06605            0.988889         0.989827  0.988889                    0.991284            0.0534214       0.106843                   6.60531   6.60531            0.0914581\n",
       "7        0.150056                    0.986308           1.07803   1.07003            1                0.987543  0.992579                    0.990042            0.0537215       0.160564                   7.80312   7.0031             0.14518\n",
       "8        0.200167                    0.983928           1.06006   1.06754            0.983333         0.985142  0.990264                    0.988815            0.0531212       0.213685                   6.0064    6.75358            0.186762\n",
       "9        0.300111                    0.978435           1.06001   1.06503            0.983287         0.981268  0.987941                    0.986302            0.105942        0.319628                   6.0014    6.50308            0.269628\n",
       "10       0.400056                    0.972027           1.05701   1.06303            0.980501         0.975355  0.986082                    0.983567            0.105642        0.42527                    5.70111   6.30273            0.348347\n",
       "11       0.5                         0.963913           1.042     1.05882            0.966574         0.968239  0.982183                    0.980503            0.104142        0.529412                   4.19967   5.88235            0.406335\n",
       "12       0.599944                    0.952694           1.02698   1.05352            0.952646         0.958817  0.977262                    0.97689             0.102641        0.632053                   2.69824   5.35191            0.443591\n",
       "13       0.699889                    0.934544           1.00897   1.04716            0.935933         0.944494  0.97136                     0.972264            0.10084         0.732893                   0.896515  4.71568            0.45597\n",
       "14       0.799833                    0.906294           0.984942  1.03938            0.913649         0.92184   0.964149                    0.965963            0.0984394       0.831333                   -1.50578  3.93827            0.435179\n",
       "15       0.899777                    0.841753           0.969928  1.03167            0.899721         0.879065  0.956993                    0.956311            0.0969388       0.928271                   -3.00722  3.16679            0.393656\n",
       "16       1                           0.053996           0.715693  1                  0.663889         0.670388  0.927617                    0.927655            0.0717287       1                          -28.4307  0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                      mean        sd            cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "--------------------  ----------  ------------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy              0.93580943  0.0064131757  0.9413534     0.93817204    0.92975205    0.94158554    0.9281843\n",
       "auc                   0.8111817   0.026948027   0.8406321     0.77960366    0.8378777     0.8024905     0.79530483\n",
       "err                   0.06419054  0.0064131757  0.058646616   0.061827958   0.07024793    0.058414463   0.07181572\n",
       "err_count             46.2        5.890671      39.0          46.0          51.0          42.0          53.0\n",
       "f0point5              0.9498739   0.0064801197  0.95194083    0.95336646    0.9430756     0.9577222     0.94326437\n",
       "f1                    0.96639574  0.0034772388  0.9694118     0.9677871     0.9631236     0.9694323     0.9622238\n",
       "f2                    0.9835245   0.0024466885  0.98753595    0.98265076    0.9840425     0.9814324     0.981961\n",
       "lift_top_group        1.0241274   0.07384498    1.0760518     0.9353448     1.0884558     1.0683507     0.95243365\n",
       "logloss               0.20627189  0.0163552     0.19022992    0.20359048    0.21277808    0.19382682    0.23093411\n",
       "max_per_class_error   0.8251229   0.037282832   0.82978725    0.8541667     0.84745765    0.76086956    0.8333333\n",
       "---                   ---         ---           ---           ---           ---           ---           ---\n",
       "mean_per_class_error  0.41491234  0.017413044   0.41489363    0.4306753     0.42447844    0.38563538    0.41887906\n",
       "mse                   0.05558869  0.005100678   0.051150583   0.053568132   0.05897583    0.05146325    0.06278565\n",
       "null_deviance         373.59274   37.565002     339.70676     357.06476     410.56888     343.1259      417.49738\n",
       "pr_auc                0.9774215   0.0073941555  0.98421097    0.9723029     0.98175454    0.9818222     0.9670169\n",
       "precision             0.9391804   0.008535961   0.94063926    0.9439891     0.9301676     0.95007133    0.9310345\n",
       "r2                    0.16875802  0.04613821    0.22123301    0.11243145    0.21010481    0.14062622    0.15939459\n",
       "recall                0.99529815  0.0042155627  1.0           0.9928161     0.99850076    0.9895988     0.99557525\n",
       "residual_deviance     296.8968    33.057842     253.0058      302.94263     308.95377     278.723       340.85876\n",
       "rmse                  0.23557761  0.010716863   0.22616494    0.2314479     0.2428494     0.22685513    0.25057065\n",
       "specificity           0.17487712  0.037282832   0.17021276    0.14583333    0.15254237    0.23913044    0.16666667\n",
       "[22 rows x 8 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "aml = H2OAutoML(max_runtime_secs=time_sec, seed=dagstuhl_seed, verbosity=\"debug\")\n",
    "aml.train(y = 'label' , training_frame = hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e54b1cd-883a-409e-bfe3-fadc9579e9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "hf_test = h2o.H2OFrame(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7f3be7c-c4e8-4733-adf1-3c0eb96878fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9443671766342142"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = aml.predict(hf_test)\n",
    "accuracy_score(df_test[\"label\"], y_pred.as_data_frame()['predict']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1f62001-653d-412d-9343-57f2b8e7f2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>model_id                                               </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th><th>algo           </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_4_AutoML_1_20230922_181800</td><td style=\"text-align: right;\">0.81143 </td><td style=\"text-align: right;\"> 0.206638</td><td style=\"text-align: right;\">0.976673</td><td style=\"text-align: right;\">              0.445431</td><td style=\"text-align: right;\">0.235979</td><td style=\"text-align: right;\">0.055686 </td><td style=\"text-align: right;\">               379</td><td style=\"text-align: right;\">                 0.049236</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_5_AutoML_1_20230922_181800</td><td style=\"text-align: right;\">0.810435</td><td style=\"text-align: right;\"> 0.207089</td><td style=\"text-align: right;\">0.977956</td><td style=\"text-align: right;\">              0.452823</td><td style=\"text-align: right;\">0.236443</td><td style=\"text-align: right;\">0.0559052</td><td style=\"text-align: right;\">               557</td><td style=\"text-align: right;\">                 0.080024</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_4_AutoML_1_20230922_181800   </td><td style=\"text-align: right;\">0.807343</td><td style=\"text-align: right;\"> 0.207821</td><td style=\"text-align: right;\">0.97818 </td><td style=\"text-align: right;\">              0.445281</td><td style=\"text-align: right;\">0.236665</td><td style=\"text-align: right;\">0.0560105</td><td style=\"text-align: right;\">              2276</td><td style=\"text-align: right;\">                 0.153184</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_Best1000_1_AutoML_1_20230922_181800    </td><td style=\"text-align: right;\">0.806833</td><td style=\"text-align: right;\"> 0.208537</td><td style=\"text-align: right;\">0.978026</td><td style=\"text-align: right;\">              0.443808</td><td style=\"text-align: right;\">0.23735 </td><td style=\"text-align: right;\">0.056335 </td><td style=\"text-align: right;\">              2287</td><td style=\"text-align: right;\">                 0.1998  </td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_7_AutoML_1_20230922_181800</td><td style=\"text-align: right;\">0.806788</td><td style=\"text-align: right;\"> 0.208316</td><td style=\"text-align: right;\">0.976653</td><td style=\"text-align: right;\">              0.456369</td><td style=\"text-align: right;\">0.236921</td><td style=\"text-align: right;\">0.0561316</td><td style=\"text-align: right;\">              2697</td><td style=\"text-align: right;\">                 0.059739</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_3_AutoML_1_20230922_181800   </td><td style=\"text-align: right;\">0.806752</td><td style=\"text-align: right;\"> 0.207665</td><td style=\"text-align: right;\">0.977453</td><td style=\"text-align: right;\">              0.429174</td><td style=\"text-align: right;\">0.236421</td><td style=\"text-align: right;\">0.0558948</td><td style=\"text-align: right;\">              1858</td><td style=\"text-align: right;\">                 0.137612</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_6_AutoML_1_20230922_181800   </td><td style=\"text-align: right;\">0.805612</td><td style=\"text-align: right;\"> 0.208929</td><td style=\"text-align: right;\">0.97805 </td><td style=\"text-align: right;\">              0.438039</td><td style=\"text-align: right;\">0.237439</td><td style=\"text-align: right;\">0.0563774</td><td style=\"text-align: right;\">             13554</td><td style=\"text-align: right;\">                 0.203931</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_2_AutoML_1_20230922_181800</td><td style=\"text-align: right;\">0.804071</td><td style=\"text-align: right;\"> 0.20998 </td><td style=\"text-align: right;\">0.977521</td><td style=\"text-align: right;\">              0.447354</td><td style=\"text-align: right;\">0.238091</td><td style=\"text-align: right;\">0.0566873</td><td style=\"text-align: right;\">               570</td><td style=\"text-align: right;\">                 0.043956</td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_3_AutoML_1_20230922_181800</td><td style=\"text-align: right;\">0.803668</td><td style=\"text-align: right;\"> 0.210081</td><td style=\"text-align: right;\">0.977622</td><td style=\"text-align: right;\">              0.422382</td><td style=\"text-align: right;\">0.238159</td><td style=\"text-align: right;\">0.0567196</td><td style=\"text-align: right;\">               482</td><td style=\"text-align: right;\">                 0.04503 </td><td>StackedEnsemble</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_1_20230922_181800   </td><td style=\"text-align: right;\">0.803543</td><td style=\"text-align: right;\"> 0.210387</td><td style=\"text-align: right;\">0.977933</td><td style=\"text-align: right;\">              0.447354</td><td style=\"text-align: right;\">0.238497</td><td style=\"text-align: right;\">0.0568807</td><td style=\"text-align: right;\">               513</td><td style=\"text-align: right;\">                 0.058383</td><td>StackedEnsemble</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[119 rows x 10 columns]</pre>"
      ],
      "text/plain": [
       "model_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse        mse    training_time_ms    predict_time_per_row_ms  algo\n",
       "-------------------------------------------------------  --------  ---------  --------  ----------------------  --------  ---------  ------------------  -------------------------  ---------------\n",
       "StackedEnsemble_BestOfFamily_4_AutoML_1_20230922_181800  0.81143    0.206638  0.976673                0.445431  0.235979  0.055686                  379                   0.049236  StackedEnsemble\n",
       "StackedEnsemble_BestOfFamily_5_AutoML_1_20230922_181800  0.810435   0.207089  0.977956                0.452823  0.236443  0.0559052                 557                   0.080024  StackedEnsemble\n",
       "StackedEnsemble_AllModels_4_AutoML_1_20230922_181800     0.807343   0.207821  0.97818                 0.445281  0.236665  0.0560105                2276                   0.153184  StackedEnsemble\n",
       "StackedEnsemble_Best1000_1_AutoML_1_20230922_181800      0.806833   0.208537  0.978026                0.443808  0.23735   0.056335                 2287                   0.1998    StackedEnsemble\n",
       "StackedEnsemble_BestOfFamily_7_AutoML_1_20230922_181800  0.806788   0.208316  0.976653                0.456369  0.236921  0.0561316                2697                   0.059739  StackedEnsemble\n",
       "StackedEnsemble_AllModels_3_AutoML_1_20230922_181800     0.806752   0.207665  0.977453                0.429174  0.236421  0.0558948                1858                   0.137612  StackedEnsemble\n",
       "StackedEnsemble_AllModels_6_AutoML_1_20230922_181800     0.805612   0.208929  0.97805                 0.438039  0.237439  0.0563774               13554                   0.203931  StackedEnsemble\n",
       "StackedEnsemble_BestOfFamily_2_AutoML_1_20230922_181800  0.804071   0.20998   0.977521                0.447354  0.238091  0.0566873                 570                   0.043956  StackedEnsemble\n",
       "StackedEnsemble_BestOfFamily_3_AutoML_1_20230922_181800  0.803668   0.210081  0.977622                0.422382  0.238159  0.0567196                 482                   0.04503   StackedEnsemble\n",
       "StackedEnsemble_AllModels_1_AutoML_1_20230922_181800     0.803543   0.210387  0.977933                0.447354  0.238497  0.0568807                 513                   0.058383  StackedEnsemble\n",
       "[119 rows x 10 columns]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = h2o.automl.get_leaderboard(aml, extra_columns = \"ALL\")\n",
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31764e9d-ed2a-492a-84dd-00b81f3a7e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_id', 'training_frame', 'response_column', 'validation_frame', 'blending_frame', 'base_models', 'metalearner_algorithm', 'metalearner_nfolds', 'metalearner_fold_assignment', 'metalearner_fold_column', 'metalearner_params', 'metalearner_transform', 'max_runtime_secs', 'weights_column', 'offset_column', 'seed', 'score_training_samples', 'keep_levelone_frame', 'export_checkpoints_dir', 'auc_type'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = aml.leader\n",
    "m.params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44a0c100-81bf-4dab-b86e-d5e8b8ddf2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>timestamp   </th><th>level  </th><th>stage     </th><th>message                                                                                                                                                                                              </th><th>name  </th><th>value  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>18:18:00.855</td><td>INFO   </td><td>Workflow  </td><td>Project: AutoML_1_20230922_181800                                                                                                                                                                    </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>18:18:00.859</td><td>INFO   </td><td>Validation</td><td>5-fold cross-validation will be used.                                                                                                                                                                </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>18:18:00.861</td><td>INFO   </td><td>Validation</td><td>Setting stopping tolerance adaptively based on the training frame: 0.016685216106649997                                                                                                              </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>18:18:00.861</td><td>INFO   </td><td>Validation</td><td>Build control seed: 23372                                                                                                                                                                            </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>18:18:00.865</td><td>INFO   </td><td>DataImport</td><td>training frame: Frame key: AutoML_1_20230922_181800_training_Key_Frame__upload_8bfa346ee01820b397e31d91bab24bb2.hex    cols: 1025    rows: 3592  chunks: 4    size: 403868  checksum: -87072914012808</td><td>      </td><td>       </td></tr>\n",
       "<tr><td>18:18:00.865</td><td>INFO   </td><td>DataImport</td><td>validation frame: NULL                                                                                                                                                                               </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>18:18:00.865</td><td>INFO   </td><td>DataImport</td><td>leaderboard frame: NULL                                                                                                                                                                              </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>18:18:00.866</td><td>INFO   </td><td>DataImport</td><td>blending frame: NULL                                                                                                                                                                                 </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>18:18:00.866</td><td>INFO   </td><td>DataImport</td><td>response column: label                                                                                                                                                                               </td><td>      </td><td>       </td></tr>\n",
       "<tr><td>18:18:00.867</td><td>INFO   </td><td>DataImport</td><td>fold column: null                                                                                                                                                                                    </td><td>      </td><td>       </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[413 rows x 6 columns]</pre>"
      ],
      "text/plain": [
       "timestamp     level    stage       message                                                                                                                                                                                                name    value\n",
       "------------  -------  ----------  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------  -------\n",
       "18:18:00.855  INFO     Workflow    Project: AutoML_1_20230922_181800\n",
       "18:18:00.859  INFO     Validation  5-fold cross-validation will be used.\n",
       "18:18:00.861  INFO     Validation  Setting stopping tolerance adaptively based on the training frame: 0.016685216106649997\n",
       "18:18:00.861  INFO     Validation  Build control seed: 23372\n",
       "18:18:00.865  INFO     DataImport  training frame: Frame key: AutoML_1_20230922_181800_training_Key_Frame__upload_8bfa346ee01820b397e31d91bab24bb2.hex    cols: 1025    rows: 3592  chunks: 4    size: 403868  checksum: -87072914012808\n",
       "18:18:00.865  INFO     DataImport  validation frame: NULL\n",
       "18:18:00.865  INFO     DataImport  leaderboard frame: NULL\n",
       "18:18:00.866  INFO     DataImport  blending frame: NULL\n",
       "18:18:00.866  INFO     DataImport  response column: label\n",
       "18:18:00.867  INFO     DataImport  fold column: null\n",
       "[413 rows x 6 columns]\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get AutoML event log\n",
    "log = aml.event_log\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "144b1c52-2d88-4884-9572-d96a44b29c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'creation_epoch': '1695406681',\n",
       " 'start_epoch': '1695406681',\n",
       " 'start_XGBoost_def_2': '1695406681',\n",
       " 'start_GLM_def_1': '1695406693',\n",
       " 'start_GBM_def_5': '1695406699',\n",
       " 'start_StackedEnsemble_best_of_family_1': '1695406722',\n",
       " 'start_XGBoost_def_1': '1695406723',\n",
       " 'start_DRF_def_1': '1695406727',\n",
       " 'start_GBM_def_2': '1695406741',\n",
       " 'start_GBM_def_3': '1695406765',\n",
       " 'start_GBM_def_4': '1695406790',\n",
       " 'start_StackedEnsemble_best_of_family_2': '1695406812',\n",
       " 'start_StackedEnsemble_all_2': '1695406812',\n",
       " 'start_XGBoost_def_3': '1695406813',\n",
       " 'start_DRF_XRT': '1695406821',\n",
       " 'start_GBM_def_1': '1695406831',\n",
       " 'start_DeepLearning_def_1': '1695406845',\n",
       " 'start_StackedEnsemble_best_of_family_3': '1695406859',\n",
       " 'start_StackedEnsemble_all_3': '1695406860',\n",
       " 'start_XGBoost_grid_1': '1695406860',\n",
       " 'start_GBM_grid_1': '1695407128',\n",
       " 'start_DeepLearning_grid_1': '1695407356',\n",
       " 'start_StackedEnsemble_best_of_family_4': '1695408115',\n",
       " 'start_StackedEnsemble_all_4': '1695408115',\n",
       " 'start_DeepLearning_grid_2': '1695408117',\n",
       " 'start_DeepLearning_grid_3': '1695408267',\n",
       " 'start_StackedEnsemble_best_of_family_5': '1695408420',\n",
       " 'start_StackedEnsemble_all_5': '1695408420',\n",
       " 'start_XGBoost_lr_search': '1695408423',\n",
       " 'start_GBM_lr_annealing': '1695408433',\n",
       " 'start_StackedEnsemble_best_of_family_gbm': '1695408438',\n",
       " 'start_StackedEnsemble_all_gbm': '1695408442',\n",
       " 'start_StackedEnsemble_best_of_family_xglm': '1695408460',\n",
       " 'start_StackedEnsemble_all_xglm': '1695408463',\n",
       " 'start_completion_GBM_grid_1': '1695408477',\n",
       " 'start_completion_XGBoost_grid_1': '1695408479',\n",
       " 'start_StackedEnsemble_best_N': '1695408480',\n",
       " 'stop_epoch': '1695408482',\n",
       " 'duration_secs': '1801'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get training timing info\n",
    "info = aml.training_info\n",
    "info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
